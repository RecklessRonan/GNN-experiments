nohup: ignoring input
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.1778, Train: 47.10%, Valid: 48.08%, Test: 47.22%
Epoch: 25, Loss: 0.4527, Train: 79.95%, Valid: 77.82%, Test: 77.71%
Epoch: 50, Loss: 0.4141, Train: 83.35%, Valid: 80.08%, Test: 79.67%
Epoch: 75, Loss: 0.4261, Train: 82.32%, Valid: 78.73%, Test: 78.41%
Epoch: 100, Loss: 0.3616, Train: 86.24%, Valid: 80.71%, Test: 80.78%
Epoch: 125, Loss: 0.3498, Train: 87.31%, Valid: 81.42%, Test: 81.14%
Epoch: 150, Loss: 0.3436, Train: 86.34%, Valid: 80.42%, Test: 80.44%
Epoch: 175, Loss: 0.2893, Train: 89.41%, Valid: 82.04%, Test: 82.19%
Epoch: 200, Loss: 0.3366, Train: 87.20%, Valid: 80.69%, Test: 80.63%
Epoch: 225, Loss: 0.3146, Train: 87.71%, Valid: 80.87%, Test: 81.02%
Epoch: 250, Loss: 0.2540, Train: 90.14%, Valid: 82.10%, Test: 82.62%
Epoch: 275, Loss: 0.3005, Train: 88.93%, Valid: 80.91%, Test: 81.07%
Epoch: 300, Loss: 0.2360, Train: 91.61%, Valid: 82.50%, Test: 83.31%
Epoch: 325, Loss: 0.3763, Train: 85.94%, Valid: 78.49%, Test: 78.67%
Epoch: 350, Loss: 0.2931, Train: 89.45%, Valid: 80.04%, Test: 80.10%
Epoch: 375, Loss: 0.2577, Train: 91.79%, Valid: 81.07%, Test: 81.20%
Epoch: 400, Loss: 0.2822, Train: 88.55%, Valid: 79.78%, Test: 78.85%
Epoch: 425, Loss: 0.2471, Train: 92.00%, Valid: 81.19%, Test: 81.16%
Epoch: 450, Loss: 0.2159, Train: 93.50%, Valid: 81.68%, Test: 82.05%
Epoch: 475, Loss: 0.2036, Train: 94.11%, Valid: 81.74%, Test: 82.07%
Epoch: 500, Loss: 0.1711, Train: 95.09%, Valid: 81.96%, Test: 82.16%
Epoch: 525, Loss: 0.2677, Train: 90.01%, Valid: 77.97%, Test: 77.66%
Epoch: 550, Loss: 0.2159, Train: 94.18%, Valid: 79.61%, Test: 79.80%
Epoch: 575, Loss: 0.1708, Train: 95.79%, Valid: 80.49%, Test: 81.00%
Epoch: 600, Loss: 0.1469, Train: 96.83%, Valid: 80.43%, Test: 80.96%
Epoch: 625, Loss: 0.3510, Train: 83.47%, Valid: 71.02%, Test: 71.53%
Epoch: 650, Loss: 0.2000, Train: 93.98%, Valid: 75.49%, Test: 75.26%
Epoch: 675, Loss: 0.1340, Train: 97.08%, Valid: 76.40%, Test: 76.93%
Epoch: 700, Loss: 0.0959, Train: 98.24%, Valid: 76.88%, Test: 77.42%
Epoch: 725, Loss: 0.0797, Train: 97.56%, Valid: 75.72%, Test: 76.43%
Epoch: 750, Loss: 0.0652, Train: 99.07%, Valid: 75.42%, Test: 75.84%
Epoch: 775, Loss: 0.0507, Train: 99.43%, Valid: 74.98%, Test: 75.41%
Epoch: 800, Loss: 0.0404, Train: 99.58%, Valid: 74.26%, Test: 74.89%
Epoch: 825, Loss: 0.1424, Train: 95.49%, Valid: 70.14%, Test: 70.37%
Epoch: 850, Loss: 0.0609, Train: 98.39%, Valid: 68.73%, Test: 68.97%
Epoch: 875, Loss: 0.0368, Train: 99.12%, Valid: 67.45%, Test: 68.14%
Epoch: 900, Loss: 0.0198, Train: 99.64%, Valid: 67.70%, Test: 68.59%
Epoch: 925, Loss: 0.0113, Train: 99.81%, Valid: 68.27%, Test: 69.50%
Epoch: 950, Loss: 0.0269, Train: 97.19%, Valid: 67.87%, Test: 68.46%
Epoch: 975, Loss: 0.0168, Train: 99.60%, Valid: 66.89%, Test: 67.81%
Run 01:
Highest Train: 99.87
Highest Valid: 82.91
  Final Train: 91.38
   Final Test: 83.04
All runs:
Highest Train: 99.87, nan
Highest Valid: 82.91, nan
  Final Train: 91.38, nan
   Final Test: 83.04, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.2311, Train: 58.76%, Valid: 58.86%, Test: 58.82%
Epoch: 25, Loss: 0.4480, Train: 80.37%, Valid: 78.89%, Test: 78.51%
Epoch: 50, Loss: 0.4070, Train: 83.65%, Valid: 80.31%, Test: 80.40%
Epoch: 75, Loss: 0.3852, Train: 86.80%, Valid: 81.62%, Test: 81.61%
Epoch: 100, Loss: 0.3542, Train: 87.59%, Valid: 81.84%, Test: 81.79%
Epoch: 125, Loss: 0.3065, Train: 88.93%, Valid: 82.26%, Test: 82.32%
Epoch: 150, Loss: 0.2883, Train: 89.62%, Valid: 82.03%, Test: 82.39%
Epoch: 175, Loss: 0.3313, Train: 85.96%, Valid: 79.83%, Test: 79.95%
Epoch: 200, Loss: 0.2598, Train: 91.09%, Valid: 82.71%, Test: 83.02%
Epoch: 225, Loss: 0.2649, Train: 89.87%, Valid: 82.08%, Test: 82.03%
Epoch: 250, Loss: 0.2777, Train: 88.12%, Valid: 80.12%, Test: 80.35%
Epoch: 275, Loss: 0.2288, Train: 92.47%, Valid: 82.67%, Test: 83.24%
Epoch: 300, Loss: 0.2145, Train: 93.24%, Valid: 82.84%, Test: 83.35%
Epoch: 325, Loss: 0.2364, Train: 90.82%, Valid: 81.84%, Test: 82.34%
Epoch: 350, Loss: 0.1750, Train: 94.71%, Valid: 83.06%, Test: 83.78%
Epoch: 375, Loss: 0.4753, Train: 83.33%, Valid: 75.62%, Test: 74.89%
Epoch: 400, Loss: 0.2476, Train: 91.87%, Valid: 79.54%, Test: 79.91%
Epoch: 425, Loss: 0.2850, Train: 89.77%, Valid: 78.53%, Test: 78.51%
Epoch: 450, Loss: 0.2212, Train: 94.09%, Valid: 80.14%, Test: 80.15%
Epoch: 475, Loss: 0.2162, Train: 95.28%, Valid: 81.36%, Test: 80.98%
Epoch: 500, Loss: 0.1683, Train: 96.37%, Valid: 82.31%, Test: 81.98%
Epoch: 525, Loss: 0.2543, Train: 91.02%, Valid: 78.64%, Test: 78.72%
Epoch: 550, Loss: 0.1743, Train: 95.79%, Valid: 80.65%, Test: 80.83%
Epoch: 575, Loss: 0.2685, Train: 91.84%, Valid: 78.25%, Test: 78.31%
Epoch: 600, Loss: 0.1784, Train: 95.76%, Valid: 79.33%, Test: 79.64%
Epoch: 625, Loss: 0.1473, Train: 97.32%, Valid: 79.99%, Test: 80.08%
Epoch: 650, Loss: 0.4891, Train: 83.68%, Valid: 70.30%, Test: 71.30%
Epoch: 675, Loss: 0.2183, Train: 94.24%, Valid: 75.89%, Test: 76.04%
Epoch: 700, Loss: 0.1691, Train: 96.76%, Valid: 76.46%, Test: 76.99%
Epoch: 725, Loss: 0.1473, Train: 97.82%, Valid: 76.25%, Test: 76.38%
Epoch: 750, Loss: 0.1045, Train: 97.36%, Valid: 75.82%, Test: 76.69%
Epoch: 775, Loss: 0.1032, Train: 98.52%, Valid: 76.45%, Test: 76.97%
Epoch: 800, Loss: 0.0845, Train: 98.63%, Valid: 75.83%, Test: 75.96%
Epoch: 825, Loss: 0.2774, Train: 91.82%, Valid: 70.10%, Test: 69.99%
Epoch: 850, Loss: 0.1165, Train: 97.47%, Valid: 71.96%, Test: 72.01%
Epoch: 875, Loss: 0.0769, Train: 98.33%, Valid: 72.70%, Test: 72.60%
Epoch: 900, Loss: 0.0561, Train: 99.19%, Valid: 72.49%, Test: 72.55%
Epoch: 925, Loss: 0.0437, Train: 99.53%, Valid: 72.39%, Test: 72.09%
Epoch: 950, Loss: 0.0345, Train: 99.67%, Valid: 71.90%, Test: 71.84%
Epoch: 975, Loss: 0.3816, Train: 97.37%, Valid: 70.66%, Test: 70.35%
Run 01:
Highest Train: 99.74
Highest Valid: 83.73
  Final Train: 95.52
   Final Test: 84.05
All runs:
Highest Train: 99.74, nan
Highest Valid: 83.73, nan
  Final Train: 95.52, nan
   Final Test: 84.05, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.2976, Train: 52.45%, Valid: 52.78%, Test: 51.79%
Epoch: 25, Loss: 0.4498, Train: 80.98%, Valid: 79.25%, Test: 78.83%
Epoch: 50, Loss: 0.4101, Train: 84.08%, Valid: 80.78%, Test: 80.60%
Epoch: 75, Loss: 0.3639, Train: 87.10%, Valid: 81.26%, Test: 81.48%
Epoch: 100, Loss: 0.3247, Train: 88.99%, Valid: 81.89%, Test: 82.10%
Epoch: 125, Loss: 0.3004, Train: 88.63%, Valid: 81.19%, Test: 81.73%
Epoch: 150, Loss: 0.2957, Train: 88.62%, Valid: 81.26%, Test: 81.02%
Epoch: 175, Loss: 0.2383, Train: 92.62%, Valid: 83.11%, Test: 83.17%
Epoch: 200, Loss: 0.2363, Train: 92.33%, Valid: 83.28%, Test: 83.20%
Epoch: 225, Loss: 0.2087, Train: 93.94%, Valid: 83.24%, Test: 83.89%
Epoch: 250, Loss: 0.1902, Train: 93.70%, Valid: 82.80%, Test: 83.29%
Epoch: 275, Loss: 0.1856, Train: 95.37%, Valid: 83.50%, Test: 83.89%
Epoch: 300, Loss: 0.2550, Train: 90.86%, Valid: 80.39%, Test: 80.60%
Epoch: 325, Loss: 0.5502, Train: 78.62%, Valid: 71.63%, Test: 71.05%
Epoch: 350, Loss: 0.2767, Train: 90.04%, Valid: 77.50%, Test: 77.86%
Epoch: 375, Loss: 0.2222, Train: 94.40%, Valid: 78.41%, Test: 79.24%
Epoch: 400, Loss: 0.3433, Train: 94.08%, Valid: 77.74%, Test: 77.91%
Epoch: 425, Loss: 0.1857, Train: 96.36%, Valid: 77.41%, Test: 77.99%
Epoch: 450, Loss: 0.1573, Train: 97.67%, Valid: 76.77%, Test: 76.99%
Epoch: 475, Loss: 0.1306, Train: 98.52%, Valid: 75.46%, Test: 75.88%
Epoch: 500, Loss: 0.1663, Train: 97.81%, Valid: 74.36%, Test: 74.56%
Epoch: 525, Loss: 0.0970, Train: 99.04%, Valid: 72.98%, Test: 74.15%
Epoch: 550, Loss: 0.1238, Train: 99.18%, Valid: 72.19%, Test: 72.78%
Epoch: 575, Loss: 0.0618, Train: 99.55%, Valid: 71.36%, Test: 71.53%
Epoch: 600, Loss: 0.0416, Train: 99.67%, Valid: 71.18%, Test: 71.40%
Epoch: 625, Loss: 0.0926, Train: 97.50%, Valid: 67.37%, Test: 67.54%
Epoch: 650, Loss: 0.0436, Train: 99.12%, Valid: 65.52%, Test: 65.66%
Epoch: 675, Loss: 0.0241, Train: 99.50%, Valid: 65.03%, Test: 64.69%
Epoch: 700, Loss: 0.0134, Train: 99.81%, Valid: 65.11%, Test: 64.99%
Epoch: 725, Loss: 0.0085, Train: 99.88%, Valid: 65.84%, Test: 66.05%
Epoch: 750, Loss: 0.0496, Train: 97.29%, Valid: 65.09%, Test: 65.56%
Epoch: 775, Loss: 0.0131, Train: 99.73%, Valid: 64.65%, Test: 64.83%
Epoch: 800, Loss: 0.0087, Train: 99.85%, Valid: 64.62%, Test: 64.84%
Epoch: 825, Loss: 0.0072, Train: 99.88%, Valid: 64.54%, Test: 64.59%
Epoch: 850, Loss: 0.0063, Train: 99.88%, Valid: 64.50%, Test: 64.78%
Epoch: 875, Loss: 0.0044, Train: 99.92%, Valid: 65.33%, Test: 65.48%
Epoch: 900, Loss: 0.0033, Train: 99.95%, Valid: 65.62%, Test: 66.06%
Epoch: 925, Loss: 0.0067, Train: 99.92%, Valid: 64.89%, Test: 65.20%
Epoch: 950, Loss: 0.0038, Train: 99.93%, Valid: 64.74%, Test: 65.30%
Epoch: 975, Loss: 0.0029, Train: 99.95%, Valid: 65.27%, Test: 65.74%
Run 01:
Highest Train: 99.96
Highest Valid: 83.95
  Final Train: 96.18
   Final Test: 83.76
All runs:
Highest Train: 99.96, nan
Highest Valid: 83.95, nan
  Final Train: 96.18, nan
   Final Test: 83.76, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.0956, Train: 53.52%, Valid: 52.98%, Test: 53.95%
Epoch: 25, Loss: 0.4609, Train: 78.51%, Valid: 77.16%, Test: 76.81%
Epoch: 50, Loss: 0.4197, Train: 82.08%, Valid: 79.45%, Test: 78.94%
Epoch: 75, Loss: 0.3871, Train: 84.38%, Valid: 80.27%, Test: 80.00%
Epoch: 100, Loss: 0.3625, Train: 84.33%, Valid: 79.43%, Test: 79.34%
Epoch: 125, Loss: 0.3365, Train: 84.64%, Valid: 79.72%, Test: 79.28%
Epoch: 150, Loss: 0.3057, Train: 87.48%, Valid: 80.80%, Test: 80.98%
Epoch: 175, Loss: 0.2925, Train: 87.90%, Valid: 80.87%, Test: 81.03%
Epoch: 200, Loss: 0.2889, Train: 89.19%, Valid: 81.47%, Test: 81.62%
Epoch: 225, Loss: 0.2548, Train: 91.04%, Valid: 82.51%, Test: 82.57%
Epoch: 250, Loss: 0.2567, Train: 91.65%, Valid: 82.27%, Test: 82.49%
Epoch: 275, Loss: 0.2403, Train: 91.89%, Valid: 82.60%, Test: 82.38%
Epoch: 300, Loss: 0.2648, Train: 90.99%, Valid: 81.07%, Test: 81.90%
Epoch: 325, Loss: 0.2206, Train: 93.37%, Valid: 82.28%, Test: 82.90%
Epoch: 350, Loss: 0.2292, Train: 92.75%, Valid: 81.83%, Test: 81.99%
Epoch: 375, Loss: 0.1863, Train: 94.50%, Valid: 82.41%, Test: 82.26%
Epoch: 400, Loss: 0.2043, Train: 93.97%, Valid: 80.99%, Test: 81.20%
Epoch: 425, Loss: 0.1570, Train: 95.64%, Valid: 82.37%, Test: 82.67%
Epoch: 450, Loss: 0.1943, Train: 93.63%, Valid: 80.15%, Test: 80.23%
Epoch: 475, Loss: 0.1391, Train: 95.33%, Valid: 80.62%, Test: 80.73%
Epoch: 500, Loss: 0.1200, Train: 97.02%, Valid: 80.75%, Test: 81.09%
Epoch: 525, Loss: 0.2179, Train: 92.64%, Valid: 76.07%, Test: 76.80%
Epoch: 550, Loss: 0.1259, Train: 95.93%, Valid: 78.81%, Test: 79.13%
Epoch: 575, Loss: 0.0916, Train: 98.42%, Valid: 80.15%, Test: 80.49%
Epoch: 600, Loss: 0.0966, Train: 98.27%, Valid: 78.47%, Test: 78.65%
Epoch: 625, Loss: 0.0620, Train: 99.04%, Valid: 79.33%, Test: 79.38%
Epoch: 650, Loss: 0.0645, Train: 99.00%, Valid: 77.82%, Test: 78.09%
Epoch: 675, Loss: 0.0482, Train: 97.61%, Valid: 76.22%, Test: 77.14%
Epoch: 700, Loss: 0.0458, Train: 99.39%, Valid: 78.07%, Test: 78.42%
Epoch: 725, Loss: 0.0581, Train: 99.45%, Valid: 77.89%, Test: 78.09%
Epoch: 750, Loss: 0.0307, Train: 99.68%, Valid: 77.36%, Test: 77.86%
Epoch: 775, Loss: 0.0575, Train: 99.15%, Valid: 75.16%, Test: 75.81%
Epoch: 800, Loss: 0.0415, Train: 99.56%, Valid: 74.78%, Test: 75.12%
Epoch: 825, Loss: 0.0260, Train: 99.75%, Valid: 75.44%, Test: 75.77%
Epoch: 850, Loss: 0.0208, Train: 99.73%, Valid: 75.17%, Test: 75.57%
Epoch: 875, Loss: 0.0223, Train: 99.81%, Valid: 74.66%, Test: 75.18%
Epoch: 900, Loss: 0.0153, Train: 99.84%, Valid: 74.43%, Test: 75.05%
Epoch: 925, Loss: 0.0127, Train: 99.87%, Valid: 74.43%, Test: 75.07%
Epoch: 950, Loss: 0.0112, Train: 99.47%, Valid: 73.36%, Test: 74.00%
Epoch: 975, Loss: 0.0509, Train: 99.10%, Valid: 67.31%, Test: 67.45%
Run 01:
Highest Train: 99.88
Highest Valid: 82.75
  Final Train: 94.93
   Final Test: 83.04
All runs:
Highest Train: 99.88, nan
Highest Valid: 82.75, nan
  Final Train: 94.93, nan
   Final Test: 83.04, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.3855, Train: 55.02%, Valid: 54.86%, Test: 56.39%
Epoch: 25, Loss: 0.4633, Train: 79.59%, Valid: 78.30%, Test: 77.87%
Epoch: 50, Loss: 0.4231, Train: 83.17%, Valid: 80.10%, Test: 79.76%
Epoch: 75, Loss: 0.3918, Train: 85.09%, Valid: 81.22%, Test: 80.66%
Epoch: 100, Loss: 0.3672, Train: 85.93%, Valid: 80.25%, Test: 80.74%
Epoch: 125, Loss: 0.3334, Train: 86.14%, Valid: 80.78%, Test: 79.91%
Epoch: 150, Loss: 0.3164, Train: 89.10%, Valid: 81.98%, Test: 82.03%
Epoch: 175, Loss: 0.2941, Train: 89.40%, Valid: 81.69%, Test: 81.97%
Epoch: 200, Loss: 0.2648, Train: 90.79%, Valid: 82.58%, Test: 82.86%
Epoch: 225, Loss: 0.2533, Train: 91.04%, Valid: 82.49%, Test: 82.58%
Epoch: 250, Loss: 0.2641, Train: 91.62%, Valid: 82.92%, Test: 82.75%
Epoch: 275, Loss: 0.2588, Train: 91.43%, Valid: 82.11%, Test: 82.14%
Epoch: 300, Loss: 0.2093, Train: 92.62%, Valid: 82.87%, Test: 82.96%
Epoch: 325, Loss: 0.2187, Train: 93.57%, Valid: 82.61%, Test: 83.39%
Epoch: 350, Loss: 0.1899, Train: 93.84%, Valid: 82.83%, Test: 83.49%
Epoch: 375, Loss: 0.1889, Train: 95.02%, Valid: 82.97%, Test: 83.46%
Epoch: 400, Loss: 0.1838, Train: 93.63%, Valid: 82.29%, Test: 82.18%
Epoch: 425, Loss: 0.1690, Train: 95.28%, Valid: 82.65%, Test: 83.15%
Epoch: 450, Loss: 0.1607, Train: 95.34%, Valid: 82.33%, Test: 82.42%
Epoch: 475, Loss: 0.1391, Train: 96.44%, Valid: 82.92%, Test: 83.20%
Epoch: 500, Loss: 0.1339, Train: 96.85%, Valid: 82.31%, Test: 82.43%
Epoch: 525, Loss: 0.1429, Train: 95.82%, Valid: 80.83%, Test: 81.07%
Epoch: 550, Loss: 0.1030, Train: 97.79%, Valid: 82.10%, Test: 82.65%
Epoch: 575, Loss: 0.1037, Train: 96.83%, Valid: 80.50%, Test: 80.80%
Epoch: 600, Loss: 0.0786, Train: 98.52%, Valid: 81.45%, Test: 81.49%
Epoch: 625, Loss: 0.1067, Train: 97.06%, Valid: 80.08%, Test: 80.56%
Epoch: 650, Loss: 0.0875, Train: 98.23%, Valid: 79.95%, Test: 79.82%
Epoch: 675, Loss: 0.0744, Train: 98.81%, Valid: 79.65%, Test: 79.74%
Epoch: 700, Loss: 0.0571, Train: 99.30%, Valid: 80.38%, Test: 80.41%
Epoch: 725, Loss: 0.0553, Train: 99.20%, Valid: 79.49%, Test: 79.55%
Epoch: 750, Loss: 0.0413, Train: 99.53%, Valid: 79.13%, Test: 79.47%
Epoch: 775, Loss: 0.0359, Train: 99.59%, Valid: 79.48%, Test: 79.79%
Epoch: 800, Loss: 0.0268, Train: 99.72%, Valid: 78.91%, Test: 79.69%
Epoch: 825, Loss: 0.0612, Train: 94.89%, Valid: 75.00%, Test: 76.15%
Epoch: 850, Loss: 0.1052, Train: 97.76%, Valid: 71.32%, Test: 71.94%
Epoch: 875, Loss: 0.0850, Train: 98.47%, Valid: 68.66%, Test: 68.89%
Epoch: 900, Loss: 0.0406, Train: 99.52%, Valid: 71.77%, Test: 71.45%
Epoch: 925, Loss: 0.0267, Train: 99.64%, Valid: 72.67%, Test: 73.15%
Epoch: 950, Loss: 0.0243, Train: 99.62%, Valid: 72.14%, Test: 72.60%
Epoch: 975, Loss: 0.0185, Train: 99.77%, Valid: 71.78%, Test: 72.28%
Run 01:
Highest Train: 99.82
Highest Valid: 83.47
  Final Train: 94.04
   Final Test: 83.14
All runs:
Highest Train: 99.82, nan
Highest Valid: 83.47, nan
  Final Train: 94.04, nan
   Final Test: 83.14, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.9267, Train: 50.53%, Valid: 50.62%, Test: 49.61%
Epoch: 25, Loss: 0.4592, Train: 79.71%, Valid: 77.45%, Test: 77.70%
Epoch: 50, Loss: 0.4242, Train: 83.21%, Valid: 80.21%, Test: 79.92%
Epoch: 75, Loss: 0.3962, Train: 85.01%, Valid: 80.44%, Test: 80.64%
Epoch: 100, Loss: 0.3696, Train: 86.26%, Valid: 80.90%, Test: 81.50%
Epoch: 125, Loss: 0.3575, Train: 87.93%, Valid: 81.67%, Test: 82.27%
Epoch: 150, Loss: 0.3250, Train: 88.54%, Valid: 81.66%, Test: 82.24%
Epoch: 175, Loss: 0.3334, Train: 88.52%, Valid: 81.27%, Test: 81.32%
Epoch: 200, Loss: 0.2886, Train: 90.03%, Valid: 81.69%, Test: 82.10%
Epoch: 225, Loss: 0.2662, Train: 89.96%, Valid: 81.33%, Test: 81.37%
Epoch: 250, Loss: 0.3383, Train: 89.32%, Valid: 81.82%, Test: 82.21%
Epoch: 275, Loss: 0.2498, Train: 90.06%, Valid: 80.76%, Test: 81.15%
Epoch: 300, Loss: 0.2329, Train: 91.52%, Valid: 81.69%, Test: 82.14%
Epoch: 325, Loss: 0.2179, Train: 92.57%, Valid: 82.27%, Test: 82.27%
Epoch: 350, Loss: 0.2164, Train: 92.33%, Valid: 82.41%, Test: 82.42%
Epoch: 375, Loss: 0.2155, Train: 92.12%, Valid: 81.48%, Test: 81.52%
Epoch: 400, Loss: 0.1927, Train: 93.30%, Valid: 81.68%, Test: 81.61%
Epoch: 425, Loss: 0.2059, Train: 93.54%, Valid: 82.44%, Test: 82.29%
Epoch: 450, Loss: 0.1732, Train: 94.37%, Valid: 82.31%, Test: 82.10%
Epoch: 475, Loss: 0.1909, Train: 93.88%, Valid: 81.61%, Test: 81.63%
Epoch: 500, Loss: 0.1703, Train: 94.79%, Valid: 82.24%, Test: 81.97%
Epoch: 525, Loss: 0.1565, Train: 95.67%, Valid: 82.16%, Test: 81.93%
Epoch: 550, Loss: 0.1428, Train: 96.32%, Valid: 82.27%, Test: 82.00%
Epoch: 575, Loss: 0.1315, Train: 96.60%, Valid: 82.30%, Test: 81.80%
Epoch: 600, Loss: 0.6349, Train: 81.57%, Valid: 72.08%, Test: 72.11%
Epoch: 625, Loss: 0.2405, Train: 91.48%, Valid: 76.23%, Test: 76.94%
Epoch: 650, Loss: 0.2023, Train: 94.95%, Valid: 78.88%, Test: 78.77%
Epoch: 675, Loss: 0.1811, Train: 95.04%, Valid: 78.69%, Test: 79.01%
Epoch: 700, Loss: 0.1934, Train: 96.55%, Valid: 79.59%, Test: 79.42%
Epoch: 725, Loss: 0.1533, Train: 96.34%, Valid: 79.36%, Test: 79.61%
Epoch: 750, Loss: 0.3046, Train: 88.59%, Valid: 73.50%, Test: 73.09%
Epoch: 775, Loss: 0.1856, Train: 95.64%, Valid: 76.70%, Test: 76.51%
Epoch: 800, Loss: 0.1654, Train: 96.78%, Valid: 77.37%, Test: 77.60%
Epoch: 825, Loss: 0.1497, Train: 96.99%, Valid: 77.81%, Test: 77.53%
Epoch: 850, Loss: 0.1398, Train: 97.85%, Valid: 78.30%, Test: 78.19%
Epoch: 875, Loss: 0.1147, Train: 98.34%, Valid: 79.36%, Test: 79.62%
Epoch: 900, Loss: 0.0991, Train: 98.22%, Valid: 78.14%, Test: 77.90%
Epoch: 925, Loss: 0.3462, Train: 86.89%, Valid: 69.75%, Test: 69.98%
Epoch: 950, Loss: 0.1975, Train: 94.97%, Valid: 75.82%, Test: 76.13%
Epoch: 975, Loss: 0.1602, Train: 96.75%, Valid: 76.33%, Test: 76.45%
Run 01:
Highest Train: 98.99
Highest Valid: 82.93
  Final Train: 94.84
   Final Test: 82.19
All runs:
Highest Train: 98.99, nan
Highest Valid: 82.93, nan
  Final Train: 94.84, nan
   Final Test: 82.19, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.5274, Train: 54.29%, Valid: 53.53%, Test: 54.20%
Epoch: 25, Loss: 0.4707, Train: 79.78%, Valid: 78.03%, Test: 77.99%
Epoch: 50, Loss: 0.4290, Train: 83.16%, Valid: 80.46%, Test: 80.24%
Epoch: 75, Loss: 0.3944, Train: 84.89%, Valid: 81.01%, Test: 80.76%
Epoch: 100, Loss: 0.3629, Train: 85.52%, Valid: 80.59%, Test: 80.74%
Epoch: 125, Loss: 0.3353, Train: 88.02%, Valid: 81.67%, Test: 82.36%
Epoch: 150, Loss: 0.3088, Train: 88.90%, Valid: 82.28%, Test: 82.38%
Epoch: 175, Loss: 0.2860, Train: 89.42%, Valid: 81.76%, Test: 82.37%
Epoch: 200, Loss: 0.2646, Train: 90.18%, Valid: 82.33%, Test: 82.14%
Epoch: 225, Loss: 0.2702, Train: 90.55%, Valid: 82.22%, Test: 82.61%
Epoch: 250, Loss: 0.2344, Train: 91.58%, Valid: 82.47%, Test: 82.66%
Epoch: 275, Loss: 0.2320, Train: 92.49%, Valid: 82.46%, Test: 82.32%
Epoch: 300, Loss: 0.2419, Train: 92.26%, Valid: 82.08%, Test: 82.39%
Epoch: 325, Loss: 0.2115, Train: 91.49%, Valid: 81.12%, Test: 81.29%
Epoch: 350, Loss: 0.2775, Train: 90.57%, Valid: 79.93%, Test: 80.79%
Epoch: 375, Loss: 0.2127, Train: 93.86%, Valid: 82.65%, Test: 82.79%
Epoch: 400, Loss: 0.1802, Train: 94.57%, Valid: 82.38%, Test: 82.86%
Epoch: 425, Loss: 0.1636, Train: 95.17%, Valid: 82.59%, Test: 83.11%
Epoch: 450, Loss: 0.1956, Train: 94.74%, Valid: 81.79%, Test: 82.37%
Epoch: 475, Loss: 0.1473, Train: 96.02%, Valid: 82.83%, Test: 83.10%
Epoch: 500, Loss: 0.1301, Train: 96.77%, Valid: 82.43%, Test: 82.76%
Epoch: 525, Loss: 0.1560, Train: 96.21%, Valid: 81.37%, Test: 81.30%
Epoch: 550, Loss: 0.1064, Train: 97.59%, Valid: 81.72%, Test: 81.78%
Epoch: 575, Loss: 0.0834, Train: 98.49%, Valid: 81.63%, Test: 82.16%
Epoch: 600, Loss: 0.0903, Train: 98.67%, Valid: 80.93%, Test: 81.47%
Epoch: 625, Loss: 0.0845, Train: 98.58%, Valid: 80.89%, Test: 81.09%
Epoch: 650, Loss: 0.0950, Train: 98.26%, Valid: 78.53%, Test: 78.88%
Epoch: 675, Loss: 0.0610, Train: 99.18%, Valid: 80.14%, Test: 80.94%
Epoch: 700, Loss: 0.1158, Train: 98.47%, Valid: 76.39%, Test: 77.18%
Epoch: 725, Loss: 0.0540, Train: 99.53%, Valid: 78.44%, Test: 79.10%
Epoch: 750, Loss: 0.0960, Train: 98.47%, Valid: 77.58%, Test: 77.48%
Epoch: 775, Loss: 0.0517, Train: 99.50%, Valid: 77.99%, Test: 78.60%
Epoch: 800, Loss: 0.0342, Train: 99.68%, Valid: 78.54%, Test: 79.11%
Epoch: 825, Loss: 0.1606, Train: 96.74%, Valid: 70.97%, Test: 71.17%
Epoch: 850, Loss: 0.0596, Train: 99.19%, Valid: 72.67%, Test: 73.06%
Epoch: 875, Loss: 0.0688, Train: 98.57%, Valid: 69.36%, Test: 69.39%
Epoch: 900, Loss: 0.0585, Train: 99.06%, Valid: 67.65%, Test: 67.72%
Epoch: 925, Loss: 0.0408, Train: 99.51%, Valid: 66.89%, Test: 66.83%
Epoch: 950, Loss: 0.0294, Train: 99.63%, Valid: 66.87%, Test: 66.90%
Epoch: 975, Loss: 0.0231, Train: 99.74%, Valid: 67.02%, Test: 67.12%
Run 01:
Highest Train: 99.81
Highest Valid: 83.06
  Final Train: 94.22
   Final Test: 83.38
All runs:
Highest Train: 99.81, nan
Highest Valid: 83.06, nan
  Final Train: 94.22, nan
   Final Test: 83.38, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.5471, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.4661, Train: 80.95%, Valid: 79.27%, Test: 79.02%
Epoch: 50, Loss: 0.4173, Train: 84.63%, Valid: 80.84%, Test: 80.61%
Epoch: 75, Loss: 0.3776, Train: 87.63%, Valid: 81.30%, Test: 80.91%
Epoch: 100, Loss: 0.3340, Train: 90.36%, Valid: 80.74%, Test: 80.55%
Epoch: 125, Loss: 0.3017, Train: 92.88%, Valid: 80.65%, Test: 80.52%
Epoch: 150, Loss: 0.2733, Train: 93.43%, Valid: 78.65%, Test: 79.02%
Epoch: 175, Loss: 0.2386, Train: 95.32%, Valid: 78.10%, Test: 78.91%
Epoch: 200, Loss: 0.2383, Train: 95.49%, Valid: 75.87%, Test: 76.35%
Epoch: 225, Loss: 0.1913, Train: 96.82%, Valid: 74.01%, Test: 74.80%
Epoch: 250, Loss: 0.1699, Train: 97.37%, Valid: 72.74%, Test: 73.25%
Epoch: 275, Loss: 0.1358, Train: 96.93%, Valid: 69.28%, Test: 69.16%
Epoch: 300, Loss: 0.1069, Train: 98.63%, Valid: 68.75%, Test: 68.38%
Epoch: 325, Loss: 0.0796, Train: 98.69%, Valid: 66.96%, Test: 66.85%
Epoch: 350, Loss: 0.0620, Train: 98.98%, Valid: 66.48%, Test: 66.31%
Epoch: 375, Loss: 0.0425, Train: 99.45%, Valid: 66.09%, Test: 66.28%
Epoch: 400, Loss: 0.0323, Train: 99.66%, Valid: 67.23%, Test: 66.98%
Epoch: 425, Loss: 0.0240, Train: 99.77%, Valid: 67.08%, Test: 67.10%
Epoch: 450, Loss: 0.1049, Train: 99.15%, Valid: 68.21%, Test: 68.05%
Epoch: 475, Loss: 0.0251, Train: 99.77%, Valid: 66.67%, Test: 67.09%
Epoch: 500, Loss: 0.0153, Train: 99.85%, Valid: 67.60%, Test: 67.77%
Epoch: 525, Loss: 0.0110, Train: 99.89%, Valid: 68.07%, Test: 68.65%
Epoch: 550, Loss: 0.0098, Train: 99.92%, Valid: 68.23%, Test: 68.84%
Epoch: 575, Loss: 0.0072, Train: 99.94%, Valid: 68.22%, Test: 69.02%
Epoch: 600, Loss: 0.0067, Train: 99.95%, Valid: 68.88%, Test: 69.52%
Epoch: 625, Loss: 0.0050, Train: 99.96%, Valid: 69.52%, Test: 70.21%
Epoch: 650, Loss: 0.0049, Train: 99.97%, Valid: 69.58%, Test: 70.30%
Epoch: 675, Loss: 0.0046, Train: 99.97%, Valid: 69.20%, Test: 69.63%
Epoch: 700, Loss: 0.0077, Train: 99.94%, Valid: 69.29%, Test: 69.95%
Epoch: 725, Loss: 0.0058, Train: 99.95%, Valid: 69.70%, Test: 69.73%
Epoch: 750, Loss: 0.0044, Train: 99.97%, Valid: 69.72%, Test: 70.43%
Epoch: 775, Loss: 0.0033, Train: 99.98%, Valid: 70.25%, Test: 70.71%
Epoch: 800, Loss: 0.0035, Train: 99.98%, Valid: 70.42%, Test: 71.08%
Epoch: 825, Loss: 0.0027, Train: 99.99%, Valid: 70.27%, Test: 70.92%
Epoch: 850, Loss: 0.0027, Train: 99.99%, Valid: 70.71%, Test: 71.32%
Epoch: 875, Loss: 0.0018, Train: 99.99%, Valid: 70.62%, Test: 71.16%
Epoch: 900, Loss: 0.0022, Train: 99.99%, Valid: 70.87%, Test: 71.53%
Epoch: 925, Loss: 0.0019, Train: 99.99%, Valid: 70.70%, Test: 71.40%
Epoch: 950, Loss: 0.0019, Train: 99.99%, Valid: 71.13%, Test: 71.65%
Epoch: 975, Loss: 0.0016, Train: 100.00%, Valid: 71.09%, Test: 71.52%
Run 01:
Highest Train: 100.00
Highest Valid: 81.43
  Final Train: 89.35
   Final Test: 80.86
All runs:
Highest Train: 100.00, nan
Highest Valid: 81.43, nan
  Final Train: 89.35, nan
   Final Test: 80.86, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.8602, Train: 52.64%, Valid: 52.28%, Test: 53.37%
Epoch: 25, Loss: 0.4682, Train: 78.96%, Valid: 77.63%, Test: 76.95%
Epoch: 50, Loss: 0.4265, Train: 82.74%, Valid: 80.04%, Test: 79.59%
Epoch: 75, Loss: 0.3888, Train: 85.30%, Valid: 80.72%, Test: 80.67%
Epoch: 100, Loss: 0.3542, Train: 87.34%, Valid: 81.87%, Test: 81.56%
Epoch: 125, Loss: 0.3190, Train: 88.94%, Valid: 82.09%, Test: 81.96%
Epoch: 150, Loss: 0.3062, Train: 89.35%, Valid: 81.53%, Test: 81.95%
Epoch: 175, Loss: 0.2783, Train: 91.77%, Valid: 82.53%, Test: 82.99%
Epoch: 200, Loss: 0.2509, Train: 92.73%, Valid: 82.41%, Test: 82.49%
Epoch: 225, Loss: 0.2331, Train: 93.68%, Valid: 82.39%, Test: 82.45%
Epoch: 250, Loss: 0.2794, Train: 91.42%, Valid: 79.87%, Test: 80.18%
Epoch: 275, Loss: 0.2263, Train: 93.76%, Valid: 81.06%, Test: 81.49%
Epoch: 300, Loss: 0.1930, Train: 95.39%, Valid: 81.23%, Test: 81.90%
Epoch: 325, Loss: 0.2350, Train: 92.60%, Valid: 76.75%, Test: 77.44%
Epoch: 350, Loss: 0.1778, Train: 95.84%, Valid: 78.43%, Test: 78.97%
Epoch: 375, Loss: 0.1817, Train: 95.83%, Valid: 76.87%, Test: 77.53%
Epoch: 400, Loss: 0.2451, Train: 93.53%, Valid: 71.70%, Test: 72.24%
Epoch: 425, Loss: 0.1339, Train: 97.63%, Valid: 72.95%, Test: 73.55%
Epoch: 450, Loss: 0.1114, Train: 97.52%, Valid: 71.94%, Test: 72.51%
Epoch: 475, Loss: 0.0831, Train: 98.99%, Valid: 71.47%, Test: 71.89%
Epoch: 500, Loss: 0.0634, Train: 98.10%, Valid: 69.20%, Test: 69.63%
Epoch: 525, Loss: 0.0546, Train: 99.35%, Valid: 70.13%, Test: 70.99%
Epoch: 550, Loss: 0.0364, Train: 99.10%, Valid: 69.71%, Test: 70.50%
Epoch: 575, Loss: 0.0411, Train: 99.47%, Valid: 68.78%, Test: 69.36%
Epoch: 600, Loss: 0.0347, Train: 99.57%, Valid: 69.40%, Test: 69.99%
Epoch: 625, Loss: 0.0262, Train: 99.56%, Valid: 68.35%, Test: 69.11%
Epoch: 650, Loss: 0.0298, Train: 99.42%, Valid: 67.50%, Test: 67.87%
Epoch: 675, Loss: 0.0255, Train: 99.67%, Valid: 67.82%, Test: 68.41%
Epoch: 700, Loss: 0.0167, Train: 99.65%, Valid: 67.62%, Test: 68.07%
Epoch: 725, Loss: 0.0262, Train: 99.63%, Valid: 65.87%, Test: 66.35%
Epoch: 750, Loss: 0.0174, Train: 99.76%, Valid: 66.52%, Test: 66.67%
Epoch: 775, Loss: 0.0140, Train: 99.81%, Valid: 66.66%, Test: 66.82%
Epoch: 800, Loss: 0.0144, Train: 99.83%, Valid: 67.00%, Test: 67.12%
Epoch: 825, Loss: 0.0110, Train: 99.86%, Valid: 66.94%, Test: 67.25%
Epoch: 850, Loss: 0.0149, Train: 99.87%, Valid: 66.59%, Test: 66.87%
Epoch: 875, Loss: 0.0096, Train: 99.88%, Valid: 66.42%, Test: 66.54%
Epoch: 900, Loss: 0.0104, Train: 99.74%, Valid: 65.73%, Test: 65.95%
Epoch: 925, Loss: 0.0077, Train: 99.91%, Valid: 66.45%, Test: 66.48%
Epoch: 950, Loss: 0.0091, Train: 99.93%, Valid: 66.63%, Test: 66.66%
Epoch: 975, Loss: 0.0062, Train: 99.93%, Valid: 66.10%, Test: 66.79%
Run 01:
Highest Train: 99.93
Highest Valid: 82.96
  Final Train: 92.14
   Final Test: 83.20
All runs:
Highest Train: 99.93, nan
Highest Valid: 82.96, nan
  Final Train: 92.14, nan
   Final Test: 83.20, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.9891, Train: 48.50%, Valid: 49.20%, Test: 47.84%
Epoch: 25, Loss: 0.4423, Train: 81.46%, Valid: 79.16%, Test: 79.16%
Epoch: 50, Loss: 0.4031, Train: 84.77%, Valid: 81.15%, Test: 80.83%
Epoch: 75, Loss: 0.3823, Train: 84.01%, Valid: 79.38%, Test: 78.40%
Epoch: 100, Loss: 0.3383, Train: 88.25%, Valid: 81.95%, Test: 81.70%
Epoch: 125, Loss: 0.3122, Train: 89.22%, Valid: 82.36%, Test: 82.29%
Epoch: 150, Loss: 0.3831, Train: 85.44%, Valid: 80.71%, Test: 79.88%
Epoch: 175, Loss: 0.2953, Train: 85.64%, Valid: 78.72%, Test: 78.87%
Epoch: 200, Loss: 0.2930, Train: 89.49%, Valid: 82.18%, Test: 82.25%
Epoch: 225, Loss: 0.2513, Train: 91.49%, Valid: 82.85%, Test: 82.97%
Epoch: 250, Loss: 0.3530, Train: 86.57%, Valid: 80.11%, Test: 79.41%
Epoch: 275, Loss: 0.2513, Train: 90.96%, Valid: 82.33%, Test: 82.38%
Epoch: 300, Loss: 0.3042, Train: 88.72%, Valid: 81.15%, Test: 80.45%
Epoch: 325, Loss: 0.2367, Train: 92.08%, Valid: 83.03%, Test: 82.89%
Epoch: 350, Loss: 0.3771, Train: 84.36%, Valid: 77.67%, Test: 77.40%
Epoch: 375, Loss: 0.2731, Train: 90.42%, Valid: 81.28%, Test: 80.89%
Epoch: 400, Loss: 0.2394, Train: 92.64%, Valid: 81.88%, Test: 82.24%
Epoch: 425, Loss: 0.2123, Train: 93.44%, Valid: 81.80%, Test: 81.75%
Epoch: 450, Loss: 0.2122, Train: 93.63%, Valid: 82.60%, Test: 82.33%
Epoch: 475, Loss: 0.1806, Train: 94.77%, Valid: 82.91%, Test: 83.04%
Epoch: 500, Loss: 0.2155, Train: 93.25%, Valid: 82.03%, Test: 82.08%
Epoch: 525, Loss: 0.1873, Train: 94.99%, Valid: 82.49%, Test: 82.50%
Epoch: 550, Loss: 0.1613, Train: 96.04%, Valid: 82.99%, Test: 82.83%
Epoch: 575, Loss: 0.4225, Train: 84.66%, Valid: 77.30%, Test: 76.38%
Epoch: 600, Loss: 0.2372, Train: 92.03%, Valid: 80.47%, Test: 80.61%
Epoch: 625, Loss: 0.1973, Train: 94.63%, Valid: 81.57%, Test: 81.56%
Epoch: 650, Loss: 0.2858, Train: 86.81%, Valid: 76.14%, Test: 75.26%
Epoch: 675, Loss: 0.1836, Train: 94.63%, Valid: 81.29%, Test: 81.17%
Epoch: 700, Loss: 0.1588, Train: 96.23%, Valid: 81.62%, Test: 81.49%
Epoch: 725, Loss: 0.1365, Train: 97.07%, Valid: 82.20%, Test: 81.66%
Epoch: 750, Loss: 0.1908, Train: 94.39%, Valid: 79.79%, Test: 79.75%
Epoch: 775, Loss: 0.1577, Train: 96.58%, Valid: 80.58%, Test: 80.75%
Epoch: 800, Loss: 0.1318, Train: 97.74%, Valid: 80.87%, Test: 80.97%
Epoch: 825, Loss: 0.1303, Train: 97.60%, Valid: 81.62%, Test: 81.28%
Epoch: 850, Loss: 0.5841, Train: 87.02%, Valid: 75.52%, Test: 74.52%
Epoch: 875, Loss: 0.1648, Train: 95.51%, Valid: 78.53%, Test: 78.92%
Epoch: 900, Loss: 0.1371, Train: 97.32%, Valid: 78.87%, Test: 78.84%
Epoch: 925, Loss: 0.1214, Train: 98.00%, Valid: 78.79%, Test: 78.71%
Epoch: 950, Loss: 0.1073, Train: 98.48%, Valid: 78.54%, Test: 78.55%
Epoch: 975, Loss: 0.0939, Train: 98.80%, Valid: 78.31%, Test: 78.35%
Run 01:
Highest Train: 98.92
Highest Valid: 83.24
  Final Train: 96.32
   Final Test: 82.83
All runs:
Highest Train: 98.92, nan
Highest Valid: 83.24, nan
  Final Train: 96.32, nan
   Final Test: 82.83, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.9329, Train: 54.15%, Valid: 54.52%, Test: 53.17%
Epoch: 25, Loss: 0.4592, Train: 79.56%, Valid: 77.86%, Test: 77.70%
Epoch: 50, Loss: 0.4131, Train: 84.37%, Valid: 80.94%, Test: 80.65%
Epoch: 75, Loss: 0.3767, Train: 86.29%, Valid: 81.15%, Test: 81.02%
Epoch: 100, Loss: 0.3433, Train: 88.46%, Valid: 82.11%, Test: 82.05%
Epoch: 125, Loss: 0.3385, Train: 87.50%, Valid: 80.69%, Test: 81.42%
Epoch: 150, Loss: 0.2883, Train: 91.12%, Valid: 82.72%, Test: 82.91%
Epoch: 175, Loss: 0.3167, Train: 88.46%, Valid: 81.16%, Test: 81.36%
Epoch: 200, Loss: 0.2672, Train: 91.38%, Valid: 82.71%, Test: 82.70%
Epoch: 225, Loss: 0.3371, Train: 87.28%, Valid: 80.63%, Test: 80.03%
Epoch: 250, Loss: 0.2517, Train: 91.41%, Valid: 82.45%, Test: 82.47%
Epoch: 275, Loss: 0.2218, Train: 93.20%, Valid: 82.73%, Test: 82.57%
Epoch: 300, Loss: 0.4873, Train: 85.66%, Valid: 79.59%, Test: 79.27%
Epoch: 325, Loss: 0.2449, Train: 91.43%, Valid: 81.19%, Test: 81.88%
Epoch: 350, Loss: 0.2025, Train: 93.94%, Valid: 82.43%, Test: 82.30%
Epoch: 375, Loss: 0.2283, Train: 92.09%, Valid: 81.76%, Test: 81.56%
Epoch: 400, Loss: 0.1851, Train: 94.40%, Valid: 82.55%, Test: 82.17%
Epoch: 425, Loss: 0.1659, Train: 95.45%, Valid: 82.42%, Test: 82.09%
Epoch: 450, Loss: 0.2791, Train: 89.46%, Valid: 79.93%, Test: 80.33%
Epoch: 475, Loss: 0.1866, Train: 93.75%, Valid: 82.34%, Test: 81.84%
Epoch: 500, Loss: 0.1647, Train: 95.38%, Valid: 82.17%, Test: 81.84%
Epoch: 525, Loss: 0.1493, Train: 95.94%, Valid: 82.08%, Test: 81.79%
Epoch: 550, Loss: 0.2383, Train: 91.06%, Valid: 79.98%, Test: 80.43%
Epoch: 575, Loss: 0.1695, Train: 94.96%, Valid: 81.62%, Test: 81.74%
Epoch: 600, Loss: 0.1495, Train: 96.01%, Valid: 82.05%, Test: 81.57%
Epoch: 625, Loss: 0.2949, Train: 87.63%, Valid: 77.62%, Test: 78.24%
Epoch: 650, Loss: 0.1844, Train: 94.33%, Valid: 81.23%, Test: 81.61%
Epoch: 675, Loss: 0.1558, Train: 95.88%, Valid: 81.48%, Test: 81.42%
Epoch: 700, Loss: 0.1405, Train: 96.57%, Valid: 81.71%, Test: 81.23%
Epoch: 725, Loss: 0.2922, Train: 89.70%, Valid: 78.66%, Test: 78.85%
Epoch: 750, Loss: 0.1812, Train: 94.39%, Valid: 81.12%, Test: 81.36%
Epoch: 775, Loss: 0.1544, Train: 95.96%, Valid: 81.30%, Test: 81.51%
Epoch: 800, Loss: 0.1387, Train: 96.64%, Valid: 81.49%, Test: 81.27%
Epoch: 825, Loss: 0.1271, Train: 97.08%, Valid: 81.53%, Test: 81.03%
Epoch: 850, Loss: 0.3989, Train: 82.93%, Valid: 75.11%, Test: 75.12%
Epoch: 875, Loss: 0.1986, Train: 93.19%, Valid: 80.25%, Test: 81.17%
Epoch: 900, Loss: 0.1609, Train: 95.55%, Valid: 80.86%, Test: 81.55%
Epoch: 925, Loss: 0.7182, Train: 83.88%, Valid: 75.52%, Test: 75.30%
Epoch: 950, Loss: 0.2192, Train: 92.43%, Valid: 80.54%, Test: 80.63%
Epoch: 975, Loss: 0.1880, Train: 94.39%, Valid: 80.69%, Test: 81.22%
Run 01:
Highest Train: 97.15
Highest Valid: 82.98
  Final Train: 90.90
   Final Test: 82.91
All runs:
Highest Train: 97.15, nan
Highest Valid: 82.98, nan
  Final Train: 90.90, nan
   Final Test: 82.91, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.4403, Train: 55.36%, Valid: 55.62%, Test: 55.97%
Epoch: 25, Loss: 0.4492, Train: 80.49%, Valid: 78.80%, Test: 78.31%
Epoch: 50, Loss: 0.4024, Train: 84.54%, Valid: 81.10%, Test: 80.75%
Epoch: 75, Loss: 0.3706, Train: 86.02%, Valid: 80.89%, Test: 80.87%
Epoch: 100, Loss: 0.3381, Train: 87.25%, Valid: 81.56%, Test: 81.66%
Epoch: 125, Loss: 0.2997, Train: 88.80%, Valid: 82.00%, Test: 82.36%
Epoch: 150, Loss: 0.3366, Train: 87.06%, Valid: 80.99%, Test: 81.15%
Epoch: 175, Loss: 0.2674, Train: 90.46%, Valid: 82.79%, Test: 83.04%
Epoch: 200, Loss: 0.3447, Train: 87.33%, Valid: 80.56%, Test: 80.94%
Epoch: 225, Loss: 0.2508, Train: 90.90%, Valid: 82.60%, Test: 83.06%
Epoch: 250, Loss: 0.5118, Train: 82.49%, Valid: 77.78%, Test: 77.09%
Epoch: 275, Loss: 0.2818, Train: 88.66%, Valid: 81.41%, Test: 81.39%
Epoch: 300, Loss: 0.2907, Train: 88.75%, Valid: 80.71%, Test: 80.62%
Epoch: 325, Loss: 0.2442, Train: 91.13%, Valid: 82.12%, Test: 82.26%
Epoch: 350, Loss: 0.2116, Train: 92.76%, Valid: 82.83%, Test: 82.80%
Epoch: 375, Loss: 0.2169, Train: 92.25%, Valid: 82.50%, Test: 82.75%
Epoch: 400, Loss: 0.1837, Train: 93.99%, Valid: 82.92%, Test: 82.90%
Epoch: 425, Loss: 0.2060, Train: 82.08%, Valid: 73.52%, Test: 73.86%
Epoch: 450, Loss: 0.3041, Train: 87.26%, Valid: 78.53%, Test: 78.54%
Epoch: 475, Loss: 0.2326, Train: 91.46%, Valid: 81.25%, Test: 81.39%
Epoch: 500, Loss: 0.3484, Train: 84.38%, Valid: 77.02%, Test: 77.09%
Epoch: 525, Loss: 0.2522, Train: 91.02%, Valid: 80.77%, Test: 80.69%
Epoch: 550, Loss: 0.2251, Train: 92.66%, Valid: 81.40%, Test: 81.56%
Epoch: 575, Loss: 0.2058, Train: 93.68%, Valid: 81.75%, Test: 81.95%
Epoch: 600, Loss: 0.2633, Train: 90.79%, Valid: 81.08%, Test: 81.25%
Epoch: 625, Loss: 0.2092, Train: 93.11%, Valid: 81.51%, Test: 81.42%
Epoch: 650, Loss: 0.1918, Train: 94.22%, Valid: 81.80%, Test: 82.11%
Epoch: 675, Loss: 0.1751, Train: 95.19%, Valid: 82.20%, Test: 82.43%
Epoch: 700, Loss: 0.1568, Train: 95.88%, Valid: 82.52%, Test: 82.70%
Epoch: 725, Loss: 0.4202, Train: 86.78%, Valid: 78.08%, Test: 77.93%
Epoch: 750, Loss: 0.2029, Train: 92.78%, Valid: 81.43%, Test: 81.31%
Epoch: 775, Loss: 0.1739, Train: 94.88%, Valid: 81.66%, Test: 82.04%
Epoch: 800, Loss: 0.1547, Train: 95.72%, Valid: 82.11%, Test: 82.61%
Epoch: 825, Loss: 0.1349, Train: 96.48%, Valid: 82.43%, Test: 82.66%
Epoch: 850, Loss: 0.6165, Train: 82.44%, Valid: 74.93%, Test: 74.99%
Epoch: 875, Loss: 0.2459, Train: 91.04%, Valid: 79.32%, Test: 79.71%
Epoch: 900, Loss: 0.1988, Train: 94.16%, Valid: 80.51%, Test: 80.86%
Epoch: 925, Loss: 0.1810, Train: 95.38%, Valid: 80.75%, Test: 81.18%
Epoch: 950, Loss: 0.1652, Train: 96.27%, Valid: 81.01%, Test: 81.06%
Epoch: 975, Loss: 0.1450, Train: 97.09%, Valid: 80.57%, Test: 80.63%
Run 01:
Highest Train: 97.74
Highest Valid: 83.25
  Final Train: 94.40
   Final Test: 83.08
All runs:
Highest Train: 97.74, nan
Highest Valid: 83.25, nan
  Final Train: 94.40, nan
   Final Test: 83.08, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.2592, Train: 57.39%, Valid: 57.20%, Test: 56.49%
Epoch: 25, Loss: 0.4575, Train: 80.52%, Valid: 78.54%, Test: 78.42%
Epoch: 50, Loss: 0.4185, Train: 83.83%, Valid: 80.73%, Test: 80.40%
Epoch: 75, Loss: 0.3864, Train: 85.52%, Valid: 80.99%, Test: 81.10%
Epoch: 100, Loss: 0.3519, Train: 87.18%, Valid: 81.18%, Test: 81.22%
Epoch: 125, Loss: 0.3318, Train: 88.19%, Valid: 81.88%, Test: 82.12%
Epoch: 150, Loss: 0.3083, Train: 88.64%, Valid: 82.04%, Test: 81.66%
Epoch: 175, Loss: 0.2891, Train: 90.51%, Valid: 82.56%, Test: 82.95%
Epoch: 200, Loss: 0.2885, Train: 88.52%, Valid: 80.75%, Test: 81.64%
Epoch: 225, Loss: 0.2744, Train: 90.75%, Valid: 83.27%, Test: 83.01%
Epoch: 250, Loss: 0.2479, Train: 91.24%, Valid: 82.24%, Test: 82.26%
Epoch: 275, Loss: 0.2310, Train: 92.02%, Valid: 82.90%, Test: 82.95%
Epoch: 300, Loss: 0.2148, Train: 92.42%, Valid: 82.49%, Test: 82.63%
Epoch: 325, Loss: 0.2173, Train: 93.15%, Valid: 83.12%, Test: 83.40%
Epoch: 350, Loss: 0.1982, Train: 93.64%, Valid: 82.85%, Test: 82.94%
Epoch: 375, Loss: 0.2476, Train: 93.50%, Valid: 83.08%, Test: 83.31%
Epoch: 400, Loss: 0.1936, Train: 91.95%, Valid: 81.78%, Test: 81.98%
Epoch: 425, Loss: 0.1862, Train: 94.38%, Valid: 82.55%, Test: 82.66%
Epoch: 450, Loss: 0.1649, Train: 95.55%, Valid: 83.12%, Test: 83.16%
Epoch: 475, Loss: 0.1911, Train: 93.73%, Valid: 81.56%, Test: 81.58%
Epoch: 500, Loss: 0.1536, Train: 95.84%, Valid: 82.96%, Test: 83.06%
Epoch: 525, Loss: 0.1499, Train: 95.26%, Valid: 82.67%, Test: 82.44%
Epoch: 550, Loss: 0.1550, Train: 95.25%, Valid: 82.19%, Test: 82.41%
Epoch: 575, Loss: 0.1285, Train: 96.56%, Valid: 82.77%, Test: 82.82%
Epoch: 600, Loss: 0.1198, Train: 97.36%, Valid: 83.39%, Test: 83.28%
Epoch: 625, Loss: 0.0973, Train: 97.17%, Valid: 82.76%, Test: 82.55%
Epoch: 650, Loss: 0.1740, Train: 95.85%, Valid: 81.92%, Test: 82.43%
Epoch: 675, Loss: 0.1065, Train: 97.48%, Valid: 82.82%, Test: 83.00%
Epoch: 700, Loss: 0.0932, Train: 98.31%, Valid: 82.90%, Test: 83.15%
Epoch: 725, Loss: 0.0904, Train: 97.99%, Valid: 82.12%, Test: 82.27%
Epoch: 750, Loss: 0.0852, Train: 98.12%, Valid: 81.88%, Test: 82.29%
Epoch: 775, Loss: 0.2733, Train: 90.47%, Valid: 76.87%, Test: 77.36%
Epoch: 800, Loss: 0.0980, Train: 97.83%, Valid: 81.91%, Test: 82.48%
Epoch: 825, Loss: 0.0839, Train: 98.57%, Valid: 82.19%, Test: 82.38%
Epoch: 850, Loss: 0.0614, Train: 99.03%, Valid: 81.93%, Test: 81.66%
Epoch: 875, Loss: 0.1105, Train: 97.72%, Valid: 79.76%, Test: 80.02%
Epoch: 900, Loss: 0.0660, Train: 99.01%, Valid: 81.95%, Test: 82.22%
Epoch: 925, Loss: 0.0557, Train: 99.44%, Valid: 81.46%, Test: 81.75%
Epoch: 950, Loss: 0.0389, Train: 99.62%, Valid: 81.32%, Test: 82.15%
Epoch: 975, Loss: 0.0496, Train: 99.56%, Valid: 81.07%, Test: 81.56%
Run 01:
Highest Train: 99.65
Highest Valid: 83.62
  Final Train: 97.07
   Final Test: 83.31
All runs:
Highest Train: 99.65, nan
Highest Valid: 83.62, nan
  Final Train: 97.07, nan
   Final Test: 83.31, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.8141, Train: 52.12%, Valid: 52.50%, Test: 51.03%
Epoch: 25, Loss: 0.4521, Train: 80.25%, Valid: 78.57%, Test: 78.19%
Epoch: 50, Loss: 0.4135, Train: 83.91%, Valid: 80.51%, Test: 80.54%
Epoch: 75, Loss: 0.3840, Train: 85.97%, Valid: 81.46%, Test: 81.26%
Epoch: 100, Loss: 0.3563, Train: 86.83%, Valid: 80.99%, Test: 81.09%
Epoch: 125, Loss: 0.3257, Train: 88.17%, Valid: 81.79%, Test: 81.56%
Epoch: 150, Loss: 0.3141, Train: 89.30%, Valid: 82.01%, Test: 82.18%
Epoch: 175, Loss: 0.2846, Train: 89.49%, Valid: 81.60%, Test: 81.87%
Epoch: 200, Loss: 0.2741, Train: 90.24%, Valid: 82.45%, Test: 82.25%
Epoch: 225, Loss: 0.2591, Train: 90.65%, Valid: 82.38%, Test: 82.41%
Epoch: 250, Loss: 0.2548, Train: 89.08%, Valid: 81.55%, Test: 81.23%
Epoch: 275, Loss: 0.2353, Train: 92.16%, Valid: 82.78%, Test: 82.78%
Epoch: 300, Loss: 0.2283, Train: 92.73%, Valid: 82.77%, Test: 82.77%
Epoch: 325, Loss: 0.2396, Train: 92.03%, Valid: 82.09%, Test: 82.02%
Epoch: 350, Loss: 0.2222, Train: 90.29%, Valid: 81.02%, Test: 80.76%
Epoch: 375, Loss: 0.2172, Train: 93.13%, Valid: 82.57%, Test: 82.96%
Epoch: 400, Loss: 0.2046, Train: 93.42%, Valid: 82.43%, Test: 82.86%
Epoch: 425, Loss: 0.1999, Train: 92.45%, Valid: 81.93%, Test: 82.19%
Epoch: 450, Loss: 0.1997, Train: 93.51%, Valid: 82.37%, Test: 82.08%
Epoch: 475, Loss: 0.1895, Train: 93.71%, Valid: 82.62%, Test: 82.21%
Epoch: 500, Loss: 0.1871, Train: 93.37%, Valid: 81.98%, Test: 82.08%
Epoch: 525, Loss: 0.1886, Train: 94.09%, Valid: 82.36%, Test: 81.91%
Epoch: 550, Loss: 0.2049, Train: 94.35%, Valid: 82.34%, Test: 82.14%
Epoch: 575, Loss: 0.1626, Train: 94.53%, Valid: 82.35%, Test: 82.29%
Epoch: 600, Loss: 0.1625, Train: 94.95%, Valid: 82.60%, Test: 82.09%
Epoch: 625, Loss: 0.1810, Train: 94.89%, Valid: 82.43%, Test: 82.17%
Epoch: 650, Loss: 0.1608, Train: 95.21%, Valid: 82.04%, Test: 81.40%
Epoch: 675, Loss: 0.1523, Train: 94.67%, Valid: 81.72%, Test: 81.65%
Epoch: 700, Loss: 0.1579, Train: 94.65%, Valid: 82.09%, Test: 81.64%
Epoch: 725, Loss: 0.1522, Train: 95.51%, Valid: 82.48%, Test: 82.24%
Epoch: 750, Loss: 0.1454, Train: 94.26%, Valid: 81.61%, Test: 81.54%
Epoch: 775, Loss: 0.1561, Train: 95.46%, Valid: 82.72%, Test: 82.34%
Epoch: 800, Loss: 0.1393, Train: 95.80%, Valid: 82.45%, Test: 82.16%
Epoch: 825, Loss: 0.1726, Train: 95.79%, Valid: 82.50%, Test: 82.38%
Epoch: 850, Loss: 0.1431, Train: 95.99%, Valid: 82.16%, Test: 81.60%
Epoch: 875, Loss: 0.1308, Train: 96.29%, Valid: 81.90%, Test: 81.37%
Epoch: 900, Loss: 0.1433, Train: 96.48%, Valid: 82.33%, Test: 81.83%
Epoch: 925, Loss: 0.1314, Train: 95.76%, Valid: 82.12%, Test: 81.74%
Epoch: 950, Loss: 0.1409, Train: 96.17%, Valid: 81.72%, Test: 81.40%
Epoch: 975, Loss: 0.1267, Train: 96.18%, Valid: 81.45%, Test: 81.56%
Run 01:
Highest Train: 96.82
Highest Valid: 83.17
  Final Train: 95.33
   Final Test: 82.83
All runs:
Highest Train: 96.82, nan
Highest Valid: 83.17, nan
  Final Train: 95.33, nan
   Final Test: 82.83, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.1430, Train: 58.24%, Valid: 58.23%, Test: 57.90%
Epoch: 25, Loss: 0.4570, Train: 79.94%, Valid: 78.11%, Test: 77.93%
Epoch: 50, Loss: 0.4137, Train: 83.64%, Valid: 80.36%, Test: 80.14%
Epoch: 75, Loss: 0.3866, Train: 84.95%, Valid: 80.90%, Test: 80.44%
Epoch: 100, Loss: 0.3433, Train: 87.50%, Valid: 81.82%, Test: 82.04%
Epoch: 125, Loss: 0.3157, Train: 87.49%, Valid: 81.37%, Test: 81.70%
Epoch: 150, Loss: 0.3003, Train: 88.34%, Valid: 81.89%, Test: 81.91%
Epoch: 175, Loss: 0.2911, Train: 88.67%, Valid: 81.71%, Test: 81.72%
Epoch: 200, Loss: 0.2752, Train: 90.43%, Valid: 82.63%, Test: 82.69%
Epoch: 225, Loss: 0.2573, Train: 89.92%, Valid: 81.69%, Test: 81.77%
Epoch: 250, Loss: 0.2566, Train: 91.53%, Valid: 82.85%, Test: 83.27%
Epoch: 275, Loss: 0.2228, Train: 92.12%, Valid: 82.61%, Test: 82.89%
Epoch: 300, Loss: 0.2099, Train: 93.19%, Valid: 82.87%, Test: 82.97%
Epoch: 325, Loss: 0.2024, Train: 92.68%, Valid: 83.01%, Test: 83.15%
Epoch: 350, Loss: 0.2027, Train: 91.63%, Valid: 81.46%, Test: 81.59%
Epoch: 375, Loss: 0.2226, Train: 90.36%, Valid: 81.52%, Test: 80.83%
Epoch: 400, Loss: 0.1955, Train: 93.87%, Valid: 82.62%, Test: 83.17%
Epoch: 425, Loss: 0.1791, Train: 94.14%, Valid: 82.98%, Test: 82.87%
Epoch: 450, Loss: 0.1860, Train: 93.59%, Valid: 83.05%, Test: 82.85%
Epoch: 475, Loss: 0.1724, Train: 94.84%, Valid: 82.61%, Test: 82.61%
Epoch: 500, Loss: 0.1607, Train: 95.41%, Valid: 82.82%, Test: 83.04%
Epoch: 525, Loss: 0.1604, Train: 94.90%, Valid: 82.68%, Test: 82.53%
Epoch: 550, Loss: 0.1488, Train: 95.49%, Valid: 83.19%, Test: 82.97%
Epoch: 575, Loss: 0.1887, Train: 95.92%, Valid: 82.59%, Test: 82.72%
Epoch: 600, Loss: 0.1483, Train: 96.03%, Valid: 83.13%, Test: 82.96%
Epoch: 625, Loss: 0.1286, Train: 96.24%, Valid: 82.72%, Test: 82.76%
Epoch: 650, Loss: 0.1284, Train: 96.42%, Valid: 82.74%, Test: 82.62%
Epoch: 675, Loss: 0.1378, Train: 97.27%, Valid: 82.60%, Test: 82.78%
Epoch: 700, Loss: 0.1976, Train: 92.59%, Valid: 79.76%, Test: 79.86%
Epoch: 725, Loss: 0.1965, Train: 92.12%, Valid: 79.28%, Test: 79.56%
Epoch: 750, Loss: 0.1280, Train: 96.76%, Valid: 82.81%, Test: 82.61%
Epoch: 775, Loss: 0.1099, Train: 97.36%, Valid: 82.56%, Test: 82.56%
Epoch: 800, Loss: 0.0906, Train: 98.10%, Valid: 82.40%, Test: 82.60%
Epoch: 825, Loss: 0.0875, Train: 98.52%, Valid: 82.48%, Test: 82.59%
Epoch: 850, Loss: 0.0783, Train: 98.44%, Valid: 82.00%, Test: 81.94%
Epoch: 875, Loss: 0.0788, Train: 98.00%, Valid: 81.88%, Test: 82.12%
Epoch: 900, Loss: 0.0851, Train: 98.68%, Valid: 82.21%, Test: 82.24%
Epoch: 925, Loss: 0.0624, Train: 99.09%, Valid: 82.46%, Test: 82.57%
Epoch: 950, Loss: 0.0559, Train: 99.09%, Valid: 81.44%, Test: 81.94%
Epoch: 975, Loss: 0.0659, Train: 95.60%, Valid: 78.09%, Test: 77.83%
Run 01:
Highest Train: 99.36
Highest Valid: 83.50
  Final Train: 95.47
   Final Test: 83.49
All runs:
Highest Train: 99.36, nan
Highest Valid: 83.50, nan
  Final Train: 95.47, nan
   Final Test: 83.49, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.2996, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.4545, Train: 81.37%, Valid: 79.57%, Test: 79.27%
Epoch: 50, Loss: 0.4153, Train: 84.12%, Valid: 80.50%, Test: 80.32%
Epoch: 75, Loss: 0.3791, Train: 86.14%, Valid: 80.99%, Test: 81.09%
Epoch: 100, Loss: 0.3470, Train: 87.88%, Valid: 81.98%, Test: 81.89%
Epoch: 125, Loss: 0.3303, Train: 87.65%, Valid: 80.83%, Test: 80.96%
Epoch: 150, Loss: 0.2946, Train: 89.78%, Valid: 82.23%, Test: 82.48%
Epoch: 175, Loss: 0.2813, Train: 90.42%, Valid: 82.82%, Test: 82.77%
Epoch: 200, Loss: 0.2921, Train: 90.98%, Valid: 82.37%, Test: 82.86%
Epoch: 225, Loss: 0.2490, Train: 91.66%, Valid: 82.45%, Test: 82.77%
Epoch: 250, Loss: 0.3008, Train: 88.90%, Valid: 79.71%, Test: 79.92%
Epoch: 275, Loss: 0.2115, Train: 92.61%, Valid: 82.09%, Test: 82.10%
Epoch: 300, Loss: 0.2192, Train: 93.50%, Valid: 82.67%, Test: 82.59%
Epoch: 325, Loss: 0.2082, Train: 94.04%, Valid: 82.24%, Test: 82.18%
Epoch: 350, Loss: 0.1901, Train: 95.73%, Valid: 82.37%, Test: 82.85%
Epoch: 375, Loss: 0.1613, Train: 95.23%, Valid: 80.95%, Test: 81.11%
Epoch: 400, Loss: 0.1491, Train: 95.37%, Valid: 81.04%, Test: 80.90%
Epoch: 425, Loss: 0.1312, Train: 97.26%, Valid: 81.91%, Test: 81.52%
Epoch: 450, Loss: 0.1556, Train: 94.81%, Valid: 78.00%, Test: 77.49%
Epoch: 475, Loss: 0.1238, Train: 96.70%, Valid: 80.07%, Test: 80.47%
Epoch: 500, Loss: 0.0927, Train: 98.03%, Valid: 80.05%, Test: 79.97%
Epoch: 525, Loss: 0.0817, Train: 98.62%, Valid: 79.76%, Test: 80.13%
Epoch: 550, Loss: 0.0849, Train: 98.74%, Valid: 79.51%, Test: 80.21%
Epoch: 575, Loss: 0.0935, Train: 98.45%, Valid: 79.15%, Test: 79.68%
Epoch: 600, Loss: 0.0727, Train: 99.10%, Valid: 79.38%, Test: 79.63%
Epoch: 625, Loss: 0.0590, Train: 99.30%, Valid: 78.21%, Test: 78.31%
Epoch: 650, Loss: 0.0502, Train: 99.34%, Valid: 77.69%, Test: 77.66%
Epoch: 675, Loss: 0.1647, Train: 96.31%, Valid: 72.63%, Test: 72.84%
Epoch: 700, Loss: 0.0721, Train: 99.15%, Valid: 76.88%, Test: 77.78%
Epoch: 725, Loss: 0.0829, Train: 97.70%, Valid: 74.59%, Test: 74.56%
Epoch: 750, Loss: 0.0516, Train: 97.73%, Valid: 75.97%, Test: 76.58%
Epoch: 775, Loss: 0.0440, Train: 99.46%, Valid: 76.98%, Test: 77.54%
Epoch: 800, Loss: 0.0654, Train: 99.38%, Valid: 76.20%, Test: 77.28%
Epoch: 825, Loss: 0.0424, Train: 99.56%, Valid: 76.53%, Test: 77.05%
Epoch: 850, Loss: 0.0419, Train: 99.64%, Valid: 75.67%, Test: 76.40%
Epoch: 875, Loss: 0.0374, Train: 99.66%, Valid: 74.89%, Test: 75.98%
Epoch: 900, Loss: 0.0384, Train: 99.74%, Valid: 74.57%, Test: 75.40%
Epoch: 925, Loss: 0.0253, Train: 99.79%, Valid: 75.85%, Test: 76.53%
Epoch: 950, Loss: 0.0673, Train: 99.34%, Valid: 70.95%, Test: 71.80%
Epoch: 975, Loss: 0.0294, Train: 99.75%, Valid: 74.39%, Test: 75.00%
Run 01:
Highest Train: 99.81
Highest Valid: 83.24
  Final Train: 91.97
   Final Test: 82.82
All runs:
Highest Train: 99.81, nan
Highest Valid: 83.24, nan
  Final Train: 91.97, nan
   Final Test: 82.82, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.7680, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.4694, Train: 79.66%, Valid: 77.89%, Test: 78.04%
Epoch: 50, Loss: 0.4370, Train: 83.39%, Valid: 80.76%, Test: 80.50%
Epoch: 75, Loss: 0.4126, Train: 84.54%, Valid: 80.93%, Test: 80.41%
Epoch: 100, Loss: 0.3801, Train: 85.09%, Valid: 80.73%, Test: 80.80%
Epoch: 125, Loss: 0.3630, Train: 86.02%, Valid: 80.78%, Test: 80.66%
Epoch: 150, Loss: 0.3426, Train: 86.62%, Valid: 80.94%, Test: 81.40%
Epoch: 175, Loss: 0.3285, Train: 87.99%, Valid: 81.90%, Test: 82.13%
Epoch: 200, Loss: 0.2975, Train: 89.11%, Valid: 82.80%, Test: 82.82%
Epoch: 225, Loss: 0.2817, Train: 89.39%, Valid: 81.71%, Test: 82.22%
Epoch: 250, Loss: 0.2657, Train: 89.65%, Valid: 81.69%, Test: 81.91%
Epoch: 275, Loss: 0.2572, Train: 91.03%, Valid: 82.20%, Test: 82.42%
Epoch: 300, Loss: 0.2402, Train: 90.38%, Valid: 82.37%, Test: 82.39%
Epoch: 325, Loss: 0.2488, Train: 91.85%, Valid: 82.35%, Test: 82.51%
Epoch: 350, Loss: 0.2317, Train: 92.74%, Valid: 83.15%, Test: 83.58%
Epoch: 375, Loss: 0.2308, Train: 92.67%, Valid: 82.97%, Test: 82.90%
Epoch: 400, Loss: 0.2344, Train: 91.72%, Valid: 82.18%, Test: 82.27%
Epoch: 425, Loss: 0.1913, Train: 93.32%, Valid: 82.84%, Test: 82.81%
Epoch: 450, Loss: 0.1789, Train: 92.96%, Valid: 81.41%, Test: 81.50%
Epoch: 475, Loss: 0.2080, Train: 93.78%, Valid: 82.70%, Test: 82.70%
Epoch: 500, Loss: 0.1657, Train: 94.84%, Valid: 83.28%, Test: 83.37%
Epoch: 525, Loss: 0.2861, Train: 91.86%, Valid: 79.96%, Test: 80.26%
Epoch: 550, Loss: 0.1777, Train: 94.61%, Valid: 82.39%, Test: 82.66%
Epoch: 575, Loss: 0.1673, Train: 95.59%, Valid: 82.99%, Test: 83.10%
Epoch: 600, Loss: 0.1483, Train: 95.80%, Valid: 82.47%, Test: 82.68%
Epoch: 625, Loss: 0.1644, Train: 96.35%, Valid: 82.03%, Test: 82.27%
Epoch: 650, Loss: 0.1232, Train: 96.33%, Valid: 82.29%, Test: 82.26%
Epoch: 675, Loss: 0.1633, Train: 95.76%, Valid: 81.12%, Test: 81.58%
Epoch: 700, Loss: 0.1061, Train: 97.19%, Valid: 82.43%, Test: 82.40%
Epoch: 725, Loss: 0.1914, Train: 95.24%, Valid: 79.89%, Test: 80.47%
Epoch: 750, Loss: 0.1144, Train: 97.21%, Valid: 82.27%, Test: 82.29%
Epoch: 775, Loss: 0.1150, Train: 97.43%, Valid: 81.32%, Test: 81.48%
Epoch: 800, Loss: 0.0869, Train: 98.36%, Valid: 81.66%, Test: 82.08%
Epoch: 825, Loss: 0.1519, Train: 95.59%, Valid: 79.45%, Test: 79.94%
Epoch: 850, Loss: 0.1124, Train: 96.37%, Valid: 80.78%, Test: 80.40%
Epoch: 875, Loss: 0.0917, Train: 98.44%, Valid: 81.67%, Test: 81.72%
Epoch: 900, Loss: 0.1056, Train: 98.86%, Valid: 81.13%, Test: 81.46%
Epoch: 925, Loss: 0.0708, Train: 98.59%, Valid: 80.73%, Test: 80.92%
Epoch: 950, Loss: 0.0598, Train: 99.13%, Valid: 81.02%, Test: 80.84%
Epoch: 975, Loss: 0.0635, Train: 97.72%, Valid: 79.90%, Test: 79.94%
Run 01:
Highest Train: 99.35
Highest Valid: 83.38
  Final Train: 95.39
   Final Test: 83.67
All runs:
Highest Train: 99.35, nan
Highest Valid: 83.38, nan
  Final Train: 95.39, nan
   Final Test: 83.67, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.5789, Train: 47.15%, Valid: 48.12%, Test: 47.20%
Epoch: 25, Loss: 0.4572, Train: 80.96%, Valid: 79.51%, Test: 78.86%
Epoch: 50, Loss: 0.4214, Train: 83.35%, Valid: 80.21%, Test: 79.95%
Epoch: 75, Loss: 0.3907, Train: 85.15%, Valid: 81.18%, Test: 81.05%
Epoch: 100, Loss: 0.3641, Train: 85.73%, Valid: 81.49%, Test: 81.06%
Epoch: 125, Loss: 0.3425, Train: 86.72%, Valid: 81.45%, Test: 81.75%
Epoch: 150, Loss: 0.3361, Train: 87.16%, Valid: 81.13%, Test: 81.03%
Epoch: 175, Loss: 0.3045, Train: 87.84%, Valid: 81.55%, Test: 81.74%
Epoch: 200, Loss: 0.2973, Train: 89.03%, Valid: 82.11%, Test: 82.17%
Epoch: 225, Loss: 0.2839, Train: 89.17%, Valid: 82.05%, Test: 81.94%
Epoch: 250, Loss: 0.2530, Train: 90.33%, Valid: 82.36%, Test: 82.81%
Epoch: 275, Loss: 0.2513, Train: 90.43%, Valid: 81.79%, Test: 82.56%
Epoch: 300, Loss: 0.2322, Train: 91.19%, Valid: 82.70%, Test: 82.67%
Epoch: 325, Loss: 0.2361, Train: 92.22%, Valid: 83.16%, Test: 83.05%
Epoch: 350, Loss: 0.2232, Train: 92.31%, Valid: 83.20%, Test: 83.52%
Epoch: 375, Loss: 0.2138, Train: 92.48%, Valid: 82.38%, Test: 83.07%
Epoch: 400, Loss: 0.2280, Train: 92.78%, Valid: 82.77%, Test: 83.11%
Epoch: 425, Loss: 0.1930, Train: 93.48%, Valid: 82.95%, Test: 83.29%
Epoch: 450, Loss: 0.1917, Train: 93.86%, Valid: 82.78%, Test: 83.19%
Epoch: 475, Loss: 0.2103, Train: 93.36%, Valid: 83.06%, Test: 82.83%
Epoch: 500, Loss: 0.1815, Train: 94.23%, Valid: 82.71%, Test: 83.06%
Epoch: 525, Loss: 0.1630, Train: 95.26%, Valid: 83.27%, Test: 83.66%
Epoch: 550, Loss: 0.1725, Train: 94.90%, Valid: 82.81%, Test: 82.75%
Epoch: 575, Loss: 0.1866, Train: 95.21%, Valid: 82.25%, Test: 82.87%
Epoch: 600, Loss: 0.1636, Train: 95.32%, Valid: 82.51%, Test: 82.71%
Epoch: 625, Loss: 0.1439, Train: 96.38%, Valid: 83.04%, Test: 83.04%
Epoch: 650, Loss: 0.1272, Train: 96.90%, Valid: 82.41%, Test: 82.74%
Epoch: 675, Loss: 0.4978, Train: 84.83%, Valid: 73.14%, Test: 73.38%
Epoch: 700, Loss: 0.2029, Train: 93.62%, Valid: 79.81%, Test: 80.19%
Epoch: 725, Loss: 0.1663, Train: 95.85%, Valid: 81.89%, Test: 81.75%
Epoch: 750, Loss: 0.1553, Train: 96.50%, Valid: 82.33%, Test: 82.33%
Epoch: 775, Loss: 0.1208, Train: 97.33%, Valid: 82.30%, Test: 82.65%
Epoch: 800, Loss: 0.1152, Train: 96.86%, Valid: 81.51%, Test: 81.89%
Epoch: 825, Loss: 0.1416, Train: 97.00%, Valid: 81.48%, Test: 81.97%
Epoch: 850, Loss: 0.1046, Train: 98.04%, Valid: 82.23%, Test: 82.76%
Epoch: 875, Loss: 0.1214, Train: 97.59%, Valid: 82.09%, Test: 82.27%
Epoch: 900, Loss: 0.0853, Train: 98.24%, Valid: 81.93%, Test: 82.43%
Epoch: 925, Loss: 0.0929, Train: 97.55%, Valid: 80.67%, Test: 80.61%
Epoch: 950, Loss: 0.1424, Train: 97.50%, Valid: 79.06%, Test: 78.70%
Epoch: 975, Loss: 0.1233, Train: 98.33%, Valid: 79.57%, Test: 79.78%
Run 01:
Highest Train: 98.96
Highest Valid: 83.45
  Final Train: 94.61
   Final Test: 83.41
All runs:
Highest Train: 98.96, nan
Highest Valid: 83.45, nan
  Final Train: 94.61, nan
   Final Test: 83.41, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.4139, Train: 47.51%, Valid: 48.39%, Test: 47.55%
Epoch: 25, Loss: 0.4698, Train: 78.84%, Valid: 77.41%, Test: 77.43%
Epoch: 50, Loss: 0.4144, Train: 83.41%, Valid: 80.63%, Test: 80.35%
Epoch: 75, Loss: 0.3912, Train: 86.06%, Valid: 81.43%, Test: 81.58%
Epoch: 100, Loss: 0.3718, Train: 88.28%, Valid: 82.29%, Test: 82.37%
Epoch: 125, Loss: 0.3547, Train: 89.64%, Valid: 82.41%, Test: 82.63%
Epoch: 150, Loss: 0.3391, Train: 90.52%, Valid: 82.86%, Test: 82.76%
Epoch: 175, Loss: 0.3428, Train: 91.26%, Valid: 83.55%, Test: 83.26%
Epoch: 200, Loss: 0.3172, Train: 92.00%, Valid: 82.95%, Test: 83.00%
Epoch: 225, Loss: 0.3081, Train: 92.48%, Valid: 83.25%, Test: 83.05%
Epoch: 250, Loss: 0.2989, Train: 93.12%, Valid: 83.28%, Test: 83.20%
Epoch: 275, Loss: 0.3063, Train: 92.22%, Valid: 83.19%, Test: 83.37%
Epoch: 300, Loss: 0.2777, Train: 93.88%, Valid: 83.78%, Test: 83.34%
Epoch: 325, Loss: 0.2874, Train: 90.48%, Valid: 81.39%, Test: 80.94%
Epoch: 350, Loss: 0.2630, Train: 94.56%, Valid: 84.08%, Test: 84.02%
Epoch: 375, Loss: 0.2484, Train: 95.49%, Valid: 84.41%, Test: 83.85%
Epoch: 400, Loss: 0.2586, Train: 93.72%, Valid: 83.27%, Test: 83.35%
Epoch: 425, Loss: 0.2352, Train: 95.78%, Valid: 84.30%, Test: 83.98%
Epoch: 450, Loss: 0.2364, Train: 94.29%, Valid: 82.36%, Test: 82.84%
Epoch: 475, Loss: 0.2172, Train: 96.62%, Valid: 84.37%, Test: 84.41%
Epoch: 500, Loss: 0.2349, Train: 94.69%, Valid: 83.37%, Test: 83.38%
Epoch: 525, Loss: 0.2038, Train: 96.86%, Valid: 84.79%, Test: 84.43%
Epoch: 550, Loss: 0.2190, Train: 94.42%, Valid: 82.34%, Test: 82.24%
Epoch: 575, Loss: 0.1911, Train: 97.16%, Valid: 84.60%, Test: 84.01%
Epoch: 600, Loss: 0.2294, Train: 95.83%, Valid: 82.88%, Test: 82.64%
Epoch: 625, Loss: 0.2394, Train: 94.49%, Valid: 82.73%, Test: 82.45%
Epoch: 650, Loss: 0.1923, Train: 96.67%, Valid: 83.48%, Test: 83.12%
Epoch: 675, Loss: 0.1774, Train: 97.37%, Valid: 84.14%, Test: 83.65%
Epoch: 700, Loss: 0.2196, Train: 94.19%, Valid: 82.61%, Test: 82.92%
Epoch: 725, Loss: 0.1716, Train: 97.08%, Valid: 83.95%, Test: 84.01%
Epoch: 750, Loss: 0.1545, Train: 97.63%, Valid: 84.53%, Test: 84.10%
Epoch: 775, Loss: 0.3198, Train: 86.00%, Valid: 77.29%, Test: 77.38%
Epoch: 800, Loss: 0.2252, Train: 94.06%, Valid: 81.43%, Test: 81.52%
Epoch: 825, Loss: 0.1892, Train: 96.53%, Valid: 82.28%, Test: 82.52%
Epoch: 850, Loss: 0.1745, Train: 96.80%, Valid: 82.35%, Test: 81.98%
Epoch: 875, Loss: 0.1785, Train: 96.59%, Valid: 82.58%, Test: 83.02%
Epoch: 900, Loss: 0.1545, Train: 97.62%, Valid: 83.47%, Test: 83.04%
Epoch: 925, Loss: 0.1419, Train: 97.95%, Valid: 83.74%, Test: 83.19%
Epoch: 950, Loss: 0.7822, Train: 75.75%, Valid: 67.71%, Test: 66.43%
Epoch: 975, Loss: 0.3120, Train: 87.77%, Valid: 76.41%, Test: 76.67%
Run 01:
Highest Train: 98.08
Highest Valid: 84.93
  Final Train: 96.83
   Final Test: 84.25
All runs:
Highest Train: 98.08, nan
Highest Valid: 84.93, nan
  Final Train: 96.83, nan
   Final Test: 84.25, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.7974, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.4645, Train: 79.21%, Valid: 77.51%, Test: 77.86%
Epoch: 50, Loss: 0.4197, Train: 83.58%, Valid: 80.43%, Test: 80.48%
Epoch: 75, Loss: 0.3964, Train: 85.73%, Valid: 81.24%, Test: 81.11%
Epoch: 100, Loss: 0.3794, Train: 87.92%, Valid: 81.88%, Test: 81.78%
Epoch: 125, Loss: 0.3676, Train: 89.44%, Valid: 82.83%, Test: 82.76%
Epoch: 150, Loss: 0.3424, Train: 90.70%, Valid: 83.18%, Test: 83.25%
Epoch: 175, Loss: 0.3346, Train: 90.64%, Valid: 82.89%, Test: 82.91%
Epoch: 200, Loss: 0.3185, Train: 91.76%, Valid: 83.16%, Test: 83.15%
Epoch: 225, Loss: 0.3185, Train: 91.68%, Valid: 82.92%, Test: 83.30%
Epoch: 250, Loss: 0.2993, Train: 92.99%, Valid: 83.60%, Test: 83.34%
Epoch: 275, Loss: 0.3183, Train: 91.44%, Valid: 82.44%, Test: 82.79%
Epoch: 300, Loss: 0.2837, Train: 93.45%, Valid: 83.35%, Test: 83.47%
Epoch: 325, Loss: 0.2763, Train: 91.23%, Valid: 81.39%, Test: 80.97%
Epoch: 350, Loss: 0.2859, Train: 92.78%, Valid: 82.81%, Test: 83.24%
Epoch: 375, Loss: 0.2593, Train: 94.47%, Valid: 83.81%, Test: 83.54%
Epoch: 400, Loss: 0.2967, Train: 84.05%, Valid: 75.48%, Test: 74.93%
Epoch: 425, Loss: 0.2545, Train: 93.14%, Valid: 82.96%, Test: 83.03%
Epoch: 450, Loss: 0.2351, Train: 95.13%, Valid: 84.08%, Test: 83.61%
Epoch: 475, Loss: 0.2224, Train: 95.77%, Valid: 84.05%, Test: 84.00%
Epoch: 500, Loss: 0.2339, Train: 94.64%, Valid: 83.57%, Test: 83.66%
Epoch: 525, Loss: 0.2098, Train: 96.07%, Valid: 84.07%, Test: 84.02%
Epoch: 550, Loss: 0.3332, Train: 80.37%, Valid: 72.61%, Test: 72.04%
Epoch: 575, Loss: 0.2741, Train: 91.61%, Valid: 82.02%, Test: 81.73%
Epoch: 600, Loss: 0.2057, Train: 95.41%, Valid: 83.58%, Test: 83.45%
Epoch: 625, Loss: 0.2361, Train: 90.56%, Valid: 81.24%, Test: 80.80%
Epoch: 650, Loss: 0.2087, Train: 95.23%, Valid: 83.38%, Test: 83.81%
Epoch: 675, Loss: 0.1801, Train: 96.43%, Valid: 84.12%, Test: 83.94%
Epoch: 700, Loss: 0.6978, Train: 77.17%, Valid: 71.41%, Test: 70.32%
Epoch: 725, Loss: 0.3155, Train: 89.10%, Valid: 79.99%, Test: 79.93%
Epoch: 750, Loss: 0.2527, Train: 93.39%, Valid: 81.51%, Test: 81.69%
Epoch: 775, Loss: 0.2533, Train: 92.26%, Valid: 79.94%, Test: 80.18%
Epoch: 800, Loss: 0.2150, Train: 95.85%, Valid: 82.23%, Test: 82.10%
Epoch: 825, Loss: 0.1955, Train: 96.87%, Valid: 82.72%, Test: 82.27%
Epoch: 850, Loss: 0.1814, Train: 97.20%, Valid: 82.97%, Test: 82.70%
Epoch: 875, Loss: 0.4104, Train: 88.07%, Valid: 78.12%, Test: 77.21%
Epoch: 900, Loss: 0.2300, Train: 94.02%, Valid: 81.58%, Test: 81.73%
Epoch: 925, Loss: 0.1792, Train: 96.63%, Valid: 82.90%, Test: 82.83%
Epoch: 950, Loss: 0.1546, Train: 97.23%, Valid: 83.59%, Test: 83.46%
Epoch: 975, Loss: 0.2714, Train: 91.36%, Valid: 80.10%, Test: 79.91%
Run 01:
Highest Train: 97.38
Highest Valid: 84.45
  Final Train: 96.62
   Final Test: 84.25
All runs:
Highest Train: 97.38, nan
Highest Valid: 84.45, nan
  Final Train: 96.62, nan
   Final Test: 84.25, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.7392, Train: 47.35%, Valid: 48.26%, Test: 47.50%
Epoch: 25, Loss: 0.4564, Train: 79.67%, Valid: 77.76%, Test: 77.53%
Epoch: 50, Loss: 0.4119, Train: 83.90%, Valid: 80.80%, Test: 80.49%
Epoch: 75, Loss: 0.3868, Train: 86.50%, Valid: 81.57%, Test: 81.79%
Epoch: 100, Loss: 0.3710, Train: 88.31%, Valid: 82.20%, Test: 82.56%
Epoch: 125, Loss: 0.3598, Train: 88.00%, Valid: 81.19%, Test: 80.84%
Epoch: 150, Loss: 0.3413, Train: 90.41%, Valid: 82.86%, Test: 83.12%
Epoch: 175, Loss: 0.3551, Train: 89.44%, Valid: 82.17%, Test: 82.39%
Epoch: 200, Loss: 0.3203, Train: 91.39%, Valid: 82.79%, Test: 83.00%
Epoch: 225, Loss: 0.3531, Train: 85.81%, Valid: 78.26%, Test: 78.18%
Epoch: 250, Loss: 0.3088, Train: 91.65%, Valid: 83.07%, Test: 82.82%
Epoch: 275, Loss: 0.2924, Train: 92.83%, Valid: 83.42%, Test: 83.42%
Epoch: 300, Loss: 0.3064, Train: 91.22%, Valid: 82.80%, Test: 82.74%
Epoch: 325, Loss: 0.2801, Train: 93.02%, Valid: 83.23%, Test: 83.40%
Epoch: 350, Loss: 0.2685, Train: 93.86%, Valid: 83.38%, Test: 83.47%
Epoch: 375, Loss: 0.3158, Train: 89.52%, Valid: 81.43%, Test: 81.30%
Epoch: 400, Loss: 0.2695, Train: 93.02%, Valid: 82.93%, Test: 83.13%
Epoch: 425, Loss: 0.2531, Train: 94.23%, Valid: 83.41%, Test: 83.25%
Epoch: 450, Loss: 0.3342, Train: 84.04%, Valid: 76.85%, Test: 76.21%
Epoch: 475, Loss: 0.2753, Train: 92.34%, Valid: 82.71%, Test: 82.78%
Epoch: 500, Loss: 0.2428, Train: 94.24%, Valid: 83.46%, Test: 83.33%
Epoch: 525, Loss: 0.2305, Train: 94.96%, Valid: 83.52%, Test: 83.44%
Epoch: 550, Loss: 0.2208, Train: 95.41%, Valid: 83.39%, Test: 83.35%
Epoch: 575, Loss: 0.2481, Train: 93.31%, Valid: 82.65%, Test: 83.00%
Epoch: 600, Loss: 0.2150, Train: 95.24%, Valid: 83.71%, Test: 83.44%
Epoch: 625, Loss: 0.2041, Train: 95.82%, Valid: 83.54%, Test: 83.47%
Epoch: 650, Loss: 0.4314, Train: 90.58%, Valid: 81.78%, Test: 81.88%
Epoch: 675, Loss: 0.2372, Train: 93.36%, Valid: 82.78%, Test: 82.99%
Epoch: 700, Loss: 0.1987, Train: 95.53%, Valid: 83.63%, Test: 83.40%
Epoch: 725, Loss: 0.1876, Train: 96.15%, Valid: 83.56%, Test: 83.48%
Epoch: 750, Loss: 0.1791, Train: 96.61%, Valid: 83.44%, Test: 83.44%
Epoch: 775, Loss: 0.3022, Train: 89.55%, Valid: 80.86%, Test: 81.01%
Epoch: 800, Loss: 0.2244, Train: 93.70%, Valid: 82.38%, Test: 82.52%
Epoch: 825, Loss: 0.1878, Train: 95.77%, Valid: 83.17%, Test: 82.87%
Epoch: 850, Loss: 0.1738, Train: 96.52%, Valid: 83.43%, Test: 83.35%
Epoch: 875, Loss: 0.2748, Train: 90.16%, Valid: 81.23%, Test: 80.69%
Epoch: 900, Loss: 0.1985, Train: 94.80%, Valid: 83.06%, Test: 83.10%
Epoch: 925, Loss: 0.1717, Train: 96.38%, Valid: 83.42%, Test: 83.36%
Epoch: 950, Loss: 0.1610, Train: 96.91%, Valid: 83.55%, Test: 83.50%
Epoch: 975, Loss: 0.1534, Train: 97.21%, Valid: 83.57%, Test: 83.36%
Run 01:
Highest Train: 97.26
Highest Valid: 83.74
  Final Train: 95.26
   Final Test: 83.36
All runs:
Highest Train: 97.26, nan
Highest Valid: 83.74, nan
  Final Train: 95.26, nan
   Final Test: 83.36, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.8754, Train: 56.01%, Valid: 56.00%, Test: 57.13%
Epoch: 25, Loss: 0.4561, Train: 79.77%, Valid: 78.18%, Test: 77.91%
Epoch: 50, Loss: 0.4089, Train: 84.11%, Valid: 80.89%, Test: 80.80%
Epoch: 75, Loss: 0.3853, Train: 86.14%, Valid: 81.52%, Test: 81.79%
Epoch: 100, Loss: 0.3746, Train: 88.40%, Valid: 82.27%, Test: 82.80%
Epoch: 125, Loss: 0.3472, Train: 88.80%, Valid: 82.50%, Test: 82.33%
Epoch: 150, Loss: 0.3325, Train: 90.01%, Valid: 82.63%, Test: 82.61%
Epoch: 175, Loss: 0.3266, Train: 90.51%, Valid: 82.65%, Test: 82.92%
Epoch: 200, Loss: 0.3192, Train: 90.99%, Valid: 82.80%, Test: 82.93%
Epoch: 225, Loss: 0.3032, Train: 92.09%, Valid: 83.15%, Test: 83.11%
Epoch: 250, Loss: 0.2917, Train: 92.24%, Valid: 83.15%, Test: 83.02%
Epoch: 275, Loss: 0.2806, Train: 92.45%, Valid: 82.61%, Test: 82.89%
Epoch: 300, Loss: 0.2736, Train: 92.99%, Valid: 83.55%, Test: 83.00%
Epoch: 325, Loss: 0.2667, Train: 93.63%, Valid: 83.87%, Test: 83.37%
Epoch: 350, Loss: 0.2543, Train: 93.14%, Valid: 82.98%, Test: 82.38%
Epoch: 375, Loss: 0.2407, Train: 94.61%, Valid: 83.80%, Test: 83.44%
Epoch: 400, Loss: 0.2369, Train: 94.72%, Valid: 83.60%, Test: 83.39%
Epoch: 425, Loss: 0.2268, Train: 94.71%, Valid: 82.94%, Test: 82.80%
Epoch: 450, Loss: 0.2118, Train: 95.00%, Valid: 84.00%, Test: 83.11%
Epoch: 475, Loss: 0.2037, Train: 96.12%, Valid: 84.10%, Test: 83.88%
Epoch: 500, Loss: 0.1914, Train: 96.14%, Valid: 83.72%, Test: 83.28%
Epoch: 525, Loss: 0.1910, Train: 96.21%, Valid: 83.19%, Test: 83.44%
Epoch: 550, Loss: 0.2162, Train: 95.01%, Valid: 82.87%, Test: 82.50%
Epoch: 575, Loss: 0.1625, Train: 96.80%, Valid: 84.08%, Test: 83.79%
Epoch: 600, Loss: 0.1945, Train: 96.02%, Valid: 82.81%, Test: 82.56%
Epoch: 625, Loss: 0.1846, Train: 96.94%, Valid: 83.90%, Test: 83.57%
Epoch: 650, Loss: 0.1644, Train: 97.43%, Valid: 84.04%, Test: 83.50%
Epoch: 675, Loss: 0.1949, Train: 95.56%, Valid: 81.33%, Test: 81.16%
Epoch: 700, Loss: 0.1487, Train: 97.32%, Valid: 82.70%, Test: 82.50%
Epoch: 725, Loss: 0.1310, Train: 98.00%, Valid: 83.59%, Test: 83.35%
Epoch: 750, Loss: 0.1595, Train: 96.62%, Valid: 82.30%, Test: 82.25%
Epoch: 775, Loss: 0.1286, Train: 97.82%, Valid: 82.67%, Test: 82.69%
Epoch: 800, Loss: 0.1068, Train: 98.39%, Valid: 83.38%, Test: 82.99%
Epoch: 825, Loss: 0.1210, Train: 95.72%, Valid: 79.94%, Test: 80.10%
Epoch: 850, Loss: 0.1010, Train: 98.76%, Valid: 82.47%, Test: 82.74%
Epoch: 875, Loss: 0.0938, Train: 98.26%, Valid: 81.85%, Test: 81.90%
Epoch: 900, Loss: 0.0791, Train: 99.04%, Valid: 82.39%, Test: 82.55%
Epoch: 925, Loss: 0.2827, Train: 86.22%, Valid: 72.95%, Test: 73.67%
Epoch: 950, Loss: 0.1466, Train: 96.88%, Valid: 78.29%, Test: 78.69%
Epoch: 975, Loss: 0.1076, Train: 98.21%, Valid: 79.68%, Test: 79.84%
Run 01:
Highest Train: 99.20
Highest Valid: 84.48
  Final Train: 96.94
   Final Test: 83.87
All runs:
Highest Train: 99.20, nan
Highest Valid: 84.48, nan
  Final Train: 96.94, nan
   Final Test: 83.87, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.7956, Train: 51.29%, Valid: 51.09%, Test: 52.42%
Epoch: 25, Loss: 0.4854, Train: 77.72%, Valid: 76.95%, Test: 76.48%
Epoch: 50, Loss: 0.4200, Train: 82.75%, Valid: 80.20%, Test: 80.39%
Epoch: 75, Loss: 0.3964, Train: 85.44%, Valid: 81.42%, Test: 81.43%
Epoch: 100, Loss: 0.3754, Train: 87.51%, Valid: 82.06%, Test: 82.18%
Epoch: 125, Loss: 0.3558, Train: 89.33%, Valid: 82.84%, Test: 82.66%
Epoch: 150, Loss: 0.3418, Train: 90.14%, Valid: 83.09%, Test: 82.92%
Epoch: 175, Loss: 0.3343, Train: 90.91%, Valid: 82.93%, Test: 83.19%
Epoch: 200, Loss: 0.3185, Train: 91.31%, Valid: 82.86%, Test: 83.14%
Epoch: 225, Loss: 0.3030, Train: 92.27%, Valid: 83.35%, Test: 83.37%
Epoch: 250, Loss: 0.3036, Train: 91.19%, Valid: 82.39%, Test: 82.10%
Epoch: 275, Loss: 0.2879, Train: 92.87%, Valid: 83.09%, Test: 83.61%
Epoch: 300, Loss: 0.2815, Train: 93.06%, Valid: 83.47%, Test: 83.19%
Epoch: 325, Loss: 0.2656, Train: 94.25%, Valid: 83.66%, Test: 83.69%
Epoch: 350, Loss: 0.2529, Train: 94.10%, Valid: 83.74%, Test: 83.51%
Epoch: 375, Loss: 0.2430, Train: 94.29%, Valid: 83.58%, Test: 83.70%
Epoch: 400, Loss: 0.2377, Train: 95.23%, Valid: 83.77%, Test: 83.78%
Epoch: 425, Loss: 0.2269, Train: 95.30%, Valid: 83.98%, Test: 84.21%
Epoch: 450, Loss: 0.2338, Train: 95.95%, Valid: 83.80%, Test: 83.88%
Epoch: 475, Loss: 0.2094, Train: 95.77%, Valid: 83.18%, Test: 83.47%
Epoch: 500, Loss: 0.2041, Train: 96.37%, Valid: 83.54%, Test: 83.59%
Epoch: 525, Loss: 0.2230, Train: 95.01%, Valid: 81.41%, Test: 81.80%
Epoch: 550, Loss: 0.1929, Train: 96.62%, Valid: 82.54%, Test: 82.62%
Epoch: 575, Loss: 0.1727, Train: 97.10%, Valid: 83.41%, Test: 83.63%
Epoch: 600, Loss: 0.1515, Train: 97.58%, Valid: 83.62%, Test: 83.97%
Epoch: 625, Loss: 0.4225, Train: 78.18%, Valid: 70.79%, Test: 71.11%
Epoch: 650, Loss: 0.2506, Train: 92.64%, Valid: 79.09%, Test: 80.04%
Epoch: 675, Loss: 0.2215, Train: 95.28%, Valid: 80.13%, Test: 80.41%
Epoch: 700, Loss: 0.2068, Train: 95.74%, Valid: 79.89%, Test: 80.10%
Epoch: 725, Loss: 0.2023, Train: 96.05%, Valid: 80.43%, Test: 80.36%
Epoch: 750, Loss: 0.1929, Train: 96.82%, Valid: 80.58%, Test: 80.93%
Epoch: 775, Loss: 0.1815, Train: 96.87%, Valid: 81.13%, Test: 81.05%
Epoch: 800, Loss: 0.1714, Train: 96.76%, Valid: 81.20%, Test: 81.13%
Epoch: 825, Loss: 0.1633, Train: 97.16%, Valid: 81.25%, Test: 81.24%
Epoch: 850, Loss: 0.1409, Train: 97.57%, Valid: 81.68%, Test: 81.87%
Epoch: 875, Loss: 0.1361, Train: 97.97%, Valid: 82.27%, Test: 82.11%
Epoch: 900, Loss: 0.1198, Train: 97.77%, Valid: 80.96%, Test: 81.34%
Epoch: 925, Loss: 0.1148, Train: 97.79%, Valid: 81.01%, Test: 81.16%
Epoch: 950, Loss: 0.1041, Train: 98.30%, Valid: 81.57%, Test: 81.81%
Epoch: 975, Loss: 0.0941, Train: 98.78%, Valid: 81.55%, Test: 82.00%
Run 01:
Highest Train: 98.91
Highest Valid: 84.35
  Final Train: 94.88
   Final Test: 84.18
All runs:
Highest Train: 98.91, nan
Highest Valid: 84.35, nan
  Final Train: 94.88, nan
   Final Test: 84.18, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.6105, Train: 47.51%, Valid: 48.45%, Test: 47.65%
Epoch: 25, Loss: 0.4545, Train: 79.68%, Valid: 78.07%, Test: 77.73%
Epoch: 50, Loss: 0.4122, Train: 83.87%, Valid: 80.74%, Test: 80.58%
Epoch: 75, Loss: 0.3920, Train: 86.24%, Valid: 81.58%, Test: 81.72%
Epoch: 100, Loss: 0.3739, Train: 86.69%, Valid: 81.19%, Test: 81.07%
Epoch: 125, Loss: 0.3616, Train: 88.58%, Valid: 82.39%, Test: 82.52%
Epoch: 150, Loss: 0.3476, Train: 88.99%, Valid: 81.98%, Test: 82.02%
Epoch: 175, Loss: 0.3392, Train: 89.18%, Valid: 81.91%, Test: 81.73%
Epoch: 200, Loss: 0.3268, Train: 91.05%, Valid: 83.07%, Test: 82.98%
Epoch: 225, Loss: 0.3145, Train: 91.18%, Valid: 83.37%, Test: 83.08%
Epoch: 250, Loss: 0.3096, Train: 90.64%, Valid: 82.13%, Test: 82.42%
Epoch: 275, Loss: 0.2986, Train: 91.93%, Valid: 83.15%, Test: 83.15%
Epoch: 300, Loss: 0.2910, Train: 92.42%, Valid: 83.45%, Test: 83.26%
Epoch: 325, Loss: 0.2817, Train: 92.73%, Valid: 82.97%, Test: 83.05%
Epoch: 350, Loss: 0.2682, Train: 93.35%, Valid: 83.35%, Test: 83.50%
Epoch: 375, Loss: 0.2585, Train: 93.22%, Valid: 82.93%, Test: 82.95%
Epoch: 400, Loss: 0.2509, Train: 93.71%, Valid: 83.46%, Test: 83.28%
Epoch: 425, Loss: 0.2575, Train: 93.88%, Valid: 83.77%, Test: 83.59%
Epoch: 450, Loss: 0.2381, Train: 94.11%, Valid: 82.83%, Test: 83.02%
Epoch: 475, Loss: 0.2420, Train: 94.81%, Valid: 83.79%, Test: 83.92%
Epoch: 500, Loss: 0.2263, Train: 94.74%, Valid: 83.15%, Test: 83.24%
Epoch: 525, Loss: 0.2228, Train: 95.02%, Valid: 83.74%, Test: 83.68%
Epoch: 550, Loss: 0.2193, Train: 94.85%, Valid: 83.74%, Test: 83.55%
Epoch: 575, Loss: 0.2033, Train: 95.01%, Valid: 83.77%, Test: 83.30%
Epoch: 600, Loss: 0.1969, Train: 95.56%, Valid: 83.83%, Test: 83.94%
Epoch: 625, Loss: 0.1901, Train: 93.49%, Valid: 81.00%, Test: 80.49%
Epoch: 650, Loss: 0.1930, Train: 95.51%, Valid: 83.35%, Test: 83.44%
Epoch: 675, Loss: 0.1745, Train: 96.44%, Valid: 83.58%, Test: 83.89%
Epoch: 700, Loss: 0.1802, Train: 96.19%, Valid: 83.61%, Test: 83.26%
Epoch: 725, Loss: 0.1609, Train: 96.35%, Valid: 83.04%, Test: 82.95%
Epoch: 750, Loss: 0.1538, Train: 96.33%, Valid: 83.01%, Test: 83.06%
Epoch: 775, Loss: 0.1805, Train: 95.62%, Valid: 82.48%, Test: 82.10%
Epoch: 800, Loss: 0.1532, Train: 96.55%, Valid: 83.23%, Test: 83.02%
Epoch: 825, Loss: 0.1400, Train: 96.67%, Valid: 82.95%, Test: 83.05%
Epoch: 850, Loss: 0.1501, Train: 96.32%, Valid: 82.70%, Test: 83.20%
Epoch: 875, Loss: 0.1267, Train: 97.72%, Valid: 83.75%, Test: 83.36%
Epoch: 900, Loss: 0.1526, Train: 96.05%, Valid: 81.86%, Test: 81.98%
Epoch: 925, Loss: 0.1134, Train: 97.97%, Valid: 83.86%, Test: 83.48%
Epoch: 950, Loss: 0.1181, Train: 98.16%, Valid: 83.58%, Test: 83.45%
Epoch: 975, Loss: 0.1239, Train: 97.72%, Valid: 82.49%, Test: 83.07%
Run 01:
Highest Train: 98.57
Highest Valid: 84.45
  Final Train: 94.56
   Final Test: 84.12
All runs:
Highest Train: 98.57, nan
Highest Valid: 84.45, nan
  Final Train: 94.56, nan
   Final Test: 84.12, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.8903, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.5341, Train: 71.42%, Valid: 70.92%, Test: 70.62%
Epoch: 50, Loss: 0.4452, Train: 81.43%, Valid: 78.94%, Test: 79.06%
Epoch: 75, Loss: 0.4232, Train: 83.53%, Valid: 80.72%, Test: 80.56%
Epoch: 100, Loss: 0.4166, Train: 85.08%, Valid: 81.17%, Test: 81.00%
Epoch: 125, Loss: 0.3965, Train: 86.02%, Valid: 81.73%, Test: 81.20%
Epoch: 150, Loss: 0.3877, Train: 87.08%, Valid: 81.66%, Test: 81.49%
Epoch: 175, Loss: 0.3789, Train: 87.88%, Valid: 81.73%, Test: 81.72%
Epoch: 200, Loss: 0.3660, Train: 87.99%, Valid: 82.01%, Test: 81.71%
Epoch: 225, Loss: 0.3533, Train: 89.59%, Valid: 82.80%, Test: 82.50%
Epoch: 250, Loss: 0.3393, Train: 90.24%, Valid: 82.52%, Test: 82.92%
Epoch: 275, Loss: 0.3316, Train: 90.27%, Valid: 82.19%, Test: 82.13%
Epoch: 300, Loss: 0.3246, Train: 91.25%, Valid: 82.86%, Test: 82.96%
Epoch: 325, Loss: 0.3121, Train: 91.77%, Valid: 82.91%, Test: 82.83%
Epoch: 350, Loss: 0.3066, Train: 92.33%, Valid: 83.27%, Test: 83.10%
Epoch: 375, Loss: 0.2997, Train: 92.27%, Valid: 83.01%, Test: 82.86%
Epoch: 400, Loss: 0.2877, Train: 92.90%, Valid: 83.58%, Test: 83.37%
Epoch: 425, Loss: 0.2774, Train: 93.58%, Valid: 83.68%, Test: 83.48%
Epoch: 450, Loss: 0.2786, Train: 92.84%, Valid: 82.77%, Test: 83.04%
Epoch: 475, Loss: 0.2608, Train: 94.51%, Valid: 83.89%, Test: 83.94%
Epoch: 500, Loss: 0.2572, Train: 94.55%, Valid: 84.16%, Test: 83.99%
Epoch: 525, Loss: 0.2509, Train: 95.21%, Valid: 83.69%, Test: 83.76%
Epoch: 550, Loss: 0.2365, Train: 95.16%, Valid: 83.88%, Test: 83.80%
Epoch: 575, Loss: 0.2401, Train: 95.09%, Valid: 83.95%, Test: 83.58%
Epoch: 600, Loss: 0.2195, Train: 95.84%, Valid: 83.93%, Test: 83.72%
Epoch: 625, Loss: 0.2184, Train: 96.21%, Valid: 83.80%, Test: 83.58%
Epoch: 650, Loss: 0.2165, Train: 94.06%, Valid: 81.83%, Test: 81.80%
Epoch: 675, Loss: 0.1973, Train: 96.51%, Valid: 83.96%, Test: 83.85%
Epoch: 700, Loss: 0.2329, Train: 94.88%, Valid: 82.67%, Test: 82.23%
Epoch: 725, Loss: 0.1763, Train: 96.51%, Valid: 83.59%, Test: 83.30%
Epoch: 750, Loss: 0.1888, Train: 95.60%, Valid: 82.26%, Test: 82.16%
Epoch: 775, Loss: 0.1981, Train: 94.89%, Valid: 81.75%, Test: 81.59%
Epoch: 800, Loss: 0.1522, Train: 96.80%, Valid: 82.15%, Test: 82.40%
Epoch: 825, Loss: 0.1931, Train: 94.21%, Valid: 79.57%, Test: 79.68%
Epoch: 850, Loss: 0.1463, Train: 97.60%, Valid: 82.72%, Test: 82.74%
Epoch: 875, Loss: 0.1273, Train: 97.27%, Valid: 81.94%, Test: 81.97%
Epoch: 900, Loss: 0.2066, Train: 91.01%, Valid: 75.56%, Test: 76.12%
Epoch: 925, Loss: 0.1486, Train: 97.13%, Valid: 80.50%, Test: 81.08%
Epoch: 950, Loss: 0.1300, Train: 98.20%, Valid: 82.12%, Test: 82.38%
Epoch: 975, Loss: 0.1376, Train: 97.61%, Valid: 80.66%, Test: 81.00%
Run 01:
Highest Train: 98.78
Highest Valid: 84.45
  Final Train: 96.93
   Final Test: 83.78
All runs:
Highest Train: 98.78, nan
Highest Valid: 84.45, nan
  Final Train: 96.93, nan
   Final Test: 83.78, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.2754, Train: 47.21%, Valid: 48.10%, Test: 47.47%
Epoch: 25, Loss: 0.4552, Train: 79.73%, Valid: 78.07%, Test: 77.68%
Epoch: 50, Loss: 0.4130, Train: 83.90%, Valid: 80.89%, Test: 80.67%
Epoch: 75, Loss: 0.3973, Train: 85.76%, Valid: 81.41%, Test: 81.32%
Epoch: 100, Loss: 0.3776, Train: 87.03%, Valid: 81.67%, Test: 81.83%
Epoch: 125, Loss: 0.3702, Train: 87.45%, Valid: 81.10%, Test: 81.26%
Epoch: 150, Loss: 0.3465, Train: 89.26%, Valid: 82.25%, Test: 82.65%
Epoch: 175, Loss: 0.3307, Train: 89.86%, Valid: 82.24%, Test: 82.44%
Epoch: 200, Loss: 0.3243, Train: 90.15%, Valid: 82.78%, Test: 82.44%
Epoch: 225, Loss: 0.3179, Train: 90.79%, Valid: 82.49%, Test: 82.19%
Epoch: 250, Loss: 0.3076, Train: 91.40%, Valid: 83.24%, Test: 82.98%
Epoch: 275, Loss: 0.2972, Train: 91.70%, Valid: 82.89%, Test: 83.24%
Epoch: 300, Loss: 0.2922, Train: 91.49%, Valid: 82.51%, Test: 82.47%
Epoch: 325, Loss: 0.2944, Train: 91.40%, Valid: 82.57%, Test: 82.52%
Epoch: 350, Loss: 0.2790, Train: 92.66%, Valid: 82.97%, Test: 83.06%
Epoch: 375, Loss: 0.2721, Train: 92.35%, Valid: 82.77%, Test: 82.80%
Epoch: 400, Loss: 0.2709, Train: 93.19%, Valid: 82.93%, Test: 83.07%
Epoch: 425, Loss: 0.2532, Train: 93.16%, Valid: 83.31%, Test: 83.17%
Epoch: 450, Loss: 0.2505, Train: 93.69%, Valid: 83.18%, Test: 83.34%
Epoch: 475, Loss: 0.2393, Train: 92.87%, Valid: 82.33%, Test: 82.57%
Epoch: 500, Loss: 0.2345, Train: 94.04%, Valid: 83.43%, Test: 83.24%
Epoch: 525, Loss: 0.2274, Train: 94.38%, Valid: 83.51%, Test: 83.37%
Epoch: 550, Loss: 0.2217, Train: 94.71%, Valid: 83.79%, Test: 84.05%
Epoch: 575, Loss: 0.2110, Train: 95.02%, Valid: 83.46%, Test: 83.69%
Epoch: 600, Loss: 0.2117, Train: 94.90%, Valid: 83.31%, Test: 83.28%
Epoch: 625, Loss: 0.2034, Train: 94.16%, Valid: 82.82%, Test: 82.93%
Epoch: 650, Loss: 0.2054, Train: 95.54%, Valid: 83.81%, Test: 83.89%
Epoch: 675, Loss: 0.1899, Train: 94.92%, Valid: 82.54%, Test: 82.36%
Epoch: 700, Loss: 0.1843, Train: 95.58%, Valid: 83.39%, Test: 83.16%
Epoch: 725, Loss: 0.1737, Train: 96.23%, Valid: 83.91%, Test: 83.70%
Epoch: 750, Loss: 0.1738, Train: 96.52%, Valid: 83.88%, Test: 84.00%
Epoch: 775, Loss: 0.1575, Train: 96.86%, Valid: 84.05%, Test: 84.27%
Epoch: 800, Loss: 0.1574, Train: 97.08%, Valid: 83.27%, Test: 83.43%
Epoch: 825, Loss: 0.1350, Train: 95.98%, Valid: 81.95%, Test: 81.95%
Epoch: 850, Loss: 0.1346, Train: 97.37%, Valid: 83.02%, Test: 83.42%
Epoch: 875, Loss: 0.1715, Train: 95.84%, Valid: 81.41%, Test: 82.04%
Epoch: 900, Loss: 0.1359, Train: 97.71%, Valid: 83.25%, Test: 83.41%
Epoch: 925, Loss: 0.1175, Train: 98.15%, Valid: 83.49%, Test: 83.34%
Epoch: 950, Loss: 0.1701, Train: 96.01%, Valid: 81.28%, Test: 81.10%
Epoch: 975, Loss: 0.1072, Train: 98.38%, Valid: 82.97%, Test: 83.08%
Run 01:
Highest Train: 98.67
Highest Valid: 84.32
  Final Train: 96.77
   Final Test: 84.47
All runs:
Highest Train: 98.67, nan
Highest Valid: 84.32, nan
  Final Train: 96.77, nan
   Final Test: 84.47, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.7543, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.4697, Train: 78.10%, Valid: 76.90%, Test: 76.36%
Epoch: 50, Loss: 0.4236, Train: 82.84%, Valid: 79.95%, Test: 79.98%
Epoch: 75, Loss: 0.4038, Train: 84.92%, Valid: 81.01%, Test: 80.86%
Epoch: 100, Loss: 0.3856, Train: 86.04%, Valid: 81.05%, Test: 80.91%
Epoch: 125, Loss: 0.3717, Train: 87.39%, Valid: 81.64%, Test: 81.84%
Epoch: 150, Loss: 0.3546, Train: 88.67%, Valid: 82.73%, Test: 82.08%
Epoch: 175, Loss: 0.3434, Train: 89.73%, Valid: 82.73%, Test: 82.86%
Epoch: 200, Loss: 0.3316, Train: 90.05%, Valid: 82.53%, Test: 83.06%
Epoch: 225, Loss: 0.3271, Train: 90.34%, Valid: 82.39%, Test: 82.40%
Epoch: 250, Loss: 0.3135, Train: 90.40%, Valid: 82.34%, Test: 82.22%
Epoch: 275, Loss: 0.3040, Train: 91.52%, Valid: 83.54%, Test: 82.89%
Epoch: 300, Loss: 0.3034, Train: 91.68%, Valid: 83.13%, Test: 83.05%
Epoch: 325, Loss: 0.2966, Train: 91.69%, Valid: 83.01%, Test: 83.16%
Epoch: 350, Loss: 0.2899, Train: 91.78%, Valid: 82.63%, Test: 83.10%
Epoch: 375, Loss: 0.2837, Train: 92.06%, Valid: 83.38%, Test: 83.10%
Epoch: 400, Loss: 0.2688, Train: 92.86%, Valid: 83.24%, Test: 83.32%
Epoch: 425, Loss: 0.2618, Train: 92.93%, Valid: 83.39%, Test: 83.21%
Epoch: 450, Loss: 0.2583, Train: 93.54%, Valid: 83.62%, Test: 83.14%
Epoch: 475, Loss: 0.2696, Train: 93.20%, Valid: 83.36%, Test: 83.19%
Epoch: 500, Loss: 0.2440, Train: 94.05%, Valid: 83.43%, Test: 83.82%
Epoch: 525, Loss: 0.2484, Train: 93.70%, Valid: 83.32%, Test: 83.51%
Epoch: 550, Loss: 0.2235, Train: 94.17%, Valid: 83.74%, Test: 83.37%
Epoch: 575, Loss: 0.2256, Train: 94.47%, Valid: 83.07%, Test: 83.76%
Epoch: 600, Loss: 0.2124, Train: 94.61%, Valid: 82.84%, Test: 83.14%
Epoch: 625, Loss: 0.2113, Train: 94.74%, Valid: 83.44%, Test: 83.58%
Epoch: 650, Loss: 0.2041, Train: 95.01%, Valid: 83.42%, Test: 83.50%
Epoch: 675, Loss: 0.1981, Train: 95.85%, Valid: 83.81%, Test: 83.76%
Epoch: 700, Loss: 0.1881, Train: 96.11%, Valid: 83.91%, Test: 83.84%
Epoch: 725, Loss: 0.1835, Train: 96.27%, Valid: 83.90%, Test: 83.76%
Epoch: 750, Loss: 0.1937, Train: 95.49%, Valid: 84.09%, Test: 83.36%
Epoch: 775, Loss: 0.1783, Train: 96.72%, Valid: 83.99%, Test: 83.83%
Epoch: 800, Loss: 0.1576, Train: 96.77%, Valid: 84.11%, Test: 83.74%
Epoch: 825, Loss: 0.1634, Train: 96.33%, Valid: 82.92%, Test: 82.81%
Epoch: 850, Loss: 0.1461, Train: 96.79%, Valid: 83.69%, Test: 83.39%
Epoch: 875, Loss: 0.1374, Train: 97.55%, Valid: 83.58%, Test: 83.23%
Epoch: 900, Loss: 0.1293, Train: 97.55%, Valid: 83.66%, Test: 83.89%
Epoch: 925, Loss: 0.2551, Train: 93.36%, Valid: 80.01%, Test: 80.34%
Epoch: 950, Loss: 0.1654, Train: 96.43%, Valid: 82.01%, Test: 82.18%
Epoch: 975, Loss: 0.1268, Train: 97.64%, Valid: 83.19%, Test: 83.24%
Run 01:
Highest Train: 98.18
Highest Valid: 84.36
  Final Train: 95.55
   Final Test: 83.98
All runs:
Highest Train: 98.18, nan
Highest Valid: 84.36, nan
  Final Train: 95.55, nan
   Final Test: 83.98, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.3493, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.4844, Train: 77.60%, Valid: 76.96%, Test: 76.02%
Epoch: 50, Loss: 0.4220, Train: 82.99%, Valid: 80.22%, Test: 80.29%
Epoch: 75, Loss: 0.3960, Train: 85.86%, Valid: 81.32%, Test: 81.56%
Epoch: 100, Loss: 0.3749, Train: 87.87%, Valid: 82.19%, Test: 82.07%
Epoch: 125, Loss: 0.3573, Train: 89.47%, Valid: 82.67%, Test: 82.55%
Epoch: 150, Loss: 0.3424, Train: 90.18%, Valid: 82.89%, Test: 82.68%
Epoch: 175, Loss: 0.3299, Train: 91.11%, Valid: 83.09%, Test: 83.10%
Epoch: 200, Loss: 0.3184, Train: 92.02%, Valid: 83.22%, Test: 83.32%
Epoch: 225, Loss: 0.3182, Train: 90.91%, Valid: 82.59%, Test: 82.93%
Epoch: 250, Loss: 0.2993, Train: 92.68%, Valid: 83.51%, Test: 83.19%
Epoch: 275, Loss: 0.3180, Train: 86.14%, Valid: 78.45%, Test: 78.69%
Epoch: 300, Loss: 0.2919, Train: 92.83%, Valid: 83.16%, Test: 83.04%
Epoch: 325, Loss: 0.2746, Train: 93.76%, Valid: 83.51%, Test: 83.10%
Epoch: 350, Loss: 0.4618, Train: 90.99%, Valid: 82.41%, Test: 82.31%
Epoch: 375, Loss: 0.2753, Train: 93.07%, Valid: 83.06%, Test: 82.99%
Epoch: 400, Loss: 0.2556, Train: 94.27%, Valid: 83.25%, Test: 83.19%
Epoch: 425, Loss: 0.2453, Train: 94.80%, Valid: 83.45%, Test: 83.37%
Epoch: 450, Loss: 0.3204, Train: 88.49%, Valid: 80.27%, Test: 80.49%
Epoch: 475, Loss: 0.2597, Train: 93.51%, Valid: 83.06%, Test: 83.10%
Epoch: 500, Loss: 0.2370, Train: 94.68%, Valid: 83.27%, Test: 83.09%
Epoch: 525, Loss: 0.2271, Train: 95.19%, Valid: 83.37%, Test: 83.23%
Epoch: 550, Loss: 0.2850, Train: 89.97%, Valid: 80.48%, Test: 80.95%
Epoch: 575, Loss: 0.2346, Train: 94.48%, Valid: 83.38%, Test: 83.41%
Epoch: 600, Loss: 0.2164, Train: 95.38%, Valid: 83.27%, Test: 83.04%
Epoch: 625, Loss: 0.2081, Train: 95.77%, Valid: 83.44%, Test: 83.17%
Epoch: 650, Loss: 0.2008, Train: 96.11%, Valid: 83.27%, Test: 83.10%
Epoch: 675, Loss: 0.2983, Train: 91.07%, Valid: 81.66%, Test: 81.69%
Epoch: 700, Loss: 0.2181, Train: 94.48%, Valid: 82.90%, Test: 83.18%
Epoch: 725, Loss: 0.1963, Train: 95.79%, Valid: 83.18%, Test: 83.04%
Epoch: 750, Loss: 0.1880, Train: 96.25%, Valid: 83.51%, Test: 83.19%
Epoch: 775, Loss: 0.3108, Train: 90.18%, Valid: 81.39%, Test: 80.71%
Epoch: 800, Loss: 0.2268, Train: 93.57%, Valid: 82.87%, Test: 82.99%
Epoch: 825, Loss: 0.1893, Train: 95.75%, Valid: 83.10%, Test: 83.31%
Epoch: 850, Loss: 0.1790, Train: 96.34%, Valid: 83.07%, Test: 82.94%
Epoch: 875, Loss: 0.1725, Train: 96.68%, Valid: 83.15%, Test: 82.94%
Epoch: 900, Loss: 0.1668, Train: 96.90%, Valid: 83.27%, Test: 82.93%
Epoch: 925, Loss: 0.1616, Train: 97.14%, Valid: 83.25%, Test: 82.87%
Epoch: 950, Loss: 0.4588, Train: 90.06%, Valid: 80.05%, Test: 79.87%
Epoch: 975, Loss: 0.1970, Train: 94.65%, Valid: 82.49%, Test: 82.91%
Run 01:
Highest Train: 97.30
Highest Valid: 83.85
  Final Train: 93.46
   Final Test: 83.45
All runs:
Highest Train: 97.30, nan
Highest Valid: 83.85, nan
  Final Train: 93.46, nan
   Final Test: 83.45, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.9816, Train: 47.94%, Valid: 48.73%, Test: 47.55%
Epoch: 25, Loss: 0.4979, Train: 77.19%, Valid: 77.01%, Test: 75.92%
Epoch: 50, Loss: 0.4188, Train: 82.77%, Valid: 80.11%, Test: 79.93%
Epoch: 75, Loss: 0.3925, Train: 85.83%, Valid: 81.39%, Test: 81.32%
Epoch: 100, Loss: 0.3738, Train: 87.67%, Valid: 81.79%, Test: 81.70%
Epoch: 125, Loss: 0.3539, Train: 89.32%, Valid: 82.44%, Test: 82.53%
Epoch: 150, Loss: 0.3439, Train: 89.75%, Valid: 81.98%, Test: 82.12%
Epoch: 175, Loss: 0.3298, Train: 91.12%, Valid: 82.85%, Test: 83.11%
Epoch: 200, Loss: 0.3172, Train: 92.10%, Valid: 83.55%, Test: 83.50%
Epoch: 225, Loss: 0.3202, Train: 91.44%, Valid: 83.09%, Test: 83.09%
Epoch: 250, Loss: 0.3004, Train: 92.82%, Valid: 83.54%, Test: 83.54%
Epoch: 275, Loss: 0.3206, Train: 87.91%, Valid: 80.75%, Test: 80.81%
Epoch: 300, Loss: 0.2917, Train: 92.12%, Valid: 83.17%, Test: 83.10%
Epoch: 325, Loss: 0.2770, Train: 93.52%, Valid: 84.11%, Test: 83.50%
Epoch: 350, Loss: 0.2652, Train: 94.17%, Valid: 84.17%, Test: 83.54%
Epoch: 375, Loss: 0.2700, Train: 92.95%, Valid: 83.61%, Test: 83.36%
Epoch: 400, Loss: 0.2519, Train: 94.57%, Valid: 84.21%, Test: 83.87%
Epoch: 425, Loss: 0.2409, Train: 95.21%, Valid: 84.20%, Test: 83.68%
Epoch: 450, Loss: 0.2573, Train: 93.35%, Valid: 83.30%, Test: 83.48%
Epoch: 475, Loss: 0.2317, Train: 95.34%, Valid: 84.58%, Test: 84.23%
Epoch: 500, Loss: 0.2201, Train: 95.86%, Valid: 84.62%, Test: 83.94%
Epoch: 525, Loss: 0.2280, Train: 94.55%, Valid: 83.61%, Test: 83.32%
Epoch: 550, Loss: 0.2078, Train: 96.28%, Valid: 84.65%, Test: 84.08%
Epoch: 575, Loss: 0.2036, Train: 94.28%, Valid: 82.47%, Test: 81.98%
Epoch: 600, Loss: 0.2810, Train: 90.72%, Valid: 81.96%, Test: 81.45%
Epoch: 625, Loss: 0.2203, Train: 94.46%, Valid: 82.97%, Test: 83.08%
Epoch: 650, Loss: 0.2005, Train: 96.05%, Valid: 84.19%, Test: 83.77%
Epoch: 675, Loss: 0.4364, Train: 90.78%, Valid: 81.46%, Test: 80.73%
Epoch: 700, Loss: 0.2175, Train: 94.01%, Valid: 83.32%, Test: 83.60%
Epoch: 725, Loss: 0.1880, Train: 96.22%, Valid: 84.13%, Test: 83.76%
Epoch: 750, Loss: 0.1767, Train: 96.67%, Valid: 84.49%, Test: 83.96%
Epoch: 775, Loss: 0.1672, Train: 96.95%, Valid: 84.45%, Test: 84.39%
Epoch: 800, Loss: 0.3325, Train: 86.81%, Valid: 79.05%, Test: 79.05%
Epoch: 825, Loss: 0.2459, Train: 92.72%, Valid: 82.28%, Test: 82.28%
Epoch: 850, Loss: 0.2027, Train: 95.10%, Valid: 82.73%, Test: 83.19%
Epoch: 875, Loss: 0.1748, Train: 96.63%, Valid: 83.52%, Test: 83.46%
Epoch: 900, Loss: 0.1627, Train: 97.21%, Valid: 83.86%, Test: 83.53%
Epoch: 925, Loss: 0.4548, Train: 84.25%, Valid: 76.17%, Test: 74.91%
Epoch: 950, Loss: 0.2578, Train: 91.91%, Valid: 81.55%, Test: 81.66%
Epoch: 975, Loss: 0.1942, Train: 95.01%, Valid: 82.85%, Test: 83.34%
Run 01:
Highest Train: 97.49
Highest Valid: 84.73
  Final Train: 96.25
   Final Test: 84.36
All runs:
Highest Train: 97.49, nan
Highest Valid: 84.73, nan
  Final Train: 96.25, nan
   Final Test: 84.36, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.2799, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.4803, Train: 77.90%, Valid: 76.69%, Test: 76.54%
Epoch: 50, Loss: 0.4265, Train: 82.90%, Valid: 80.31%, Test: 80.03%
Epoch: 75, Loss: 0.4018, Train: 85.65%, Valid: 81.36%, Test: 81.27%
Epoch: 100, Loss: 0.3786, Train: 87.73%, Valid: 81.90%, Test: 81.81%
Epoch: 125, Loss: 0.3648, Train: 89.50%, Valid: 82.88%, Test: 82.79%
Epoch: 150, Loss: 0.3487, Train: 90.36%, Valid: 82.79%, Test: 82.91%
Epoch: 175, Loss: 0.3475, Train: 90.51%, Valid: 82.99%, Test: 82.75%
Epoch: 200, Loss: 0.3218, Train: 92.09%, Valid: 83.73%, Test: 83.66%
Epoch: 225, Loss: 0.3185, Train: 92.34%, Valid: 83.77%, Test: 83.50%
Epoch: 250, Loss: 0.3162, Train: 88.40%, Valid: 79.98%, Test: 78.94%
Epoch: 275, Loss: 0.2967, Train: 93.02%, Valid: 83.73%, Test: 83.25%
Epoch: 300, Loss: 0.2834, Train: 93.79%, Valid: 83.97%, Test: 83.48%
Epoch: 325, Loss: 0.2909, Train: 92.97%, Valid: 83.55%, Test: 83.70%
Epoch: 350, Loss: 0.2702, Train: 93.95%, Valid: 84.07%, Test: 83.57%
Epoch: 375, Loss: 0.2593, Train: 94.65%, Valid: 84.13%, Test: 83.65%
Epoch: 400, Loss: 0.2836, Train: 92.31%, Valid: 83.38%, Test: 83.25%
Epoch: 425, Loss: 0.2487, Train: 94.78%, Valid: 84.31%, Test: 83.97%
Epoch: 450, Loss: 0.2374, Train: 95.43%, Valid: 84.15%, Test: 83.88%
Epoch: 475, Loss: 0.2422, Train: 94.72%, Valid: 84.18%, Test: 83.91%
Epoch: 500, Loss: 0.2245, Train: 95.64%, Valid: 84.18%, Test: 83.94%
Epoch: 525, Loss: 0.2149, Train: 96.10%, Valid: 84.53%, Test: 84.07%
Epoch: 550, Loss: 0.2426, Train: 92.82%, Valid: 82.60%, Test: 82.37%
Epoch: 575, Loss: 0.2093, Train: 95.89%, Valid: 84.26%, Test: 83.89%
Epoch: 600, Loss: 0.2021, Train: 95.65%, Valid: 83.76%, Test: 83.84%
Epoch: 625, Loss: 0.1977, Train: 95.72%, Valid: 83.92%, Test: 83.81%
Epoch: 650, Loss: 0.1858, Train: 96.88%, Valid: 84.32%, Test: 84.05%
Epoch: 675, Loss: 0.2323, Train: 94.42%, Valid: 83.86%, Test: 83.47%
Epoch: 700, Loss: 0.1824, Train: 96.51%, Valid: 83.50%, Test: 83.34%
Epoch: 725, Loss: 0.2232, Train: 93.48%, Valid: 83.35%, Test: 82.89%
Epoch: 750, Loss: 0.1784, Train: 96.54%, Valid: 84.13%, Test: 83.51%
Epoch: 775, Loss: 0.1660, Train: 97.16%, Valid: 84.28%, Test: 84.13%
Epoch: 800, Loss: 0.1561, Train: 97.34%, Valid: 84.53%, Test: 84.03%
Epoch: 825, Loss: 0.3433, Train: 84.19%, Valid: 77.41%, Test: 77.64%
Epoch: 850, Loss: 0.2342, Train: 92.33%, Valid: 81.11%, Test: 81.71%
Epoch: 875, Loss: 0.3430, Train: 88.39%, Valid: 79.81%, Test: 79.37%
Epoch: 900, Loss: 0.2385, Train: 92.42%, Valid: 81.79%, Test: 81.67%
Epoch: 925, Loss: 0.1944, Train: 94.95%, Valid: 82.33%, Test: 82.18%
Epoch: 950, Loss: 0.1774, Train: 96.06%, Valid: 82.99%, Test: 82.71%
Epoch: 975, Loss: 0.1952, Train: 94.85%, Valid: 82.57%, Test: 83.10%
Run 01:
Highest Train: 97.34
Highest Valid: 84.64
  Final Train: 96.24
   Final Test: 84.15
All runs:
Highest Train: 97.34, nan
Highest Valid: 84.64, nan
  Final Train: 96.24, nan
   Final Test: 84.15, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.8448, Train: 55.91%, Valid: 55.33%, Test: 55.51%
Epoch: 25, Loss: 0.4640, Train: 78.77%, Valid: 77.55%, Test: 77.16%
Epoch: 50, Loss: 0.4153, Train: 83.43%, Valid: 80.70%, Test: 80.33%
Epoch: 75, Loss: 0.3951, Train: 85.63%, Valid: 81.33%, Test: 81.52%
Epoch: 100, Loss: 0.3727, Train: 86.90%, Valid: 81.68%, Test: 81.79%
Epoch: 125, Loss: 0.3661, Train: 88.45%, Valid: 82.45%, Test: 82.57%
Epoch: 150, Loss: 0.3469, Train: 89.25%, Valid: 82.55%, Test: 82.72%
Epoch: 175, Loss: 0.3392, Train: 89.24%, Valid: 82.36%, Test: 82.12%
Epoch: 200, Loss: 0.3250, Train: 90.04%, Valid: 82.26%, Test: 82.51%
Epoch: 225, Loss: 0.3158, Train: 90.67%, Valid: 83.01%, Test: 82.82%
Epoch: 250, Loss: 0.3039, Train: 90.41%, Valid: 82.51%, Test: 82.01%
Epoch: 275, Loss: 0.2972, Train: 91.25%, Valid: 83.01%, Test: 83.23%
Epoch: 300, Loss: 0.2906, Train: 91.61%, Valid: 82.86%, Test: 82.87%
Epoch: 325, Loss: 0.2816, Train: 91.99%, Valid: 83.21%, Test: 83.27%
Epoch: 350, Loss: 0.2734, Train: 91.96%, Valid: 83.18%, Test: 83.02%
Epoch: 375, Loss: 0.2651, Train: 92.61%, Valid: 83.30%, Test: 83.58%
Epoch: 400, Loss: 0.2577, Train: 93.20%, Valid: 83.39%, Test: 83.32%
Epoch: 425, Loss: 0.2547, Train: 92.80%, Valid: 83.30%, Test: 83.10%
Epoch: 450, Loss: 0.2472, Train: 93.21%, Valid: 83.57%, Test: 83.26%
Epoch: 475, Loss: 0.2438, Train: 93.48%, Valid: 83.44%, Test: 83.31%
Epoch: 500, Loss: 0.2337, Train: 93.82%, Valid: 83.70%, Test: 83.32%
Epoch: 525, Loss: 0.2321, Train: 93.55%, Valid: 82.75%, Test: 82.64%
Epoch: 550, Loss: 0.2241, Train: 94.24%, Valid: 83.56%, Test: 83.52%
Epoch: 575, Loss: 0.2199, Train: 94.18%, Valid: 83.74%, Test: 83.40%
Epoch: 600, Loss: 0.2176, Train: 94.89%, Valid: 83.66%, Test: 83.51%
Epoch: 625, Loss: 0.2033, Train: 95.16%, Valid: 83.58%, Test: 83.27%
Epoch: 650, Loss: 0.1992, Train: 95.40%, Valid: 83.77%, Test: 83.66%
Epoch: 675, Loss: 0.1952, Train: 95.51%, Valid: 83.63%, Test: 83.50%
Epoch: 700, Loss: 0.1880, Train: 95.59%, Valid: 83.65%, Test: 83.33%
Epoch: 725, Loss: 0.2033, Train: 95.60%, Valid: 83.76%, Test: 83.73%
Epoch: 750, Loss: 0.1737, Train: 96.25%, Valid: 84.09%, Test: 83.92%
Epoch: 775, Loss: 0.1743, Train: 95.96%, Valid: 84.05%, Test: 83.65%
Epoch: 800, Loss: 0.1750, Train: 96.21%, Valid: 83.69%, Test: 83.30%
Epoch: 825, Loss: 0.1555, Train: 96.87%, Valid: 83.69%, Test: 83.50%
Epoch: 850, Loss: 0.1554, Train: 96.13%, Valid: 83.43%, Test: 83.19%
Epoch: 875, Loss: 0.1480, Train: 96.65%, Valid: 83.55%, Test: 83.52%
Epoch: 900, Loss: 0.1377, Train: 96.89%, Valid: 83.85%, Test: 84.13%
Epoch: 925, Loss: 0.1427, Train: 96.96%, Valid: 83.65%, Test: 83.63%
Epoch: 950, Loss: 0.1782, Train: 92.23%, Valid: 80.39%, Test: 80.26%
Epoch: 975, Loss: 0.1488, Train: 95.35%, Valid: 82.31%, Test: 82.69%
Run 01:
Highest Train: 98.08
Highest Valid: 84.42
  Final Train: 96.71
   Final Test: 83.67
All runs:
Highest Train: 98.08, nan
Highest Valid: 84.42, nan
  Final Train: 96.71, nan
   Final Test: 83.67, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.7175, Train: 55.46%, Valid: 55.51%, Test: 55.55%
Epoch: 25, Loss: 0.4713, Train: 78.54%, Valid: 77.15%, Test: 76.98%
Epoch: 50, Loss: 0.4160, Train: 83.11%, Valid: 80.25%, Test: 80.21%
Epoch: 75, Loss: 0.3930, Train: 85.29%, Valid: 81.27%, Test: 81.43%
Epoch: 100, Loss: 0.3764, Train: 87.04%, Valid: 81.71%, Test: 81.66%
Epoch: 125, Loss: 0.3570, Train: 88.15%, Valid: 81.82%, Test: 82.06%
Epoch: 150, Loss: 0.3417, Train: 89.39%, Valid: 82.73%, Test: 82.94%
Epoch: 175, Loss: 0.3276, Train: 89.95%, Valid: 82.71%, Test: 83.06%
Epoch: 200, Loss: 0.3234, Train: 90.29%, Valid: 82.54%, Test: 82.43%
Epoch: 225, Loss: 0.3062, Train: 91.00%, Valid: 82.82%, Test: 82.93%
Epoch: 250, Loss: 0.3064, Train: 90.36%, Valid: 82.51%, Test: 82.22%
Epoch: 275, Loss: 0.3039, Train: 91.46%, Valid: 82.95%, Test: 82.84%
Epoch: 300, Loss: 0.2825, Train: 91.60%, Valid: 82.91%, Test: 82.53%
Epoch: 325, Loss: 0.2790, Train: 92.20%, Valid: 83.15%, Test: 83.20%
Epoch: 350, Loss: 0.2722, Train: 91.97%, Valid: 83.09%, Test: 82.83%
Epoch: 375, Loss: 0.2746, Train: 92.78%, Valid: 83.37%, Test: 82.94%
Epoch: 400, Loss: 0.2643, Train: 92.16%, Valid: 82.42%, Test: 82.52%
Epoch: 425, Loss: 0.2504, Train: 91.59%, Valid: 82.41%, Test: 81.70%
Epoch: 450, Loss: 0.2490, Train: 92.85%, Valid: 82.57%, Test: 82.42%
Epoch: 475, Loss: 0.2419, Train: 93.30%, Valid: 83.22%, Test: 83.09%
Epoch: 500, Loss: 0.2342, Train: 93.89%, Valid: 83.31%, Test: 83.40%
Epoch: 525, Loss: 0.2272, Train: 93.28%, Valid: 82.02%, Test: 82.58%
Epoch: 550, Loss: 0.2238, Train: 94.13%, Valid: 82.95%, Test: 82.81%
Epoch: 575, Loss: 0.2270, Train: 93.90%, Valid: 83.37%, Test: 82.87%
Epoch: 600, Loss: 0.2282, Train: 94.13%, Valid: 83.59%, Test: 82.97%
Epoch: 625, Loss: 0.2220, Train: 93.47%, Valid: 82.82%, Test: 82.41%
Epoch: 650, Loss: 0.2058, Train: 94.74%, Valid: 83.17%, Test: 83.18%
Epoch: 675, Loss: 0.2054, Train: 94.45%, Valid: 82.67%, Test: 82.81%
Epoch: 700, Loss: 0.2012, Train: 94.47%, Valid: 83.18%, Test: 82.44%
Epoch: 725, Loss: 0.1915, Train: 94.28%, Valid: 83.03%, Test: 82.32%
Epoch: 750, Loss: 0.2000, Train: 95.08%, Valid: 83.04%, Test: 82.91%
Epoch: 775, Loss: 0.2058, Train: 94.80%, Valid: 82.76%, Test: 82.98%
Epoch: 800, Loss: 0.1767, Train: 95.80%, Valid: 83.02%, Test: 82.83%
Epoch: 825, Loss: 0.1719, Train: 95.86%, Valid: 83.58%, Test: 83.24%
Epoch: 850, Loss: 0.1681, Train: 95.64%, Valid: 83.44%, Test: 83.11%
Epoch: 875, Loss: 0.1619, Train: 95.66%, Valid: 83.44%, Test: 83.34%
Epoch: 900, Loss: 0.1730, Train: 95.49%, Valid: 83.23%, Test: 83.16%
Epoch: 925, Loss: 0.1603, Train: 95.46%, Valid: 83.31%, Test: 82.96%
Epoch: 950, Loss: 0.1637, Train: 96.27%, Valid: 83.81%, Test: 83.27%
Epoch: 975, Loss: 0.1543, Train: 96.55%, Valid: 83.27%, Test: 83.28%
Run 01:
Highest Train: 97.17
Highest Valid: 84.08
  Final Train: 96.47
   Final Test: 83.45
All runs:
Highest Train: 97.17, nan
Highest Valid: 84.08, nan
  Final Train: 96.47, nan
   Final Test: 83.45, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.4429, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.5195, Train: 76.24%, Valid: 75.24%, Test: 74.84%
Epoch: 50, Loss: 0.4408, Train: 81.55%, Valid: 79.27%, Test: 79.28%
Epoch: 75, Loss: 0.4187, Train: 83.90%, Valid: 80.96%, Test: 80.72%
Epoch: 100, Loss: 0.4080, Train: 85.34%, Valid: 81.39%, Test: 81.25%
Epoch: 125, Loss: 0.3911, Train: 86.40%, Valid: 81.72%, Test: 81.57%
Epoch: 150, Loss: 0.3811, Train: 87.61%, Valid: 81.97%, Test: 81.79%
Epoch: 175, Loss: 0.3674, Train: 88.38%, Valid: 81.98%, Test: 82.25%
Epoch: 200, Loss: 0.3601, Train: 88.74%, Valid: 82.13%, Test: 82.36%
Epoch: 225, Loss: 0.3425, Train: 90.04%, Valid: 82.94%, Test: 82.58%
Epoch: 250, Loss: 0.3357, Train: 90.48%, Valid: 82.91%, Test: 82.71%
Epoch: 275, Loss: 0.3283, Train: 90.87%, Valid: 83.15%, Test: 82.87%
Epoch: 300, Loss: 0.3237, Train: 90.99%, Valid: 83.16%, Test: 83.12%
Epoch: 325, Loss: 0.3197, Train: 90.93%, Valid: 82.93%, Test: 82.90%
Epoch: 350, Loss: 0.3049, Train: 91.93%, Valid: 83.65%, Test: 83.14%
Epoch: 375, Loss: 0.2995, Train: 92.37%, Valid: 83.15%, Test: 83.10%
Epoch: 400, Loss: 0.2881, Train: 92.63%, Valid: 83.17%, Test: 83.20%
Epoch: 425, Loss: 0.3051, Train: 92.38%, Valid: 83.30%, Test: 82.98%
Epoch: 450, Loss: 0.2752, Train: 92.50%, Valid: 83.38%, Test: 82.79%
Epoch: 475, Loss: 0.2683, Train: 92.74%, Valid: 83.54%, Test: 83.09%
Epoch: 500, Loss: 0.2645, Train: 92.81%, Valid: 82.95%, Test: 82.92%
Epoch: 525, Loss: 0.2745, Train: 93.46%, Valid: 83.71%, Test: 83.10%
Epoch: 550, Loss: 0.2729, Train: 93.08%, Valid: 83.56%, Test: 83.52%
Epoch: 575, Loss: 0.2447, Train: 93.53%, Valid: 83.18%, Test: 82.99%
Epoch: 600, Loss: 0.2439, Train: 94.14%, Valid: 83.75%, Test: 83.26%
Epoch: 625, Loss: 0.2511, Train: 94.23%, Valid: 84.17%, Test: 83.46%
Epoch: 650, Loss: 0.2265, Train: 94.44%, Valid: 83.90%, Test: 83.67%
Epoch: 675, Loss: 0.2278, Train: 94.90%, Valid: 84.12%, Test: 83.71%
Epoch: 700, Loss: 0.2260, Train: 94.39%, Valid: 83.55%, Test: 83.29%
Epoch: 725, Loss: 0.2153, Train: 94.87%, Valid: 83.94%, Test: 83.87%
Epoch: 750, Loss: 0.2063, Train: 94.67%, Valid: 83.22%, Test: 82.90%
Epoch: 775, Loss: 0.2068, Train: 95.28%, Valid: 83.54%, Test: 83.47%
Epoch: 800, Loss: 0.2051, Train: 94.32%, Valid: 82.81%, Test: 82.72%
Epoch: 825, Loss: 0.1957, Train: 95.65%, Valid: 83.85%, Test: 83.58%
Epoch: 850, Loss: 0.1919, Train: 95.91%, Valid: 83.85%, Test: 83.71%
Epoch: 875, Loss: 0.1846, Train: 96.23%, Valid: 83.79%, Test: 84.01%
Epoch: 900, Loss: 0.1862, Train: 95.92%, Valid: 84.07%, Test: 84.02%
Epoch: 925, Loss: 0.2005, Train: 95.14%, Valid: 83.46%, Test: 83.19%
Epoch: 950, Loss: 0.1875, Train: 96.22%, Valid: 83.41%, Test: 83.23%
Epoch: 975, Loss: 0.1616, Train: 96.98%, Valid: 83.70%, Test: 83.46%
Run 01:
Highest Train: 96.98
Highest Valid: 84.36
  Final Train: 95.02
   Final Test: 83.66
All runs:
Highest Train: 96.98, nan
Highest Valid: 84.36, nan
  Final Train: 95.02, nan
   Final Test: 83.66, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.5373, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.5140, Train: 76.38%, Valid: 75.92%, Test: 75.14%
Epoch: 50, Loss: 0.4421, Train: 81.03%, Valid: 79.19%, Test: 79.22%
Epoch: 75, Loss: 0.4192, Train: 83.45%, Valid: 80.47%, Test: 80.48%
Epoch: 100, Loss: 0.4035, Train: 84.98%, Valid: 81.12%, Test: 81.06%
Epoch: 125, Loss: 0.3923, Train: 85.91%, Valid: 81.39%, Test: 81.25%
Epoch: 150, Loss: 0.3758, Train: 86.91%, Valid: 81.76%, Test: 81.50%
Epoch: 175, Loss: 0.3615, Train: 87.83%, Valid: 81.90%, Test: 82.07%
Epoch: 200, Loss: 0.3603, Train: 88.85%, Valid: 82.67%, Test: 82.40%
Epoch: 225, Loss: 0.3390, Train: 89.55%, Valid: 82.82%, Test: 82.84%
Epoch: 250, Loss: 0.3322, Train: 89.20%, Valid: 82.62%, Test: 82.28%
Epoch: 275, Loss: 0.3228, Train: 89.78%, Valid: 82.53%, Test: 82.55%
Epoch: 300, Loss: 0.3182, Train: 90.24%, Valid: 82.65%, Test: 82.56%
Epoch: 325, Loss: 0.3161, Train: 90.28%, Valid: 82.60%, Test: 82.16%
Epoch: 350, Loss: 0.3038, Train: 91.21%, Valid: 82.93%, Test: 82.81%
Epoch: 375, Loss: 0.3068, Train: 91.26%, Valid: 83.27%, Test: 82.86%
Epoch: 400, Loss: 0.2943, Train: 91.19%, Valid: 82.70%, Test: 82.41%
Epoch: 425, Loss: 0.2924, Train: 91.57%, Valid: 83.06%, Test: 82.49%
Epoch: 450, Loss: 0.2858, Train: 91.92%, Valid: 82.90%, Test: 82.86%
Epoch: 475, Loss: 0.2706, Train: 92.33%, Valid: 83.18%, Test: 83.14%
Epoch: 500, Loss: 0.2702, Train: 92.27%, Valid: 83.49%, Test: 83.18%
Epoch: 525, Loss: 0.2613, Train: 92.17%, Valid: 82.90%, Test: 83.08%
Epoch: 550, Loss: 0.2551, Train: 92.88%, Valid: 83.37%, Test: 83.33%
Epoch: 575, Loss: 0.2553, Train: 92.40%, Valid: 83.21%, Test: 82.47%
Epoch: 600, Loss: 0.2436, Train: 93.49%, Valid: 83.43%, Test: 83.49%
Epoch: 625, Loss: 0.2423, Train: 93.38%, Valid: 83.61%, Test: 83.32%
Epoch: 650, Loss: 0.2404, Train: 93.55%, Valid: 83.42%, Test: 83.41%
Epoch: 675, Loss: 0.2337, Train: 93.31%, Valid: 83.42%, Test: 83.10%
Epoch: 700, Loss: 0.2355, Train: 93.40%, Valid: 82.95%, Test: 83.05%
Epoch: 725, Loss: 0.2318, Train: 93.88%, Valid: 83.27%, Test: 83.23%
Epoch: 750, Loss: 0.2124, Train: 94.53%, Valid: 83.31%, Test: 83.23%
Epoch: 775, Loss: 0.2134, Train: 94.68%, Valid: 83.79%, Test: 83.68%
Epoch: 800, Loss: 0.2098, Train: 94.50%, Valid: 83.34%, Test: 83.32%
Epoch: 825, Loss: 0.2004, Train: 93.57%, Valid: 83.03%, Test: 83.03%
Epoch: 850, Loss: 0.2018, Train: 94.97%, Valid: 83.49%, Test: 83.34%
Epoch: 875, Loss: 0.1918, Train: 94.57%, Valid: 83.70%, Test: 83.66%
Epoch: 900, Loss: 0.1847, Train: 95.32%, Valid: 83.85%, Test: 83.51%
Epoch: 925, Loss: 0.1945, Train: 95.54%, Valid: 83.65%, Test: 83.44%
Epoch: 950, Loss: 0.1826, Train: 95.12%, Valid: 83.39%, Test: 83.57%
Epoch: 975, Loss: 0.1819, Train: 94.87%, Valid: 83.36%, Test: 83.30%
Run 01:
Highest Train: 95.80
Highest Valid: 84.24
  Final Train: 94.58
   Final Test: 83.82
All runs:
Highest Train: 95.80, nan
Highest Valid: 84.24, nan
  Final Train: 94.58, nan
   Final Test: 83.82, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.4594, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.4850, Train: 77.54%, Valid: 76.67%, Test: 75.68%
Epoch: 50, Loss: 0.4291, Train: 81.99%, Valid: 79.74%, Test: 79.67%
Epoch: 75, Loss: 0.4101, Train: 83.95%, Valid: 80.83%, Test: 80.59%
Epoch: 100, Loss: 0.3970, Train: 85.12%, Valid: 81.06%, Test: 80.88%
Epoch: 125, Loss: 0.3826, Train: 86.35%, Valid: 81.39%, Test: 81.79%
Epoch: 150, Loss: 0.3739, Train: 86.95%, Valid: 81.30%, Test: 81.50%
Epoch: 175, Loss: 0.3587, Train: 88.12%, Valid: 82.11%, Test: 82.13%
Epoch: 200, Loss: 0.3451, Train: 88.11%, Valid: 81.83%, Test: 81.68%
Epoch: 225, Loss: 0.3454, Train: 89.29%, Valid: 82.55%, Test: 82.74%
Epoch: 250, Loss: 0.3264, Train: 89.71%, Valid: 82.64%, Test: 82.62%
Epoch: 275, Loss: 0.3198, Train: 88.65%, Valid: 81.40%, Test: 81.52%
Epoch: 300, Loss: 0.3093, Train: 90.57%, Valid: 83.07%, Test: 83.15%
Epoch: 325, Loss: 0.3082, Train: 90.78%, Valid: 83.07%, Test: 82.94%
Epoch: 350, Loss: 0.3009, Train: 90.74%, Valid: 82.74%, Test: 83.12%
Epoch: 375, Loss: 0.2891, Train: 91.13%, Valid: 82.85%, Test: 82.93%
Epoch: 400, Loss: 0.2861, Train: 91.04%, Valid: 82.64%, Test: 82.96%
Epoch: 425, Loss: 0.2745, Train: 91.63%, Valid: 82.96%, Test: 83.09%
Epoch: 450, Loss: 0.2809, Train: 91.35%, Valid: 82.67%, Test: 82.84%
Epoch: 475, Loss: 0.2751, Train: 91.76%, Valid: 82.82%, Test: 82.56%
Epoch: 500, Loss: 0.2672, Train: 92.26%, Valid: 82.95%, Test: 82.87%
Epoch: 525, Loss: 0.2600, Train: 92.32%, Valid: 82.95%, Test: 83.03%
Epoch: 550, Loss: 0.2644, Train: 92.33%, Valid: 83.09%, Test: 82.57%
Epoch: 575, Loss: 0.2630, Train: 92.63%, Valid: 82.91%, Test: 83.01%
Epoch: 600, Loss: 0.2604, Train: 92.66%, Valid: 82.80%, Test: 82.93%
Epoch: 625, Loss: 0.2456, Train: 93.12%, Valid: 82.99%, Test: 83.01%
Epoch: 650, Loss: 0.2480, Train: 92.10%, Valid: 82.40%, Test: 82.74%
Epoch: 675, Loss: 0.2582, Train: 93.32%, Valid: 83.19%, Test: 82.91%
Epoch: 700, Loss: 0.2292, Train: 93.33%, Valid: 82.84%, Test: 82.79%
Epoch: 725, Loss: 0.2302, Train: 93.47%, Valid: 83.10%, Test: 83.16%
Epoch: 750, Loss: 0.2372, Train: 92.92%, Valid: 82.75%, Test: 82.57%
Epoch: 775, Loss: 0.2178, Train: 93.65%, Valid: 82.71%, Test: 82.92%
Epoch: 800, Loss: 0.2196, Train: 93.55%, Valid: 82.84%, Test: 82.98%
Epoch: 825, Loss: 0.2261, Train: 93.96%, Valid: 83.12%, Test: 83.07%
Epoch: 850, Loss: 0.2120, Train: 94.00%, Valid: 82.95%, Test: 82.99%
Epoch: 875, Loss: 0.2086, Train: 94.00%, Valid: 82.63%, Test: 82.79%
Epoch: 900, Loss: 0.2141, Train: 93.97%, Valid: 82.52%, Test: 82.68%
Epoch: 925, Loss: 0.2256, Train: 93.50%, Valid: 82.37%, Test: 82.52%
Epoch: 950, Loss: 0.1986, Train: 93.98%, Valid: 82.83%, Test: 82.80%
Epoch: 975, Loss: 0.2022, Train: 94.34%, Valid: 83.05%, Test: 82.82%
Run 01:
Highest Train: 94.62
Highest Valid: 83.53
  Final Train: 93.54
   Final Test: 83.24
All runs:
Highest Train: 94.62, nan
Highest Valid: 83.53, nan
  Final Train: 93.54, nan
   Final Test: 83.24, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.8702, Train: 54.26%, Valid: 53.73%, Test: 54.22%
Epoch: 25, Loss: 0.4687, Train: 78.62%, Valid: 77.71%, Test: 77.16%
Epoch: 50, Loss: 0.4202, Train: 83.01%, Valid: 80.31%, Test: 80.42%
Epoch: 75, Loss: 0.4015, Train: 84.97%, Valid: 81.04%, Test: 80.98%
Epoch: 100, Loss: 0.3826, Train: 86.29%, Valid: 81.78%, Test: 81.66%
Epoch: 125, Loss: 0.3653, Train: 87.67%, Valid: 82.18%, Test: 82.21%
Epoch: 150, Loss: 0.3538, Train: 88.46%, Valid: 82.33%, Test: 82.06%
Epoch: 175, Loss: 0.3401, Train: 89.22%, Valid: 82.58%, Test: 82.52%
Epoch: 200, Loss: 0.3472, Train: 89.47%, Valid: 82.63%, Test: 82.81%
Epoch: 225, Loss: 0.3258, Train: 89.93%, Valid: 83.02%, Test: 82.73%
Epoch: 250, Loss: 0.3216, Train: 90.37%, Valid: 82.43%, Test: 82.37%
Epoch: 275, Loss: 0.3073, Train: 90.36%, Valid: 82.94%, Test: 82.55%
Epoch: 300, Loss: 0.2982, Train: 90.82%, Valid: 83.22%, Test: 83.14%
Epoch: 325, Loss: 0.2884, Train: 91.29%, Valid: 83.03%, Test: 83.14%
Epoch: 350, Loss: 0.2909, Train: 91.17%, Valid: 83.12%, Test: 82.75%
Epoch: 375, Loss: 0.2847, Train: 92.18%, Valid: 83.53%, Test: 83.36%
Epoch: 400, Loss: 0.2744, Train: 92.09%, Valid: 83.18%, Test: 83.11%
Epoch: 425, Loss: 0.2742, Train: 92.59%, Valid: 83.45%, Test: 83.57%
Epoch: 450, Loss: 0.2551, Train: 92.84%, Valid: 83.30%, Test: 83.21%
Epoch: 475, Loss: 0.2471, Train: 93.06%, Valid: 83.60%, Test: 83.46%
Epoch: 500, Loss: 0.2436, Train: 93.10%, Valid: 83.56%, Test: 83.30%
Epoch: 525, Loss: 0.2411, Train: 93.41%, Valid: 83.12%, Test: 83.27%
Epoch: 550, Loss: 0.2377, Train: 94.05%, Valid: 83.64%, Test: 83.49%
Epoch: 575, Loss: 0.2248, Train: 94.09%, Valid: 83.56%, Test: 83.40%
Epoch: 600, Loss: 0.2199, Train: 93.58%, Valid: 83.63%, Test: 83.29%
Epoch: 625, Loss: 0.2120, Train: 94.69%, Valid: 83.47%, Test: 83.77%
Epoch: 650, Loss: 0.2113, Train: 94.77%, Valid: 83.93%, Test: 83.54%
Epoch: 675, Loss: 0.2019, Train: 94.91%, Valid: 83.88%, Test: 83.84%
Epoch: 700, Loss: 0.1965, Train: 95.56%, Valid: 84.32%, Test: 84.12%
Epoch: 725, Loss: 0.1879, Train: 95.24%, Valid: 83.96%, Test: 83.67%
Epoch: 750, Loss: 0.2235, Train: 94.92%, Valid: 83.31%, Test: 83.59%
Epoch: 775, Loss: 0.1953, Train: 96.16%, Valid: 84.15%, Test: 84.08%
Epoch: 800, Loss: 0.1712, Train: 95.94%, Valid: 84.02%, Test: 83.83%
Epoch: 825, Loss: 0.1639, Train: 95.89%, Valid: 83.39%, Test: 83.40%
Epoch: 850, Loss: 0.1621, Train: 92.83%, Valid: 80.12%, Test: 80.30%
Epoch: 875, Loss: 0.1898, Train: 94.89%, Valid: 82.09%, Test: 81.71%
Epoch: 900, Loss: 0.1772, Train: 96.09%, Valid: 83.42%, Test: 83.25%
Epoch: 925, Loss: 0.1421, Train: 96.95%, Valid: 83.99%, Test: 83.97%
Epoch: 950, Loss: 0.1660, Train: 97.12%, Valid: 83.91%, Test: 84.09%
Epoch: 975, Loss: 0.1356, Train: 97.10%, Valid: 83.84%, Test: 83.75%
Run 01:
Highest Train: 97.55
Highest Valid: 84.51
  Final Train: 96.40
   Final Test: 84.40
All runs:
Highest Train: 97.55, nan
Highest Valid: 84.51, nan
  Final Train: 96.40, nan
   Final Test: 84.40, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.8118, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.4891, Train: 77.88%, Valid: 77.08%, Test: 76.64%
Epoch: 50, Loss: 0.4198, Train: 82.89%, Valid: 80.08%, Test: 80.16%
Epoch: 75, Loss: 0.3975, Train: 85.62%, Valid: 81.33%, Test: 81.36%
Epoch: 100, Loss: 0.3784, Train: 87.51%, Valid: 81.90%, Test: 82.12%
Epoch: 125, Loss: 0.3673, Train: 88.83%, Valid: 82.29%, Test: 82.50%
Epoch: 150, Loss: 0.3534, Train: 90.38%, Valid: 83.13%, Test: 83.18%
Epoch: 175, Loss: 0.3471, Train: 90.09%, Valid: 82.43%, Test: 82.83%
Epoch: 200, Loss: 0.3379, Train: 91.59%, Valid: 83.22%, Test: 83.55%
Epoch: 225, Loss: 0.3290, Train: 92.04%, Valid: 83.21%, Test: 83.10%
Epoch: 250, Loss: 0.3240, Train: 92.58%, Valid: 83.31%, Test: 83.32%
Epoch: 275, Loss: 0.3166, Train: 92.70%, Valid: 82.81%, Test: 82.97%
Epoch: 300, Loss: 0.3113, Train: 93.06%, Valid: 83.58%, Test: 83.38%
Epoch: 325, Loss: 0.3024, Train: 93.82%, Valid: 83.68%, Test: 83.46%
Epoch: 350, Loss: 0.3120, Train: 93.38%, Valid: 83.43%, Test: 83.36%
Epoch: 375, Loss: 0.2916, Train: 94.26%, Valid: 83.70%, Test: 83.54%
Epoch: 400, Loss: 0.3446, Train: 91.67%, Valid: 82.49%, Test: 82.19%
Epoch: 425, Loss: 0.2873, Train: 94.01%, Valid: 83.31%, Test: 83.28%
Epoch: 450, Loss: 0.2774, Train: 94.98%, Valid: 83.53%, Test: 83.47%
Epoch: 475, Loss: 0.2949, Train: 88.96%, Valid: 77.90%, Test: 77.31%
Epoch: 500, Loss: 0.2801, Train: 94.09%, Valid: 83.27%, Test: 83.32%
Epoch: 525, Loss: 0.2651, Train: 95.33%, Valid: 83.48%, Test: 83.52%
Epoch: 550, Loss: 0.2584, Train: 95.63%, Valid: 83.74%, Test: 83.39%
Epoch: 575, Loss: 0.2525, Train: 95.77%, Valid: 83.57%, Test: 83.23%
Epoch: 600, Loss: 0.2634, Train: 94.62%, Valid: 83.43%, Test: 83.30%
Epoch: 625, Loss: 0.2472, Train: 95.89%, Valid: 83.72%, Test: 83.66%
Epoch: 650, Loss: 0.2398, Train: 96.19%, Valid: 83.73%, Test: 83.43%
Epoch: 675, Loss: 0.3403, Train: 90.45%, Valid: 81.36%, Test: 81.18%
Epoch: 700, Loss: 0.2548, Train: 94.46%, Valid: 82.96%, Test: 83.31%
Epoch: 725, Loss: 0.2328, Train: 96.09%, Valid: 83.76%, Test: 83.78%
Epoch: 750, Loss: 0.2252, Train: 96.54%, Valid: 83.77%, Test: 83.82%
Epoch: 775, Loss: 0.2194, Train: 96.72%, Valid: 83.90%, Test: 83.69%
Epoch: 800, Loss: 0.2139, Train: 96.86%, Valid: 83.97%, Test: 83.57%
Epoch: 825, Loss: 0.2215, Train: 95.94%, Valid: 83.51%, Test: 83.41%
Epoch: 850, Loss: 0.2076, Train: 97.08%, Valid: 83.94%, Test: 84.02%
Epoch: 875, Loss: 0.2014, Train: 97.26%, Valid: 83.99%, Test: 83.69%
Epoch: 900, Loss: 0.3087, Train: 92.68%, Valid: 81.94%, Test: 81.05%
Epoch: 925, Loss: 0.2179, Train: 95.73%, Valid: 83.38%, Test: 83.39%
Epoch: 950, Loss: 0.1964, Train: 97.22%, Valid: 83.88%, Test: 83.85%
Epoch: 975, Loss: 0.1892, Train: 97.49%, Valid: 83.92%, Test: 84.01%
Run 01:
Highest Train: 97.67
Highest Valid: 84.24
  Final Train: 97.61
   Final Test: 83.87
All runs:
Highest Train: 97.67, nan
Highest Valid: 84.24, nan
  Final Train: 97.61, nan
   Final Test: 83.87, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.8798, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.5471, Train: 71.25%, Valid: 70.86%, Test: 70.50%
Epoch: 50, Loss: 0.4368, Train: 81.35%, Valid: 79.04%, Test: 79.36%
Epoch: 75, Loss: 0.4126, Train: 84.20%, Valid: 80.92%, Test: 80.70%
Epoch: 100, Loss: 0.3941, Train: 86.38%, Valid: 81.68%, Test: 81.50%
Epoch: 125, Loss: 0.3777, Train: 88.30%, Valid: 82.40%, Test: 82.35%
Epoch: 150, Loss: 0.3703, Train: 88.53%, Valid: 81.77%, Test: 81.74%
Epoch: 175, Loss: 0.3543, Train: 90.50%, Valid: 83.22%, Test: 82.93%
Epoch: 200, Loss: 0.3512, Train: 91.03%, Valid: 83.35%, Test: 83.19%
Epoch: 225, Loss: 0.3354, Train: 91.85%, Valid: 83.42%, Test: 83.28%
Epoch: 250, Loss: 0.3286, Train: 92.11%, Valid: 83.28%, Test: 83.15%
Epoch: 275, Loss: 0.3653, Train: 89.32%, Valid: 80.37%, Test: 80.10%
Epoch: 300, Loss: 0.3175, Train: 93.28%, Valid: 83.80%, Test: 83.50%
Epoch: 325, Loss: 0.3068, Train: 93.88%, Valid: 83.72%, Test: 83.35%
Epoch: 350, Loss: 0.3050, Train: 93.26%, Valid: 83.36%, Test: 83.01%
Epoch: 375, Loss: 0.2940, Train: 94.50%, Valid: 83.73%, Test: 83.12%
Epoch: 400, Loss: 0.3153, Train: 92.81%, Valid: 83.05%, Test: 82.87%
Epoch: 425, Loss: 0.2862, Train: 94.66%, Valid: 84.00%, Test: 83.70%
Epoch: 450, Loss: 0.2776, Train: 95.23%, Valid: 84.03%, Test: 83.53%
Epoch: 475, Loss: 0.2719, Train: 95.36%, Valid: 83.50%, Test: 83.52%
Epoch: 500, Loss: 0.2746, Train: 94.85%, Valid: 83.55%, Test: 83.46%
Epoch: 525, Loss: 0.2613, Train: 95.94%, Valid: 84.12%, Test: 83.91%
Epoch: 550, Loss: 0.2902, Train: 94.88%, Valid: 83.68%, Test: 83.47%
Epoch: 575, Loss: 0.2524, Train: 96.23%, Valid: 84.22%, Test: 84.23%
Epoch: 600, Loss: 0.2484, Train: 96.08%, Valid: 84.11%, Test: 83.86%
Epoch: 625, Loss: 0.2477, Train: 95.42%, Valid: 83.75%, Test: 83.54%
Epoch: 650, Loss: 0.2337, Train: 96.87%, Valid: 84.20%, Test: 84.00%
Epoch: 675, Loss: 0.2314, Train: 96.76%, Valid: 84.19%, Test: 83.99%
Epoch: 700, Loss: 0.3539, Train: 88.14%, Valid: 79.73%, Test: 78.55%
Epoch: 725, Loss: 0.2488, Train: 94.90%, Valid: 82.55%, Test: 82.29%
Epoch: 750, Loss: 0.2240, Train: 96.85%, Valid: 83.85%, Test: 83.71%
Epoch: 775, Loss: 0.2581, Train: 95.86%, Valid: 83.30%, Test: 83.28%
Epoch: 800, Loss: 0.2176, Train: 96.88%, Valid: 84.32%, Test: 83.92%
Epoch: 825, Loss: 0.2071, Train: 97.48%, Valid: 84.45%, Test: 84.17%
Epoch: 850, Loss: 0.2517, Train: 96.17%, Valid: 83.19%, Test: 83.40%
Epoch: 875, Loss: 0.2081, Train: 97.03%, Valid: 84.57%, Test: 84.16%
Epoch: 900, Loss: 0.1952, Train: 97.56%, Valid: 84.59%, Test: 84.60%
Epoch: 925, Loss: 0.1888, Train: 97.73%, Valid: 84.43%, Test: 84.34%
Epoch: 950, Loss: 0.3566, Train: 83.99%, Valid: 75.66%, Test: 75.88%
Epoch: 975, Loss: 0.2624, Train: 93.58%, Valid: 81.17%, Test: 81.27%
Run 01:
Highest Train: 97.75
Highest Valid: 84.70
  Final Train: 97.61
   Final Test: 84.51
All runs:
Highest Train: 97.75, nan
Highest Valid: 84.70, nan
  Final Train: 97.61, nan
   Final Test: 84.51, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.0361, Train: 54.38%, Valid: 53.60%, Test: 53.97%
Epoch: 25, Loss: 0.4813, Train: 77.94%, Valid: 77.40%, Test: 76.69%
Epoch: 50, Loss: 0.4152, Train: 83.34%, Valid: 80.59%, Test: 80.40%
Epoch: 75, Loss: 0.3898, Train: 86.25%, Valid: 81.80%, Test: 81.74%
Epoch: 100, Loss: 0.3700, Train: 88.55%, Valid: 82.23%, Test: 82.49%
Epoch: 125, Loss: 0.3558, Train: 89.94%, Valid: 82.88%, Test: 82.86%
Epoch: 150, Loss: 0.3445, Train: 91.18%, Valid: 83.40%, Test: 83.45%
Epoch: 175, Loss: 0.3368, Train: 91.79%, Valid: 83.52%, Test: 83.64%
Epoch: 200, Loss: 0.3287, Train: 92.28%, Valid: 83.02%, Test: 83.23%
Epoch: 225, Loss: 0.3185, Train: 93.10%, Valid: 83.79%, Test: 83.52%
Epoch: 250, Loss: 0.3215, Train: 92.78%, Valid: 83.37%, Test: 83.36%
Epoch: 275, Loss: 0.3058, Train: 93.74%, Valid: 83.82%, Test: 83.39%
Epoch: 300, Loss: 0.3405, Train: 89.72%, Valid: 80.38%, Test: 79.80%
Epoch: 325, Loss: 0.2956, Train: 94.12%, Valid: 83.76%, Test: 83.60%
Epoch: 350, Loss: 0.2846, Train: 94.83%, Valid: 84.11%, Test: 83.68%
Epoch: 375, Loss: 0.3403, Train: 93.15%, Valid: 83.48%, Test: 83.29%
Epoch: 400, Loss: 0.2775, Train: 94.62%, Valid: 83.82%, Test: 83.58%
Epoch: 425, Loss: 0.2667, Train: 95.41%, Valid: 84.36%, Test: 83.97%
Epoch: 450, Loss: 0.2590, Train: 95.75%, Valid: 84.39%, Test: 84.03%
Epoch: 475, Loss: 0.2825, Train: 93.39%, Valid: 81.98%, Test: 82.07%
Epoch: 500, Loss: 0.2511, Train: 95.93%, Valid: 84.09%, Test: 83.82%
Epoch: 525, Loss: 0.2416, Train: 96.26%, Valid: 84.55%, Test: 84.12%
Epoch: 550, Loss: 0.2734, Train: 94.17%, Valid: 83.21%, Test: 83.04%
Epoch: 575, Loss: 0.2317, Train: 96.69%, Valid: 84.30%, Test: 84.12%
Epoch: 600, Loss: 0.2399, Train: 95.16%, Valid: 83.36%, Test: 83.19%
Epoch: 625, Loss: 0.2219, Train: 96.92%, Valid: 84.41%, Test: 84.31%
Epoch: 650, Loss: 0.2377, Train: 96.70%, Valid: 84.42%, Test: 84.00%
Epoch: 675, Loss: 0.2187, Train: 96.31%, Valid: 83.99%, Test: 83.52%
Epoch: 700, Loss: 0.2048, Train: 97.31%, Valid: 84.47%, Test: 84.30%
Epoch: 725, Loss: 0.3177, Train: 87.38%, Valid: 78.29%, Test: 78.18%
Epoch: 750, Loss: 0.2524, Train: 94.14%, Valid: 82.00%, Test: 81.72%
Epoch: 775, Loss: 0.2273, Train: 95.88%, Valid: 82.88%, Test: 82.55%
Epoch: 800, Loss: 0.2677, Train: 93.07%, Valid: 81.85%, Test: 81.27%
Epoch: 825, Loss: 0.2256, Train: 95.55%, Valid: 83.06%, Test: 82.38%
Epoch: 850, Loss: 0.2089, Train: 96.68%, Valid: 83.38%, Test: 83.02%
Epoch: 875, Loss: 0.2002, Train: 97.16%, Valid: 83.82%, Test: 83.27%
Epoch: 900, Loss: 0.1927, Train: 97.34%, Valid: 83.90%, Test: 83.66%
Epoch: 925, Loss: 0.1845, Train: 97.56%, Valid: 84.13%, Test: 83.94%
Epoch: 950, Loss: 0.2729, Train: 92.91%, Valid: 81.10%, Test: 80.66%
Epoch: 975, Loss: 0.1909, Train: 96.33%, Valid: 83.40%, Test: 83.53%
Run 01:
Highest Train: 97.57
Highest Valid: 84.85
  Final Train: 96.97
   Final Test: 84.19
All runs:
Highest Train: 97.57, nan
Highest Valid: 84.85, nan
  Final Train: 96.97, nan
   Final Test: 84.19, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.5307, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.5224, Train: 75.96%, Valid: 75.53%, Test: 74.80%
Epoch: 50, Loss: 0.4428, Train: 81.02%, Valid: 78.71%, Test: 78.85%
Epoch: 75, Loss: 0.4148, Train: 83.16%, Valid: 80.51%, Test: 80.46%
Epoch: 100, Loss: 0.3976, Train: 85.25%, Valid: 81.30%, Test: 81.31%
Epoch: 125, Loss: 0.3848, Train: 86.91%, Valid: 82.02%, Test: 81.76%
Epoch: 150, Loss: 0.3708, Train: 87.98%, Valid: 82.24%, Test: 82.11%
Epoch: 175, Loss: 0.3586, Train: 88.97%, Valid: 82.78%, Test: 82.61%
Epoch: 200, Loss: 0.3516, Train: 89.68%, Valid: 82.50%, Test: 82.41%
Epoch: 225, Loss: 0.3454, Train: 90.55%, Valid: 83.14%, Test: 83.20%
Epoch: 250, Loss: 0.3386, Train: 90.93%, Valid: 82.85%, Test: 83.09%
Epoch: 275, Loss: 0.3283, Train: 91.15%, Valid: 82.51%, Test: 82.46%
Epoch: 300, Loss: 0.3204, Train: 91.49%, Valid: 83.17%, Test: 82.97%
Epoch: 325, Loss: 0.3139, Train: 92.14%, Valid: 83.09%, Test: 83.14%
Epoch: 350, Loss: 0.3084, Train: 92.08%, Valid: 82.79%, Test: 82.55%
Epoch: 375, Loss: 0.3033, Train: 92.57%, Valid: 83.04%, Test: 82.70%
Epoch: 400, Loss: 0.3001, Train: 93.11%, Valid: 83.09%, Test: 83.33%
Epoch: 425, Loss: 0.2938, Train: 92.11%, Valid: 82.59%, Test: 82.63%
Epoch: 450, Loss: 0.2885, Train: 92.59%, Valid: 82.55%, Test: 82.94%
Epoch: 475, Loss: 0.2833, Train: 93.86%, Valid: 83.41%, Test: 83.81%
Epoch: 500, Loss: 0.2770, Train: 93.84%, Valid: 83.02%, Test: 83.18%
Epoch: 525, Loss: 0.2774, Train: 93.04%, Valid: 82.80%, Test: 82.59%
Epoch: 550, Loss: 0.2746, Train: 93.68%, Valid: 83.34%, Test: 83.13%
Epoch: 575, Loss: 0.2671, Train: 93.84%, Valid: 83.26%, Test: 83.14%
Epoch: 600, Loss: 0.2615, Train: 94.52%, Valid: 83.71%, Test: 83.46%
Epoch: 625, Loss: 0.2568, Train: 94.49%, Valid: 83.18%, Test: 83.16%
Epoch: 650, Loss: 0.2501, Train: 94.73%, Valid: 83.52%, Test: 83.43%
Epoch: 675, Loss: 0.2552, Train: 94.69%, Valid: 83.43%, Test: 83.35%
Epoch: 700, Loss: 0.2470, Train: 94.63%, Valid: 83.72%, Test: 83.28%
Epoch: 725, Loss: 0.2436, Train: 94.83%, Valid: 83.47%, Test: 83.33%
Epoch: 750, Loss: 0.2427, Train: 95.16%, Valid: 83.96%, Test: 83.50%
Epoch: 775, Loss: 0.2436, Train: 95.16%, Valid: 83.88%, Test: 83.51%
Epoch: 800, Loss: 0.2603, Train: 95.07%, Valid: 83.84%, Test: 83.74%
Epoch: 825, Loss: 0.2344, Train: 95.28%, Valid: 83.56%, Test: 83.16%
Epoch: 850, Loss: 0.2203, Train: 95.49%, Valid: 83.55%, Test: 83.10%
Epoch: 875, Loss: 0.2166, Train: 96.00%, Valid: 83.38%, Test: 83.60%
Epoch: 900, Loss: 0.2125, Train: 95.95%, Valid: 83.45%, Test: 83.47%
Epoch: 925, Loss: 0.2093, Train: 96.14%, Valid: 83.96%, Test: 83.70%
Epoch: 950, Loss: 0.2065, Train: 96.33%, Valid: 83.76%, Test: 83.65%
Epoch: 975, Loss: 0.2159, Train: 96.68%, Valid: 83.78%, Test: 83.52%
Run 01:
Highest Train: 96.83
Highest Valid: 84.35
  Final Train: 95.92
   Final Test: 83.79
All runs:
Highest Train: 96.83, nan
Highest Valid: 84.35, nan
  Final Train: 95.92, nan
   Final Test: 83.79, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.9603, Train: 54.14%, Valid: 55.12%, Test: 54.83%
Epoch: 25, Loss: 0.4912, Train: 77.68%, Valid: 77.16%, Test: 76.32%
Epoch: 50, Loss: 0.4244, Train: 82.18%, Valid: 79.99%, Test: 79.74%
Epoch: 75, Loss: 0.4030, Train: 84.69%, Valid: 80.95%, Test: 80.84%
Epoch: 100, Loss: 0.3874, Train: 86.56%, Valid: 81.89%, Test: 81.78%
Epoch: 125, Loss: 0.3740, Train: 87.67%, Valid: 81.78%, Test: 81.77%
Epoch: 150, Loss: 0.3660, Train: 88.70%, Valid: 82.38%, Test: 82.39%
Epoch: 175, Loss: 0.3583, Train: 89.43%, Valid: 82.53%, Test: 82.53%
Epoch: 200, Loss: 0.3466, Train: 89.45%, Valid: 82.10%, Test: 81.90%
Epoch: 225, Loss: 0.3409, Train: 90.92%, Valid: 83.01%, Test: 83.10%
Epoch: 250, Loss: 0.3335, Train: 91.38%, Valid: 83.12%, Test: 83.16%
Epoch: 275, Loss: 0.3261, Train: 90.88%, Valid: 82.64%, Test: 82.29%
Epoch: 300, Loss: 0.3227, Train: 91.90%, Valid: 83.04%, Test: 83.20%
Epoch: 325, Loss: 0.3163, Train: 92.45%, Valid: 83.57%, Test: 83.42%
Epoch: 350, Loss: 0.3085, Train: 92.51%, Valid: 83.09%, Test: 83.16%
Epoch: 375, Loss: 0.3046, Train: 92.78%, Valid: 83.48%, Test: 83.30%
Epoch: 400, Loss: 0.3028, Train: 92.77%, Valid: 83.27%, Test: 82.77%
Epoch: 425, Loss: 0.2956, Train: 92.98%, Valid: 83.23%, Test: 83.37%
Epoch: 450, Loss: 0.2887, Train: 93.22%, Valid: 82.89%, Test: 82.93%
Epoch: 475, Loss: 0.2869, Train: 93.82%, Valid: 83.89%, Test: 83.79%
Epoch: 500, Loss: 0.2774, Train: 93.86%, Valid: 83.63%, Test: 83.21%
Epoch: 525, Loss: 0.2753, Train: 94.17%, Valid: 83.60%, Test: 83.34%
Epoch: 550, Loss: 0.2680, Train: 94.24%, Valid: 83.66%, Test: 83.33%
Epoch: 575, Loss: 0.2591, Train: 94.83%, Valid: 84.05%, Test: 83.66%
Epoch: 600, Loss: 0.2564, Train: 94.69%, Valid: 83.80%, Test: 83.38%
Epoch: 625, Loss: 0.2507, Train: 95.11%, Valid: 83.68%, Test: 83.79%
Epoch: 650, Loss: 0.2438, Train: 95.36%, Valid: 83.38%, Test: 83.24%
Epoch: 675, Loss: 0.2362, Train: 95.83%, Valid: 84.00%, Test: 83.81%
Epoch: 700, Loss: 0.2397, Train: 95.02%, Valid: 83.82%, Test: 83.15%
Epoch: 725, Loss: 0.2327, Train: 95.81%, Valid: 84.04%, Test: 83.81%
Epoch: 750, Loss: 0.2211, Train: 96.05%, Valid: 84.30%, Test: 83.84%
Epoch: 775, Loss: 0.2262, Train: 95.76%, Valid: 83.68%, Test: 84.02%
Epoch: 800, Loss: 0.2250, Train: 95.99%, Valid: 83.86%, Test: 83.95%
Epoch: 825, Loss: 0.2058, Train: 96.69%, Valid: 84.05%, Test: 83.95%
Epoch: 850, Loss: 0.2142, Train: 95.58%, Valid: 82.97%, Test: 82.43%
Epoch: 875, Loss: 0.2112, Train: 95.32%, Valid: 82.99%, Test: 83.18%
Epoch: 900, Loss: 0.1911, Train: 96.32%, Valid: 83.34%, Test: 83.52%
Epoch: 925, Loss: 0.1854, Train: 96.79%, Valid: 83.47%, Test: 83.25%
Epoch: 950, Loss: 0.2836, Train: 91.77%, Valid: 80.05%, Test: 79.91%
Epoch: 975, Loss: 0.2362, Train: 94.51%, Valid: 81.30%, Test: 81.65%
Run 01:
Highest Train: 97.28
Highest Valid: 84.45
  Final Train: 96.97
   Final Test: 84.06
All runs:
Highest Train: 97.28, nan
Highest Valid: 84.45, nan
  Final Train: 96.97, nan
   Final Test: 84.06, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.1575, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.6447, Train: 59.01%, Valid: 58.83%, Test: 58.45%
Epoch: 50, Loss: 0.4855, Train: 77.91%, Valid: 76.85%, Test: 76.49%
Epoch: 75, Loss: 0.4353, Train: 81.59%, Valid: 79.01%, Test: 79.04%
Epoch: 100, Loss: 0.4168, Train: 83.53%, Valid: 80.61%, Test: 80.26%
Epoch: 125, Loss: 0.4062, Train: 85.11%, Valid: 81.03%, Test: 81.08%
Epoch: 150, Loss: 0.3969, Train: 86.03%, Valid: 81.44%, Test: 81.45%
Epoch: 175, Loss: 0.3893, Train: 86.69%, Valid: 81.46%, Test: 81.52%
Epoch: 200, Loss: 0.3844, Train: 87.71%, Valid: 81.97%, Test: 81.84%
Epoch: 225, Loss: 0.3771, Train: 88.18%, Valid: 82.43%, Test: 82.29%
Epoch: 250, Loss: 0.3723, Train: 88.94%, Valid: 82.34%, Test: 82.74%
Epoch: 275, Loss: 0.3658, Train: 89.46%, Valid: 82.65%, Test: 82.64%
Epoch: 300, Loss: 0.3600, Train: 89.98%, Valid: 82.89%, Test: 82.64%
Epoch: 325, Loss: 0.3575, Train: 90.46%, Valid: 83.04%, Test: 82.89%
Epoch: 350, Loss: 0.3499, Train: 91.09%, Valid: 83.27%, Test: 83.14%
Epoch: 375, Loss: 0.3466, Train: 91.26%, Valid: 83.08%, Test: 83.13%
Epoch: 400, Loss: 0.3415, Train: 91.33%, Valid: 82.90%, Test: 82.92%
Epoch: 425, Loss: 0.3426, Train: 91.33%, Valid: 82.81%, Test: 82.41%
Epoch: 450, Loss: 0.3355, Train: 92.29%, Valid: 83.37%, Test: 83.23%
Epoch: 475, Loss: 0.3284, Train: 92.57%, Valid: 83.31%, Test: 83.54%
Epoch: 500, Loss: 0.3325, Train: 92.36%, Valid: 83.28%, Test: 82.85%
Epoch: 525, Loss: 0.3220, Train: 92.89%, Valid: 83.35%, Test: 83.31%
Epoch: 550, Loss: 0.3221, Train: 93.38%, Valid: 83.59%, Test: 83.23%
Epoch: 575, Loss: 0.3149, Train: 93.54%, Valid: 83.58%, Test: 83.33%
Epoch: 600, Loss: 0.3083, Train: 93.39%, Valid: 83.14%, Test: 82.91%
Epoch: 625, Loss: 0.3058, Train: 93.57%, Valid: 83.20%, Test: 82.98%
Epoch: 650, Loss: 0.3044, Train: 94.10%, Valid: 83.60%, Test: 83.39%
Epoch: 675, Loss: 0.3008, Train: 94.48%, Valid: 83.61%, Test: 83.35%
Epoch: 700, Loss: 0.2952, Train: 94.45%, Valid: 83.20%, Test: 83.20%
Epoch: 725, Loss: 0.2864, Train: 94.50%, Valid: 83.08%, Test: 82.76%
Epoch: 750, Loss: 0.2839, Train: 94.70%, Valid: 83.45%, Test: 83.21%
Epoch: 775, Loss: 0.2769, Train: 95.13%, Valid: 83.96%, Test: 83.51%
Epoch: 800, Loss: 0.2749, Train: 94.98%, Valid: 83.42%, Test: 83.28%
Epoch: 825, Loss: 0.2701, Train: 95.30%, Valid: 83.27%, Test: 83.37%
Epoch: 850, Loss: 0.2651, Train: 95.57%, Valid: 83.21%, Test: 83.43%
Epoch: 875, Loss: 0.2638, Train: 95.54%, Valid: 83.41%, Test: 83.81%
Epoch: 900, Loss: 0.2578, Train: 95.72%, Valid: 83.38%, Test: 83.42%
Epoch: 925, Loss: 0.2587, Train: 96.19%, Valid: 83.46%, Test: 83.77%
Epoch: 950, Loss: 0.2498, Train: 96.06%, Valid: 83.43%, Test: 83.68%
Epoch: 975, Loss: 0.2417, Train: 96.29%, Valid: 83.16%, Test: 83.60%
Run 01:
Highest Train: 96.69
Highest Valid: 84.02
  Final Train: 95.16
   Final Test: 83.34
All runs:
Highest Train: 96.69, nan
Highest Valid: 84.02, nan
  Final Train: 95.16, nan
   Final Test: 83.34, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.7644, Train: 53.05%, Valid: 52.07%, Test: 52.91%
Epoch: 25, Loss: 0.5288, Train: 76.32%, Valid: 75.88%, Test: 75.27%
Epoch: 50, Loss: 0.4392, Train: 81.12%, Valid: 79.06%, Test: 78.84%
Epoch: 75, Loss: 0.4128, Train: 83.77%, Valid: 80.75%, Test: 80.47%
Epoch: 100, Loss: 0.3966, Train: 85.52%, Valid: 81.45%, Test: 81.51%
Epoch: 125, Loss: 0.3848, Train: 86.84%, Valid: 82.04%, Test: 81.99%
Epoch: 150, Loss: 0.3750, Train: 87.45%, Valid: 81.73%, Test: 81.73%
Epoch: 175, Loss: 0.3670, Train: 88.62%, Valid: 82.69%, Test: 82.47%
Epoch: 200, Loss: 0.3582, Train: 89.31%, Valid: 82.74%, Test: 82.59%
Epoch: 225, Loss: 0.3532, Train: 89.90%, Valid: 82.69%, Test: 82.70%
Epoch: 250, Loss: 0.3457, Train: 89.77%, Valid: 82.53%, Test: 82.32%
Epoch: 275, Loss: 0.3466, Train: 89.96%, Valid: 82.08%, Test: 81.97%
Epoch: 300, Loss: 0.3381, Train: 90.55%, Valid: 83.09%, Test: 83.02%
Epoch: 325, Loss: 0.3314, Train: 91.19%, Valid: 83.19%, Test: 82.90%
Epoch: 350, Loss: 0.3299, Train: 91.18%, Valid: 83.10%, Test: 82.62%
Epoch: 375, Loss: 0.3294, Train: 90.62%, Valid: 82.23%, Test: 82.21%
Epoch: 400, Loss: 0.3163, Train: 91.90%, Valid: 82.91%, Test: 83.07%
Epoch: 425, Loss: 0.3121, Train: 92.44%, Valid: 83.71%, Test: 83.33%
Epoch: 450, Loss: 0.3130, Train: 92.07%, Valid: 83.06%, Test: 82.95%
Epoch: 475, Loss: 0.3036, Train: 92.43%, Valid: 83.04%, Test: 82.70%
Epoch: 500, Loss: 0.2977, Train: 92.86%, Valid: 83.38%, Test: 83.40%
Epoch: 525, Loss: 0.2907, Train: 93.47%, Valid: 83.64%, Test: 83.23%
Epoch: 550, Loss: 0.2900, Train: 93.49%, Valid: 83.63%, Test: 83.27%
Epoch: 575, Loss: 0.2821, Train: 93.34%, Valid: 82.87%, Test: 82.82%
Epoch: 600, Loss: 0.2789, Train: 93.75%, Valid: 83.42%, Test: 83.42%
Epoch: 625, Loss: 0.2710, Train: 94.02%, Valid: 83.73%, Test: 83.50%
Epoch: 650, Loss: 0.2699, Train: 93.95%, Valid: 83.54%, Test: 83.31%
Epoch: 675, Loss: 0.2783, Train: 94.15%, Valid: 83.58%, Test: 83.51%
Epoch: 700, Loss: 0.2608, Train: 94.57%, Valid: 83.50%, Test: 83.51%
Epoch: 725, Loss: 0.2625, Train: 94.31%, Valid: 83.34%, Test: 83.28%
Epoch: 750, Loss: 0.2550, Train: 94.26%, Valid: 83.31%, Test: 83.01%
Epoch: 775, Loss: 0.2516, Train: 95.03%, Valid: 83.69%, Test: 83.72%
Epoch: 800, Loss: 0.2403, Train: 94.96%, Valid: 83.40%, Test: 83.28%
Epoch: 825, Loss: 0.2422, Train: 95.11%, Valid: 83.30%, Test: 83.16%
Epoch: 850, Loss: 0.2359, Train: 94.64%, Valid: 83.16%, Test: 83.20%
Epoch: 875, Loss: 0.2310, Train: 95.18%, Valid: 83.31%, Test: 83.13%
Epoch: 900, Loss: 0.2258, Train: 95.81%, Valid: 83.68%, Test: 83.60%
Epoch: 925, Loss: 0.2255, Train: 96.07%, Valid: 84.14%, Test: 83.81%
Epoch: 950, Loss: 0.2149, Train: 95.21%, Valid: 83.22%, Test: 82.86%
Epoch: 975, Loss: 0.2069, Train: 96.73%, Valid: 83.95%, Test: 83.91%
Run 01:
Highest Train: 96.97
Highest Valid: 84.52
  Final Train: 96.74
   Final Test: 83.99
All runs:
Highest Train: 96.97, nan
Highest Valid: 84.52, nan
  Final Train: 96.74, nan
   Final Test: 83.99, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.2248, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.7252, Train: 57.63%, Valid: 57.52%, Test: 57.17%
Epoch: 50, Loss: 0.4679, Train: 78.56%, Valid: 77.08%, Test: 76.99%
Epoch: 75, Loss: 0.4348, Train: 82.26%, Valid: 79.73%, Test: 79.72%
Epoch: 100, Loss: 0.4184, Train: 83.73%, Valid: 80.67%, Test: 80.60%
Epoch: 125, Loss: 0.4082, Train: 84.98%, Valid: 81.13%, Test: 81.13%
Epoch: 150, Loss: 0.3999, Train: 85.69%, Valid: 80.95%, Test: 80.97%
Epoch: 175, Loss: 0.3898, Train: 86.57%, Valid: 81.50%, Test: 81.33%
Epoch: 200, Loss: 0.3801, Train: 87.55%, Valid: 81.97%, Test: 81.64%
Epoch: 225, Loss: 0.3734, Train: 88.40%, Valid: 82.36%, Test: 82.14%
Epoch: 250, Loss: 0.3673, Train: 89.01%, Valid: 82.47%, Test: 82.67%
Epoch: 275, Loss: 0.3594, Train: 89.70%, Valid: 82.91%, Test: 82.56%
Epoch: 300, Loss: 0.3559, Train: 89.93%, Valid: 82.50%, Test: 82.67%
Epoch: 325, Loss: 0.3479, Train: 90.32%, Valid: 82.96%, Test: 82.61%
Epoch: 350, Loss: 0.3418, Train: 90.56%, Valid: 82.85%, Test: 82.51%
Epoch: 375, Loss: 0.3417, Train: 91.02%, Valid: 83.20%, Test: 82.63%
Epoch: 400, Loss: 0.3365, Train: 91.68%, Valid: 83.22%, Test: 83.21%
Epoch: 425, Loss: 0.3298, Train: 91.97%, Valid: 83.36%, Test: 82.99%
Epoch: 450, Loss: 0.3254, Train: 92.14%, Valid: 83.68%, Test: 83.23%
Epoch: 475, Loss: 0.3244, Train: 92.07%, Valid: 82.88%, Test: 82.69%
Epoch: 500, Loss: 0.3109, Train: 92.52%, Valid: 83.62%, Test: 83.29%
Epoch: 525, Loss: 0.3053, Train: 93.21%, Valid: 83.82%, Test: 83.40%
Epoch: 550, Loss: 0.3088, Train: 93.09%, Valid: 83.52%, Test: 83.30%
Epoch: 575, Loss: 0.2985, Train: 93.04%, Valid: 83.53%, Test: 83.01%
Epoch: 600, Loss: 0.2959, Train: 93.44%, Valid: 83.54%, Test: 83.37%
Epoch: 625, Loss: 0.2957, Train: 93.71%, Valid: 83.89%, Test: 83.54%
Epoch: 650, Loss: 0.2877, Train: 93.59%, Valid: 83.72%, Test: 83.11%
Epoch: 675, Loss: 0.2835, Train: 93.57%, Valid: 83.64%, Test: 82.97%
Epoch: 700, Loss: 0.2737, Train: 94.02%, Valid: 83.81%, Test: 83.24%
Epoch: 725, Loss: 0.2703, Train: 94.50%, Valid: 84.02%, Test: 83.39%
Epoch: 750, Loss: 0.2692, Train: 94.88%, Valid: 83.96%, Test: 83.92%
Epoch: 775, Loss: 0.2609, Train: 95.08%, Valid: 84.00%, Test: 84.10%
Epoch: 800, Loss: 0.2682, Train: 94.97%, Valid: 83.91%, Test: 83.91%
Epoch: 825, Loss: 0.2630, Train: 94.69%, Valid: 83.95%, Test: 83.68%
Epoch: 850, Loss: 0.2508, Train: 95.06%, Valid: 83.58%, Test: 83.55%
Epoch: 875, Loss: 0.2476, Train: 95.25%, Valid: 84.31%, Test: 84.15%
Epoch: 900, Loss: 0.2425, Train: 95.63%, Valid: 84.42%, Test: 84.28%
Epoch: 925, Loss: 0.2417, Train: 95.53%, Valid: 83.75%, Test: 83.77%
Epoch: 950, Loss: 0.2361, Train: 95.74%, Valid: 84.46%, Test: 84.03%
Epoch: 975, Loss: 0.2309, Train: 95.60%, Valid: 83.58%, Test: 83.87%
Run 01:
Highest Train: 96.15
Highest Valid: 84.56
  Final Train: 95.56
   Final Test: 84.21
All runs:
Highest Train: 96.15, nan
Highest Valid: 84.56, nan
  Final Train: 95.56, nan
   Final Test: 84.21, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.1949, Train: 47.40%, Valid: 48.35%, Test: 47.62%
Epoch: 25, Loss: 0.4987, Train: 77.32%, Valid: 76.83%, Test: 76.06%
Epoch: 50, Loss: 0.4324, Train: 81.61%, Valid: 79.49%, Test: 79.12%
Epoch: 75, Loss: 0.4110, Train: 83.97%, Valid: 80.69%, Test: 80.46%
Epoch: 100, Loss: 0.3970, Train: 85.19%, Valid: 81.20%, Test: 81.31%
Epoch: 125, Loss: 0.3854, Train: 86.23%, Valid: 81.37%, Test: 81.63%
Epoch: 150, Loss: 0.3748, Train: 87.84%, Valid: 82.19%, Test: 82.22%
Epoch: 175, Loss: 0.3647, Train: 88.59%, Valid: 82.31%, Test: 82.56%
Epoch: 200, Loss: 0.3592, Train: 89.40%, Valid: 82.76%, Test: 82.65%
Epoch: 225, Loss: 0.3524, Train: 90.15%, Valid: 82.87%, Test: 82.78%
Epoch: 250, Loss: 0.3422, Train: 90.54%, Valid: 83.11%, Test: 83.04%
Epoch: 275, Loss: 0.3362, Train: 91.09%, Valid: 82.86%, Test: 82.95%
Epoch: 300, Loss: 0.3305, Train: 91.07%, Valid: 82.57%, Test: 82.72%
Epoch: 325, Loss: 0.3253, Train: 91.19%, Valid: 82.79%, Test: 82.57%
Epoch: 350, Loss: 0.3222, Train: 91.81%, Valid: 83.46%, Test: 83.06%
Epoch: 375, Loss: 0.3156, Train: 92.42%, Valid: 83.58%, Test: 83.21%
Epoch: 400, Loss: 0.3141, Train: 91.27%, Valid: 82.53%, Test: 82.32%
Epoch: 425, Loss: 0.3048, Train: 91.95%, Valid: 82.42%, Test: 82.31%
Epoch: 450, Loss: 0.3000, Train: 92.28%, Valid: 83.27%, Test: 83.07%
Epoch: 475, Loss: 0.2961, Train: 93.18%, Valid: 83.52%, Test: 83.64%
Epoch: 500, Loss: 0.2893, Train: 92.66%, Valid: 82.60%, Test: 82.67%
Epoch: 525, Loss: 0.2822, Train: 93.54%, Valid: 83.58%, Test: 83.23%
Epoch: 550, Loss: 0.2818, Train: 93.45%, Valid: 83.48%, Test: 83.04%
Epoch: 575, Loss: 0.2860, Train: 93.84%, Valid: 83.59%, Test: 83.30%
Epoch: 600, Loss: 0.2744, Train: 94.18%, Valid: 84.05%, Test: 83.43%
Epoch: 625, Loss: 0.2684, Train: 93.92%, Valid: 83.26%, Test: 83.07%
Epoch: 650, Loss: 0.2613, Train: 94.07%, Valid: 83.70%, Test: 83.38%
Epoch: 675, Loss: 0.2578, Train: 94.62%, Valid: 83.60%, Test: 83.37%
Epoch: 700, Loss: 0.2562, Train: 94.94%, Valid: 84.07%, Test: 83.68%
Epoch: 725, Loss: 0.2477, Train: 95.18%, Valid: 83.92%, Test: 83.92%
Epoch: 750, Loss: 0.2497, Train: 95.31%, Valid: 83.98%, Test: 83.80%
Epoch: 775, Loss: 0.2414, Train: 95.21%, Valid: 83.75%, Test: 83.62%
Epoch: 800, Loss: 0.2362, Train: 95.73%, Valid: 84.23%, Test: 83.86%
Epoch: 825, Loss: 0.2291, Train: 95.65%, Valid: 83.87%, Test: 83.48%
Epoch: 850, Loss: 0.2299, Train: 95.71%, Valid: 83.51%, Test: 83.17%
Epoch: 875, Loss: 0.2276, Train: 96.16%, Valid: 83.96%, Test: 83.84%
Epoch: 900, Loss: 0.2116, Train: 95.79%, Valid: 83.86%, Test: 83.66%
Epoch: 925, Loss: 0.2120, Train: 95.95%, Valid: 83.46%, Test: 83.66%
Epoch: 950, Loss: 0.2101, Train: 96.33%, Valid: 83.70%, Test: 83.29%
Epoch: 975, Loss: 0.2501, Train: 91.89%, Valid: 80.52%, Test: 80.56%
Run 01:
Highest Train: 96.70
Highest Valid: 84.47
  Final Train: 96.65
   Final Test: 84.29
All runs:
Highest Train: 96.70, nan
Highest Valid: 84.47, nan
  Final Train: 96.65, nan
   Final Test: 84.29, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.3243, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.5247, Train: 76.01%, Valid: 75.42%, Test: 74.54%
Epoch: 50, Loss: 0.4380, Train: 81.08%, Valid: 79.18%, Test: 78.93%
Epoch: 75, Loss: 0.4104, Train: 84.09%, Valid: 81.02%, Test: 80.64%
Epoch: 100, Loss: 0.3920, Train: 86.31%, Valid: 81.56%, Test: 81.76%
Epoch: 125, Loss: 0.3749, Train: 88.22%, Valid: 82.20%, Test: 82.36%
Epoch: 150, Loss: 0.3628, Train: 89.49%, Valid: 82.83%, Test: 82.84%
Epoch: 175, Loss: 0.3526, Train: 90.03%, Valid: 83.12%, Test: 83.01%
Epoch: 200, Loss: 0.3446, Train: 91.00%, Valid: 83.31%, Test: 83.25%
Epoch: 225, Loss: 0.3332, Train: 91.73%, Valid: 83.42%, Test: 83.31%
Epoch: 250, Loss: 0.3270, Train: 92.18%, Valid: 83.54%, Test: 83.34%
Epoch: 275, Loss: 0.3189, Train: 91.99%, Valid: 82.87%, Test: 82.81%
Epoch: 300, Loss: 0.3119, Train: 93.01%, Valid: 83.48%, Test: 83.10%
Epoch: 325, Loss: 0.3210, Train: 92.72%, Valid: 83.29%, Test: 83.07%
Epoch: 350, Loss: 0.3011, Train: 93.67%, Valid: 83.64%, Test: 83.58%
Epoch: 375, Loss: 0.3514, Train: 92.01%, Valid: 83.19%, Test: 83.16%
Epoch: 400, Loss: 0.2945, Train: 93.56%, Valid: 83.64%, Test: 83.32%
Epoch: 425, Loss: 0.2867, Train: 94.25%, Valid: 83.58%, Test: 83.38%
Epoch: 450, Loss: 0.2805, Train: 94.50%, Valid: 83.63%, Test: 83.54%
Epoch: 475, Loss: 0.2879, Train: 88.42%, Valid: 79.34%, Test: 79.21%
Epoch: 500, Loss: 0.2789, Train: 94.24%, Valid: 83.41%, Test: 83.48%
Epoch: 525, Loss: 0.2682, Train: 94.82%, Valid: 83.55%, Test: 83.54%
Epoch: 550, Loss: 0.2626, Train: 95.04%, Valid: 83.74%, Test: 83.47%
Epoch: 575, Loss: 0.2571, Train: 95.30%, Valid: 83.68%, Test: 83.51%
Epoch: 600, Loss: 0.2514, Train: 95.47%, Valid: 83.68%, Test: 83.48%
Epoch: 625, Loss: 0.2634, Train: 93.02%, Valid: 82.36%, Test: 82.42%
Epoch: 650, Loss: 0.2457, Train: 95.37%, Valid: 83.69%, Test: 83.65%
Epoch: 675, Loss: 0.2390, Train: 95.79%, Valid: 83.84%, Test: 83.61%
Epoch: 700, Loss: 0.2347, Train: 95.76%, Valid: 83.39%, Test: 83.39%
Epoch: 725, Loss: 0.2576, Train: 93.51%, Valid: 83.09%, Test: 82.94%
Epoch: 750, Loss: 0.2330, Train: 95.66%, Valid: 84.02%, Test: 83.84%
Epoch: 775, Loss: 0.2255, Train: 96.11%, Valid: 83.91%, Test: 83.57%
Epoch: 800, Loss: 0.2205, Train: 96.30%, Valid: 83.87%, Test: 83.57%
Epoch: 825, Loss: 0.2158, Train: 96.49%, Valid: 84.02%, Test: 83.58%
Epoch: 850, Loss: 0.2353, Train: 94.33%, Valid: 82.98%, Test: 82.73%
Epoch: 875, Loss: 0.2110, Train: 96.31%, Valid: 84.09%, Test: 83.74%
Epoch: 900, Loss: 0.2048, Train: 96.73%, Valid: 84.22%, Test: 83.67%
Epoch: 925, Loss: 0.2003, Train: 96.91%, Valid: 84.12%, Test: 83.74%
Epoch: 950, Loss: 0.1962, Train: 97.00%, Valid: 84.26%, Test: 83.72%
Epoch: 975, Loss: 0.2759, Train: 91.55%, Valid: 82.11%, Test: 81.75%
Run 01:
Highest Train: 97.05
Highest Valid: 84.26
  Final Train: 97.00
   Final Test: 83.72
All runs:
Highest Train: 97.05, nan
Highest Valid: 84.26, nan
  Final Train: 97.00, nan
   Final Test: 83.72, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.0009, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.4894, Train: 77.94%, Valid: 77.07%, Test: 76.66%
Epoch: 50, Loss: 0.4237, Train: 82.31%, Valid: 79.71%, Test: 79.62%
Epoch: 75, Loss: 0.4012, Train: 85.00%, Valid: 81.12%, Test: 81.01%
Epoch: 100, Loss: 0.3827, Train: 86.93%, Valid: 81.82%, Test: 81.84%
Epoch: 125, Loss: 0.3674, Train: 88.66%, Valid: 82.37%, Test: 82.77%
Epoch: 150, Loss: 0.3554, Train: 89.78%, Valid: 82.97%, Test: 83.09%
Epoch: 175, Loss: 0.3501, Train: 90.29%, Valid: 82.97%, Test: 83.15%
Epoch: 200, Loss: 0.3379, Train: 90.97%, Valid: 83.08%, Test: 83.17%
Epoch: 225, Loss: 0.3344, Train: 91.52%, Valid: 83.08%, Test: 83.34%
Epoch: 250, Loss: 0.3227, Train: 92.07%, Valid: 83.21%, Test: 83.32%
Epoch: 275, Loss: 0.3168, Train: 92.54%, Valid: 83.47%, Test: 83.44%
Epoch: 300, Loss: 0.3125, Train: 91.80%, Valid: 82.54%, Test: 82.90%
Epoch: 325, Loss: 0.3040, Train: 93.12%, Valid: 83.27%, Test: 83.29%
Epoch: 350, Loss: 0.3178, Train: 87.89%, Valid: 78.64%, Test: 78.04%
Epoch: 375, Loss: 0.2975, Train: 93.28%, Valid: 83.46%, Test: 83.40%
Epoch: 400, Loss: 0.2881, Train: 93.80%, Valid: 83.28%, Test: 83.34%
Epoch: 425, Loss: 0.2909, Train: 90.41%, Valid: 80.71%, Test: 80.55%
Epoch: 450, Loss: 0.2815, Train: 93.94%, Valid: 83.14%, Test: 83.47%
Epoch: 475, Loss: 0.2747, Train: 94.48%, Valid: 83.34%, Test: 83.49%
Epoch: 500, Loss: 0.2690, Train: 94.75%, Valid: 83.35%, Test: 83.25%
Epoch: 525, Loss: 0.2997, Train: 92.29%, Valid: 82.34%, Test: 82.55%
Epoch: 550, Loss: 0.2685, Train: 94.22%, Valid: 83.44%, Test: 83.24%
Epoch: 575, Loss: 0.2607, Train: 94.82%, Valid: 83.27%, Test: 83.33%
Epoch: 600, Loss: 0.2568, Train: 94.97%, Valid: 83.35%, Test: 83.20%
Epoch: 625, Loss: 0.2725, Train: 91.33%, Valid: 81.56%, Test: 81.83%
Epoch: 650, Loss: 0.2541, Train: 94.87%, Valid: 83.18%, Test: 83.23%
Epoch: 675, Loss: 0.2459, Train: 95.27%, Valid: 83.40%, Test: 83.20%
Epoch: 700, Loss: 0.2411, Train: 95.50%, Valid: 83.16%, Test: 83.10%
Epoch: 725, Loss: 0.2366, Train: 95.64%, Valid: 83.20%, Test: 82.93%
Epoch: 750, Loss: 0.2893, Train: 89.94%, Valid: 80.45%, Test: 80.27%
Epoch: 775, Loss: 0.2433, Train: 94.65%, Valid: 83.11%, Test: 83.18%
Epoch: 800, Loss: 0.2311, Train: 95.58%, Valid: 83.12%, Test: 82.92%
Epoch: 825, Loss: 0.2259, Train: 95.91%, Valid: 83.31%, Test: 82.90%
Epoch: 850, Loss: 0.2216, Train: 96.07%, Valid: 83.18%, Test: 82.82%
Epoch: 875, Loss: 0.2852, Train: 90.28%, Valid: 80.94%, Test: 81.30%
Epoch: 900, Loss: 0.2412, Train: 94.51%, Valid: 83.11%, Test: 83.33%
Epoch: 925, Loss: 0.2216, Train: 95.56%, Valid: 83.11%, Test: 82.93%
Epoch: 950, Loss: 0.2155, Train: 95.96%, Valid: 83.13%, Test: 82.75%
Epoch: 975, Loss: 0.2111, Train: 96.20%, Valid: 82.96%, Test: 82.81%
Run 01:
Highest Train: 96.34
Highest Valid: 83.64
  Final Train: 93.38
   Final Test: 83.48
All runs:
Highest Train: 96.34, nan
Highest Valid: 83.64, nan
  Final Train: 93.38, nan
   Final Test: 83.48, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.9596, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.5101, Train: 76.63%, Valid: 76.48%, Test: 75.62%
Epoch: 50, Loss: 0.4294, Train: 81.88%, Valid: 79.66%, Test: 79.52%
Epoch: 75, Loss: 0.4038, Train: 84.57%, Valid: 81.13%, Test: 81.01%
Epoch: 100, Loss: 0.3854, Train: 86.68%, Valid: 81.92%, Test: 81.78%
Epoch: 125, Loss: 0.3696, Train: 88.43%, Valid: 82.14%, Test: 82.47%
Epoch: 150, Loss: 0.3572, Train: 89.64%, Valid: 82.79%, Test: 83.04%
Epoch: 175, Loss: 0.3473, Train: 90.44%, Valid: 83.18%, Test: 83.30%
Epoch: 200, Loss: 0.3489, Train: 89.99%, Valid: 82.22%, Test: 82.63%
Epoch: 225, Loss: 0.3316, Train: 91.31%, Valid: 83.10%, Test: 83.43%
Epoch: 250, Loss: 0.3238, Train: 92.03%, Valid: 83.26%, Test: 83.59%
Epoch: 275, Loss: 0.3238, Train: 92.25%, Valid: 83.49%, Test: 83.47%
Epoch: 300, Loss: 0.3111, Train: 92.77%, Valid: 83.54%, Test: 83.43%
Epoch: 325, Loss: 0.3124, Train: 90.29%, Valid: 81.87%, Test: 81.94%
Epoch: 350, Loss: 0.3012, Train: 93.15%, Valid: 83.72%, Test: 83.64%
Epoch: 375, Loss: 0.2937, Train: 93.65%, Valid: 83.78%, Test: 83.45%
Epoch: 400, Loss: 0.3064, Train: 92.49%, Valid: 83.13%, Test: 83.00%
Epoch: 425, Loss: 0.2868, Train: 93.72%, Valid: 83.50%, Test: 83.46%
Epoch: 450, Loss: 0.2802, Train: 94.13%, Valid: 83.70%, Test: 83.52%
Epoch: 475, Loss: 0.2745, Train: 94.41%, Valid: 83.83%, Test: 83.63%
Epoch: 500, Loss: 0.2833, Train: 92.54%, Valid: 82.73%, Test: 82.05%
Epoch: 525, Loss: 0.2683, Train: 94.47%, Valid: 83.79%, Test: 83.73%
Epoch: 550, Loss: 0.2610, Train: 94.90%, Valid: 83.91%, Test: 83.62%
Epoch: 575, Loss: 0.3839, Train: 91.01%, Valid: 82.41%, Test: 82.15%
Epoch: 600, Loss: 0.2697, Train: 93.66%, Valid: 83.14%, Test: 83.15%
Epoch: 625, Loss: 0.2537, Train: 94.93%, Valid: 83.93%, Test: 83.47%
Epoch: 650, Loss: 0.2474, Train: 95.23%, Valid: 83.95%, Test: 83.62%
Epoch: 675, Loss: 0.2423, Train: 95.39%, Valid: 84.00%, Test: 83.52%
Epoch: 700, Loss: 0.2372, Train: 95.67%, Valid: 84.03%, Test: 83.66%
Epoch: 725, Loss: 0.2870, Train: 93.21%, Valid: 82.95%, Test: 83.18%
Epoch: 750, Loss: 0.2392, Train: 95.04%, Valid: 83.70%, Test: 83.59%
Epoch: 775, Loss: 0.2292, Train: 95.67%, Valid: 83.82%, Test: 83.40%
Epoch: 800, Loss: 0.2239, Train: 95.98%, Valid: 83.96%, Test: 83.66%
Epoch: 825, Loss: 0.2192, Train: 96.19%, Valid: 83.97%, Test: 83.75%
Epoch: 850, Loss: 0.2698, Train: 91.88%, Valid: 82.34%, Test: 82.66%
Epoch: 875, Loss: 0.2326, Train: 94.75%, Valid: 83.39%, Test: 83.55%
Epoch: 900, Loss: 0.2176, Train: 95.93%, Valid: 83.73%, Test: 83.46%
Epoch: 925, Loss: 0.2111, Train: 96.26%, Valid: 83.89%, Test: 83.60%
Epoch: 950, Loss: 0.2061, Train: 96.46%, Valid: 83.89%, Test: 83.67%
Epoch: 975, Loss: 0.2029, Train: 96.40%, Valid: 83.62%, Test: 83.19%
Run 01:
Highest Train: 96.61
Highest Valid: 84.09
  Final Train: 95.83
   Final Test: 83.85
All runs:
Highest Train: 96.61, nan
Highest Valid: 84.09, nan
  Final Train: 95.83, nan
   Final Test: 83.85, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.8080, Train: 53.70%, Valid: 52.85%, Test: 53.33%
Epoch: 25, Loss: 0.5040, Train: 77.08%, Valid: 76.42%, Test: 75.67%
Epoch: 50, Loss: 0.4317, Train: 81.59%, Valid: 79.42%, Test: 79.23%
Epoch: 75, Loss: 0.4092, Train: 83.90%, Valid: 80.83%, Test: 80.55%
Epoch: 100, Loss: 0.3961, Train: 85.41%, Valid: 81.27%, Test: 81.12%
Epoch: 125, Loss: 0.3837, Train: 86.58%, Valid: 81.71%, Test: 81.79%
Epoch: 150, Loss: 0.3723, Train: 87.67%, Valid: 82.08%, Test: 82.03%
Epoch: 175, Loss: 0.3649, Train: 88.58%, Valid: 82.40%, Test: 82.34%
Epoch: 200, Loss: 0.3576, Train: 88.57%, Valid: 82.12%, Test: 82.27%
Epoch: 225, Loss: 0.3486, Train: 89.30%, Valid: 82.83%, Test: 82.44%
Epoch: 250, Loss: 0.3425, Train: 89.85%, Valid: 82.93%, Test: 82.79%
Epoch: 275, Loss: 0.3397, Train: 90.08%, Valid: 82.78%, Test: 82.35%
Epoch: 300, Loss: 0.3348, Train: 90.61%, Valid: 82.84%, Test: 82.90%
Epoch: 325, Loss: 0.3261, Train: 90.67%, Valid: 82.88%, Test: 83.04%
Epoch: 350, Loss: 0.3209, Train: 91.13%, Valid: 83.05%, Test: 82.89%
Epoch: 375, Loss: 0.3181, Train: 91.12%, Valid: 82.69%, Test: 82.57%
Epoch: 400, Loss: 0.3192, Train: 91.65%, Valid: 83.50%, Test: 83.35%
Epoch: 425, Loss: 0.3137, Train: 91.33%, Valid: 82.63%, Test: 82.33%
Epoch: 450, Loss: 0.3020, Train: 91.77%, Valid: 82.85%, Test: 82.98%
Epoch: 475, Loss: 0.3041, Train: 91.05%, Valid: 82.71%, Test: 82.08%
Epoch: 500, Loss: 0.2995, Train: 91.97%, Valid: 82.91%, Test: 82.77%
Epoch: 525, Loss: 0.2925, Train: 92.27%, Valid: 83.10%, Test: 82.99%
Epoch: 550, Loss: 0.2874, Train: 92.44%, Valid: 82.96%, Test: 83.04%
Epoch: 575, Loss: 0.2911, Train: 92.69%, Valid: 83.37%, Test: 83.30%
Epoch: 600, Loss: 0.2813, Train: 92.05%, Valid: 82.87%, Test: 82.71%
Epoch: 625, Loss: 0.2732, Train: 92.66%, Valid: 82.91%, Test: 82.56%
Epoch: 650, Loss: 0.2763, Train: 92.90%, Valid: 83.25%, Test: 83.07%
Epoch: 675, Loss: 0.2675, Train: 93.01%, Valid: 83.07%, Test: 83.13%
Epoch: 700, Loss: 0.2702, Train: 93.23%, Valid: 83.35%, Test: 83.24%
Epoch: 725, Loss: 0.2697, Train: 93.12%, Valid: 82.74%, Test: 83.06%
Epoch: 750, Loss: 0.2587, Train: 93.34%, Valid: 83.21%, Test: 82.96%
Epoch: 775, Loss: 0.2541, Train: 92.67%, Valid: 82.67%, Test: 82.36%
Epoch: 800, Loss: 0.2570, Train: 93.46%, Valid: 83.38%, Test: 83.23%
Epoch: 825, Loss: 0.2494, Train: 93.80%, Valid: 83.59%, Test: 83.36%
Epoch: 850, Loss: 0.2617, Train: 92.81%, Valid: 82.46%, Test: 82.26%
Epoch: 875, Loss: 0.2411, Train: 93.85%, Valid: 83.40%, Test: 83.11%
Epoch: 900, Loss: 0.2468, Train: 93.94%, Valid: 83.38%, Test: 83.14%
Epoch: 925, Loss: 0.2384, Train: 93.61%, Valid: 82.92%, Test: 82.77%
Epoch: 950, Loss: 0.2344, Train: 93.78%, Valid: 82.77%, Test: 82.62%
Epoch: 975, Loss: 0.2348, Train: 93.24%, Valid: 82.46%, Test: 82.15%
Run 01:
Highest Train: 94.36
Highest Valid: 83.68
  Final Train: 94.12
   Final Test: 83.16
All runs:
Highest Train: 94.36, nan
Highest Valid: 83.68, nan
  Final Train: 94.12, nan
   Final Test: 83.16, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.7081, Train: 58.89%, Valid: 59.20%, Test: 58.93%
Epoch: 25, Loss: 0.4717, Train: 78.30%, Valid: 77.12%, Test: 77.06%
Epoch: 50, Loss: 0.4188, Train: 82.66%, Valid: 80.14%, Test: 80.08%
Epoch: 75, Loss: 0.3987, Train: 84.80%, Valid: 81.09%, Test: 81.01%
Epoch: 100, Loss: 0.3875, Train: 86.26%, Valid: 81.68%, Test: 81.54%
Epoch: 125, Loss: 0.3711, Train: 87.18%, Valid: 81.79%, Test: 81.99%
Epoch: 150, Loss: 0.3637, Train: 88.10%, Valid: 82.02%, Test: 82.47%
Epoch: 175, Loss: 0.3555, Train: 88.44%, Valid: 82.09%, Test: 82.22%
Epoch: 200, Loss: 0.3437, Train: 89.08%, Valid: 82.28%, Test: 82.34%
Epoch: 225, Loss: 0.3351, Train: 89.41%, Valid: 82.49%, Test: 82.17%
Epoch: 250, Loss: 0.3296, Train: 90.03%, Valid: 82.38%, Test: 82.98%
Epoch: 275, Loss: 0.3252, Train: 90.33%, Valid: 82.84%, Test: 82.65%
Epoch: 300, Loss: 0.3214, Train: 90.38%, Valid: 83.04%, Test: 82.69%
Epoch: 325, Loss: 0.3172, Train: 90.35%, Valid: 82.72%, Test: 82.67%
Epoch: 350, Loss: 0.3127, Train: 90.80%, Valid: 82.72%, Test: 82.69%
Epoch: 375, Loss: 0.3065, Train: 91.19%, Valid: 83.01%, Test: 82.78%
Epoch: 400, Loss: 0.3069, Train: 91.53%, Valid: 83.07%, Test: 83.18%
Epoch: 425, Loss: 0.2954, Train: 91.46%, Valid: 82.63%, Test: 82.63%
Epoch: 450, Loss: 0.2900, Train: 91.58%, Valid: 82.89%, Test: 82.69%
Epoch: 475, Loss: 0.2853, Train: 92.07%, Valid: 82.90%, Test: 83.21%
Epoch: 500, Loss: 0.2824, Train: 92.09%, Valid: 82.94%, Test: 83.06%
Epoch: 525, Loss: 0.2807, Train: 92.33%, Valid: 83.24%, Test: 82.98%
Epoch: 550, Loss: 0.2775, Train: 92.21%, Valid: 83.01%, Test: 82.82%
Epoch: 575, Loss: 0.2717, Train: 92.32%, Valid: 83.40%, Test: 83.08%
Epoch: 600, Loss: 0.2671, Train: 92.25%, Valid: 82.91%, Test: 82.62%
Epoch: 625, Loss: 0.2682, Train: 92.34%, Valid: 82.92%, Test: 82.76%
Epoch: 650, Loss: 0.2671, Train: 92.78%, Valid: 83.13%, Test: 83.20%
Epoch: 675, Loss: 0.2615, Train: 92.85%, Valid: 83.22%, Test: 82.82%
Epoch: 700, Loss: 0.2498, Train: 93.07%, Valid: 82.79%, Test: 82.96%
Epoch: 725, Loss: 0.2505, Train: 93.10%, Valid: 83.09%, Test: 83.31%
Epoch: 750, Loss: 0.2459, Train: 93.20%, Valid: 82.99%, Test: 83.00%
Epoch: 775, Loss: 0.2438, Train: 93.20%, Valid: 82.70%, Test: 82.68%
Epoch: 800, Loss: 0.2441, Train: 93.33%, Valid: 82.77%, Test: 82.82%
Epoch: 825, Loss: 0.2407, Train: 93.61%, Valid: 82.98%, Test: 83.08%
Epoch: 850, Loss: 0.2408, Train: 92.52%, Valid: 82.30%, Test: 82.23%
Epoch: 875, Loss: 0.2515, Train: 93.27%, Valid: 82.67%, Test: 82.53%
Epoch: 900, Loss: 0.2363, Train: 93.45%, Valid: 82.89%, Test: 83.20%
Epoch: 925, Loss: 0.2277, Train: 93.68%, Valid: 83.13%, Test: 82.78%
Epoch: 950, Loss: 0.2240, Train: 93.99%, Valid: 83.03%, Test: 82.96%
Epoch: 975, Loss: 0.2276, Train: 93.95%, Valid: 83.24%, Test: 83.10%
Run 01:
Highest Train: 94.34
Highest Valid: 83.68
  Final Train: 92.94
   Final Test: 83.41
All runs:
Highest Train: 94.34, nan
Highest Valid: 83.68, nan
  Final Train: 92.94, nan
   Final Test: 83.41, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.8163, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.5433, Train: 75.05%, Valid: 75.07%, Test: 73.75%
Epoch: 50, Loss: 0.4626, Train: 79.67%, Valid: 78.00%, Test: 77.68%
Epoch: 75, Loss: 0.4249, Train: 82.35%, Valid: 79.91%, Test: 79.74%
Epoch: 100, Loss: 0.4101, Train: 84.12%, Valid: 80.85%, Test: 80.75%
Epoch: 125, Loss: 0.3979, Train: 85.15%, Valid: 81.24%, Test: 81.06%
Epoch: 150, Loss: 0.3881, Train: 86.12%, Valid: 81.82%, Test: 82.01%
Epoch: 175, Loss: 0.3815, Train: 87.07%, Valid: 82.00%, Test: 82.01%
Epoch: 200, Loss: 0.3726, Train: 87.41%, Valid: 81.73%, Test: 81.92%
Epoch: 225, Loss: 0.3653, Train: 88.10%, Valid: 82.22%, Test: 82.17%
Epoch: 250, Loss: 0.3602, Train: 88.49%, Valid: 81.97%, Test: 82.12%
Epoch: 275, Loss: 0.3526, Train: 89.13%, Valid: 82.49%, Test: 82.61%
Epoch: 300, Loss: 0.3472, Train: 89.89%, Valid: 82.55%, Test: 83.02%
Epoch: 325, Loss: 0.3409, Train: 89.56%, Valid: 82.47%, Test: 82.29%
Epoch: 350, Loss: 0.3352, Train: 90.31%, Valid: 82.94%, Test: 82.80%
Epoch: 375, Loss: 0.3327, Train: 90.78%, Valid: 82.95%, Test: 83.26%
Epoch: 400, Loss: 0.3277, Train: 91.03%, Valid: 83.17%, Test: 83.12%
Epoch: 425, Loss: 0.3223, Train: 91.01%, Valid: 82.88%, Test: 82.95%
Epoch: 450, Loss: 0.3172, Train: 91.09%, Valid: 82.79%, Test: 82.98%
Epoch: 475, Loss: 0.3113, Train: 91.77%, Valid: 83.24%, Test: 83.14%
Epoch: 500, Loss: 0.3163, Train: 91.90%, Valid: 83.18%, Test: 82.94%
Epoch: 525, Loss: 0.3014, Train: 91.92%, Valid: 82.59%, Test: 82.67%
Epoch: 550, Loss: 0.3002, Train: 92.29%, Valid: 83.21%, Test: 83.09%
Epoch: 575, Loss: 0.2965, Train: 92.46%, Valid: 82.76%, Test: 82.82%
Epoch: 600, Loss: 0.2896, Train: 92.43%, Valid: 82.88%, Test: 82.86%
Epoch: 625, Loss: 0.2966, Train: 92.34%, Valid: 83.05%, Test: 82.65%
Epoch: 650, Loss: 0.2869, Train: 92.38%, Valid: 82.69%, Test: 82.75%
Epoch: 675, Loss: 0.2908, Train: 93.07%, Valid: 83.18%, Test: 82.98%
Epoch: 700, Loss: 0.2828, Train: 93.28%, Valid: 83.26%, Test: 83.18%
Epoch: 725, Loss: 0.2760, Train: 93.21%, Valid: 83.17%, Test: 82.87%
Epoch: 750, Loss: 0.2740, Train: 93.53%, Valid: 83.05%, Test: 83.07%
Epoch: 775, Loss: 0.2675, Train: 92.91%, Valid: 82.11%, Test: 82.19%
Epoch: 800, Loss: 0.2687, Train: 93.72%, Valid: 83.08%, Test: 83.20%
Epoch: 825, Loss: 0.2582, Train: 93.55%, Valid: 82.67%, Test: 82.98%
Epoch: 850, Loss: 0.2635, Train: 93.16%, Valid: 82.21%, Test: 82.63%
Epoch: 875, Loss: 0.2594, Train: 93.73%, Valid: 82.82%, Test: 82.90%
Epoch: 900, Loss: 0.2638, Train: 94.25%, Valid: 82.80%, Test: 83.02%
Epoch: 925, Loss: 0.2573, Train: 94.05%, Valid: 82.94%, Test: 83.25%
Epoch: 950, Loss: 0.2460, Train: 94.58%, Valid: 83.13%, Test: 82.97%
Epoch: 975, Loss: 0.2439, Train: 94.09%, Valid: 82.55%, Test: 82.68%
Run 01:
Highest Train: 94.64
Highest Valid: 83.66
  Final Train: 92.73
   Final Test: 83.34
All runs:
Highest Train: 94.64, nan
Highest Valid: 83.66, nan
  Final Train: 92.73, nan
   Final Test: 83.34, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.1583, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.5294, Train: 75.46%, Valid: 75.18%, Test: 74.34%
Epoch: 50, Loss: 0.4537, Train: 79.98%, Valid: 78.29%, Test: 77.98%
Epoch: 75, Loss: 0.4241, Train: 82.26%, Valid: 79.95%, Test: 79.87%
Epoch: 100, Loss: 0.4121, Train: 83.99%, Valid: 80.52%, Test: 80.75%
Epoch: 125, Loss: 0.4019, Train: 85.02%, Valid: 81.24%, Test: 81.04%
Epoch: 150, Loss: 0.3911, Train: 86.00%, Valid: 81.54%, Test: 81.48%
Epoch: 175, Loss: 0.3847, Train: 86.51%, Valid: 81.87%, Test: 81.71%
Epoch: 200, Loss: 0.3737, Train: 87.54%, Valid: 82.05%, Test: 82.16%
Epoch: 225, Loss: 0.3669, Train: 88.05%, Valid: 82.27%, Test: 82.10%
Epoch: 250, Loss: 0.3599, Train: 88.44%, Valid: 82.52%, Test: 82.11%
Epoch: 275, Loss: 0.3535, Train: 88.45%, Valid: 82.20%, Test: 81.79%
Epoch: 300, Loss: 0.3473, Train: 89.08%, Valid: 82.23%, Test: 82.29%
Epoch: 325, Loss: 0.3440, Train: 89.18%, Valid: 81.96%, Test: 81.95%
Epoch: 350, Loss: 0.3356, Train: 89.60%, Valid: 82.34%, Test: 82.17%
Epoch: 375, Loss: 0.3310, Train: 90.10%, Valid: 82.37%, Test: 82.66%
Epoch: 400, Loss: 0.3377, Train: 90.41%, Valid: 83.16%, Test: 83.36%
Epoch: 425, Loss: 0.3226, Train: 90.70%, Valid: 83.26%, Test: 83.12%
Epoch: 450, Loss: 0.3217, Train: 90.95%, Valid: 83.28%, Test: 83.08%
Epoch: 475, Loss: 0.3188, Train: 90.91%, Valid: 82.65%, Test: 82.62%
Epoch: 500, Loss: 0.3138, Train: 90.91%, Valid: 82.78%, Test: 83.04%
Epoch: 525, Loss: 0.3081, Train: 91.35%, Valid: 83.30%, Test: 82.92%
Epoch: 550, Loss: 0.3048, Train: 91.50%, Valid: 83.23%, Test: 83.12%
Epoch: 575, Loss: 0.3005, Train: 91.79%, Valid: 83.06%, Test: 82.79%
Epoch: 600, Loss: 0.2918, Train: 91.97%, Valid: 83.24%, Test: 83.25%
Epoch: 625, Loss: 0.2953, Train: 91.69%, Valid: 82.82%, Test: 82.87%
Epoch: 650, Loss: 0.2903, Train: 91.43%, Valid: 82.70%, Test: 82.87%
Epoch: 675, Loss: 0.2906, Train: 91.43%, Valid: 82.16%, Test: 82.40%
Epoch: 700, Loss: 0.2783, Train: 91.87%, Valid: 82.36%, Test: 82.43%
Epoch: 725, Loss: 0.2744, Train: 92.30%, Valid: 83.35%, Test: 83.45%
Epoch: 750, Loss: 0.2776, Train: 92.61%, Valid: 83.02%, Test: 83.09%
Epoch: 775, Loss: 0.2812, Train: 92.40%, Valid: 82.64%, Test: 82.63%
Epoch: 800, Loss: 0.2740, Train: 93.02%, Valid: 83.52%, Test: 83.36%
Epoch: 825, Loss: 0.2650, Train: 92.23%, Valid: 82.35%, Test: 82.53%
Epoch: 850, Loss: 0.2629, Train: 92.73%, Valid: 83.09%, Test: 82.82%
Epoch: 875, Loss: 0.2579, Train: 93.38%, Valid: 83.57%, Test: 83.60%
Epoch: 900, Loss: 0.2599, Train: 92.76%, Valid: 82.98%, Test: 83.36%
Epoch: 925, Loss: 0.2532, Train: 93.18%, Valid: 82.84%, Test: 83.07%
Epoch: 950, Loss: 0.2460, Train: 93.54%, Valid: 83.66%, Test: 83.59%
Epoch: 975, Loss: 0.2455, Train: 93.28%, Valid: 83.09%, Test: 83.12%
Run 01:
Highest Train: 93.71
Highest Valid: 83.96
  Final Train: 93.53
   Final Test: 83.70
All runs:
Highest Train: 93.71, nan
Highest Valid: 83.96, nan
  Final Train: 93.53, nan
   Final Test: 83.70, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.2216, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.5140, Train: 76.40%, Valid: 75.54%, Test: 74.76%
Epoch: 50, Loss: 0.4463, Train: 80.55%, Valid: 78.87%, Test: 78.49%
Epoch: 75, Loss: 0.4228, Train: 83.02%, Valid: 80.15%, Test: 80.02%
Epoch: 100, Loss: 0.4097, Train: 84.75%, Valid: 80.91%, Test: 80.65%
Epoch: 125, Loss: 0.4001, Train: 85.25%, Valid: 81.09%, Test: 80.95%
Epoch: 150, Loss: 0.3899, Train: 86.29%, Valid: 81.61%, Test: 81.44%
Epoch: 175, Loss: 0.3909, Train: 86.67%, Valid: 81.58%, Test: 81.65%
Epoch: 200, Loss: 0.3741, Train: 87.64%, Valid: 82.10%, Test: 81.66%
Epoch: 225, Loss: 0.3658, Train: 87.95%, Valid: 82.14%, Test: 81.88%
Epoch: 250, Loss: 0.3590, Train: 88.73%, Valid: 82.16%, Test: 82.55%
Epoch: 275, Loss: 0.3531, Train: 88.67%, Valid: 82.03%, Test: 82.26%
Epoch: 300, Loss: 0.3495, Train: 89.73%, Valid: 82.75%, Test: 82.66%
Epoch: 325, Loss: 0.3430, Train: 89.36%, Valid: 82.14%, Test: 82.00%
Epoch: 350, Loss: 0.3410, Train: 90.39%, Valid: 82.96%, Test: 83.20%
Epoch: 375, Loss: 0.3358, Train: 90.45%, Valid: 82.89%, Test: 82.94%
Epoch: 400, Loss: 0.3302, Train: 90.86%, Valid: 83.28%, Test: 82.98%
Epoch: 425, Loss: 0.3254, Train: 90.71%, Valid: 82.95%, Test: 83.02%
Epoch: 450, Loss: 0.3232, Train: 91.05%, Valid: 83.25%, Test: 83.28%
Epoch: 475, Loss: 0.3169, Train: 90.67%, Valid: 82.56%, Test: 82.68%
Epoch: 500, Loss: 0.3110, Train: 91.31%, Valid: 83.03%, Test: 82.95%
Epoch: 525, Loss: 0.3173, Train: 90.86%, Valid: 82.57%, Test: 82.26%
Epoch: 550, Loss: 0.3036, Train: 91.81%, Valid: 83.07%, Test: 82.99%
Epoch: 575, Loss: 0.3132, Train: 91.41%, Valid: 83.01%, Test: 82.65%
Epoch: 600, Loss: 0.2964, Train: 91.66%, Valid: 83.23%, Test: 83.19%
Epoch: 625, Loss: 0.2946, Train: 91.92%, Valid: 83.14%, Test: 82.75%
Epoch: 650, Loss: 0.2901, Train: 92.30%, Valid: 83.24%, Test: 83.08%
Epoch: 675, Loss: 0.2854, Train: 91.90%, Valid: 82.49%, Test: 82.40%
Epoch: 700, Loss: 0.2809, Train: 92.53%, Valid: 83.24%, Test: 82.82%
Epoch: 725, Loss: 0.2848, Train: 92.48%, Valid: 83.23%, Test: 83.01%
Epoch: 750, Loss: 0.2817, Train: 92.52%, Valid: 82.84%, Test: 82.63%
Epoch: 775, Loss: 0.2737, Train: 92.05%, Valid: 82.88%, Test: 82.82%
Epoch: 800, Loss: 0.2963, Train: 92.52%, Valid: 83.15%, Test: 82.68%
Epoch: 825, Loss: 0.2703, Train: 92.29%, Valid: 83.01%, Test: 82.83%
Epoch: 850, Loss: 0.2668, Train: 92.54%, Valid: 82.67%, Test: 82.74%
Epoch: 875, Loss: 0.2717, Train: 92.88%, Valid: 83.07%, Test: 82.87%
Epoch: 900, Loss: 0.2599, Train: 93.30%, Valid: 83.52%, Test: 83.31%
Epoch: 925, Loss: 0.2573, Train: 93.61%, Valid: 83.62%, Test: 83.10%
Epoch: 950, Loss: 0.2530, Train: 93.70%, Valid: 83.47%, Test: 83.30%
Epoch: 975, Loss: 0.2556, Train: 93.63%, Valid: 83.50%, Test: 83.29%
Run 01:
Highest Train: 93.70
Highest Valid: 83.68
  Final Train: 93.45
   Final Test: 83.19
All runs:
Highest Train: 93.70, nan
Highest Valid: 83.68, nan
  Final Train: 93.45, nan
   Final Test: 83.19, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.8520, Train: 47.24%, Valid: 48.21%, Test: 47.43%
Epoch: 25, Loss: 0.5166, Train: 76.56%, Valid: 76.33%, Test: 75.56%
Epoch: 50, Loss: 0.4381, Train: 81.01%, Valid: 78.95%, Test: 78.90%
Epoch: 75, Loss: 0.4160, Train: 83.22%, Valid: 80.56%, Test: 80.39%
Epoch: 100, Loss: 0.4043, Train: 84.38%, Valid: 80.59%, Test: 80.72%
Epoch: 125, Loss: 0.3936, Train: 85.62%, Valid: 81.49%, Test: 81.34%
Epoch: 150, Loss: 0.3815, Train: 86.50%, Valid: 81.62%, Test: 81.69%
Epoch: 175, Loss: 0.3777, Train: 87.21%, Valid: 82.07%, Test: 82.37%
Epoch: 200, Loss: 0.3697, Train: 87.81%, Valid: 82.11%, Test: 82.10%
Epoch: 225, Loss: 0.3600, Train: 88.21%, Valid: 82.16%, Test: 82.43%
Epoch: 250, Loss: 0.3527, Train: 88.76%, Valid: 82.25%, Test: 82.39%
Epoch: 275, Loss: 0.3456, Train: 89.45%, Valid: 82.54%, Test: 82.80%
Epoch: 300, Loss: 0.3399, Train: 89.93%, Valid: 82.68%, Test: 82.81%
Epoch: 325, Loss: 0.3378, Train: 90.07%, Valid: 82.50%, Test: 82.68%
Epoch: 350, Loss: 0.3348, Train: 90.38%, Valid: 82.81%, Test: 83.15%
Epoch: 375, Loss: 0.3236, Train: 90.65%, Valid: 83.17%, Test: 83.11%
Epoch: 400, Loss: 0.3239, Train: 90.24%, Valid: 82.22%, Test: 82.27%
Epoch: 425, Loss: 0.3144, Train: 89.92%, Valid: 82.20%, Test: 82.30%
Epoch: 450, Loss: 0.3127, Train: 90.49%, Valid: 82.33%, Test: 82.18%
Epoch: 475, Loss: 0.3081, Train: 90.84%, Valid: 82.44%, Test: 82.56%
Epoch: 500, Loss: 0.3054, Train: 91.21%, Valid: 83.08%, Test: 83.00%
Epoch: 525, Loss: 0.3116, Train: 91.29%, Valid: 82.87%, Test: 82.81%
Epoch: 550, Loss: 0.3002, Train: 91.63%, Valid: 83.03%, Test: 83.31%
Epoch: 575, Loss: 0.2923, Train: 91.80%, Valid: 82.93%, Test: 82.89%
Epoch: 600, Loss: 0.2932, Train: 91.51%, Valid: 82.55%, Test: 82.87%
Epoch: 625, Loss: 0.2933, Train: 92.02%, Valid: 82.85%, Test: 82.90%
Epoch: 650, Loss: 0.2860, Train: 92.11%, Valid: 83.09%, Test: 82.91%
Epoch: 675, Loss: 0.2972, Train: 91.99%, Valid: 82.93%, Test: 82.76%
Epoch: 700, Loss: 0.2870, Train: 92.35%, Valid: 82.93%, Test: 83.08%
Epoch: 725, Loss: 0.2745, Train: 92.25%, Valid: 82.70%, Test: 82.79%
Epoch: 750, Loss: 0.2745, Train: 91.38%, Valid: 81.88%, Test: 82.39%
Epoch: 775, Loss: 0.2713, Train: 92.20%, Valid: 82.76%, Test: 82.76%
Epoch: 800, Loss: 0.2690, Train: 92.81%, Valid: 83.13%, Test: 83.11%
Epoch: 825, Loss: 0.2688, Train: 92.56%, Valid: 82.81%, Test: 82.81%
Epoch: 850, Loss: 0.2597, Train: 92.19%, Valid: 82.67%, Test: 82.68%
Epoch: 875, Loss: 0.2577, Train: 92.24%, Valid: 82.72%, Test: 82.38%
Epoch: 900, Loss: 0.2571, Train: 93.06%, Valid: 83.32%, Test: 83.12%
Epoch: 925, Loss: 0.2487, Train: 92.58%, Valid: 82.44%, Test: 82.79%
Epoch: 950, Loss: 0.2556, Train: 92.90%, Valid: 82.98%, Test: 82.74%
Epoch: 975, Loss: 0.2493, Train: 92.87%, Valid: 82.73%, Test: 82.81%
Run 01:
Highest Train: 93.50
Highest Valid: 83.45
  Final Train: 92.18
   Final Test: 83.20
All runs:
Highest Train: 93.50, nan
Highest Valid: 83.45, nan
  Final Train: 92.18, nan
   Final Test: 83.20, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.8199, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.7828, Train: 49.50%, Valid: 50.40%, Test: 49.94%
Epoch: 50, Loss: 0.5705, Train: 73.32%, Valid: 73.31%, Test: 72.48%
Epoch: 75, Loss: 0.5136, Train: 77.39%, Valid: 76.68%, Test: 76.16%
Epoch: 100, Loss: 0.4735, Train: 79.45%, Valid: 78.10%, Test: 77.50%
Epoch: 125, Loss: 0.4446, Train: 81.12%, Valid: 79.10%, Test: 78.96%
Epoch: 150, Loss: 0.4264, Train: 82.40%, Valid: 79.89%, Test: 79.64%
Epoch: 175, Loss: 0.4147, Train: 83.67%, Valid: 80.47%, Test: 80.30%
Epoch: 200, Loss: 0.4059, Train: 84.74%, Valid: 81.07%, Test: 81.03%
Epoch: 225, Loss: 0.3984, Train: 85.62%, Valid: 81.57%, Test: 81.41%
Epoch: 250, Loss: 0.3914, Train: 86.43%, Valid: 81.78%, Test: 81.67%
Epoch: 275, Loss: 0.3847, Train: 87.21%, Valid: 82.01%, Test: 82.05%
Epoch: 300, Loss: 0.3784, Train: 88.07%, Valid: 82.20%, Test: 82.61%
Epoch: 325, Loss: 0.3727, Train: 88.81%, Valid: 82.56%, Test: 82.86%
Epoch: 350, Loss: 0.3674, Train: 89.35%, Valid: 82.83%, Test: 82.90%
Epoch: 375, Loss: 0.3625, Train: 89.94%, Valid: 82.96%, Test: 83.11%
Epoch: 400, Loss: 0.3579, Train: 90.51%, Valid: 83.05%, Test: 83.33%
Epoch: 425, Loss: 0.3537, Train: 90.92%, Valid: 83.24%, Test: 83.39%
Epoch: 450, Loss: 0.3497, Train: 91.36%, Valid: 83.45%, Test: 83.43%
Epoch: 475, Loss: 0.3463, Train: 91.81%, Valid: 83.48%, Test: 83.33%
Epoch: 500, Loss: 0.3426, Train: 92.15%, Valid: 83.56%, Test: 83.70%
Epoch: 525, Loss: 0.3394, Train: 92.49%, Valid: 83.68%, Test: 83.77%
Epoch: 550, Loss: 0.3362, Train: 92.81%, Valid: 83.74%, Test: 83.64%
Epoch: 575, Loss: 0.3333, Train: 93.12%, Valid: 83.84%, Test: 83.67%
Epoch: 600, Loss: 0.3306, Train: 93.40%, Valid: 83.83%, Test: 83.61%
Epoch: 625, Loss: 0.3279, Train: 93.69%, Valid: 83.80%, Test: 83.55%
Epoch: 650, Loss: 0.3253, Train: 93.86%, Valid: 83.91%, Test: 83.54%
Epoch: 675, Loss: 0.3234, Train: 93.96%, Valid: 83.77%, Test: 83.32%
Epoch: 700, Loss: 0.3204, Train: 94.24%, Valid: 83.86%, Test: 83.43%
Epoch: 725, Loss: 0.3190, Train: 94.39%, Valid: 83.87%, Test: 83.47%
Epoch: 750, Loss: 0.3161, Train: 94.54%, Valid: 83.96%, Test: 83.32%
Epoch: 775, Loss: 0.3138, Train: 94.75%, Valid: 83.97%, Test: 83.38%
Epoch: 800, Loss: 0.3124, Train: 94.69%, Valid: 83.55%, Test: 83.16%
Epoch: 825, Loss: 0.3099, Train: 94.98%, Valid: 83.83%, Test: 83.34%
Epoch: 850, Loss: 0.3079, Train: 95.12%, Valid: 83.85%, Test: 83.26%
Epoch: 875, Loss: 0.3072, Train: 95.06%, Valid: 83.65%, Test: 83.42%
Epoch: 900, Loss: 0.3043, Train: 95.40%, Valid: 83.83%, Test: 83.29%
Epoch: 925, Loss: 0.3024, Train: 95.51%, Valid: 83.77%, Test: 83.39%
Epoch: 950, Loss: 0.3006, Train: 95.62%, Valid: 83.73%, Test: 83.42%
Epoch: 975, Loss: 0.3002, Train: 95.57%, Valid: 83.44%, Test: 83.29%
Run 01:
Highest Train: 95.77
Highest Valid: 84.03
  Final Train: 94.53
   Final Test: 83.39
All runs:
Highest Train: 95.77, nan
Highest Valid: 84.03, nan
  Final Train: 94.53, nan
   Final Test: 83.39, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.7838, Train: 53.11%, Valid: 52.34%, Test: 52.97%
Epoch: 25, Loss: 0.5896, Train: 73.26%, Valid: 73.10%, Test: 72.07%
Epoch: 50, Loss: 0.5027, Train: 77.31%, Valid: 76.91%, Test: 76.04%
Epoch: 75, Loss: 0.4480, Train: 80.63%, Valid: 78.60%, Test: 78.48%
Epoch: 100, Loss: 0.4218, Train: 82.65%, Valid: 80.05%, Test: 79.97%
Epoch: 125, Loss: 0.4074, Train: 84.33%, Valid: 80.91%, Test: 80.72%
Epoch: 150, Loss: 0.3967, Train: 85.63%, Valid: 81.34%, Test: 81.29%
Epoch: 175, Loss: 0.3876, Train: 86.78%, Valid: 81.83%, Test: 81.95%
Epoch: 200, Loss: 0.3796, Train: 87.81%, Valid: 82.07%, Test: 82.34%
Epoch: 225, Loss: 0.3725, Train: 88.71%, Valid: 82.41%, Test: 82.66%
Epoch: 250, Loss: 0.3666, Train: 89.40%, Valid: 82.67%, Test: 82.82%
Epoch: 275, Loss: 0.3613, Train: 89.98%, Valid: 83.01%, Test: 83.13%
Epoch: 300, Loss: 0.3566, Train: 90.51%, Valid: 83.01%, Test: 83.13%
Epoch: 325, Loss: 0.3523, Train: 91.06%, Valid: 83.15%, Test: 83.30%
Epoch: 350, Loss: 0.3495, Train: 91.37%, Valid: 83.29%, Test: 83.06%
Epoch: 375, Loss: 0.3449, Train: 91.79%, Valid: 83.34%, Test: 83.35%
Epoch: 400, Loss: 0.3413, Train: 92.16%, Valid: 83.46%, Test: 83.28%
Epoch: 425, Loss: 0.3381, Train: 92.49%, Valid: 83.69%, Test: 83.35%
Epoch: 450, Loss: 0.3351, Train: 92.68%, Valid: 83.69%, Test: 83.28%
Epoch: 475, Loss: 0.3322, Train: 92.99%, Valid: 83.62%, Test: 83.34%
Epoch: 500, Loss: 0.3296, Train: 93.16%, Valid: 83.72%, Test: 83.49%
Epoch: 525, Loss: 0.3268, Train: 93.47%, Valid: 83.77%, Test: 83.49%
Epoch: 550, Loss: 0.3244, Train: 93.61%, Valid: 83.82%, Test: 83.43%
Epoch: 575, Loss: 0.3246, Train: 93.67%, Valid: 83.80%, Test: 83.61%
Epoch: 600, Loss: 0.3199, Train: 93.97%, Valid: 83.73%, Test: 83.33%
Epoch: 625, Loss: 0.3174, Train: 94.14%, Valid: 83.88%, Test: 83.29%
Epoch: 650, Loss: 0.3154, Train: 94.11%, Valid: 83.66%, Test: 83.12%
Epoch: 675, Loss: 0.3133, Train: 94.44%, Valid: 83.86%, Test: 83.33%
Epoch: 700, Loss: 0.3115, Train: 94.54%, Valid: 83.85%, Test: 83.47%
Epoch: 725, Loss: 0.3094, Train: 94.68%, Valid: 83.79%, Test: 83.28%
Epoch: 750, Loss: 0.3083, Train: 94.78%, Valid: 83.50%, Test: 83.13%
Epoch: 775, Loss: 0.3060, Train: 94.93%, Valid: 83.84%, Test: 83.42%
Epoch: 800, Loss: 0.3039, Train: 95.07%, Valid: 83.76%, Test: 83.27%
Epoch: 825, Loss: 0.3020, Train: 95.21%, Valid: 83.68%, Test: 83.25%
Epoch: 850, Loss: 0.3002, Train: 95.35%, Valid: 83.70%, Test: 83.31%
Epoch: 875, Loss: 0.3010, Train: 95.15%, Valid: 83.49%, Test: 82.97%
Epoch: 900, Loss: 0.2973, Train: 95.39%, Valid: 83.66%, Test: 83.19%
Epoch: 925, Loss: 0.2957, Train: 95.60%, Valid: 83.73%, Test: 83.33%
Epoch: 950, Loss: 0.2941, Train: 95.69%, Valid: 83.73%, Test: 83.34%
Epoch: 975, Loss: 0.2926, Train: 95.76%, Valid: 83.68%, Test: 83.31%
Run 01:
Highest Train: 95.86
Highest Valid: 83.98
  Final Train: 94.33
   Final Test: 83.46
All runs:
Highest Train: 95.86, nan
Highest Valid: 83.98, nan
  Final Train: 94.33, nan
   Final Test: 83.46, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.4479, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.7186, Train: 54.17%, Valid: 54.51%, Test: 53.64%
Epoch: 50, Loss: 0.5458, Train: 75.52%, Valid: 74.75%, Test: 74.40%
Epoch: 75, Loss: 0.4886, Train: 78.40%, Valid: 77.37%, Test: 76.85%
Epoch: 100, Loss: 0.4502, Train: 80.66%, Valid: 78.91%, Test: 78.56%
Epoch: 125, Loss: 0.4275, Train: 82.38%, Valid: 79.85%, Test: 79.78%
Epoch: 150, Loss: 0.4144, Train: 83.74%, Valid: 80.63%, Test: 80.42%
Epoch: 175, Loss: 0.4051, Train: 84.81%, Valid: 81.08%, Test: 80.97%
Epoch: 200, Loss: 0.3973, Train: 85.72%, Valid: 81.48%, Test: 81.27%
Epoch: 225, Loss: 0.3900, Train: 86.59%, Valid: 81.78%, Test: 81.70%
Epoch: 250, Loss: 0.3830, Train: 87.34%, Valid: 82.01%, Test: 82.12%
Epoch: 275, Loss: 0.3765, Train: 88.32%, Valid: 82.21%, Test: 82.50%
Epoch: 300, Loss: 0.3705, Train: 88.98%, Valid: 82.62%, Test: 82.80%
Epoch: 325, Loss: 0.3653, Train: 89.67%, Valid: 82.84%, Test: 82.94%
Epoch: 350, Loss: 0.3600, Train: 90.26%, Valid: 82.95%, Test: 83.18%
Epoch: 375, Loss: 0.3553, Train: 90.79%, Valid: 83.10%, Test: 83.19%
Epoch: 400, Loss: 0.3511, Train: 91.20%, Valid: 83.19%, Test: 83.23%
Epoch: 425, Loss: 0.3470, Train: 91.71%, Valid: 83.40%, Test: 83.42%
Epoch: 450, Loss: 0.3434, Train: 92.16%, Valid: 83.42%, Test: 83.48%
Epoch: 475, Loss: 0.3398, Train: 92.51%, Valid: 83.48%, Test: 83.40%
Epoch: 500, Loss: 0.3367, Train: 92.82%, Valid: 83.46%, Test: 83.40%
Epoch: 525, Loss: 0.3336, Train: 93.18%, Valid: 83.60%, Test: 83.63%
Epoch: 550, Loss: 0.3306, Train: 93.30%, Valid: 83.47%, Test: 83.45%
Epoch: 575, Loss: 0.3276, Train: 93.65%, Valid: 83.59%, Test: 83.50%
Epoch: 600, Loss: 0.3250, Train: 93.85%, Valid: 83.62%, Test: 83.46%
Epoch: 625, Loss: 0.3227, Train: 94.13%, Valid: 83.73%, Test: 83.41%
Epoch: 650, Loss: 0.3199, Train: 94.34%, Valid: 83.72%, Test: 83.46%
Epoch: 675, Loss: 0.3179, Train: 94.49%, Valid: 83.68%, Test: 83.44%
Epoch: 700, Loss: 0.3153, Train: 94.74%, Valid: 83.63%, Test: 83.49%
Epoch: 725, Loss: 0.3131, Train: 94.85%, Valid: 83.51%, Test: 83.37%
Epoch: 750, Loss: 0.3110, Train: 95.01%, Valid: 83.60%, Test: 83.42%
Epoch: 775, Loss: 0.3089, Train: 95.20%, Valid: 83.52%, Test: 83.57%
Epoch: 800, Loss: 0.3077, Train: 95.13%, Valid: 83.37%, Test: 83.21%
Epoch: 825, Loss: 0.3053, Train: 95.36%, Valid: 83.49%, Test: 83.27%
Epoch: 850, Loss: 0.3032, Train: 95.51%, Valid: 83.55%, Test: 83.31%
Epoch: 875, Loss: 0.3012, Train: 95.65%, Valid: 83.43%, Test: 83.31%
Epoch: 900, Loss: 0.2996, Train: 95.69%, Valid: 83.50%, Test: 83.17%
Epoch: 925, Loss: 0.2993, Train: 95.76%, Valid: 83.58%, Test: 83.30%
Epoch: 950, Loss: 0.2960, Train: 95.93%, Valid: 83.52%, Test: 83.37%
Epoch: 975, Loss: 0.2944, Train: 96.07%, Valid: 83.55%, Test: 83.20%
Run 01:
Highest Train: 96.18
Highest Valid: 83.80
  Final Train: 94.08
   Final Test: 83.68
All runs:
Highest Train: 96.18, nan
Highest Valid: 83.80, nan
  Final Train: 94.08, nan
   Final Test: 83.68, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.3370, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.6720, Train: 61.40%, Valid: 60.51%, Test: 60.21%
Epoch: 50, Loss: 0.6246, Train: 70.72%, Valid: 70.49%, Test: 69.65%
Epoch: 75, Loss: 0.5890, Train: 74.38%, Valid: 73.68%, Test: 73.12%
Epoch: 100, Loss: 0.5552, Train: 75.88%, Valid: 75.52%, Test: 74.39%
Epoch: 125, Loss: 0.5157, Train: 77.39%, Valid: 76.62%, Test: 75.95%
Epoch: 150, Loss: 0.4765, Train: 79.18%, Valid: 77.94%, Test: 77.47%
Epoch: 175, Loss: 0.4497, Train: 80.68%, Valid: 78.72%, Test: 78.51%
Epoch: 200, Loss: 0.4334, Train: 81.78%, Valid: 79.32%, Test: 79.33%
Epoch: 225, Loss: 0.4229, Train: 82.87%, Valid: 79.92%, Test: 80.16%
Epoch: 250, Loss: 0.4150, Train: 83.68%, Valid: 80.45%, Test: 80.31%
Epoch: 275, Loss: 0.4091, Train: 84.42%, Valid: 80.95%, Test: 80.87%
Epoch: 300, Loss: 0.4038, Train: 85.01%, Valid: 81.25%, Test: 81.05%
Epoch: 325, Loss: 0.3995, Train: 85.49%, Valid: 81.42%, Test: 81.45%
Epoch: 350, Loss: 0.3950, Train: 85.93%, Valid: 81.63%, Test: 81.68%
Epoch: 375, Loss: 0.3915, Train: 86.28%, Valid: 81.74%, Test: 81.76%
Epoch: 400, Loss: 0.3878, Train: 86.90%, Valid: 81.93%, Test: 82.07%
Epoch: 425, Loss: 0.3838, Train: 87.24%, Valid: 82.05%, Test: 82.25%
Epoch: 450, Loss: 0.3807, Train: 87.69%, Valid: 82.05%, Test: 82.18%
Epoch: 475, Loss: 0.3779, Train: 87.99%, Valid: 82.22%, Test: 82.27%
Epoch: 500, Loss: 0.3768, Train: 88.49%, Valid: 82.39%, Test: 82.65%
Epoch: 525, Loss: 0.3722, Train: 88.84%, Valid: 82.42%, Test: 82.83%
Epoch: 550, Loss: 0.3695, Train: 89.05%, Valid: 82.56%, Test: 82.79%
Epoch: 575, Loss: 0.3673, Train: 89.38%, Valid: 82.57%, Test: 82.95%
Epoch: 600, Loss: 0.3648, Train: 89.47%, Valid: 82.91%, Test: 82.92%
Epoch: 625, Loss: 0.3630, Train: 89.57%, Valid: 82.55%, Test: 82.76%
Epoch: 650, Loss: 0.3607, Train: 89.92%, Valid: 82.83%, Test: 83.12%
Epoch: 675, Loss: 0.3590, Train: 90.20%, Valid: 82.88%, Test: 83.07%
Epoch: 700, Loss: 0.3583, Train: 90.37%, Valid: 83.01%, Test: 83.06%
Epoch: 725, Loss: 0.3556, Train: 90.88%, Valid: 82.92%, Test: 83.52%
Epoch: 750, Loss: 0.3539, Train: 90.67%, Valid: 82.97%, Test: 82.95%
Epoch: 775, Loss: 0.3510, Train: 90.74%, Valid: 82.90%, Test: 83.02%
Epoch: 800, Loss: 0.3498, Train: 91.18%, Valid: 83.18%, Test: 83.34%
Epoch: 825, Loss: 0.3484, Train: 91.24%, Valid: 83.30%, Test: 83.26%
Epoch: 850, Loss: 0.3462, Train: 91.50%, Valid: 83.20%, Test: 83.32%
Epoch: 875, Loss: 0.3456, Train: 91.63%, Valid: 83.50%, Test: 83.25%
Epoch: 900, Loss: 0.3464, Train: 91.53%, Valid: 83.21%, Test: 83.13%
Epoch: 925, Loss: 0.3456, Train: 91.72%, Valid: 83.02%, Test: 82.92%
Epoch: 950, Loss: 0.3421, Train: 91.78%, Valid: 83.22%, Test: 83.25%
Epoch: 975, Loss: 0.3407, Train: 91.94%, Valid: 83.31%, Test: 83.37%
Run 01:
Highest Train: 92.17
Highest Valid: 83.64
  Final Train: 92.02
   Final Test: 83.37
All runs:
Highest Train: 92.17, nan
Highest Valid: 83.64, nan
  Final Train: 92.02, nan
   Final Test: 83.37, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.2899, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.8773, Train: 49.01%, Valid: 49.98%, Test: 49.09%
Epoch: 50, Loss: 0.5578, Train: 71.49%, Valid: 71.15%, Test: 70.84%
Epoch: 75, Loss: 0.4817, Train: 78.43%, Valid: 77.07%, Test: 77.01%
Epoch: 100, Loss: 0.4482, Train: 80.58%, Valid: 78.79%, Test: 78.54%
Epoch: 125, Loss: 0.4297, Train: 82.04%, Valid: 79.60%, Test: 79.68%
Epoch: 150, Loss: 0.4193, Train: 83.15%, Valid: 80.27%, Test: 80.13%
Epoch: 175, Loss: 0.4116, Train: 84.07%, Valid: 80.83%, Test: 80.75%
Epoch: 200, Loss: 0.4051, Train: 84.97%, Valid: 81.22%, Test: 81.10%
Epoch: 225, Loss: 0.3995, Train: 85.40%, Valid: 81.39%, Test: 81.13%
Epoch: 250, Loss: 0.3944, Train: 86.15%, Valid: 81.68%, Test: 81.74%
Epoch: 275, Loss: 0.3898, Train: 86.68%, Valid: 82.26%, Test: 81.98%
Epoch: 300, Loss: 0.3855, Train: 87.10%, Valid: 81.88%, Test: 82.02%
Epoch: 325, Loss: 0.3819, Train: 87.70%, Valid: 81.95%, Test: 82.34%
Epoch: 350, Loss: 0.3790, Train: 88.12%, Valid: 82.35%, Test: 82.44%
Epoch: 375, Loss: 0.3743, Train: 88.51%, Valid: 82.42%, Test: 82.50%
Epoch: 400, Loss: 0.3724, Train: 88.89%, Valid: 82.44%, Test: 82.51%
Epoch: 425, Loss: 0.3691, Train: 89.05%, Valid: 82.60%, Test: 82.86%
Epoch: 450, Loss: 0.3660, Train: 89.45%, Valid: 82.77%, Test: 83.05%
Epoch: 475, Loss: 0.3651, Train: 89.77%, Valid: 82.73%, Test: 83.05%
Epoch: 500, Loss: 0.3622, Train: 89.83%, Valid: 82.91%, Test: 82.75%
Epoch: 525, Loss: 0.3596, Train: 90.20%, Valid: 83.06%, Test: 83.10%
Epoch: 550, Loss: 0.3580, Train: 90.16%, Valid: 82.93%, Test: 82.85%
Epoch: 575, Loss: 0.3555, Train: 90.62%, Valid: 83.34%, Test: 83.14%
Epoch: 600, Loss: 0.3522, Train: 90.76%, Valid: 83.36%, Test: 83.18%
Epoch: 625, Loss: 0.3522, Train: 90.86%, Valid: 82.87%, Test: 83.21%
Epoch: 650, Loss: 0.3492, Train: 91.05%, Valid: 83.28%, Test: 83.07%
Epoch: 675, Loss: 0.3502, Train: 91.03%, Valid: 83.03%, Test: 82.97%
Epoch: 700, Loss: 0.3481, Train: 91.26%, Valid: 83.43%, Test: 83.19%
Epoch: 725, Loss: 0.3443, Train: 91.47%, Valid: 83.44%, Test: 83.62%
Epoch: 750, Loss: 0.3417, Train: 91.70%, Valid: 83.39%, Test: 83.61%
Epoch: 775, Loss: 0.3409, Train: 91.68%, Valid: 83.57%, Test: 83.52%
Epoch: 800, Loss: 0.3395, Train: 91.78%, Valid: 83.49%, Test: 83.23%
Epoch: 825, Loss: 0.3369, Train: 91.97%, Valid: 83.34%, Test: 83.33%
Epoch: 850, Loss: 0.3365, Train: 91.88%, Valid: 83.25%, Test: 83.15%
Epoch: 875, Loss: 0.3348, Train: 92.02%, Valid: 83.30%, Test: 83.08%
Epoch: 900, Loss: 0.3362, Train: 92.34%, Valid: 83.25%, Test: 83.19%
Epoch: 925, Loss: 0.3329, Train: 92.25%, Valid: 83.16%, Test: 83.21%
Epoch: 950, Loss: 0.3306, Train: 92.40%, Valid: 83.13%, Test: 83.24%
Epoch: 975, Loss: 0.3287, Train: 92.65%, Valid: 83.27%, Test: 83.37%
Run 01:
Highest Train: 92.80
Highest Valid: 83.80
  Final Train: 92.05
   Final Test: 83.53
All runs:
Highest Train: 92.80, nan
Highest Valid: 83.80, nan
  Final Train: 92.05, nan
   Final Test: 83.53, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.2222, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.6953, Train: 53.39%, Valid: 53.66%, Test: 53.15%
Epoch: 50, Loss: 0.5904, Train: 73.72%, Valid: 73.47%, Test: 73.08%
Epoch: 75, Loss: 0.5379, Train: 76.54%, Valid: 76.27%, Test: 75.33%
Epoch: 100, Loss: 0.4913, Train: 78.43%, Valid: 77.46%, Test: 76.81%
Epoch: 125, Loss: 0.4586, Train: 80.15%, Valid: 78.20%, Test: 77.99%
Epoch: 150, Loss: 0.4389, Train: 81.43%, Valid: 79.14%, Test: 78.92%
Epoch: 175, Loss: 0.4264, Train: 82.24%, Valid: 79.96%, Test: 79.51%
Epoch: 200, Loss: 0.4175, Train: 83.22%, Valid: 80.21%, Test: 80.11%
Epoch: 225, Loss: 0.4112, Train: 84.11%, Valid: 80.63%, Test: 80.58%
Epoch: 250, Loss: 0.4060, Train: 84.72%, Valid: 80.93%, Test: 80.95%
Epoch: 275, Loss: 0.4013, Train: 85.24%, Valid: 81.34%, Test: 81.20%
Epoch: 300, Loss: 0.3966, Train: 85.64%, Valid: 81.48%, Test: 81.35%
Epoch: 325, Loss: 0.3931, Train: 86.04%, Valid: 81.53%, Test: 81.66%
Epoch: 350, Loss: 0.3889, Train: 86.46%, Valid: 81.82%, Test: 81.85%
Epoch: 375, Loss: 0.3855, Train: 87.03%, Valid: 82.06%, Test: 82.07%
Epoch: 400, Loss: 0.3819, Train: 87.47%, Valid: 82.01%, Test: 82.11%
Epoch: 425, Loss: 0.3791, Train: 87.81%, Valid: 82.09%, Test: 82.26%
Epoch: 450, Loss: 0.3768, Train: 88.06%, Valid: 82.19%, Test: 82.32%
Epoch: 475, Loss: 0.3731, Train: 88.46%, Valid: 82.33%, Test: 82.47%
Epoch: 500, Loss: 0.3719, Train: 88.66%, Valid: 82.08%, Test: 82.52%
Epoch: 525, Loss: 0.3690, Train: 88.93%, Valid: 82.42%, Test: 82.84%
Epoch: 550, Loss: 0.3659, Train: 89.17%, Valid: 82.45%, Test: 82.69%
Epoch: 575, Loss: 0.3677, Train: 89.33%, Valid: 82.42%, Test: 82.71%
Epoch: 600, Loss: 0.3635, Train: 89.49%, Valid: 82.53%, Test: 82.97%
Epoch: 625, Loss: 0.3603, Train: 89.89%, Valid: 82.67%, Test: 83.03%
Epoch: 650, Loss: 0.3583, Train: 89.76%, Valid: 82.70%, Test: 82.84%
Epoch: 675, Loss: 0.3555, Train: 90.24%, Valid: 82.72%, Test: 83.17%
Epoch: 700, Loss: 0.3533, Train: 90.39%, Valid: 82.87%, Test: 83.07%
Epoch: 725, Loss: 0.3516, Train: 90.63%, Valid: 83.03%, Test: 83.04%
Epoch: 750, Loss: 0.3504, Train: 90.54%, Valid: 82.78%, Test: 82.65%
Epoch: 775, Loss: 0.3505, Train: 90.81%, Valid: 83.01%, Test: 83.15%
Epoch: 800, Loss: 0.3477, Train: 90.92%, Valid: 83.02%, Test: 83.15%
Epoch: 825, Loss: 0.3461, Train: 91.07%, Valid: 82.92%, Test: 82.92%
Epoch: 850, Loss: 0.3428, Train: 91.11%, Valid: 82.74%, Test: 82.85%
Epoch: 875, Loss: 0.3430, Train: 91.16%, Valid: 82.87%, Test: 82.98%
Epoch: 900, Loss: 0.3416, Train: 91.30%, Valid: 83.15%, Test: 83.10%
Epoch: 925, Loss: 0.3388, Train: 91.38%, Valid: 83.20%, Test: 83.06%
Epoch: 950, Loss: 0.3380, Train: 91.33%, Valid: 82.58%, Test: 83.24%
Epoch: 975, Loss: 0.3373, Train: 91.88%, Valid: 83.23%, Test: 83.20%
Run 01:
Highest Train: 92.00
Highest Valid: 83.45
  Final Train: 91.92
   Final Test: 83.59
All runs:
Highest Train: 92.00, nan
Highest Valid: 83.45, nan
  Final Train: 91.92, nan
   Final Test: 83.59, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.5147, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 1.1079, Train: 52.90%, Valid: 51.96%, Test: 52.84%
Epoch: 50, Loss: 0.7724, Train: 57.77%, Valid: 56.56%, Test: 57.21%
Epoch: 75, Loss: 0.5587, Train: 73.19%, Valid: 72.06%, Test: 71.98%
Epoch: 100, Loss: 0.4805, Train: 78.62%, Valid: 77.43%, Test: 77.03%
Epoch: 125, Loss: 0.4496, Train: 80.62%, Valid: 78.92%, Test: 78.59%
Epoch: 150, Loss: 0.4344, Train: 81.74%, Valid: 79.42%, Test: 79.38%
Epoch: 175, Loss: 0.4245, Train: 82.59%, Valid: 80.18%, Test: 80.07%
Epoch: 200, Loss: 0.4187, Train: 83.50%, Valid: 80.53%, Test: 80.46%
Epoch: 225, Loss: 0.4123, Train: 84.19%, Valid: 80.63%, Test: 80.62%
Epoch: 250, Loss: 0.4076, Train: 84.85%, Valid: 81.02%, Test: 80.96%
Epoch: 275, Loss: 0.4046, Train: 85.31%, Valid: 81.49%, Test: 81.43%
Epoch: 300, Loss: 0.4005, Train: 85.55%, Valid: 81.44%, Test: 81.31%
Epoch: 325, Loss: 0.3975, Train: 86.21%, Valid: 81.71%, Test: 81.77%
Epoch: 350, Loss: 0.3938, Train: 86.53%, Valid: 81.84%, Test: 81.77%
Epoch: 375, Loss: 0.3883, Train: 86.64%, Valid: 81.88%, Test: 81.72%
Epoch: 400, Loss: 0.3877, Train: 87.16%, Valid: 81.96%, Test: 81.84%
Epoch: 425, Loss: 0.3845, Train: 87.35%, Valid: 81.90%, Test: 81.98%
Epoch: 450, Loss: 0.3809, Train: 87.82%, Valid: 82.09%, Test: 82.07%
Epoch: 475, Loss: 0.3783, Train: 88.23%, Valid: 82.26%, Test: 82.39%
Epoch: 500, Loss: 0.3771, Train: 88.42%, Valid: 82.46%, Test: 82.62%
Epoch: 525, Loss: 0.3743, Train: 88.67%, Valid: 82.45%, Test: 82.64%
Epoch: 550, Loss: 0.3717, Train: 88.59%, Valid: 82.26%, Test: 82.61%
Epoch: 575, Loss: 0.3689, Train: 88.76%, Valid: 82.38%, Test: 82.46%
Epoch: 600, Loss: 0.3668, Train: 89.14%, Valid: 82.55%, Test: 82.87%
Epoch: 625, Loss: 0.3670, Train: 89.10%, Valid: 82.77%, Test: 82.59%
Epoch: 650, Loss: 0.3651, Train: 89.54%, Valid: 82.58%, Test: 82.77%
Epoch: 675, Loss: 0.3669, Train: 89.67%, Valid: 82.90%, Test: 83.03%
Epoch: 700, Loss: 0.3635, Train: 89.76%, Valid: 82.92%, Test: 83.11%
Epoch: 725, Loss: 0.3598, Train: 90.08%, Valid: 82.83%, Test: 83.39%
Epoch: 750, Loss: 0.3583, Train: 89.96%, Valid: 82.78%, Test: 82.95%
Epoch: 775, Loss: 0.3567, Train: 90.22%, Valid: 82.84%, Test: 82.97%
Epoch: 800, Loss: 0.3544, Train: 90.31%, Valid: 82.62%, Test: 82.75%
Epoch: 825, Loss: 0.3546, Train: 90.19%, Valid: 82.50%, Test: 82.63%
Epoch: 850, Loss: 0.3519, Train: 90.27%, Valid: 82.99%, Test: 82.80%
Epoch: 875, Loss: 0.3502, Train: 90.75%, Valid: 83.21%, Test: 83.19%
Epoch: 900, Loss: 0.3477, Train: 90.85%, Valid: 83.09%, Test: 83.09%
Epoch: 925, Loss: 0.3488, Train: 90.73%, Valid: 82.96%, Test: 82.97%
Epoch: 950, Loss: 0.3449, Train: 91.01%, Valid: 83.15%, Test: 83.29%
Epoch: 975, Loss: 0.3436, Train: 91.11%, Valid: 83.14%, Test: 83.25%
Run 01:
Highest Train: 91.35
Highest Valid: 83.45
  Final Train: 91.31
   Final Test: 83.28
All runs:
Highest Train: 91.35, nan
Highest Valid: 83.45, nan
  Final Train: 91.31, nan
   Final Test: 83.28, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.8253, Train: 52.85%, Valid: 52.01%, Test: 52.77%
Epoch: 25, Loss: 0.6147, Train: 71.15%, Valid: 71.07%, Test: 70.74%
Epoch: 50, Loss: 0.5380, Train: 75.96%, Valid: 75.73%, Test: 74.74%
Epoch: 75, Loss: 0.4850, Train: 78.68%, Valid: 77.72%, Test: 77.08%
Epoch: 100, Loss: 0.4498, Train: 80.67%, Valid: 78.93%, Test: 78.67%
Epoch: 125, Loss: 0.4297, Train: 81.88%, Valid: 79.99%, Test: 79.39%
Epoch: 150, Loss: 0.4194, Train: 83.16%, Valid: 80.41%, Test: 80.32%
Epoch: 175, Loss: 0.4116, Train: 83.90%, Valid: 80.51%, Test: 80.67%
Epoch: 200, Loss: 0.4063, Train: 84.64%, Valid: 81.09%, Test: 80.99%
Epoch: 225, Loss: 0.4008, Train: 85.21%, Valid: 81.22%, Test: 81.33%
Epoch: 250, Loss: 0.3958, Train: 85.68%, Valid: 81.43%, Test: 81.41%
Epoch: 275, Loss: 0.3919, Train: 86.11%, Valid: 81.55%, Test: 81.79%
Epoch: 300, Loss: 0.3873, Train: 86.63%, Valid: 82.04%, Test: 82.05%
Epoch: 325, Loss: 0.3842, Train: 87.04%, Valid: 81.93%, Test: 82.27%
Epoch: 350, Loss: 0.3800, Train: 87.34%, Valid: 82.23%, Test: 82.26%
Epoch: 375, Loss: 0.3779, Train: 87.81%, Valid: 82.26%, Test: 82.40%
Epoch: 400, Loss: 0.3745, Train: 87.92%, Valid: 81.94%, Test: 82.11%
Epoch: 425, Loss: 0.3719, Train: 88.65%, Valid: 82.40%, Test: 82.60%
Epoch: 450, Loss: 0.3690, Train: 88.83%, Valid: 82.61%, Test: 82.65%
Epoch: 475, Loss: 0.3674, Train: 88.82%, Valid: 82.37%, Test: 82.93%
Epoch: 500, Loss: 0.3639, Train: 89.28%, Valid: 82.67%, Test: 82.90%
Epoch: 525, Loss: 0.3637, Train: 89.42%, Valid: 82.79%, Test: 82.90%
Epoch: 550, Loss: 0.3604, Train: 89.63%, Valid: 82.63%, Test: 82.84%
Epoch: 575, Loss: 0.3581, Train: 89.79%, Valid: 82.64%, Test: 83.03%
Epoch: 600, Loss: 0.3579, Train: 89.78%, Valid: 82.77%, Test: 82.70%
Epoch: 625, Loss: 0.3554, Train: 90.14%, Valid: 82.89%, Test: 83.19%
Epoch: 650, Loss: 0.3505, Train: 90.25%, Valid: 82.74%, Test: 83.03%
Epoch: 675, Loss: 0.3501, Train: 90.43%, Valid: 83.10%, Test: 83.12%
Epoch: 700, Loss: 0.3501, Train: 90.63%, Valid: 82.82%, Test: 83.01%
Epoch: 725, Loss: 0.3473, Train: 90.50%, Valid: 82.83%, Test: 82.94%
Epoch: 750, Loss: 0.3450, Train: 90.89%, Valid: 83.07%, Test: 83.04%
Epoch: 775, Loss: 0.3447, Train: 90.65%, Valid: 82.77%, Test: 82.93%
Epoch: 800, Loss: 0.3414, Train: 91.08%, Valid: 83.10%, Test: 83.23%
Epoch: 825, Loss: 0.3418, Train: 91.04%, Valid: 82.88%, Test: 82.76%
Epoch: 850, Loss: 0.3390, Train: 91.15%, Valid: 83.31%, Test: 83.42%
Epoch: 875, Loss: 0.3386, Train: 91.49%, Valid: 83.08%, Test: 83.38%
Epoch: 900, Loss: 0.3358, Train: 91.43%, Valid: 83.15%, Test: 82.98%
Epoch: 925, Loss: 0.3350, Train: 91.79%, Valid: 83.22%, Test: 83.43%
Epoch: 950, Loss: 0.3339, Train: 91.90%, Valid: 83.31%, Test: 83.44%
Epoch: 975, Loss: 0.3354, Train: 91.85%, Valid: 82.93%, Test: 83.34%
Run 01:
Highest Train: 91.98
Highest Valid: 83.59
  Final Train: 91.80
   Final Test: 83.29
All runs:
Highest Train: 91.98, nan
Highest Valid: 83.59, nan
  Final Train: 91.80, nan
   Final Test: 83.29, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.2088, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 1.0626, Train: 53.15%, Valid: 52.24%, Test: 53.02%
Epoch: 50, Loss: 0.6678, Train: 63.32%, Valid: 62.16%, Test: 62.68%
Epoch: 75, Loss: 0.5473, Train: 75.28%, Valid: 74.79%, Test: 74.23%
Epoch: 100, Loss: 0.5003, Train: 77.99%, Valid: 76.83%, Test: 76.37%
Epoch: 125, Loss: 0.4672, Train: 79.59%, Valid: 77.89%, Test: 77.61%
Epoch: 150, Loss: 0.4454, Train: 81.03%, Valid: 79.00%, Test: 78.71%
Epoch: 175, Loss: 0.4327, Train: 81.93%, Valid: 79.68%, Test: 79.40%
Epoch: 200, Loss: 0.4243, Train: 82.77%, Valid: 80.08%, Test: 79.88%
Epoch: 225, Loss: 0.4188, Train: 83.60%, Valid: 80.53%, Test: 80.42%
Epoch: 250, Loss: 0.4122, Train: 84.17%, Valid: 80.82%, Test: 80.73%
Epoch: 275, Loss: 0.4082, Train: 84.72%, Valid: 81.01%, Test: 80.61%
Epoch: 300, Loss: 0.4051, Train: 85.05%, Valid: 81.11%, Test: 81.10%
Epoch: 325, Loss: 0.4019, Train: 85.35%, Valid: 81.33%, Test: 81.32%
Epoch: 350, Loss: 0.3986, Train: 85.68%, Valid: 81.47%, Test: 81.46%
Epoch: 375, Loss: 0.3941, Train: 86.22%, Valid: 81.49%, Test: 81.49%
Epoch: 400, Loss: 0.3913, Train: 86.56%, Valid: 81.81%, Test: 81.84%
Epoch: 425, Loss: 0.3873, Train: 86.96%, Valid: 82.03%, Test: 81.83%
Epoch: 450, Loss: 0.3859, Train: 87.06%, Valid: 82.14%, Test: 81.91%
Epoch: 475, Loss: 0.3819, Train: 87.70%, Valid: 82.16%, Test: 82.27%
Epoch: 500, Loss: 0.3797, Train: 87.81%, Valid: 82.13%, Test: 82.41%
Epoch: 525, Loss: 0.3774, Train: 88.00%, Valid: 82.28%, Test: 82.49%
Epoch: 550, Loss: 0.3760, Train: 88.35%, Valid: 82.46%, Test: 82.52%
Epoch: 575, Loss: 0.3730, Train: 88.50%, Valid: 82.51%, Test: 82.70%
Epoch: 600, Loss: 0.3704, Train: 88.87%, Valid: 82.46%, Test: 82.87%
Epoch: 625, Loss: 0.3686, Train: 88.99%, Valid: 82.73%, Test: 82.87%
Epoch: 650, Loss: 0.3666, Train: 89.02%, Valid: 82.60%, Test: 82.90%
Epoch: 675, Loss: 0.3637, Train: 89.44%, Valid: 82.94%, Test: 83.10%
Epoch: 700, Loss: 0.3622, Train: 89.49%, Valid: 82.67%, Test: 83.04%
Epoch: 725, Loss: 0.3635, Train: 89.73%, Valid: 83.03%, Test: 82.89%
Epoch: 750, Loss: 0.3582, Train: 89.89%, Valid: 83.08%, Test: 83.19%
Epoch: 775, Loss: 0.3569, Train: 89.88%, Valid: 82.76%, Test: 82.82%
Epoch: 800, Loss: 0.3599, Train: 90.31%, Valid: 83.25%, Test: 83.48%
Epoch: 825, Loss: 0.3528, Train: 90.42%, Valid: 83.07%, Test: 83.34%
Epoch: 850, Loss: 0.3525, Train: 90.61%, Valid: 83.24%, Test: 83.40%
Epoch: 875, Loss: 0.3502, Train: 90.71%, Valid: 83.27%, Test: 83.21%
Epoch: 900, Loss: 0.3503, Train: 90.53%, Valid: 83.20%, Test: 83.14%
Epoch: 925, Loss: 0.3468, Train: 90.82%, Valid: 83.29%, Test: 83.00%
Epoch: 950, Loss: 0.3475, Train: 91.09%, Valid: 83.40%, Test: 83.21%
Epoch: 975, Loss: 0.3464, Train: 91.13%, Valid: 83.37%, Test: 83.16%
Run 01:
Highest Train: 91.33
Highest Valid: 83.61
  Final Train: 90.92
   Final Test: 83.06
All runs:
Highest Train: 91.33, nan
Highest Valid: 83.61, nan
  Final Train: 90.92, nan
   Final Test: 83.06, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.1218, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.6357, Train: 67.90%, Valid: 68.19%, Test: 66.67%
Epoch: 50, Loss: 0.5706, Train: 74.61%, Valid: 74.53%, Test: 73.83%
Epoch: 75, Loss: 0.5172, Train: 77.04%, Valid: 76.73%, Test: 75.85%
Epoch: 100, Loss: 0.4760, Train: 79.04%, Valid: 77.84%, Test: 77.53%
Epoch: 125, Loss: 0.4491, Train: 80.93%, Valid: 78.83%, Test: 78.57%
Epoch: 150, Loss: 0.4320, Train: 81.98%, Valid: 79.61%, Test: 79.53%
Epoch: 175, Loss: 0.4209, Train: 83.02%, Valid: 80.32%, Test: 79.96%
Epoch: 200, Loss: 0.4126, Train: 83.84%, Valid: 80.73%, Test: 80.45%
Epoch: 225, Loss: 0.4059, Train: 84.57%, Valid: 80.94%, Test: 80.86%
Epoch: 250, Loss: 0.4002, Train: 85.23%, Valid: 81.25%, Test: 81.31%
Epoch: 275, Loss: 0.3949, Train: 85.82%, Valid: 81.47%, Test: 81.74%
Epoch: 300, Loss: 0.3899, Train: 86.26%, Valid: 81.45%, Test: 81.96%
Epoch: 325, Loss: 0.3850, Train: 86.73%, Valid: 81.70%, Test: 82.19%
Epoch: 350, Loss: 0.3805, Train: 87.33%, Valid: 81.89%, Test: 82.42%
Epoch: 375, Loss: 0.3763, Train: 87.93%, Valid: 82.16%, Test: 82.51%
Epoch: 400, Loss: 0.3721, Train: 88.49%, Valid: 82.35%, Test: 82.72%
Epoch: 425, Loss: 0.3682, Train: 88.91%, Valid: 82.55%, Test: 82.82%
Epoch: 450, Loss: 0.3644, Train: 89.39%, Valid: 82.68%, Test: 82.93%
Epoch: 475, Loss: 0.3607, Train: 89.80%, Valid: 82.74%, Test: 82.92%
Epoch: 500, Loss: 0.3572, Train: 90.17%, Valid: 82.93%, Test: 83.10%
Epoch: 525, Loss: 0.3539, Train: 90.50%, Valid: 83.06%, Test: 83.13%
Epoch: 550, Loss: 0.3507, Train: 90.80%, Valid: 83.19%, Test: 83.38%
Epoch: 575, Loss: 0.3474, Train: 91.11%, Valid: 83.21%, Test: 83.37%
Epoch: 600, Loss: 0.3446, Train: 91.40%, Valid: 83.40%, Test: 83.47%
Epoch: 625, Loss: 0.3418, Train: 91.75%, Valid: 83.44%, Test: 83.54%
Epoch: 650, Loss: 0.3393, Train: 91.97%, Valid: 83.57%, Test: 83.51%
Epoch: 675, Loss: 0.3364, Train: 92.20%, Valid: 83.58%, Test: 83.58%
Epoch: 700, Loss: 0.3345, Train: 92.37%, Valid: 83.35%, Test: 83.50%
Epoch: 725, Loss: 0.3314, Train: 92.66%, Valid: 83.70%, Test: 83.61%
Epoch: 750, Loss: 0.3294, Train: 92.86%, Valid: 83.72%, Test: 83.51%
Epoch: 775, Loss: 0.3268, Train: 93.08%, Valid: 83.69%, Test: 83.50%
Epoch: 800, Loss: 0.3249, Train: 93.28%, Valid: 83.65%, Test: 83.51%
Epoch: 825, Loss: 0.3225, Train: 93.46%, Valid: 83.69%, Test: 83.41%
Epoch: 850, Loss: 0.3204, Train: 93.62%, Valid: 83.77%, Test: 83.40%
Epoch: 875, Loss: 0.3185, Train: 93.81%, Valid: 83.72%, Test: 83.34%
Epoch: 900, Loss: 0.3165, Train: 93.91%, Valid: 83.75%, Test: 83.39%
Epoch: 925, Loss: 0.3146, Train: 94.14%, Valid: 83.76%, Test: 83.48%
Epoch: 950, Loss: 0.3128, Train: 94.20%, Valid: 83.85%, Test: 83.41%
Epoch: 975, Loss: 0.3111, Train: 94.30%, Valid: 83.71%, Test: 83.30%
Run 01:
Highest Train: 94.47
Highest Valid: 83.85
  Final Train: 94.20
   Final Test: 83.41
All runs:
Highest Train: 94.47, nan
Highest Valid: 83.85, nan
  Final Train: 94.20, nan
   Final Test: 83.41, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.2953, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.9477, Train: 54.05%, Valid: 52.96%, Test: 53.61%
Epoch: 50, Loss: 0.6343, Train: 67.04%, Valid: 65.57%, Test: 65.99%
Epoch: 75, Loss: 0.5199, Train: 76.47%, Valid: 76.00%, Test: 75.01%
Epoch: 100, Loss: 0.4777, Train: 79.08%, Valid: 77.76%, Test: 77.05%
Epoch: 125, Loss: 0.4536, Train: 80.67%, Valid: 78.97%, Test: 78.46%
Epoch: 150, Loss: 0.4378, Train: 81.75%, Valid: 79.68%, Test: 79.45%
Epoch: 175, Loss: 0.4266, Train: 82.65%, Valid: 80.09%, Test: 80.03%
Epoch: 200, Loss: 0.4182, Train: 83.39%, Valid: 80.44%, Test: 80.32%
Epoch: 225, Loss: 0.4115, Train: 84.09%, Valid: 80.87%, Test: 80.82%
Epoch: 250, Loss: 0.4059, Train: 84.61%, Valid: 80.91%, Test: 81.10%
Epoch: 275, Loss: 0.4009, Train: 85.21%, Valid: 81.21%, Test: 81.24%
Epoch: 300, Loss: 0.3963, Train: 85.63%, Valid: 81.39%, Test: 81.43%
Epoch: 325, Loss: 0.3919, Train: 86.20%, Valid: 81.52%, Test: 81.67%
Epoch: 350, Loss: 0.3878, Train: 86.65%, Valid: 81.78%, Test: 81.92%
Epoch: 375, Loss: 0.3838, Train: 87.12%, Valid: 81.83%, Test: 82.13%
Epoch: 400, Loss: 0.3799, Train: 87.57%, Valid: 81.91%, Test: 82.09%
Epoch: 425, Loss: 0.3761, Train: 88.01%, Valid: 82.11%, Test: 82.22%
Epoch: 450, Loss: 0.3725, Train: 88.40%, Valid: 82.27%, Test: 82.50%
Epoch: 475, Loss: 0.3690, Train: 88.80%, Valid: 82.42%, Test: 82.70%
Epoch: 500, Loss: 0.3655, Train: 89.20%, Valid: 82.70%, Test: 82.73%
Epoch: 525, Loss: 0.3621, Train: 89.52%, Valid: 82.78%, Test: 82.79%
Epoch: 550, Loss: 0.3588, Train: 89.89%, Valid: 82.88%, Test: 82.98%
Epoch: 575, Loss: 0.3555, Train: 90.23%, Valid: 82.98%, Test: 83.07%
Epoch: 600, Loss: 0.3524, Train: 90.52%, Valid: 83.07%, Test: 83.02%
Epoch: 625, Loss: 0.3493, Train: 90.84%, Valid: 83.15%, Test: 82.98%
Epoch: 650, Loss: 0.3464, Train: 91.02%, Valid: 83.04%, Test: 83.01%
Epoch: 675, Loss: 0.3435, Train: 91.32%, Valid: 83.18%, Test: 83.21%
Epoch: 700, Loss: 0.3408, Train: 91.61%, Valid: 83.18%, Test: 83.35%
Epoch: 725, Loss: 0.3381, Train: 91.99%, Valid: 83.24%, Test: 83.20%
Epoch: 750, Loss: 0.3355, Train: 92.16%, Valid: 83.35%, Test: 83.37%
Epoch: 775, Loss: 0.3329, Train: 92.34%, Valid: 83.46%, Test: 83.44%
Epoch: 800, Loss: 0.3303, Train: 92.69%, Valid: 83.38%, Test: 83.47%
Epoch: 825, Loss: 0.3279, Train: 92.82%, Valid: 83.46%, Test: 83.39%
Epoch: 850, Loss: 0.3256, Train: 93.08%, Valid: 83.46%, Test: 83.45%
Epoch: 875, Loss: 0.3233, Train: 93.27%, Valid: 83.44%, Test: 83.48%
Epoch: 900, Loss: 0.3215, Train: 93.39%, Valid: 83.36%, Test: 83.43%
Epoch: 925, Loss: 0.3191, Train: 93.64%, Valid: 83.49%, Test: 83.45%
Epoch: 950, Loss: 0.3171, Train: 93.77%, Valid: 83.52%, Test: 83.50%
Epoch: 975, Loss: 0.3152, Train: 93.94%, Valid: 83.54%, Test: 83.50%
Run 01:
Highest Train: 94.08
Highest Valid: 83.65
  Final Train: 94.05
   Final Test: 83.48
All runs:
Highest Train: 94.08, nan
Highest Valid: 83.65, nan
  Final Train: 94.05, nan
   Final Test: 83.48, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.5214, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 1.1266, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 50, Loss: 0.8073, Train: 56.56%, Valid: 55.43%, Test: 56.16%
Epoch: 75, Loss: 0.5881, Train: 70.64%, Valid: 69.28%, Test: 69.25%
Epoch: 100, Loss: 0.5072, Train: 77.21%, Valid: 76.63%, Test: 75.97%
Epoch: 125, Loss: 0.4696, Train: 79.41%, Valid: 78.03%, Test: 77.79%
Epoch: 150, Loss: 0.4470, Train: 80.95%, Valid: 79.03%, Test: 78.82%
Epoch: 175, Loss: 0.4330, Train: 81.97%, Valid: 79.68%, Test: 79.75%
Epoch: 200, Loss: 0.4234, Train: 82.76%, Valid: 80.13%, Test: 80.14%
Epoch: 225, Loss: 0.4162, Train: 83.59%, Valid: 80.43%, Test: 80.47%
Epoch: 250, Loss: 0.4101, Train: 84.27%, Valid: 80.80%, Test: 80.70%
Epoch: 275, Loss: 0.4048, Train: 84.78%, Valid: 81.14%, Test: 81.08%
Epoch: 300, Loss: 0.4000, Train: 85.28%, Valid: 81.34%, Test: 81.26%
Epoch: 325, Loss: 0.3949, Train: 85.92%, Valid: 81.45%, Test: 81.41%
Epoch: 350, Loss: 0.3901, Train: 86.48%, Valid: 81.69%, Test: 81.75%
Epoch: 375, Loss: 0.3855, Train: 87.04%, Valid: 81.82%, Test: 81.96%
Epoch: 400, Loss: 0.3810, Train: 87.70%, Valid: 81.95%, Test: 82.21%
Epoch: 425, Loss: 0.3766, Train: 88.24%, Valid: 82.25%, Test: 82.43%
Epoch: 450, Loss: 0.3723, Train: 88.64%, Valid: 82.43%, Test: 82.61%
Epoch: 475, Loss: 0.3680, Train: 89.13%, Valid: 82.71%, Test: 82.84%
Epoch: 500, Loss: 0.3638, Train: 89.65%, Valid: 82.97%, Test: 82.74%
Epoch: 525, Loss: 0.3599, Train: 90.07%, Valid: 82.90%, Test: 82.97%
Epoch: 550, Loss: 0.3562, Train: 90.49%, Valid: 83.12%, Test: 83.01%
Epoch: 575, Loss: 0.3527, Train: 90.77%, Valid: 83.04%, Test: 83.10%
Epoch: 600, Loss: 0.3493, Train: 91.14%, Valid: 83.20%, Test: 83.14%
Epoch: 625, Loss: 0.3461, Train: 91.51%, Valid: 83.36%, Test: 83.28%
Epoch: 650, Loss: 0.3431, Train: 91.89%, Valid: 83.37%, Test: 83.42%
Epoch: 675, Loss: 0.3402, Train: 92.14%, Valid: 83.36%, Test: 83.37%
Epoch: 700, Loss: 0.3375, Train: 92.39%, Valid: 83.34%, Test: 83.44%
Epoch: 725, Loss: 0.3348, Train: 92.56%, Valid: 83.49%, Test: 83.24%
Epoch: 750, Loss: 0.3329, Train: 92.70%, Valid: 83.47%, Test: 83.19%
Epoch: 775, Loss: 0.3300, Train: 93.04%, Valid: 83.49%, Test: 83.35%
Epoch: 800, Loss: 0.3277, Train: 93.20%, Valid: 83.57%, Test: 83.43%
Epoch: 825, Loss: 0.3260, Train: 93.39%, Valid: 83.54%, Test: 83.40%
Epoch: 850, Loss: 0.3234, Train: 93.54%, Valid: 83.59%, Test: 83.38%
Epoch: 875, Loss: 0.3213, Train: 93.77%, Valid: 83.56%, Test: 83.34%
Epoch: 900, Loss: 0.3194, Train: 93.98%, Valid: 83.59%, Test: 83.39%
Epoch: 925, Loss: 0.3174, Train: 94.06%, Valid: 83.49%, Test: 83.38%
Epoch: 950, Loss: 0.3154, Train: 94.21%, Valid: 83.55%, Test: 83.38%
Epoch: 975, Loss: 0.3135, Train: 94.38%, Valid: 83.47%, Test: 83.44%
Run 01:
Highest Train: 94.49
Highest Valid: 83.71
  Final Train: 93.99
   Final Test: 83.32
All runs:
Highest Train: 94.49, nan
Highest Valid: 83.71, nan
  Final Train: 93.99, nan
   Final Test: 83.32, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.2068, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.9265, Train: 53.65%, Valid: 52.70%, Test: 53.36%
Epoch: 50, Loss: 0.6625, Train: 64.39%, Valid: 62.99%, Test: 63.59%
Epoch: 75, Loss: 0.5413, Train: 75.15%, Valid: 74.41%, Test: 74.00%
Epoch: 100, Loss: 0.4894, Train: 78.11%, Valid: 77.42%, Test: 76.64%
Epoch: 125, Loss: 0.4619, Train: 79.75%, Valid: 78.58%, Test: 77.91%
Epoch: 150, Loss: 0.4447, Train: 81.09%, Valid: 79.05%, Test: 79.02%
Epoch: 175, Loss: 0.4327, Train: 81.94%, Valid: 79.55%, Test: 79.66%
Epoch: 200, Loss: 0.4241, Train: 82.69%, Valid: 79.95%, Test: 80.23%
Epoch: 225, Loss: 0.4176, Train: 83.31%, Valid: 80.23%, Test: 80.35%
Epoch: 250, Loss: 0.4126, Train: 83.92%, Valid: 80.49%, Test: 80.47%
Epoch: 275, Loss: 0.4098, Train: 84.34%, Valid: 80.51%, Test: 80.82%
Epoch: 300, Loss: 0.4050, Train: 84.76%, Valid: 80.97%, Test: 81.16%
Epoch: 325, Loss: 0.4007, Train: 85.27%, Valid: 81.01%, Test: 81.15%
Epoch: 350, Loss: 0.3975, Train: 85.80%, Valid: 81.30%, Test: 81.56%
Epoch: 375, Loss: 0.3942, Train: 86.03%, Valid: 81.70%, Test: 81.57%
Epoch: 400, Loss: 0.3909, Train: 86.16%, Valid: 81.53%, Test: 81.52%
Epoch: 425, Loss: 0.3892, Train: 86.62%, Valid: 81.74%, Test: 81.73%
Epoch: 450, Loss: 0.3857, Train: 86.91%, Valid: 81.92%, Test: 81.97%
Epoch: 475, Loss: 0.3827, Train: 87.26%, Valid: 82.03%, Test: 82.21%
Epoch: 500, Loss: 0.3805, Train: 87.50%, Valid: 82.17%, Test: 82.06%
Epoch: 525, Loss: 0.3791, Train: 87.73%, Valid: 82.08%, Test: 82.25%
Epoch: 550, Loss: 0.3767, Train: 88.06%, Valid: 82.18%, Test: 82.44%
Epoch: 575, Loss: 0.3747, Train: 88.22%, Valid: 82.23%, Test: 82.47%
Epoch: 600, Loss: 0.3717, Train: 88.35%, Valid: 82.31%, Test: 82.60%
Epoch: 625, Loss: 0.3707, Train: 88.37%, Valid: 82.25%, Test: 82.62%
Epoch: 650, Loss: 0.3685, Train: 88.76%, Valid: 82.53%, Test: 82.72%
Epoch: 675, Loss: 0.3681, Train: 88.78%, Valid: 82.46%, Test: 82.64%
Epoch: 700, Loss: 0.3680, Train: 88.61%, Valid: 82.40%, Test: 82.58%
Epoch: 725, Loss: 0.3629, Train: 89.00%, Valid: 82.56%, Test: 82.84%
Epoch: 750, Loss: 0.3616, Train: 89.15%, Valid: 82.57%, Test: 82.77%
Epoch: 775, Loss: 0.3629, Train: 89.37%, Valid: 82.64%, Test: 82.91%
Epoch: 800, Loss: 0.3580, Train: 89.44%, Valid: 82.52%, Test: 82.61%
Epoch: 825, Loss: 0.3567, Train: 89.53%, Valid: 82.65%, Test: 82.71%
Epoch: 850, Loss: 0.3558, Train: 89.77%, Valid: 82.91%, Test: 83.10%
Epoch: 875, Loss: 0.3547, Train: 90.06%, Valid: 83.11%, Test: 83.05%
Epoch: 900, Loss: 0.3538, Train: 89.77%, Valid: 82.76%, Test: 82.99%
Epoch: 925, Loss: 0.3508, Train: 90.00%, Valid: 82.97%, Test: 83.23%
Epoch: 950, Loss: 0.3539, Train: 90.10%, Valid: 82.87%, Test: 83.04%
Epoch: 975, Loss: 0.3492, Train: 90.19%, Valid: 82.86%, Test: 83.20%
Run 01:
Highest Train: 90.52
Highest Valid: 83.22
  Final Train: 90.41
   Final Test: 83.15
All runs:
Highest Train: 90.52, nan
Highest Valid: 83.22, nan
  Final Train: 90.41, nan
   Final Test: 83.15, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.8460, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.6409, Train: 68.17%, Valid: 68.44%, Test: 67.40%
Epoch: 50, Loss: 0.5828, Train: 73.95%, Valid: 73.85%, Test: 72.93%
Epoch: 75, Loss: 0.5276, Train: 76.63%, Valid: 76.54%, Test: 75.35%
Epoch: 100, Loss: 0.4812, Train: 78.81%, Valid: 77.87%, Test: 77.19%
Epoch: 125, Loss: 0.4537, Train: 80.51%, Valid: 78.80%, Test: 78.51%
Epoch: 150, Loss: 0.4356, Train: 81.64%, Valid: 79.42%, Test: 79.30%
Epoch: 175, Loss: 0.4253, Train: 82.38%, Valid: 79.93%, Test: 79.78%
Epoch: 200, Loss: 0.4175, Train: 83.25%, Valid: 80.27%, Test: 80.24%
Epoch: 225, Loss: 0.4115, Train: 83.82%, Valid: 80.61%, Test: 80.54%
Epoch: 250, Loss: 0.4066, Train: 84.41%, Valid: 80.87%, Test: 80.86%
Epoch: 275, Loss: 0.4020, Train: 84.86%, Valid: 81.16%, Test: 81.26%
Epoch: 300, Loss: 0.3984, Train: 85.34%, Valid: 81.38%, Test: 81.26%
Epoch: 325, Loss: 0.3947, Train: 85.61%, Valid: 81.50%, Test: 81.17%
Epoch: 350, Loss: 0.3920, Train: 86.10%, Valid: 81.62%, Test: 81.44%
Epoch: 375, Loss: 0.3879, Train: 86.36%, Valid: 81.85%, Test: 81.80%
Epoch: 400, Loss: 0.3852, Train: 86.78%, Valid: 81.91%, Test: 81.93%
Epoch: 425, Loss: 0.3819, Train: 87.17%, Valid: 81.95%, Test: 82.21%
Epoch: 450, Loss: 0.3805, Train: 87.40%, Valid: 82.10%, Test: 82.10%
Epoch: 475, Loss: 0.3769, Train: 87.57%, Valid: 82.26%, Test: 82.04%
Epoch: 500, Loss: 0.3762, Train: 87.82%, Valid: 82.09%, Test: 82.25%
Epoch: 525, Loss: 0.3729, Train: 88.14%, Valid: 82.31%, Test: 82.38%
Epoch: 550, Loss: 0.3704, Train: 88.37%, Valid: 82.34%, Test: 82.57%
Epoch: 575, Loss: 0.3679, Train: 88.35%, Valid: 82.17%, Test: 82.31%
Epoch: 600, Loss: 0.3673, Train: 88.60%, Valid: 82.35%, Test: 82.67%
Epoch: 625, Loss: 0.3658, Train: 88.59%, Valid: 82.45%, Test: 82.44%
Epoch: 650, Loss: 0.3624, Train: 88.99%, Valid: 82.47%, Test: 82.81%
Epoch: 675, Loss: 0.3607, Train: 89.03%, Valid: 82.41%, Test: 82.35%
Epoch: 700, Loss: 0.3596, Train: 89.32%, Valid: 82.55%, Test: 82.99%
Epoch: 725, Loss: 0.3571, Train: 89.20%, Valid: 82.75%, Test: 82.67%
Epoch: 750, Loss: 0.3557, Train: 89.62%, Valid: 82.75%, Test: 82.92%
Epoch: 775, Loss: 0.3538, Train: 89.68%, Valid: 82.72%, Test: 82.57%
Epoch: 800, Loss: 0.3537, Train: 89.73%, Valid: 82.71%, Test: 82.71%
Epoch: 825, Loss: 0.3521, Train: 89.77%, Valid: 82.60%, Test: 82.45%
Epoch: 850, Loss: 0.3517, Train: 90.00%, Valid: 82.72%, Test: 82.72%
Epoch: 875, Loss: 0.3482, Train: 89.96%, Valid: 82.79%, Test: 82.71%
Epoch: 900, Loss: 0.3463, Train: 90.27%, Valid: 82.93%, Test: 82.84%
Epoch: 925, Loss: 0.3466, Train: 90.17%, Valid: 82.77%, Test: 82.75%
Epoch: 950, Loss: 0.3446, Train: 90.45%, Valid: 83.14%, Test: 82.78%
Epoch: 975, Loss: 0.3432, Train: 90.57%, Valid: 82.92%, Test: 82.80%
Run 01:
Highest Train: 90.70
Highest Valid: 83.14
  Final Train: 90.05
   Final Test: 82.65
All runs:
Highest Train: 90.70, nan
Highest Valid: 83.14, nan
  Final Train: 90.05, nan
   Final Test: 82.65, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.1, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.1173, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.7585, Train: 55.87%, Valid: 54.91%, Test: 55.80%
Epoch: 50, Loss: 0.5743, Train: 73.29%, Valid: 72.84%, Test: 72.06%
Epoch: 75, Loss: 0.5156, Train: 77.01%, Valid: 76.53%, Test: 75.53%
Epoch: 100, Loss: 0.4801, Train: 78.98%, Valid: 78.03%, Test: 77.56%
Epoch: 125, Loss: 0.4560, Train: 80.47%, Valid: 78.81%, Test: 78.66%
Epoch: 150, Loss: 0.4399, Train: 81.69%, Valid: 79.55%, Test: 79.25%
Epoch: 175, Loss: 0.4291, Train: 82.24%, Valid: 79.90%, Test: 79.82%
Epoch: 200, Loss: 0.4211, Train: 83.00%, Valid: 80.36%, Test: 80.20%
Epoch: 225, Loss: 0.4150, Train: 83.49%, Valid: 80.37%, Test: 80.46%
Epoch: 250, Loss: 0.4099, Train: 84.06%, Valid: 80.52%, Test: 80.76%
Epoch: 275, Loss: 0.4065, Train: 84.58%, Valid: 80.73%, Test: 80.78%
Epoch: 300, Loss: 0.4023, Train: 84.92%, Valid: 81.24%, Test: 81.24%
Epoch: 325, Loss: 0.3989, Train: 85.32%, Valid: 81.36%, Test: 81.34%
Epoch: 350, Loss: 0.3950, Train: 85.70%, Valid: 81.66%, Test: 81.39%
Epoch: 375, Loss: 0.3932, Train: 86.13%, Valid: 81.55%, Test: 81.65%
Epoch: 400, Loss: 0.3892, Train: 86.44%, Valid: 81.82%, Test: 81.66%
Epoch: 425, Loss: 0.3859, Train: 86.73%, Valid: 81.82%, Test: 81.87%
Epoch: 450, Loss: 0.3837, Train: 86.81%, Valid: 81.79%, Test: 81.67%
Epoch: 475, Loss: 0.3813, Train: 87.37%, Valid: 82.01%, Test: 81.89%
Epoch: 500, Loss: 0.3782, Train: 87.61%, Valid: 82.11%, Test: 82.05%
Epoch: 525, Loss: 0.3756, Train: 87.84%, Valid: 82.07%, Test: 82.34%
Epoch: 550, Loss: 0.3747, Train: 88.16%, Valid: 82.28%, Test: 82.41%
Epoch: 575, Loss: 0.3710, Train: 88.28%, Valid: 82.33%, Test: 82.51%
Epoch: 600, Loss: 0.3690, Train: 88.41%, Valid: 82.49%, Test: 82.38%
Epoch: 625, Loss: 0.3673, Train: 88.58%, Valid: 82.31%, Test: 82.42%
Epoch: 650, Loss: 0.3646, Train: 88.97%, Valid: 82.49%, Test: 82.75%
Epoch: 675, Loss: 0.3627, Train: 89.08%, Valid: 82.41%, Test: 82.77%
Epoch: 700, Loss: 0.3612, Train: 89.14%, Valid: 82.65%, Test: 82.62%
Epoch: 725, Loss: 0.3597, Train: 89.52%, Valid: 82.77%, Test: 82.79%
Epoch: 750, Loss: 0.3576, Train: 89.42%, Valid: 82.93%, Test: 82.63%
Epoch: 775, Loss: 0.3575, Train: 89.41%, Valid: 82.59%, Test: 82.42%
Epoch: 800, Loss: 0.3541, Train: 89.92%, Valid: 82.91%, Test: 83.08%
Epoch: 825, Loss: 0.3548, Train: 89.69%, Valid: 82.83%, Test: 82.90%
Epoch: 850, Loss: 0.3518, Train: 90.15%, Valid: 82.87%, Test: 82.98%
Epoch: 875, Loss: 0.3508, Train: 90.03%, Valid: 82.89%, Test: 82.94%
Epoch: 900, Loss: 0.3495, Train: 90.18%, Valid: 82.85%, Test: 83.04%
Epoch: 925, Loss: 0.3476, Train: 90.24%, Valid: 83.13%, Test: 83.02%
Epoch: 950, Loss: 0.3457, Train: 90.60%, Valid: 83.10%, Test: 83.26%
Epoch: 975, Loss: 0.3450, Train: 90.55%, Valid: 82.87%, Test: 82.96%
Run 01:
Highest Train: 90.76
Highest Valid: 83.28
  Final Train: 90.62
   Final Test: 83.08
All runs:
Highest Train: 90.76, nan
Highest Valid: 83.28, nan
  Final Train: 90.62, nan
   Final Test: 83.08, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.0459, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.8082, Train: 48.24%, Valid: 49.19%, Test: 48.38%
Epoch: 50, Loss: 0.6122, Train: 65.99%, Valid: 65.93%, Test: 65.60%
Epoch: 75, Loss: 0.5290, Train: 75.87%, Valid: 75.70%, Test: 75.22%
Epoch: 100, Loss: 0.4895, Train: 78.39%, Valid: 77.22%, Test: 76.83%
Epoch: 125, Loss: 0.4639, Train: 79.81%, Valid: 78.19%, Test: 77.85%
Epoch: 150, Loss: 0.4476, Train: 81.02%, Valid: 78.60%, Test: 78.53%
Epoch: 175, Loss: 0.4355, Train: 81.90%, Valid: 79.53%, Test: 79.35%
Epoch: 200, Loss: 0.4272, Train: 82.23%, Valid: 79.92%, Test: 79.63%
Epoch: 225, Loss: 0.4215, Train: 83.00%, Valid: 79.98%, Test: 80.04%
Epoch: 250, Loss: 0.4162, Train: 83.45%, Valid: 80.42%, Test: 80.36%
Epoch: 275, Loss: 0.4123, Train: 83.98%, Valid: 80.47%, Test: 80.44%
Epoch: 300, Loss: 0.4098, Train: 84.37%, Valid: 80.91%, Test: 80.79%
Epoch: 325, Loss: 0.4050, Train: 84.68%, Valid: 80.97%, Test: 80.94%
Epoch: 350, Loss: 0.4034, Train: 84.99%, Valid: 81.16%, Test: 81.11%
Epoch: 375, Loss: 0.4006, Train: 85.31%, Valid: 81.20%, Test: 81.09%
Epoch: 400, Loss: 0.3977, Train: 85.70%, Valid: 81.28%, Test: 81.40%
Epoch: 425, Loss: 0.3939, Train: 85.98%, Valid: 81.70%, Test: 81.56%
Epoch: 450, Loss: 0.3920, Train: 86.32%, Valid: 81.46%, Test: 81.73%
Epoch: 475, Loss: 0.3894, Train: 86.72%, Valid: 81.80%, Test: 81.93%
Epoch: 500, Loss: 0.3882, Train: 86.65%, Valid: 81.81%, Test: 81.65%
Epoch: 525, Loss: 0.3829, Train: 87.12%, Valid: 81.89%, Test: 82.25%
Epoch: 550, Loss: 0.3833, Train: 87.16%, Valid: 81.89%, Test: 82.18%
Epoch: 575, Loss: 0.3796, Train: 87.53%, Valid: 82.12%, Test: 82.22%
Epoch: 600, Loss: 0.3785, Train: 87.81%, Valid: 82.34%, Test: 82.26%
Epoch: 625, Loss: 0.3761, Train: 87.94%, Valid: 82.28%, Test: 82.46%
Epoch: 650, Loss: 0.3756, Train: 87.86%, Valid: 82.27%, Test: 82.34%
Epoch: 675, Loss: 0.3720, Train: 88.35%, Valid: 82.34%, Test: 82.49%
Epoch: 700, Loss: 0.3709, Train: 88.46%, Valid: 82.40%, Test: 82.32%
Epoch: 725, Loss: 0.3679, Train: 88.70%, Valid: 82.53%, Test: 82.75%
Epoch: 750, Loss: 0.3696, Train: 88.46%, Valid: 82.21%, Test: 82.58%
Epoch: 775, Loss: 0.3642, Train: 88.88%, Valid: 82.45%, Test: 82.69%
Epoch: 800, Loss: 0.3646, Train: 88.76%, Valid: 82.39%, Test: 82.40%
Epoch: 825, Loss: 0.3629, Train: 89.09%, Valid: 82.78%, Test: 83.02%
Epoch: 850, Loss: 0.3617, Train: 88.86%, Valid: 82.47%, Test: 82.47%
Epoch: 875, Loss: 0.3600, Train: 89.41%, Valid: 82.60%, Test: 83.01%
Epoch: 900, Loss: 0.3590, Train: 89.23%, Valid: 82.59%, Test: 82.66%
Epoch: 925, Loss: 0.3559, Train: 89.63%, Valid: 82.91%, Test: 83.19%
Epoch: 950, Loss: 0.3543, Train: 89.68%, Valid: 82.61%, Test: 83.03%
Epoch: 975, Loss: 0.3534, Train: 89.77%, Valid: 82.85%, Test: 83.03%
Run 01:
Highest Train: 89.95
Highest Valid: 83.04
  Final Train: 89.64
   Final Test: 83.18
All runs:
Highest Train: 89.95, nan
Highest Valid: 83.04, nan
  Final Train: 89.64, nan
   Final Test: 83.18, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=1e-05)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 1.8374, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.6822, Train: 59.94%, Valid: 59.66%, Test: 59.38%
Epoch: 50, Loss: 0.6263, Train: 71.66%, Valid: 71.30%, Test: 70.86%
Epoch: 75, Loss: 0.5903, Train: 74.28%, Valid: 73.35%, Test: 72.88%
Epoch: 100, Loss: 0.5556, Train: 75.73%, Valid: 75.09%, Test: 74.28%
Epoch: 125, Loss: 0.5185, Train: 77.42%, Valid: 76.80%, Test: 76.11%
Epoch: 150, Loss: 0.4875, Train: 78.56%, Valid: 77.31%, Test: 77.06%
Epoch: 175, Loss: 0.4655, Train: 79.87%, Valid: 78.48%, Test: 77.95%
Epoch: 200, Loss: 0.4491, Train: 80.69%, Valid: 78.94%, Test: 78.77%
Epoch: 225, Loss: 0.4395, Train: 81.43%, Valid: 79.47%, Test: 78.97%
Epoch: 250, Loss: 0.4317, Train: 81.96%, Valid: 79.69%, Test: 79.55%
Epoch: 275, Loss: 0.4259, Train: 82.64%, Valid: 80.12%, Test: 79.92%
Epoch: 300, Loss: 0.4191, Train: 83.03%, Valid: 80.31%, Test: 80.01%
Epoch: 325, Loss: 0.4160, Train: 83.60%, Valid: 80.38%, Test: 80.42%
Epoch: 350, Loss: 0.4121, Train: 84.01%, Valid: 80.62%, Test: 80.76%
Epoch: 375, Loss: 0.4085, Train: 84.43%, Valid: 80.81%, Test: 81.00%
Epoch: 400, Loss: 0.4064, Train: 84.63%, Valid: 81.01%, Test: 81.01%
Epoch: 425, Loss: 0.4030, Train: 85.07%, Valid: 81.01%, Test: 80.95%
Epoch: 450, Loss: 0.4021, Train: 85.35%, Valid: 81.33%, Test: 81.36%
Epoch: 475, Loss: 0.3978, Train: 85.62%, Valid: 81.26%, Test: 81.41%
Epoch: 500, Loss: 0.3955, Train: 85.82%, Valid: 81.52%, Test: 81.73%
Epoch: 525, Loss: 0.3948, Train: 85.91%, Valid: 81.40%, Test: 81.50%
Epoch: 550, Loss: 0.3917, Train: 86.33%, Valid: 81.73%, Test: 81.78%
Epoch: 575, Loss: 0.3899, Train: 86.45%, Valid: 81.75%, Test: 81.84%
Epoch: 600, Loss: 0.3872, Train: 86.63%, Valid: 81.75%, Test: 81.96%
Epoch: 625, Loss: 0.3850, Train: 86.82%, Valid: 81.89%, Test: 82.09%
Epoch: 650, Loss: 0.3835, Train: 87.17%, Valid: 82.06%, Test: 82.16%
Epoch: 675, Loss: 0.3814, Train: 87.48%, Valid: 82.11%, Test: 82.34%
Epoch: 700, Loss: 0.3802, Train: 87.63%, Valid: 82.15%, Test: 82.36%
Epoch: 725, Loss: 0.3779, Train: 87.94%, Valid: 82.35%, Test: 82.40%
Epoch: 750, Loss: 0.3756, Train: 87.93%, Valid: 82.26%, Test: 82.48%
Epoch: 775, Loss: 0.3730, Train: 88.24%, Valid: 82.37%, Test: 82.46%
Epoch: 800, Loss: 0.3722, Train: 88.52%, Valid: 82.49%, Test: 82.52%
Epoch: 825, Loss: 0.3689, Train: 88.59%, Valid: 82.52%, Test: 82.63%
Epoch: 850, Loss: 0.3689, Train: 88.56%, Valid: 82.29%, Test: 82.46%
Epoch: 875, Loss: 0.3696, Train: 89.05%, Valid: 82.39%, Test: 83.07%
Epoch: 900, Loss: 0.3651, Train: 89.02%, Valid: 82.54%, Test: 82.77%
Epoch: 925, Loss: 0.3663, Train: 89.20%, Valid: 82.36%, Test: 82.48%
Epoch: 950, Loss: 0.3632, Train: 89.40%, Valid: 82.68%, Test: 82.67%
Epoch: 975, Loss: 0.3608, Train: 89.52%, Valid: 82.76%, Test: 82.86%
Run 01:
Highest Train: 89.60
Highest Valid: 82.91
  Final Train: 89.59
   Final Test: 82.94
All runs:
Highest Train: 89.60, nan
Highest Valid: 82.91, nan
  Final Train: 89.59, nan
   Final Test: 82.94, nan
Saving results to results/fb100.csv
Using backend: pytorch
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.2, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=128, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.001)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=2, bias=True)
  (fc3): Linear(in_features=128, out_features=128, bias=True)
)
Epoch: 00, Loss: 0.9786, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.6360, Train: 69.20%, Valid: 68.77%, Test: 68.48%
Epoch: 50, Loss: 0.5857, Train: 73.59%, Valid: 73.47%, Test: 72.86%
Epoch: 75, Loss: 0.5330, Train: 76.30%, Valid: 76.03%, Test: 75.28%
Epoch: 100, Loss: 0.4978, Train: 77.81%, Valid: 77.54%, Test: 76.60%
Epoch: 125, Loss: 0.4695, Train: 79.35%, Valid: 78.06%, Test: 77.75%
Epoch: 150, Loss: 0.4513, Train: 80.70%, Valid: 78.86%, Test: 78.42%
Epoch: 175, Loss: 0.4399, Train: 81.52%, Valid: 79.22%, Test: 79.01%
Epoch: 200, Loss: 0.4294, Train: 82.06%, Valid: 79.76%, Test: 79.51%
Epoch: 225, Loss: 0.4236, Train: 82.69%, Valid: 80.26%, Test: 79.94%
Epoch: 250, Loss: 0.4187, Train: 83.24%, Valid: 80.19%, Test: 80.23%
Epoch: 275, Loss: 0.4134, Train: 83.70%, Valid: 80.61%, Test: 80.33%
Epoch: 300, Loss: 0.4100, Train: 84.13%, Valid: 81.00%, Test: 80.71%
Epoch: 325, Loss: 0.4058, Train: 84.60%, Valid: 80.92%, Test: 80.88%
Epoch: 350, Loss: 0.4035, Train: 84.93%, Valid: 81.11%, Test: 81.17%
Epoch: 375, Loss: 0.4009, Train: 85.19%, Valid: 81.48%, Test: 81.06%
Epoch: 400, Loss: 0.3962, Train: 85.55%, Valid: 81.49%, Test: 81.22%
Epoch: 425, Loss: 0.3945, Train: 85.71%, Valid: 81.27%, Test: 81.38%
Epoch: 450, Loss: 0.3949, Train: 85.92%, Valid: 81.69%, Test: 81.62%
Epoch: 475, Loss: 0.3900, Train: 86.20%, Valid: 81.86%, Test: 81.71%
Epoch: 500, Loss: 0.3877, Train: 86.58%, Valid: 81.95%, Test: 81.69%
Epoch: 525, Loss: 0.3852, Train: 86.67%, Valid: 81.91%, Test: 81.81%
Epoch: 550, Loss: 0.3843, Train: 86.77%, Valid: 82.02%, Test: 81.83%
Epoch: 575, Loss: 0.3817, Train: 87.00%, Valid: 82.08%, Test: 81.91%
Epoch: 600, Loss: 0.3806, Train: 87.30%, Valid: 82.20%, Test: 82.06%
Epoch: 625, Loss: 0.3767, Train: 87.54%, Valid: 82.07%, Test: 82.12%
Epoch: 650, Loss: 0.3752, Train: 87.61%, Valid: 82.17%, Test: 82.11%
Epoch: 675, Loss: 0.3749, Train: 87.95%, Valid: 82.29%, Test: 82.35%
Epoch: 700, Loss: 0.3727, Train: 88.15%, Valid: 82.33%, Test: 82.45%
Epoch: 725, Loss: 0.3686, Train: 88.23%, Valid: 82.34%, Test: 82.48%
Epoch: 750, Loss: 0.3688, Train: 88.20%, Valid: 82.12%, Test: 82.18%
Epoch: 775, Loss: 0.3686, Train: 88.42%, Valid: 82.19%, Test: 82.47%
Epoch: 800, Loss: 0.3665, Train: 88.45%, Valid: 82.42%, Test: 82.64%
Epoch: 825, Loss: 0.3628, Train: 88.65%, Valid: 82.29%, Test: 82.48%
Epoch: 850, Loss: 0.3624, Train: 88.62%, Valid: 82.41%, Test: 82.48%
Epoch: 875, Loss: 0.3605, Train: 88.55%, Valid: 82.33%, Test: 82.37%
Epoch: 900, Loss: 0.3621, Train: 88.93%, Valid: 82.41%, Test: 82.60%
Epoch: 925, Loss: 0.3570, Train: 88.94%, Valid: 82.48%, Test: 82.65%
Epoch: 950, Loss: 0.3554, Train: 89.31%, Valid: 82.91%, Test: 83.09%
Epoch: 975, Loss: 0.3546, Train: 89.16%, Valid: 82.57%, Test: 82.61%
Run 01:
Highest Train: 89.51
Highest Valid: 82.95
  Final Train: 89.38
   Final Test: 82.76
All runs:
Highest Train: 89.51, nan
Highest Valid: 82.95, nan
  Final Train: 89.38, nan
   Final Test: 82.76, nan
Saving results to results/fb100.csv
20211123-06:35 ---> 20211123-12:32 Totl:21414 seconds
