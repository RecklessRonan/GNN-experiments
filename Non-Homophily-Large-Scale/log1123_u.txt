nohup: ignoring input
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 7.0256, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 3227430.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 1895490.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 32664322.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 10223.2803, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 46554.6562, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 25887.1895, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 454690.0938, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 93.4224, Train: 84.89%, Valid: 84.81%, Test: 85.03%
Epoch: 225, Loss: 324.5469, Train: 84.81%, Valid: 84.74%, Test: 84.95%
Epoch: 250, Loss: 30865.3906, Train: 83.87%, Valid: 83.75%, Test: 83.98%
Epoch: 275, Loss: 563.2124, Train: 87.37%, Valid: 87.27%, Test: 87.40%
Epoch: 300, Loss: 192.7045, Train: 85.14%, Valid: 85.10%, Test: 85.24%
Epoch: 325, Loss: 259.5402, Train: 85.14%, Valid: 85.10%, Test: 85.24%
Epoch: 350, Loss: 178.4806, Train: 87.38%, Valid: 87.28%, Test: 87.41%
Epoch: 375, Loss: 191.5424, Train: 85.15%, Valid: 85.11%, Test: 85.25%
Epoch: 400, Loss: 191.3282, Train: 85.14%, Valid: 85.10%, Test: 85.24%
Epoch: 425, Loss: 191.6420, Train: 87.38%, Valid: 87.28%, Test: 87.41%
Epoch: 450, Loss: 190.6200, Train: 85.14%, Valid: 85.11%, Test: 85.24%
Epoch: 475, Loss: 192.1023, Train: 85.14%, Valid: 85.10%, Test: 85.25%
Run 01:
Highest Train: 88.27
Highest Valid: 88.35
  Final Train: 88.27
   Final Test: 88.33
All runs:
Highest Train: 88.27, nan
Highest Valid: 88.35, nan
  Final Train: 88.27, nan
   Final Test: 88.33, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.4492, Train: 84.87%, Valid: 84.82%, Test: 85.02%
Epoch: 25, Loss: 209299.2656, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 26290570.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 3979.7971, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 64.3413, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 209507.6406, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 10369.1309, Train: 84.92%, Valid: 84.78%, Test: 85.02%
Epoch: 175, Loss: 29565.5605, Train: 83.80%, Valid: 83.78%, Test: 83.86%
Epoch: 200, Loss: 257.5277, Train: 15.30%, Valid: 15.44%, Test: 15.11%
Epoch: 225, Loss: 471.7707, Train: 15.89%, Valid: 15.96%, Test: 15.72%
Epoch: 250, Loss: 670.0549, Train: 15.32%, Valid: 15.46%, Test: 15.13%
Epoch: 275, Loss: 1283.6627, Train: 15.24%, Valid: 15.39%, Test: 15.05%
Epoch: 300, Loss: 461.0887, Train: 16.22%, Valid: 16.27%, Test: 16.08%
Epoch: 325, Loss: 387.0124, Train: 15.91%, Valid: 15.98%, Test: 15.74%
Epoch: 350, Loss: 1070.8015, Train: 15.21%, Valid: 15.36%, Test: 15.02%
Epoch: 375, Loss: 529.3159, Train: 15.24%, Valid: 15.39%, Test: 15.05%
Epoch: 400, Loss: 569.7605, Train: 15.52%, Valid: 15.65%, Test: 15.35%
Epoch: 425, Loss: 440.4558, Train: 84.75%, Valid: 84.80%, Test: 84.69%
Epoch: 450, Loss: 499.2299, Train: 15.88%, Valid: 15.95%, Test: 15.71%
Epoch: 475, Loss: 989.6178, Train: 15.19%, Valid: 15.34%, Test: 15.00%
Run 01:
Highest Train: 86.67
Highest Valid: 86.68
  Final Train: 86.67
   Final Test: 86.66
All runs:
Highest Train: 86.67, nan
Highest Valid: 86.68, nan
  Final Train: 86.67, nan
   Final Test: 86.66, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5315, Train: 84.72%, Valid: 84.50%, Test: 84.83%
Epoch: 25, Loss: 184142592.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 5100483.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 136692944.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 29323.7988, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 23982.0762, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 7004.5532, Train: 83.90%, Valid: 83.90%, Test: 84.04%
Epoch: 175, Loss: 14128.6660, Train: 17.58%, Valid: 17.55%, Test: 17.49%
Epoch: 200, Loss: 5198.8647, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 54.3824, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 8921.2090, Train: 17.40%, Valid: 17.34%, Test: 17.28%
Epoch: 275, Loss: 65.8538, Train: 16.64%, Valid: 16.73%, Test: 16.54%
Epoch: 300, Loss: 14.4729, Train: 16.02%, Valid: 16.09%, Test: 15.91%
Epoch: 325, Loss: 301.1981, Train: 83.85%, Valid: 83.84%, Test: 83.98%
Epoch: 350, Loss: 17.4621, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 54.3815, Train: 83.75%, Valid: 83.60%, Test: 83.83%
Epoch: 400, Loss: 30.6101, Train: 84.64%, Valid: 84.47%, Test: 84.75%
Epoch: 425, Loss: 17.1317, Train: 15.63%, Valid: 15.80%, Test: 15.55%
Epoch: 450, Loss: 1118.7283, Train: 84.25%, Valid: 84.09%, Test: 84.32%
Epoch: 475, Loss: 111.6776, Train: 86.32%, Valid: 86.35%, Test: 86.36%
Run 01:
Highest Train: 87.79
Highest Valid: 87.73
  Final Train: 87.79
   Final Test: 87.79
All runs:
Highest Train: 87.79, nan
Highest Valid: 87.73, nan
  Final Train: 87.79, nan
   Final Test: 87.79, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4757, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 41368918286885978112.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 2661425399457571062478274560.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 2109508762075994201600374603776.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 328007422439244976921509888.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 118757581185091619390924783616.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 57248606629987038653887545344.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 1388217251538594380359139328.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 6322035072376357442319024128.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 1224562897302025773509383290880.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 110080856125194385103926591488.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 38355464336201543780304683008.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 18079427783347364154576994304.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 784044835744290277796549230592.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 71641467773427177507258368.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 3358982680924936400751558656.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 782846865814915906198738829312.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 74085727365643988829154050048.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 6904492934965120200387592192.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.6340, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 582369263908301045760.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 498163510189075148746784768.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 157228369695301559828611072.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 27269628073352056203640832.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 25656860710141826170880.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 176638040871302965755904.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 37666462064339754573365248.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 618128368497583065447530496.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 91682645140706426880.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 541687811062149547032576.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 19695619958072410112.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 2042519457649131520.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 177222680160529694064640.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 80733751698459432321024.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 392423963777095648149504.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 2740150102185213952.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 55700249975340652298240.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 1791321955938956786794496.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 4500486162847305209741312.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.1285, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 421174953886292059923415040.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 138901622988828181528576.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 2477424934652500594054876102656.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 764292778278931973275648.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 18471804353836054740992.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 16275592338410045440.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 6789374884875003173535744.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 509717757669513625600.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 43022504434302021795840.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 4120809421642699636736.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 146515345468465958879232.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 850631394821642808983552.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 1541769358078231317577728.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 22927039824808218984448.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 173927990788333515046912.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 41764632521722560512.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 74982303763905118208.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 4268511726821756108800.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 12189577859429805588480.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 84.96
Highest Valid: 84.83
  Final Train: 84.96
   Final Test: 85.04
All runs:
Highest Train: 84.96, nan
Highest Valid: 84.83, nan
  Final Train: 84.96, nan
   Final Test: 85.04, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5769, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 83.76
Highest Valid: 83.57
  Final Train: 83.76
   Final Test: 83.91
All runs:
Highest Train: 83.76, nan
Highest Valid: 83.57, nan
  Final Train: 83.76, nan
   Final Test: 83.91, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.1259, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.8008, Train: 84.45%, Valid: 84.40%, Test: 84.57%
Epoch: 25, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 87.69
Highest Valid: 87.64
  Final Train: 87.69
   Final Test: 87.70
All runs:
Highest Train: 87.69, nan
Highest Valid: 87.64, nan
  Final Train: 87.69, nan
   Final Test: 87.70, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 9.2614, Train: 84.81%, Valid: 84.79%, Test: 84.92%
Epoch: 25, Loss: 542088.1250, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 25.0185, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 72887048.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 37981832.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 11641693.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 138326.7812, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 660793.3125, Train: 83.80%, Valid: 83.67%, Test: 83.91%
Epoch: 200, Loss: 499787.4375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 603.5433, Train: 84.17%, Valid: 84.13%, Test: 84.31%
Epoch: 250, Loss: 43274.7422, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 725289.8750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 12294.3633, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 355551.6250, Train: 49.96%, Valid: 49.95%, Test: 49.96%
Epoch: 350, Loss: 11868.7070, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 2328453.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 319123.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 756393.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 6369.0176, Train: 83.97%, Valid: 83.85%, Test: 84.09%
Epoch: 475, Loss: 438.5446, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 87.35
Highest Valid: 87.24
  Final Train: 87.35
   Final Test: 87.36
All runs:
Highest Train: 87.35, nan
Highest Valid: 87.24, nan
  Final Train: 87.35, nan
   Final Test: 87.36, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.1212, Train: 84.68%, Valid: 84.51%, Test: 84.77%
Epoch: 25, Loss: 157290.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 297059808.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 5297.0078, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 372999.4062, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 276958.1250, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 3047.7708, Train: 84.13%, Valid: 84.13%, Test: 84.22%
Epoch: 175, Loss: 4739.7085, Train: 15.91%, Valid: 16.09%, Test: 15.77%
Epoch: 200, Loss: 203401.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 118843.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 44127.2344, Train: 84.08%, Valid: 84.08%, Test: 84.16%
Epoch: 275, Loss: 38181.4062, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 1212.2404, Train: 84.08%, Valid: 84.10%, Test: 84.17%
Epoch: 325, Loss: 130154.3672, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 38213.8984, Train: 16.80%, Valid: 16.88%, Test: 16.67%
Epoch: 375, Loss: 4970.5610, Train: 83.97%, Valid: 83.99%, Test: 84.06%
Epoch: 400, Loss: 1563.4762, Train: 84.09%, Valid: 83.90%, Test: 84.24%
Epoch: 425, Loss: 9.2564, Train: 86.96%, Valid: 87.00%, Test: 86.98%
Epoch: 450, Loss: 2131.3562, Train: 83.62%, Valid: 83.65%, Test: 83.67%
Epoch: 475, Loss: 50.5414, Train: 86.71%, Valid: 86.76%, Test: 86.69%
Run 01:
Highest Train: 87.08
Highest Valid: 87.11
  Final Train: 87.08
   Final Test: 87.09
All runs:
Highest Train: 87.08, nan
Highest Valid: 87.11, nan
  Final Train: 87.08, nan
   Final Test: 87.09, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.4762, Train: 15.81%, Valid: 15.67%, Test: 15.75%
Epoch: 25, Loss: 9709.5703, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 1174663.8750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 65065.2266, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 615337.8750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 4238083.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 3884.5706, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 322111.1875, Train: 15.54%, Valid: 15.63%, Test: 15.40%
Epoch: 200, Loss: 173728.3750, Train: 83.99%, Valid: 83.98%, Test: 84.13%
Epoch: 225, Loss: 63517.0898, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 168.9102, Train: 83.93%, Valid: 83.92%, Test: 84.07%
Epoch: 275, Loss: 17196.5234, Train: 83.88%, Valid: 83.89%, Test: 84.02%
Epoch: 300, Loss: 2760.6799, Train: 83.85%, Valid: 83.88%, Test: 84.00%
Epoch: 325, Loss: 1121.6256, Train: 86.01%, Valid: 85.91%, Test: 86.08%
Epoch: 350, Loss: 850.6472, Train: 83.82%, Valid: 83.83%, Test: 83.96%
Epoch: 375, Loss: 344.1711, Train: 84.68%, Valid: 84.53%, Test: 84.81%
Epoch: 400, Loss: 176.4320, Train: 85.58%, Valid: 85.44%, Test: 85.64%
Epoch: 425, Loss: 314.3487, Train: 83.84%, Valid: 83.86%, Test: 83.99%
Epoch: 450, Loss: 59.0160, Train: 84.41%, Valid: 84.38%, Test: 84.61%
Epoch: 475, Loss: 18.5680, Train: 83.84%, Valid: 83.88%, Test: 83.99%
Run 01:
Highest Train: 87.56
Highest Valid: 87.51
  Final Train: 87.56
   Final Test: 87.65
All runs:
Highest Train: 87.56, nan
Highest Valid: 87.51, nan
  Final Train: 87.56, nan
   Final Test: 87.65, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5542, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 327788799009883160576.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 290901515133900713623552.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 47034543495790488585441902592.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 12168453527219240672690176.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 354328846145690781829131562647552.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 84.53
Highest Valid: 84.34
  Final Train: 84.53
   Final Test: 84.60
All runs:
Highest Train: 84.53, nan
Highest Valid: 84.34, nan
  Final Train: 84.53, nan
   Final Test: 84.60, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 4.9131, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 1657289048064.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 9756597106835535691776.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 26996751000458493952.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 90623457758281728.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 186365392191488.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 4959794947424256.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 74222166016.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 10171310931968.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 1615676178432.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 910462937989120.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 123337300770816.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 8591172960256.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 96029138944.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 613316624384.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 283854307328.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 3806176215040.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 233097871360.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 619000216158208.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 135711462260736.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 84.61
Highest Valid: 84.60
  Final Train: 84.61
   Final Test: 84.71
All runs:
Highest Train: 84.61, nan
Highest Valid: 84.60, nan
  Final Train: 84.61, nan
   Final Test: 84.71, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.1549, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 37025902231552.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 11749954550262001288871936.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 135609991168.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 1299822450527208210432.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 135192062018958632419328.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 59995841846721787199488.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 168525959064099624058880.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 7264316332047771631616.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 3182856274479691012767744.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 2037789191738166257647616.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 5937828912551832846336.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 13055777693760109936640.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 28308730861181106032476160.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 166942122591834341376.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 8502280434318162526208.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 425748042975048972107776.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 760397993263587930406912.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 348483927479910553092096.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 22699101388667929755648.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 85.04
Highest Valid: 84.77
  Final Train: 85.04
   Final Test: 85.11
All runs:
Highest Train: 85.04, nan
Highest Valid: 84.77, nan
  Final Train: 85.04, nan
   Final Test: 85.11, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.6364, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 199851279746238432679636242530304.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4209, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.05
Highest Valid: 50.05
  Final Train: 50.05
   Final Test: 50.05
All runs:
Highest Train: 50.05, nan
Highest Valid: 50.05, nan
  Final Train: 50.05, nan
   Final Test: 50.05, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.2278, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 84.66
Highest Valid: 84.54
  Final Train: 84.66
   Final Test: 84.75
All runs:
Highest Train: 84.66, nan
Highest Valid: 84.54, nan
  Final Train: 84.66, nan
   Final Test: 84.75, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.9054, Train: 86.64%, Valid: 86.66%, Test: 86.70%
Epoch: 25, Loss: 74.4358, Train: 83.86%, Valid: 83.67%, Test: 83.98%
Epoch: 50, Loss: 1543.2979, Train: 86.10%, Valid: 85.93%, Test: 86.18%
Epoch: 75, Loss: 1217.4628, Train: 83.84%, Valid: 83.62%, Test: 83.93%
Epoch: 100, Loss: 606.5206, Train: 86.23%, Valid: 86.05%, Test: 86.32%
Epoch: 125, Loss: 447.3885, Train: 87.05%, Valid: 86.89%, Test: 87.13%
Epoch: 150, Loss: 738.0469, Train: 86.15%, Valid: 85.96%, Test: 86.22%
Epoch: 175, Loss: 572.6107, Train: 86.59%, Valid: 86.44%, Test: 86.66%
Epoch: 200, Loss: 238.3941, Train: 87.04%, Valid: 86.88%, Test: 87.13%
Epoch: 225, Loss: 929.5262, Train: 86.93%, Valid: 86.79%, Test: 87.02%
Epoch: 250, Loss: 707.7085, Train: 85.08%, Valid: 85.01%, Test: 85.18%
Epoch: 275, Loss: 769.0381, Train: 86.94%, Valid: 86.80%, Test: 87.02%
Epoch: 300, Loss: 701.1559, Train: 86.70%, Valid: 86.51%, Test: 86.76%
Epoch: 325, Loss: 666.4330, Train: 85.11%, Valid: 85.06%, Test: 85.20%
Epoch: 350, Loss: 686.6196, Train: 87.33%, Valid: 87.21%, Test: 87.40%
Epoch: 375, Loss: 667.4509, Train: 87.41%, Valid: 87.30%, Test: 87.46%
Epoch: 400, Loss: 638.1075, Train: 87.31%, Valid: 87.21%, Test: 87.38%
Epoch: 425, Loss: 772.6950, Train: 86.00%, Valid: 86.03%, Test: 86.11%
Epoch: 450, Loss: 713.5228, Train: 85.84%, Valid: 85.84%, Test: 85.92%
Epoch: 475, Loss: 927.9068, Train: 87.03%, Valid: 87.10%, Test: 87.12%
Run 01:
Highest Train: 88.26
Highest Valid: 88.34
  Final Train: 88.26
   Final Test: 88.32
All runs:
Highest Train: 88.26, nan
Highest Valid: 88.34, nan
  Final Train: 88.26, nan
   Final Test: 88.32, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.6273, Train: 86.19%, Valid: 86.07%, Test: 86.17%
Epoch: 25, Loss: 14491.1650, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 2929.1880, Train: 15.62%, Valid: 15.60%, Test: 15.57%
Epoch: 75, Loss: 1768.0826, Train: 84.28%, Valid: 84.17%, Test: 84.38%
Epoch: 100, Loss: 1102.4545, Train: 84.33%, Valid: 84.20%, Test: 84.43%
Epoch: 125, Loss: 1502.3396, Train: 15.62%, Valid: 15.67%, Test: 15.56%
Epoch: 150, Loss: 1497.8978, Train: 15.70%, Valid: 15.75%, Test: 15.63%
Epoch: 175, Loss: 1541.4769, Train: 84.85%, Valid: 84.82%, Test: 84.91%
Epoch: 200, Loss: 2316.4595, Train: 15.90%, Valid: 15.94%, Test: 15.80%
Epoch: 225, Loss: 1610.6884, Train: 17.03%, Valid: 17.15%, Test: 16.92%
Epoch: 250, Loss: 1617.9856, Train: 17.43%, Valid: 17.54%, Test: 17.38%
Epoch: 275, Loss: 1621.9098, Train: 17.48%, Valid: 17.58%, Test: 17.44%
Epoch: 300, Loss: 1614.4598, Train: 17.50%, Valid: 17.60%, Test: 17.47%
Epoch: 325, Loss: 1616.4686, Train: 17.50%, Valid: 17.59%, Test: 17.46%
Epoch: 350, Loss: 1609.1096, Train: 17.46%, Valid: 17.55%, Test: 17.42%
Epoch: 375, Loss: 1616.2273, Train: 17.47%, Valid: 17.56%, Test: 17.43%
Epoch: 400, Loss: 1614.4866, Train: 17.54%, Valid: 17.63%, Test: 17.49%
Epoch: 425, Loss: 1611.3009, Train: 17.49%, Valid: 17.59%, Test: 17.45%
Epoch: 450, Loss: 1610.2874, Train: 17.53%, Valid: 17.63%, Test: 17.50%
Epoch: 475, Loss: 1609.9307, Train: 17.48%, Valid: 17.59%, Test: 17.45%
Run 01:
Highest Train: 86.83
Highest Valid: 86.81
  Final Train: 86.83
   Final Test: 86.85
All runs:
Highest Train: 86.83, nan
Highest Valid: 86.81, nan
  Final Train: 86.83, nan
   Final Test: 86.85, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4109, Train: 86.10%, Valid: 85.92%, Test: 86.11%
Epoch: 25, Loss: 8529.7061, Train: 84.94%, Valid: 84.82%, Test: 85.07%
Epoch: 50, Loss: 20.7583, Train: 84.92%, Valid: 84.85%, Test: 85.06%
Epoch: 75, Loss: 24.8752, Train: 84.89%, Valid: 84.78%, Test: 85.04%
Epoch: 100, Loss: 15.9120, Train: 84.71%, Valid: 84.72%, Test: 84.90%
Epoch: 125, Loss: 22.0263, Train: 84.77%, Valid: 84.64%, Test: 84.91%
Epoch: 150, Loss: 24.9642, Train: 83.88%, Valid: 83.92%, Test: 84.03%
Epoch: 175, Loss: 17.3786, Train: 83.89%, Valid: 83.94%, Test: 84.05%
Epoch: 200, Loss: 16.3139, Train: 87.06%, Valid: 87.11%, Test: 87.14%
Epoch: 225, Loss: 23.1295, Train: 84.79%, Valid: 84.67%, Test: 84.94%
Epoch: 250, Loss: 21.0313, Train: 83.92%, Valid: 83.99%, Test: 84.08%
Epoch: 275, Loss: 24.2107, Train: 83.89%, Valid: 83.96%, Test: 84.05%
Epoch: 300, Loss: 19.4548, Train: 83.93%, Valid: 84.02%, Test: 84.08%
Epoch: 325, Loss: 25.5967, Train: 87.02%, Valid: 87.06%, Test: 87.11%
Epoch: 350, Loss: 26.5238, Train: 84.73%, Valid: 84.62%, Test: 84.88%
Epoch: 375, Loss: 12.1725, Train: 83.83%, Valid: 83.86%, Test: 83.98%
Epoch: 400, Loss: 16.0957, Train: 86.97%, Valid: 87.01%, Test: 87.06%
Epoch: 425, Loss: 21.8979, Train: 83.81%, Valid: 83.85%, Test: 83.97%
Epoch: 450, Loss: 19.8493, Train: 86.94%, Valid: 86.96%, Test: 87.02%
Epoch: 475, Loss: 9.0307, Train: 84.68%, Valid: 84.52%, Test: 84.81%
Run 01:
Highest Train: 87.67
Highest Valid: 87.67
  Final Train: 87.67
   Final Test: 87.62
All runs:
Highest Train: 87.67, nan
Highest Valid: 87.67, nan
  Final Train: 87.67, nan
   Final Test: 87.62, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.0849, Train: 86.81%, Valid: 86.83%, Test: 86.88%
Epoch: 25, Loss: 1949149429760.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 322652640116736.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 364570330485315600384.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 61480753693002951737240190976.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 2911487951793606709215232.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 9248330272621787964354647293952.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 551466397516367103163935752192.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 55709327663063263448257265664.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 20380589753702442598400.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 295608612612593721907609600.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 17351372942840965365760.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 81768913080009795567616.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 553696953607631837438410752.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 4076191737716783357886464.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 1426518981881790201856.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 5104832992374224322560.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 1025573830433240782995456.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 4695528125315260874752.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 4960014853753577239430037504.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 87.93
Highest Valid: 87.94
  Final Train: 87.93
   Final Test: 87.93
All runs:
Highest Train: 87.93, nan
Highest Valid: 87.94, nan
  Final Train: 87.93, nan
   Final Test: 87.93, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.5384, Train: 16.80%, Valid: 16.97%, Test: 16.79%
Epoch: 25, Loss: 130236736.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 5884014.5000, Train: 14.80%, Valid: 14.87%, Test: 14.69%
Epoch: 75, Loss: 5904.1997, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 255067.9219, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 4285807.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 19998528.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 75368.9375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 1728.7888, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 1643878912.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 895348.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 164998.4844, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 1071077.1250, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 50052.1367, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 725262.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 1521.3547, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 165923.2969, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 7520795.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 4093383.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 377077.0312, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.71
Highest Valid: 86.62
  Final Train: 86.71
   Final Test: 86.79
All runs:
Highest Train: 86.71, nan
Highest Valid: 86.62, nan
  Final Train: 86.71, nan
   Final Test: 86.79, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.6804, Train: 86.30%, Valid: 86.15%, Test: 86.29%
Epoch: 25, Loss: 5218.6743, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 1043972544.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 642054.5625, Train: 83.78%, Valid: 83.77%, Test: 83.95%
Epoch: 100, Loss: 29.2684, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 8435870.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 2980857.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 1699.3654, Train: 15.20%, Valid: 15.36%, Test: 15.13%
Epoch: 200, Loss: 467.9370, Train: 85.64%, Valid: 85.48%, Test: 85.65%
Epoch: 225, Loss: 19227822.0000, Train: 84.76%, Valid: 84.60%, Test: 84.85%
Epoch: 250, Loss: 201.3959, Train: 86.88%, Valid: 86.90%, Test: 87.01%
Epoch: 275, Loss: 212.6572, Train: 86.88%, Valid: 86.90%, Test: 87.00%
Epoch: 300, Loss: 150.8491, Train: 86.88%, Valid: 86.90%, Test: 87.00%
Epoch: 325, Loss: 90896.5547, Train: 86.88%, Valid: 86.90%, Test: 87.01%
Epoch: 350, Loss: 9840.3936, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 73508344.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 9602.6436, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 582629.9375, Train: 86.88%, Valid: 86.90%, Test: 87.01%
Epoch: 450, Loss: 13237.7041, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 101830592.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.92
Highest Valid: 86.93
  Final Train: 86.92
   Final Test: 87.01
All runs:
Highest Train: 86.92, nan
Highest Valid: 86.93, nan
  Final Train: 86.92, nan
   Final Test: 87.01, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.2730, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 12.9426, Train: 88.08%, Valid: 88.14%, Test: 88.07%
Epoch: 75, Loss: 10767105784025672843264.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 87.6443, Train: 87.97%, Valid: 88.03%, Test: 87.96%
Epoch: 125, Loss: 131.2057, Train: 87.99%, Valid: 88.05%, Test: 88.01%
Epoch: 150, Loss: 111.5323, Train: 86.63%, Valid: 86.75%, Test: 86.61%
Epoch: 175, Loss: 199248.8125, Train: 84.11%, Valid: 83.92%, Test: 84.27%
Epoch: 200, Loss: 78.5392, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 62416352.0000, Train: 15.86%, Valid: 16.05%, Test: 15.73%
Epoch: 250, Loss: 69.6511, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 62.2916, Train: 87.99%, Valid: 88.06%, Test: 88.02%
Epoch: 300, Loss: 74.0875, Train: 87.94%, Valid: 87.99%, Test: 87.95%
Epoch: 325, Loss: 130278448.0000, Train: 87.36%, Valid: 87.39%, Test: 87.38%
Epoch: 350, Loss: 4068181540864.0000, Train: 88.01%, Valid: 88.08%, Test: 88.03%
Epoch: 375, Loss: 1168485.2500, Train: 88.04%, Valid: 88.10%, Test: 88.05%
Epoch: 400, Loss: 4446518.0000, Train: 15.54%, Valid: 15.64%, Test: 15.41%
Epoch: 425, Loss: 71.5920, Train: 87.99%, Valid: 88.11%, Test: 88.03%
Epoch: 450, Loss: 72.9961, Train: 88.03%, Valid: 88.09%, Test: 88.04%
Epoch: 475, Loss: 72.9961, Train: 88.03%, Valid: 88.09%, Test: 88.04%
Run 01:
Highest Train: 88.27
Highest Valid: 88.32
  Final Train: 88.27
   Final Test: 88.31
All runs:
Highest Train: 88.27, nan
Highest Valid: 88.32, nan
  Final Train: 88.27, nan
   Final Test: 88.31, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.9612, Train: 86.57%, Valid: 86.57%, Test: 86.66%
Epoch: 25, Loss: 145.3990, Train: 86.08%, Valid: 85.99%, Test: 86.20%
Epoch: 50, Loss: 91.1382, Train: 86.16%, Valid: 86.07%, Test: 86.28%
Epoch: 75, Loss: 105.5824, Train: 86.17%, Valid: 86.08%, Test: 86.30%
Epoch: 100, Loss: 106.3795, Train: 86.17%, Valid: 86.08%, Test: 86.29%
Epoch: 125, Loss: 106.1586, Train: 86.16%, Valid: 86.08%, Test: 86.29%
Epoch: 150, Loss: 91.4255, Train: 86.16%, Valid: 86.07%, Test: 86.29%
Epoch: 175, Loss: 105.6980, Train: 86.17%, Valid: 86.08%, Test: 86.30%
Epoch: 200, Loss: 105.1725, Train: 86.15%, Valid: 86.07%, Test: 86.28%
Epoch: 225, Loss: 103.4016, Train: 86.18%, Valid: 86.10%, Test: 86.31%
Epoch: 250, Loss: 101.7027, Train: 86.17%, Valid: 86.08%, Test: 86.29%
Epoch: 275, Loss: 104.5644, Train: 86.19%, Valid: 86.10%, Test: 86.32%
Epoch: 300, Loss: 103.8647, Train: 86.14%, Valid: 86.05%, Test: 86.27%
Epoch: 325, Loss: 105.8143, Train: 86.18%, Valid: 86.09%, Test: 86.30%
Epoch: 350, Loss: 105.8802, Train: 86.17%, Valid: 86.08%, Test: 86.29%
Epoch: 375, Loss: 124.2869, Train: 86.16%, Valid: 86.08%, Test: 86.29%
Epoch: 400, Loss: 104.7845, Train: 86.16%, Valid: 86.08%, Test: 86.29%
Epoch: 425, Loss: 106.5011, Train: 86.15%, Valid: 86.06%, Test: 86.28%
Epoch: 450, Loss: 99.4953, Train: 86.18%, Valid: 86.09%, Test: 86.31%
Epoch: 475, Loss: 102.7541, Train: 86.17%, Valid: 86.09%, Test: 86.30%
Run 01:
Highest Train: 86.62
Highest Valid: 86.57
  Final Train: 86.57
   Final Test: 86.66
All runs:
Highest Train: 86.62, nan
Highest Valid: 86.57, nan
  Final Train: 86.57, nan
   Final Test: 86.66, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 4.4666, Train: 85.57%, Valid: 85.37%, Test: 85.60%
Epoch: 25, Loss: 6.1621, Train: 85.43%, Valid: 85.24%, Test: 85.51%
Epoch: 50, Loss: 6.8184, Train: 85.43%, Valid: 85.19%, Test: 85.49%
Epoch: 75, Loss: 6.9462, Train: 85.40%, Valid: 85.15%, Test: 85.44%
Epoch: 100, Loss: 6.9557, Train: 85.37%, Valid: 85.12%, Test: 85.42%
Epoch: 125, Loss: 6.9814, Train: 85.39%, Valid: 85.14%, Test: 85.43%
Epoch: 150, Loss: 6.9984, Train: 85.44%, Valid: 85.21%, Test: 85.49%
Epoch: 175, Loss: 6.9886, Train: 85.44%, Valid: 85.23%, Test: 85.50%
Epoch: 200, Loss: 6.9650, Train: 85.40%, Valid: 85.15%, Test: 85.44%
Epoch: 225, Loss: 7.0090, Train: 85.42%, Valid: 85.18%, Test: 85.47%
Epoch: 250, Loss: 7.0030, Train: 85.31%, Valid: 85.06%, Test: 85.33%
Epoch: 275, Loss: 6.9919, Train: 85.44%, Valid: 85.21%, Test: 85.49%
Epoch: 300, Loss: 6.9697, Train: 85.34%, Valid: 85.10%, Test: 85.39%
Epoch: 325, Loss: 6.9854, Train: 85.45%, Valid: 85.24%, Test: 85.51%
Epoch: 350, Loss: 6.9823, Train: 85.43%, Valid: 85.19%, Test: 85.49%
Epoch: 375, Loss: 7.0092, Train: 85.40%, Valid: 85.15%, Test: 85.44%
Epoch: 400, Loss: 6.9714, Train: 85.36%, Valid: 85.12%, Test: 85.41%
Epoch: 425, Loss: 6.9892, Train: 85.42%, Valid: 85.18%, Test: 85.48%
Epoch: 450, Loss: 6.9850, Train: 85.44%, Valid: 85.21%, Test: 85.49%
Epoch: 475, Loss: 6.9139, Train: 85.31%, Valid: 85.06%, Test: 85.33%
Run 01:
Highest Train: 86.86
Highest Valid: 86.92
  Final Train: 86.86
   Final Test: 86.95
All runs:
Highest Train: 86.86, nan
Highest Valid: 86.92, nan
  Final Train: 86.86, nan
   Final Test: 86.95, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.0220, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 339124928.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 700592.7500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 458880736.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 201616048.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 7734155.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 1283767.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 177198.2969, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 45326.2266, Train: 15.43%, Valid: 15.51%, Test: 15.30%
Epoch: 225, Loss: 12.1793, Train: 16.27%, Valid: 16.45%, Test: 16.16%
Epoch: 250, Loss: 10502.0879, Train: 15.67%, Valid: 15.80%, Test: 15.55%
Epoch: 275, Loss: 5831.2554, Train: 15.77%, Valid: 15.85%, Test: 15.65%
Epoch: 300, Loss: 40992.0430, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 3577.8123, Train: 15.18%, Valid: 15.28%, Test: 15.07%
Epoch: 350, Loss: 3451.2278, Train: 16.40%, Valid: 16.58%, Test: 16.28%
Epoch: 375, Loss: 3720.2761, Train: 15.06%, Valid: 15.15%, Test: 14.95%
Epoch: 400, Loss: 3717.0676, Train: 16.42%, Valid: 16.61%, Test: 16.31%
Epoch: 425, Loss: 3515.0876, Train: 16.39%, Valid: 16.58%, Test: 16.28%
Epoch: 450, Loss: 3248.9446, Train: 16.38%, Valid: 16.56%, Test: 16.26%
Epoch: 475, Loss: 4719.5127, Train: 15.21%, Valid: 15.27%, Test: 15.09%
Run 01:
Highest Train: 86.04
Highest Valid: 85.94
  Final Train: 86.04
   Final Test: 86.04
All runs:
Highest Train: 86.04, nan
Highest Valid: 85.94, nan
  Final Train: 86.04, nan
   Final Test: 86.04, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.5171, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 8189789601792.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 1538208563200.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 320894074880.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 15901857792.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 10633422848.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 716350848.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 8336200.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 61894208.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 83.8139, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 171.4209, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 63320.8828, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 751190.6875, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 949.0377, Train: 84.89%, Valid: 84.68%, Test: 85.06%
Epoch: 350, Loss: 25371.8379, Train: 84.76%, Valid: 84.55%, Test: 84.92%
Epoch: 375, Loss: 79.8754, Train: 84.73%, Valid: 84.54%, Test: 84.90%
Epoch: 400, Loss: 25251.9180, Train: 83.83%, Valid: 83.85%, Test: 83.91%
Epoch: 425, Loss: 120.8362, Train: 83.87%, Valid: 83.88%, Test: 83.95%
Epoch: 450, Loss: 143035.5781, Train: 84.79%, Valid: 84.58%, Test: 84.95%
Epoch: 475, Loss: 208.6577, Train: 84.73%, Valid: 84.53%, Test: 84.89%
Run 01:
Highest Train: 86.84
Highest Valid: 86.87
  Final Train: 86.84
   Final Test: 86.85
All runs:
Highest Train: 86.84, nan
Highest Valid: 86.87, nan
  Final Train: 86.84, nan
   Final Test: 86.85, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4518, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 7314766848.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 543105679360.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 470924064.0000, Train: 49.94%, Valid: 49.93%, Test: 49.94%
Epoch: 100, Loss: 1949986304.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 849853760.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 944282752.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 251801936.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 407976512.0000, Train: 49.96%, Valid: 49.94%, Test: 49.96%
Epoch: 225, Loss: 347335648.0000, Train: 50.06%, Valid: 50.07%, Test: 50.06%
Epoch: 250, Loss: 670112.0625, Train: 50.06%, Valid: 50.08%, Test: 50.07%
Epoch: 275, Loss: 48643256.0000, Train: 50.07%, Valid: 50.09%, Test: 50.07%
Epoch: 300, Loss: 172031088.0000, Train: 49.78%, Valid: 49.79%, Test: 49.77%
Epoch: 325, Loss: 134010192.0000, Train: 83.84%, Valid: 83.77%, Test: 83.95%
Epoch: 350, Loss: 1466752.7500, Train: 83.82%, Valid: 83.76%, Test: 83.93%
Epoch: 375, Loss: 567662.0625, Train: 16.20%, Valid: 16.26%, Test: 16.10%
Epoch: 400, Loss: 65363.5195, Train: 16.23%, Valid: 16.30%, Test: 16.13%
Epoch: 425, Loss: 689500.8125, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 123317.9453, Train: 83.61%, Valid: 83.55%, Test: 83.72%
Epoch: 475, Loss: 720569.8125, Train: 49.44%, Valid: 49.49%, Test: 49.44%
Run 01:
Highest Train: 84.20
Highest Valid: 84.12
  Final Train: 84.20
   Final Test: 84.32
All runs:
Highest Train: 84.20, nan
Highest Valid: 84.12, nan
  Final Train: 84.20, nan
   Final Test: 84.32, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5275, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.03
Highest Valid: 50.04
  Final Train: 50.03
   Final Test: 50.04
All runs:
Highest Train: 50.03, nan
Highest Valid: 50.04, nan
  Final Train: 50.03, nan
   Final Test: 50.04, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.8828, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 83.86%, Valid: 83.77%, Test: 83.96%
Epoch: 75, Loss: inf, Train: 16.13%, Valid: 16.22%, Test: 16.03%
Epoch: 100, Loss: 16298070572992003258084227022848.0000, Train: 83.90%, Valid: 83.80%, Test: 84.01%
Epoch: 125, Loss: -inf, Train: 83.90%, Valid: 83.80%, Test: 84.01%
Epoch: 150, Loss: inf, Train: 16.02%, Valid: 16.12%, Test: 15.90%
Epoch: 175, Loss: -inf, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 200, Loss: 62710675154000419354566459392.0000, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 225, Loss: nan, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 250, Loss: inf, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 275, Loss: inf, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 300, Loss: 2340389566221723533214406934528.0000, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 325, Loss: 9916664964719712062209574043648.0000, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 350, Loss: 151550515205001408991696726786048.0000, Train: 16.02%, Valid: 16.12%, Test: 15.90%
Epoch: 375, Loss: 3938496738307440293735038976.0000, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 400, Loss: 195630194354471993453232158408704.0000, Train: 16.02%, Valid: 16.12%, Test: 15.90%
Epoch: 425, Loss: inf, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 450, Loss: 561600940721358611276627968.0000, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Epoch: 475, Loss: 2209021037570390046630372966400.0000, Train: 83.98%, Valid: 83.88%, Test: 84.10%
Run 01:
Highest Train: 83.98
Highest Valid: 83.88
  Final Train: 83.98
   Final Test: 84.10
All runs:
Highest Train: 83.98, nan
Highest Valid: 83.88, nan
  Final Train: 83.98, nan
   Final Test: 84.10, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5665, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.1353, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.2030, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5531, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.8774, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 7729620480.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 2927324416.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 298150.4688, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 854933440.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 47290.5312, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 189942.8281, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 353164.5000, Train: 83.98%, Valid: 83.86%, Test: 84.10%
Epoch: 200, Loss: 119868.8828, Train: 83.70%, Valid: 83.55%, Test: 83.82%
Epoch: 225, Loss: 821.9170, Train: 83.93%, Valid: 83.80%, Test: 84.03%
Epoch: 250, Loss: 700.6490, Train: 83.84%, Valid: 83.73%, Test: 83.95%
Epoch: 275, Loss: 290.0962, Train: 15.55%, Valid: 15.65%, Test: 15.41%
Epoch: 300, Loss: 846.4145, Train: 15.54%, Valid: 15.64%, Test: 15.41%
Epoch: 325, Loss: 39162.6680, Train: 16.11%, Valid: 16.21%, Test: 16.00%
Epoch: 350, Loss: 11670.0693, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 207.8465, Train: 84.59%, Valid: 84.52%, Test: 84.73%
Epoch: 400, Loss: 29771.5410, Train: 83.91%, Valid: 83.79%, Test: 84.01%
Epoch: 425, Loss: 11325.9688, Train: 83.91%, Valid: 83.80%, Test: 84.02%
Epoch: 450, Loss: 201.8654, Train: 83.90%, Valid: 83.79%, Test: 84.01%
Epoch: 475, Loss: 666.9203, Train: 83.78%, Valid: 83.61%, Test: 83.91%
Run 01:
Highest Train: 87.30
Highest Valid: 87.19
  Final Train: 87.30
   Final Test: 87.34
All runs:
Highest Train: 87.30, nan
Highest Valid: 87.19, nan
  Final Train: 87.30, nan
   Final Test: 87.34, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.4477, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 70739904.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 158383243264.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 7072342.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 1971342080.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 1500978304.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 24879598.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 1215430912.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 707472.4375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 346765664.0000, Train: 16.19%, Valid: 16.25%, Test: 16.08%
Epoch: 250, Loss: 269019552.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 1962459136.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 5805679.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 3972370.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 763148544.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 1611622.7500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 1990702.8750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 12477756.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 80555512.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 1260366.1250, Train: 50.01%, Valid: 50.02%, Test: 50.01%
Run 01:
Highest Train: 50.06
Highest Valid: 50.07
  Final Train: 50.06
   Final Test: 50.06
All runs:
Highest Train: 50.06, nan
Highest Valid: 50.07, nan
  Final Train: 50.06, nan
   Final Test: 50.06, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 12.6192, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 1307518208.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 896837184.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 1316175950643200.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 118767153577984.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 560617719070720.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 76897899773952.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 335479392174080.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 117771417419776.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 700541435904.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 266767263858688.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 6054528679936.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 37962846830592.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 233094610944.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 74197893120.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 57735320174592.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 77420879872.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 130651504640.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 40650452992.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 338528993280.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 83.74
Highest Valid: 83.76
  Final Train: 83.74
   Final Test: 83.92
All runs:
Highest Train: 83.74, nan
Highest Valid: 83.76, nan
  Final Train: 83.74, nan
   Final Test: 83.92, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.9630, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: -inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 83.30
Highest Valid: 83.25
  Final Train: 83.30
   Final Test: 83.42
All runs:
Highest Train: 83.30, nan
Highest Valid: 83.25, nan
  Final Train: 83.30, nan
   Final Test: 83.42, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.2827, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.06
Highest Valid: 50.08
  Final Train: 50.06
   Final Test: 50.07
All runs:
Highest Train: 50.06, nan
Highest Valid: 50.08, nan
  Final Train: 50.06, nan
   Final Test: 50.07, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4028, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.9946, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5114, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 3645.0015, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.16
Highest Valid: 50.15
  Final Train: 50.16
   Final Test: 50.17
All runs:
Highest Train: 50.16, nan
Highest Valid: 50.15, nan
  Final Train: 50.16, nan
   Final Test: 50.17, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 4.0165, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4165, Train: 84.07%, Valid: 83.90%, Test: 84.21%
Epoch: 25, Loss: 1816.1079, Train: 83.83%, Valid: 83.77%, Test: 83.93%
Epoch: 50, Loss: 366417.2812, Train: 49.96%, Valid: 49.95%, Test: 49.96%
Epoch: 75, Loss: 19470280704.0000, Train: 50.06%, Valid: 50.07%, Test: 50.06%
Epoch: 100, Loss: 14289902.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 9993.7715, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 10919382.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 121310.9062, Train: 17.15%, Valid: 17.34%, Test: 17.03%
Epoch: 200, Loss: 179201.9219, Train: 17.03%, Valid: 17.16%, Test: 16.91%
Epoch: 225, Loss: 108005.9922, Train: 50.06%, Valid: 50.08%, Test: 50.07%
Epoch: 250, Loss: 44819.1211, Train: 16.38%, Valid: 16.47%, Test: 16.27%
Epoch: 275, Loss: 24969.4062, Train: 17.41%, Valid: 17.53%, Test: 17.32%
Epoch: 300, Loss: 56754.9453, Train: 17.05%, Valid: 17.18%, Test: 16.92%
Epoch: 325, Loss: 39525.0586, Train: 50.01%, Valid: 50.02%, Test: 50.01%
Epoch: 350, Loss: 188.2697, Train: 17.10%, Valid: 17.25%, Test: 16.97%
Epoch: 375, Loss: 24972.2324, Train: 50.06%, Valid: 50.07%, Test: 50.06%
Epoch: 400, Loss: 472.8926, Train: 84.03%, Valid: 84.07%, Test: 84.12%
Epoch: 425, Loss: 151060.9062, Train: 84.34%, Valid: 84.34%, Test: 84.43%
Epoch: 450, Loss: 49529.7109, Train: 84.54%, Valid: 84.53%, Test: 84.62%
Epoch: 475, Loss: 185076.4688, Train: 17.01%, Valid: 17.18%, Test: 16.88%
Run 01:
Highest Train: 84.99
Highest Valid: 84.95
  Final Train: 84.99
   Final Test: 85.12
All runs:
Highest Train: 84.99, nan
Highest Valid: 84.95, nan
  Final Train: 84.99, nan
   Final Test: 85.12, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.9889, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 5111661.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 43985408000.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 56983500.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 1728667.8750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 155028.7656, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 410770.9688, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 484379.0312, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 31143.3301, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 134739.7031, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 136615.8438, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 133709.0312, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 146758.7969, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 135071.9688, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 115638.3828, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 138169.5312, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 135796.9062, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 135657.0938, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 135333.3281, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 135430.6875, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 85.22
Highest Valid: 85.14
  Final Train: 85.22
   Final Test: 85.29
All runs:
Highest Train: 85.22, nan
Highest Valid: 85.14, nan
  Final Train: 85.22, nan
   Final Test: 85.29, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4179, Train: 84.95%, Valid: 84.72%, Test: 85.03%
Epoch: 25, Loss: 599374.3750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 6259849.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 93713552.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 789736192.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 40635428.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 7155610.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 118182.9844, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 995841.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 357479.5625, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 19799.7266, Train: 83.90%, Valid: 83.87%, Test: 84.04%
Epoch: 275, Loss: 9120527.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 244235.8906, Train: 50.06%, Valid: 50.08%, Test: 50.07%
Epoch: 325, Loss: 3364.3623, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 11038.6377, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 13443.1934, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 339123.7188, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 608668.8750, Train: 84.39%, Valid: 84.27%, Test: 84.52%
Epoch: 450, Loss: 2178.7642, Train: 84.80%, Valid: 84.61%, Test: 84.91%
Epoch: 475, Loss: 84968.6328, Train: 15.83%, Valid: 15.92%, Test: 15.72%
Run 01:
Highest Train: 84.95
Highest Valid: 84.72
  Final Train: 84.95
   Final Test: 85.03
All runs:
Highest Train: 84.95, nan
Highest Valid: 84.72, nan
  Final Train: 84.95, nan
   Final Test: 85.03, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.7015, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 28361381269970354176.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 347992333966360182784.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 4044093652992.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 881718869360640.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 1821333361000448.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 1743979255169024.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 9327444901232640.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 1980252385443840.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 31084133744640.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 209442534001213440.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 48780992512.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 17981071425536.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 156468957128163328.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 5043860799488.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 74857543347732480.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 36330621550723072.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 488993133166592.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 463353755467776.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 406432652141264896.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 84.52
Highest Valid: 84.54
  Final Train: 84.52
   Final Test: 84.65
All runs:
Highest Train: 84.52, nan
Highest Valid: 84.54, nan
  Final Train: 84.52, nan
   Final Test: 84.65, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 16.1753, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 228186547333880843294002682789888.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 29136442071114139202511018393600.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 2264392142262400461783957504.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 21138824743524869877600853426176.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 17318163047907964393357312.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 139641649723796494928052224.0000, Train: 50.07%, Valid: 50.08%, Test: 50.07%
Epoch: 325, Loss: 486139060289536.0000, Train: 49.31%, Valid: 49.34%, Test: 49.35%
Epoch: 350, Loss: 11220598839574528.0000, Train: 49.93%, Valid: 49.95%, Test: 49.95%
Epoch: 375, Loss: 1115335592964521984.0000, Train: 49.94%, Valid: 49.96%, Test: 49.95%
Epoch: 400, Loss: 2742893383696515072.0000, Train: 49.94%, Valid: 49.96%, Test: 49.95%
Epoch: 425, Loss: 22898941532481519616.0000, Train: 49.94%, Valid: 49.96%, Test: 49.95%
Epoch: 450, Loss: 503595888032289390592.0000, Train: 49.94%, Valid: 49.96%, Test: 49.95%
Epoch: 475, Loss: 19382705061888.0000, Train: 49.94%, Valid: 49.96%, Test: 49.95%
Run 01:
Highest Train: 84.39
Highest Valid: 84.27
  Final Train: 84.39
   Final Test: 84.52
All runs:
Highest Train: 84.39, nan
Highest Valid: 84.27, nan
  Final Train: 84.39, nan
   Final Test: 84.52, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5380, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 28028335942488887231330123776.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.26
Highest Valid: 86.11
  Final Train: 86.26
   Final Test: 86.25
All runs:
Highest Train: 86.26, nan
Highest Valid: 86.11, nan
  Final Train: 86.26, nan
   Final Test: 86.25, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 6.9274, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 6.7299, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.05, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.1290, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.2068, Train: 84.37%, Valid: 84.21%, Test: 84.47%
Epoch: 25, Loss: 14.5239, Train: 16.13%, Valid: 16.34%, Test: 16.00%
Epoch: 50, Loss: 1074.7192, Train: 86.69%, Valid: 86.75%, Test: 86.76%
Epoch: 75, Loss: 2.4020, Train: 86.55%, Valid: 86.60%, Test: 86.62%
Epoch: 100, Loss: 1.4331, Train: 86.55%, Valid: 86.61%, Test: 86.61%
Epoch: 125, Loss: 1.2664, Train: 86.55%, Valid: 86.61%, Test: 86.61%
Epoch: 150, Loss: 1.0668, Train: 86.53%, Valid: 86.58%, Test: 86.58%
Epoch: 175, Loss: 1.0932, Train: 86.55%, Valid: 86.61%, Test: 86.61%
Epoch: 200, Loss: 1.0483, Train: 86.55%, Valid: 86.61%, Test: 86.61%
Epoch: 225, Loss: 1.1827, Train: 86.48%, Valid: 86.54%, Test: 86.54%
Epoch: 250, Loss: 1.6109, Train: 86.55%, Valid: 86.61%, Test: 86.61%
Epoch: 275, Loss: 1.4581, Train: 86.53%, Valid: 86.58%, Test: 86.58%
Epoch: 300, Loss: 1.5368, Train: 86.51%, Valid: 86.56%, Test: 86.56%
Epoch: 325, Loss: 1.3108, Train: 86.55%, Valid: 86.61%, Test: 86.61%
Epoch: 350, Loss: 1.1623, Train: 86.47%, Valid: 86.53%, Test: 86.53%
Epoch: 375, Loss: 1.3283, Train: 86.55%, Valid: 86.61%, Test: 86.60%
Epoch: 400, Loss: 1.2204, Train: 86.55%, Valid: 86.61%, Test: 86.61%
Epoch: 425, Loss: 1.5648, Train: 86.55%, Valid: 86.61%, Test: 86.61%
Epoch: 450, Loss: 0.8355, Train: 86.45%, Valid: 86.50%, Test: 86.51%
Epoch: 475, Loss: 1.3713, Train: 86.48%, Valid: 86.54%, Test: 86.54%
Run 01:
Highest Train: 88.21
Highest Valid: 88.26
  Final Train: 88.21
   Final Test: 88.21
All runs:
Highest Train: 88.21, nan
Highest Valid: 88.26, nan
  Final Train: 88.21, nan
   Final Test: 88.21, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.6006, Train: 14.65%, Valid: 14.75%, Test: 14.50%
Epoch: 25, Loss: 3.4407, Train: 14.80%, Valid: 14.97%, Test: 14.66%
Epoch: 50, Loss: 456.4262, Train: 84.33%, Valid: 84.11%, Test: 84.50%
Epoch: 75, Loss: 64869.1523, Train: 83.88%, Valid: 83.68%, Test: 84.06%
Epoch: 100, Loss: 282.4466, Train: 84.23%, Valid: 84.18%, Test: 84.32%
Epoch: 125, Loss: 80.9860, Train: 84.14%, Valid: 84.10%, Test: 84.24%
Epoch: 150, Loss: 109.5173, Train: 86.93%, Valid: 86.92%, Test: 86.97%
Epoch: 175, Loss: 10.7899, Train: 15.48%, Valid: 15.63%, Test: 15.33%
Epoch: 200, Loss: 3.6784, Train: 86.88%, Valid: 86.89%, Test: 86.93%
Epoch: 225, Loss: 0.5298, Train: 15.48%, Valid: 15.62%, Test: 15.33%
Epoch: 250, Loss: 141.5172, Train: 86.88%, Valid: 86.88%, Test: 86.92%
Epoch: 275, Loss: 3.3504, Train: 86.88%, Valid: 86.88%, Test: 86.93%
Epoch: 300, Loss: 650.2961, Train: 86.86%, Valid: 86.87%, Test: 86.91%
Epoch: 325, Loss: 3.5543, Train: 86.84%, Valid: 86.85%, Test: 86.90%
Epoch: 350, Loss: 242.5785, Train: 15.45%, Valid: 15.60%, Test: 15.31%
Epoch: 375, Loss: 2.0709, Train: 86.83%, Valid: 86.83%, Test: 86.88%
Epoch: 400, Loss: 39.8381, Train: 15.43%, Valid: 15.57%, Test: 15.29%
Epoch: 425, Loss: 2.7199, Train: 86.82%, Valid: 86.82%, Test: 86.87%
Epoch: 450, Loss: 8.4525, Train: 86.85%, Valid: 86.86%, Test: 86.90%
Epoch: 475, Loss: 548.7590, Train: 15.45%, Valid: 15.59%, Test: 15.31%
Run 01:
Highest Train: 87.10
Highest Valid: 87.12
  Final Train: 87.09
   Final Test: 87.10
All runs:
Highest Train: 87.10, nan
Highest Valid: 87.12, nan
  Final Train: 87.09, nan
   Final Test: 87.10, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 4.1819, Train: 86.19%, Valid: 85.96%, Test: 86.15%
Epoch: 25, Loss: 52.8030, Train: 14.62%, Valid: 14.60%, Test: 14.56%
Epoch: 50, Loss: 42.5478, Train: 14.43%, Valid: 14.41%, Test: 14.37%
Epoch: 75, Loss: 36.4856, Train: 14.44%, Valid: 14.43%, Test: 14.38%
Epoch: 100, Loss: 22.9712, Train: 14.45%, Valid: 14.44%, Test: 14.40%
Epoch: 125, Loss: 27.0195, Train: 14.51%, Valid: 14.49%, Test: 14.45%
Epoch: 150, Loss: 30.4546, Train: 14.52%, Valid: 14.51%, Test: 14.47%
Epoch: 175, Loss: 29.7760, Train: 14.54%, Valid: 14.52%, Test: 14.49%
Epoch: 200, Loss: 28.2590, Train: 14.55%, Valid: 14.53%, Test: 14.50%
Epoch: 225, Loss: 26.8153, Train: 14.56%, Valid: 14.54%, Test: 14.51%
Epoch: 250, Loss: 25.4411, Train: 14.57%, Valid: 14.56%, Test: 14.52%
Epoch: 275, Loss: 24.1960, Train: 14.58%, Valid: 14.56%, Test: 14.53%
Epoch: 300, Loss: 23.0459, Train: 14.60%, Valid: 14.58%, Test: 14.54%
Epoch: 325, Loss: 21.9798, Train: 14.61%, Valid: 14.59%, Test: 14.55%
Epoch: 350, Loss: 21.0258, Train: 14.65%, Valid: 14.64%, Test: 14.57%
Epoch: 375, Loss: 20.1757, Train: 14.69%, Valid: 14.68%, Test: 14.59%
Epoch: 400, Loss: 19.3943, Train: 14.72%, Valid: 14.71%, Test: 14.61%
Epoch: 425, Loss: 18.7022, Train: 14.74%, Valid: 14.73%, Test: 14.63%
Epoch: 450, Loss: 18.0721, Train: 14.76%, Valid: 14.75%, Test: 14.65%
Epoch: 475, Loss: 17.5233, Train: 14.78%, Valid: 14.76%, Test: 14.67%
Run 01:
Highest Train: 86.35
Highest Valid: 86.23
  Final Train: 86.35
   Final Test: 86.38
All runs:
Highest Train: 86.35, nan
Highest Valid: 86.23, nan
  Final Train: 86.35, nan
   Final Test: 86.38, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5652, Train: 85.91%, Valid: 85.78%, Test: 86.01%
Epoch: 25, Loss: 1504.2483, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 14513322.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 417455144960.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 8872791113728.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 1437346048.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 787055968256.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 7510472.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 191195480064.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 14122625024.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 118646595584.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 32446138368.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 1320559837184.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 2277214257152.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 229904160.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 237441859584.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 18458685210624.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 550453376.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 10944729.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 170619633664.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.83
Highest Valid: 86.70
  Final Train: 86.83
   Final Test: 86.87
All runs:
Highest Train: 86.83, nan
Highest Valid: 86.70, nan
  Final Train: 86.83, nan
   Final Test: 86.87, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.3320, Train: 86.77%, Valid: 86.66%, Test: 86.76%
Epoch: 25, Loss: 194.6262, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 1192.1920, Train: 84.43%, Valid: 84.40%, Test: 84.49%
Epoch: 75, Loss: 324600.9375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 4983699.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 40969.6055, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 229190.2812, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 686827.9375, Train: 86.92%, Valid: 86.92%, Test: 86.94%
Epoch: 200, Loss: 115422.4141, Train: 15.65%, Valid: 15.82%, Test: 15.47%
Epoch: 225, Loss: 9.7617, Train: 84.29%, Valid: 84.14%, Test: 84.48%
Epoch: 250, Loss: 2698.6008, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 3967354.0000, Train: 86.92%, Valid: 86.92%, Test: 86.93%
Epoch: 300, Loss: 2836.7900, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 274779.0938, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 84329.6328, Train: 84.28%, Valid: 84.13%, Test: 84.47%
Epoch: 375, Loss: 138108.2344, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 16610.4062, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 213001.3281, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 587.7700, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 726.7626, Train: 84.43%, Valid: 84.39%, Test: 84.50%
Run 01:
Highest Train: 87.08
Highest Valid: 87.01
  Final Train: 87.08
   Final Test: 87.07
All runs:
Highest Train: 87.08, nan
Highest Valid: 87.01, nan
  Final Train: 87.08, nan
   Final Test: 87.07, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.0419, Train: 85.37%, Valid: 85.19%, Test: 85.41%
Epoch: 25, Loss: 1.5511, Train: 13.42%, Valid: 13.41%, Test: 13.31%
Epoch: 50, Loss: 260.2881, Train: 15.04%, Valid: 15.26%, Test: 14.97%
Epoch: 75, Loss: 73649976.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 504201984.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 4650.0957, Train: 83.59%, Valid: 83.58%, Test: 83.84%
Epoch: 150, Loss: 35186.7773, Train: 16.67%, Valid: 16.65%, Test: 16.55%
Epoch: 175, Loss: 230.9298, Train: 85.23%, Valid: 85.02%, Test: 85.28%
Epoch: 200, Loss: 35.7308, Train: 84.33%, Valid: 84.16%, Test: 84.40%
Epoch: 225, Loss: 25166.7793, Train: 16.69%, Valid: 16.67%, Test: 16.57%
Epoch: 250, Loss: 0.4919, Train: 84.31%, Valid: 84.14%, Test: 84.38%
Epoch: 275, Loss: 69222.2266, Train: 16.74%, Valid: 16.71%, Test: 16.63%
Epoch: 300, Loss: 5723.7490, Train: 16.67%, Valid: 16.65%, Test: 16.54%
Epoch: 325, Loss: 1173.6329, Train: 84.30%, Valid: 84.15%, Test: 84.38%
Epoch: 350, Loss: 42.6198, Train: 15.76%, Valid: 15.83%, Test: 15.72%
Epoch: 375, Loss: 73409.2891, Train: 14.39%, Valid: 14.27%, Test: 14.31%
Epoch: 400, Loss: 550769.3750, Train: 85.21%, Valid: 85.00%, Test: 85.25%
Epoch: 425, Loss: 9.6822, Train: 83.26%, Valid: 83.28%, Test: 83.42%
Epoch: 450, Loss: 98447.0781, Train: 15.52%, Valid: 15.70%, Test: 15.46%
Epoch: 475, Loss: 232.9073, Train: 84.86%, Valid: 84.68%, Test: 84.88%
Run 01:
Highest Train: 86.94
Highest Valid: 86.99
  Final Train: 86.94
   Final Test: 87.03
All runs:
Highest Train: 86.94, nan
Highest Valid: 86.99, nan
  Final Train: 86.94, nan
   Final Test: 87.03, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.5818, Train: 14.20%, Valid: 14.33%, Test: 14.24%
Epoch: 25, Loss: 10.1670, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 70526970101760.0000, Train: 84.14%, Valid: 83.92%, Test: 84.28%
Epoch: 75, Loss: 27719079297024.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 50325847870005051392.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 296663826563072.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 13.4398, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 57765.8594, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 539234003006259200.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 6032179887695198158848.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 113160.3750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 83472311910400.0000, Train: 14.07%, Valid: 14.21%, Test: 13.95%
Epoch: 300, Loss: 65822662656.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 256802709839548514304.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 1512899000200593408.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 45238557101866876928.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 74277676122112.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 379751507432344387584.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 96301275674574848.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 84764.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.21
Highest Valid: 86.21
  Final Train: 86.21
   Final Test: 86.19
All runs:
Highest Train: 86.21, nan
Highest Valid: 86.21, nan
  Final Train: 86.21, nan
   Final Test: 86.19, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.9601, Train: 86.97%, Valid: 87.00%, Test: 87.00%
Epoch: 25, Loss: 0.5047, Train: 49.93%, Valid: 49.91%, Test: 49.93%
Epoch: 50, Loss: 1667107979897339904.0000, Train: 50.13%, Valid: 50.12%, Test: 50.14%
Epoch: 75, Loss: 1.2867, Train: 86.40%, Valid: 86.44%, Test: 86.43%
Epoch: 100, Loss: 424813002752.0000, Train: 49.93%, Valid: 49.92%, Test: 49.93%
Epoch: 125, Loss: 3.4648, Train: 49.93%, Valid: 49.91%, Test: 49.93%
Epoch: 150, Loss: 2235418137329664.0000, Train: 86.71%, Valid: 86.70%, Test: 86.75%
Epoch: 175, Loss: 4390979518863725559808.0000, Train: 49.93%, Valid: 49.91%, Test: 49.93%
Epoch: 200, Loss: 233939.7188, Train: 16.24%, Valid: 16.40%, Test: 16.08%
Epoch: 225, Loss: 4.7381, Train: 49.93%, Valid: 49.91%, Test: 49.93%
Epoch: 250, Loss: 253000548352.0000, Train: 50.07%, Valid: 50.09%, Test: 50.07%
Epoch: 275, Loss: 68.0752, Train: 83.52%, Valid: 83.49%, Test: 83.61%
Epoch: 300, Loss: 2.0819, Train: 49.93%, Valid: 49.91%, Test: 49.92%
Epoch: 325, Loss: 2212883200.0000, Train: 83.85%, Valid: 83.83%, Test: 83.92%
Epoch: 350, Loss: 3.6025, Train: 49.93%, Valid: 49.91%, Test: 49.93%
Epoch: 375, Loss: 87095992.0000, Train: 50.07%, Valid: 50.09%, Test: 50.07%
Epoch: 400, Loss: 3.4280, Train: 49.93%, Valid: 49.91%, Test: 49.93%
Epoch: 425, Loss: 14632.2109, Train: 86.71%, Valid: 86.68%, Test: 86.74%
Epoch: 450, Loss: 632011328.0000, Train: 50.07%, Valid: 50.09%, Test: 50.07%
Epoch: 475, Loss: 354074689536.0000, Train: 50.07%, Valid: 50.08%, Test: 50.07%
Run 01:
Highest Train: 86.97
Highest Valid: 87.00
  Final Train: 86.97
   Final Test: 87.00
All runs:
Highest Train: 86.97, nan
Highest Valid: 87.00, nan
  Final Train: 86.97, nan
   Final Test: 87.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.2968, Train: 86.08%, Valid: 85.97%, Test: 86.08%
Epoch: 25, Loss: 32862766543180270560769736704.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 330072676518995436955571847168.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 1388118546995552680469705261056.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 247469808025600.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 15590784610793947136.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 45495151766514264178688.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 4843140414439424.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.85
Highest Valid: 86.81
  Final Train: 86.77
   Final Test: 86.83
All runs:
Highest Train: 86.85, nan
Highest Valid: 86.81, nan
  Final Train: 86.77, nan
   Final Test: 86.83, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 4.8407, Train: 86.00%, Valid: 85.88%, Test: 86.07%
Epoch: 25, Loss: 1.3725, Train: 87.05%, Valid: 87.07%, Test: 87.12%
Epoch: 50, Loss: 10.2709, Train: 87.51%, Valid: 87.54%, Test: 87.51%
Epoch: 75, Loss: 3.1668, Train: 87.60%, Valid: 87.62%, Test: 87.60%
Epoch: 100, Loss: 2.5957, Train: 87.72%, Valid: 87.77%, Test: 87.70%
Epoch: 125, Loss: 2.4865, Train: 87.80%, Valid: 87.83%, Test: 87.77%
Epoch: 150, Loss: 0.9375, Train: 87.75%, Valid: 87.79%, Test: 87.74%
Epoch: 175, Loss: 0.9863, Train: 87.77%, Valid: 87.81%, Test: 87.74%
Epoch: 200, Loss: 0.9608, Train: 87.76%, Valid: 87.80%, Test: 87.73%
Epoch: 225, Loss: 0.9485, Train: 87.76%, Valid: 87.79%, Test: 87.72%
Epoch: 250, Loss: 0.9493, Train: 87.75%, Valid: 87.79%, Test: 87.71%
Epoch: 275, Loss: 0.9531, Train: 87.74%, Valid: 87.77%, Test: 87.70%
Epoch: 300, Loss: 0.9501, Train: 87.73%, Valid: 87.76%, Test: 87.69%
Epoch: 325, Loss: 0.9170, Train: 87.70%, Valid: 87.73%, Test: 87.67%
Epoch: 350, Loss: 0.9343, Train: 87.66%, Valid: 87.70%, Test: 87.65%
Epoch: 375, Loss: 0.9475, Train: 87.55%, Valid: 87.59%, Test: 87.56%
Epoch: 400, Loss: 0.9288, Train: 87.52%, Valid: 87.58%, Test: 87.52%
Epoch: 425, Loss: 0.9323, Train: 87.51%, Valid: 87.55%, Test: 87.50%
Epoch: 450, Loss: 0.9138, Train: 87.44%, Valid: 87.50%, Test: 87.44%
Epoch: 475, Loss: 1.4539, Train: 87.75%, Valid: 87.78%, Test: 87.72%
Run 01:
Highest Train: 87.80
Highest Valid: 87.84
  Final Train: 87.80
   Final Test: 87.78
All runs:
Highest Train: 87.80, nan
Highest Valid: 87.84, nan
  Final Train: 87.80, nan
   Final Test: 87.78, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.6360, Train: 86.20%, Valid: 86.30%, Test: 86.32%
Epoch: 25, Loss: 249.8894, Train: 16.69%, Valid: 16.80%, Test: 16.52%
Epoch: 50, Loss: 167.0306, Train: 15.86%, Valid: 15.85%, Test: 15.76%
Epoch: 75, Loss: 22.4178, Train: 85.48%, Valid: 85.30%, Test: 85.59%
Epoch: 100, Loss: 61.2034, Train: 15.74%, Valid: 15.75%, Test: 15.65%
Epoch: 125, Loss: 388.8431, Train: 84.22%, Valid: 84.05%, Test: 84.40%
Epoch: 150, Loss: 409505.1875, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 18142.2617, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 7121.5850, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 38849.1016, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 51079.2344, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 117266.5078, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 55085.5547, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 79189.8906, Train: 84.47%, Valid: 84.48%, Test: 84.59%
Epoch: 350, Loss: 81050.8047, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 32282.8008, Train: 85.40%, Valid: 85.29%, Test: 85.55%
Epoch: 400, Loss: 3822.2080, Train: 85.42%, Valid: 85.31%, Test: 85.56%
Epoch: 425, Loss: 21036.3008, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 22604.1465, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 1009.5357, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.77
Highest Valid: 86.85
  Final Train: 86.77
   Final Test: 86.87
All runs:
Highest Train: 86.77, nan
Highest Valid: 86.85, nan
  Final Train: 86.77, nan
   Final Test: 86.87, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 6.7041, Train: 85.33%, Valid: 85.13%, Test: 85.38%
Epoch: 25, Loss: 0.7669, Train: 86.83%, Valid: 86.90%, Test: 86.91%
Epoch: 50, Loss: 1.0582, Train: 86.65%, Valid: 86.62%, Test: 86.66%
Epoch: 75, Loss: 1.3376, Train: 85.44%, Valid: 85.24%, Test: 85.46%
Epoch: 100, Loss: 15152.1807, Train: 84.66%, Valid: 84.46%, Test: 84.76%
Epoch: 125, Loss: 1914.9034, Train: 15.93%, Valid: 15.86%, Test: 15.76%
Epoch: 150, Loss: 9738.3867, Train: 15.57%, Valid: 15.55%, Test: 15.36%
Epoch: 175, Loss: 921.7670, Train: 84.65%, Valid: 84.40%, Test: 84.75%
Epoch: 200, Loss: 23922.8496, Train: 15.39%, Valid: 15.43%, Test: 15.19%
Epoch: 225, Loss: 3.1038, Train: 85.16%, Valid: 84.90%, Test: 85.23%
Epoch: 250, Loss: 2.1574, Train: 85.15%, Valid: 84.89%, Test: 85.21%
Epoch: 275, Loss: 2.1986, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Epoch: 300, Loss: 2.1955, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Epoch: 325, Loss: 2.1936, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Epoch: 350, Loss: 2.1929, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Epoch: 375, Loss: 2.1955, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Epoch: 400, Loss: 2.1973, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Epoch: 425, Loss: 2.2004, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Epoch: 450, Loss: 2.1965, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Epoch: 475, Loss: 2.1956, Train: 85.15%, Valid: 84.88%, Test: 85.21%
Run 01:
Highest Train: 86.94
Highest Valid: 86.98
  Final Train: 86.94
   Final Test: 86.98
All runs:
Highest Train: 86.94, nan
Highest Valid: 86.98, nan
  Final Train: 86.94, nan
   Final Test: 86.98, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 6.5661, Train: 86.71%, Valid: 86.74%, Test: 86.84%
Epoch: 25, Loss: 0.6967, Train: 86.27%, Valid: 86.21%, Test: 86.37%
Epoch: 50, Loss: 61.9765, Train: 86.26%, Valid: 86.32%, Test: 86.32%
Epoch: 75, Loss: 1720599.8750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 0.7133, Train: 84.85%, Valid: 84.84%, Test: 84.97%
Epoch: 125, Loss: 393.2585, Train: 87.33%, Valid: 87.27%, Test: 87.29%
Epoch: 150, Loss: 86097.5156, Train: 84.85%, Valid: 84.85%, Test: 84.93%
Epoch: 175, Loss: 99693.8359, Train: 87.33%, Valid: 87.27%, Test: 87.30%
Epoch: 200, Loss: 1190193.7500, Train: 87.45%, Valid: 87.41%, Test: 87.41%
Epoch: 225, Loss: 40.9337, Train: 87.41%, Valid: 87.37%, Test: 87.38%
Epoch: 250, Loss: 62944.0938, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 2098538.2500, Train: 84.83%, Valid: 84.84%, Test: 84.92%
Epoch: 300, Loss: 228.7334, Train: 87.33%, Valid: 87.27%, Test: 87.29%
Epoch: 325, Loss: 23.0461, Train: 87.47%, Valid: 87.42%, Test: 87.44%
Epoch: 350, Loss: 6.7523, Train: 87.43%, Valid: 87.38%, Test: 87.40%
Epoch: 375, Loss: 182444.8438, Train: 84.26%, Valid: 84.05%, Test: 84.38%
Epoch: 400, Loss: 10191.2656, Train: 84.79%, Valid: 84.79%, Test: 84.88%
Epoch: 425, Loss: 597707.9375, Train: 87.33%, Valid: 87.27%, Test: 87.30%
Epoch: 450, Loss: 755.1331, Train: 84.80%, Valid: 84.81%, Test: 84.89%
Epoch: 475, Loss: 66400.3750, Train: 87.43%, Valid: 87.38%, Test: 87.40%
Run 01:
Highest Train: 87.47
Highest Valid: 87.42
  Final Train: 87.47
   Final Test: 87.44
All runs:
Highest Train: 87.47, nan
Highest Valid: 87.42, nan
  Final Train: 87.47, nan
   Final Test: 87.44, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.4031, Train: 86.77%, Valid: 86.79%, Test: 86.80%
Epoch: 25, Loss: 11.2059, Train: 86.37%, Valid: 86.30%, Test: 86.39%
Epoch: 50, Loss: 11.6354, Train: 85.88%, Valid: 85.82%, Test: 85.90%
Epoch: 75, Loss: 1.2192, Train: 86.15%, Valid: 86.13%, Test: 86.20%
Epoch: 100, Loss: 7.3584, Train: 86.28%, Valid: 86.42%, Test: 86.45%
Epoch: 125, Loss: 5.3291, Train: 86.33%, Valid: 86.49%, Test: 86.49%
Epoch: 150, Loss: 5.0978, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 175, Loss: 5.0846, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 200, Loss: 5.0001, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 225, Loss: 5.0109, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 250, Loss: 4.9431, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 275, Loss: 4.9765, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 300, Loss: 4.9988, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 325, Loss: 5.0108, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 350, Loss: 5.0361, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 375, Loss: 4.9179, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 400, Loss: 4.9571, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 425, Loss: 4.8632, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 450, Loss: 4.9078, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Epoch: 475, Loss: 4.8994, Train: 86.34%, Valid: 86.49%, Test: 86.49%
Run 01:
Highest Train: 87.39
Highest Valid: 87.33
  Final Train: 87.39
   Final Test: 87.36
All runs:
Highest Train: 87.39, nan
Highest Valid: 87.33, nan
  Final Train: 87.39, nan
   Final Test: 87.36, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 4.1167, Train: 86.31%, Valid: 86.16%, Test: 86.28%
Epoch: 25, Loss: 0.7945, Train: 84.67%, Valid: 84.44%, Test: 84.77%
Epoch: 50, Loss: 15308.3730, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 26231.9648, Train: 84.80%, Valid: 84.63%, Test: 84.93%
Epoch: 100, Loss: 65.1952, Train: 85.83%, Valid: 85.87%, Test: 85.94%
Epoch: 125, Loss: 216.7709, Train: 84.88%, Valid: 84.81%, Test: 85.04%
Epoch: 150, Loss: 6.2184, Train: 85.78%, Valid: 85.85%, Test: 85.93%
Epoch: 175, Loss: 1.4696, Train: 85.87%, Valid: 85.83%, Test: 85.90%
Epoch: 200, Loss: 0.6869, Train: 16.67%, Valid: 16.79%, Test: 16.57%
Epoch: 225, Loss: 0.9782, Train: 85.83%, Valid: 85.80%, Test: 85.91%
Epoch: 250, Loss: 634.8143, Train: 16.67%, Valid: 16.79%, Test: 16.57%
Epoch: 275, Loss: 20.4328, Train: 85.89%, Valid: 85.88%, Test: 85.97%
Epoch: 300, Loss: 0.5917, Train: 85.89%, Valid: 85.88%, Test: 85.97%
Epoch: 325, Loss: 0.6272, Train: 16.46%, Valid: 16.59%, Test: 16.41%
Epoch: 350, Loss: 4.1739, Train: 85.85%, Valid: 85.83%, Test: 85.89%
Epoch: 375, Loss: 65.9722, Train: 16.73%, Valid: 16.85%, Test: 16.62%
Epoch: 400, Loss: 86.7376, Train: 85.98%, Valid: 85.84%, Test: 86.06%
Epoch: 425, Loss: 0.5559, Train: 16.41%, Valid: 16.58%, Test: 16.37%
Epoch: 450, Loss: 0.6554, Train: 85.89%, Valid: 85.88%, Test: 85.96%
Epoch: 475, Loss: 0.6028, Train: 16.63%, Valid: 16.75%, Test: 16.54%
Run 01:
Highest Train: 88.33
Highest Valid: 88.17
  Final Train: 88.33
   Final Test: 88.22
All runs:
Highest Train: 88.33, nan
Highest Valid: 88.17, nan
  Final Train: 88.33, nan
   Final Test: 88.22, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.3894, Train: 86.79%, Valid: 86.86%, Test: 86.87%
Epoch: 25, Loss: 6.3340, Train: 50.06%, Valid: 50.07%, Test: 50.06%
Epoch: 50, Loss: 16679.3730, Train: 16.17%, Valid: 16.24%, Test: 16.07%
Epoch: 75, Loss: 44.4361, Train: 14.87%, Valid: 14.77%, Test: 14.88%
Epoch: 100, Loss: 41.5412, Train: 14.82%, Valid: 14.73%, Test: 14.84%
Epoch: 125, Loss: 42.8518, Train: 14.82%, Valid: 14.72%, Test: 14.84%
Epoch: 150, Loss: 454.6197, Train: 14.82%, Valid: 14.72%, Test: 14.84%
Epoch: 175, Loss: 11595.8398, Train: 84.62%, Valid: 84.50%, Test: 84.73%
Epoch: 200, Loss: 41.3637, Train: 14.85%, Valid: 14.74%, Test: 14.87%
Epoch: 225, Loss: 45.1320, Train: 14.84%, Valid: 14.74%, Test: 14.85%
Epoch: 250, Loss: 11.5134, Train: 14.81%, Valid: 14.72%, Test: 14.83%
Epoch: 275, Loss: 44.2354, Train: 14.81%, Valid: 14.72%, Test: 14.83%
Epoch: 300, Loss: 44.5571, Train: 85.76%, Valid: 85.60%, Test: 85.90%
Epoch: 325, Loss: 40.3296, Train: 14.78%, Valid: 14.70%, Test: 14.81%
Epoch: 350, Loss: 43.8768, Train: 14.79%, Valid: 14.68%, Test: 14.81%
Epoch: 375, Loss: 44.1173, Train: 15.01%, Valid: 14.90%, Test: 15.02%
Epoch: 400, Loss: 44.2896, Train: 14.97%, Valid: 14.86%, Test: 14.98%
Epoch: 425, Loss: 38.6165, Train: 14.84%, Valid: 14.74%, Test: 14.86%
Epoch: 450, Loss: 43.4715, Train: 14.84%, Valid: 14.74%, Test: 14.85%
Epoch: 475, Loss: 45.0707, Train: 14.82%, Valid: 14.73%, Test: 14.84%
Run 01:
Highest Train: 87.24
Highest Valid: 87.27
  Final Train: 87.24
   Final Test: 87.37
All runs:
Highest Train: 87.24, nan
Highest Valid: 87.27, nan
  Final Train: 87.24, nan
   Final Test: 87.37, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.8932, Train: 86.16%, Valid: 86.09%, Test: 86.30%
Epoch: 25, Loss: 228711089400916411362050048.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 585.0005, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 7.5771, Train: 86.37%, Valid: 86.24%, Test: 86.45%
Epoch: 100, Loss: 101915574272.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 3.8733, Train: 86.37%, Valid: 86.24%, Test: 86.46%
Epoch: 150, Loss: 8.2188, Train: 86.38%, Valid: 86.26%, Test: 86.48%
Epoch: 175, Loss: 754450599772160.0000, Train: 15.35%, Valid: 15.40%, Test: 15.24%
Epoch: 200, Loss: 14.4324, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 8.1707, Train: 86.41%, Valid: 86.29%, Test: 86.50%
Epoch: 250, Loss: 606341496832.0000, Train: 86.40%, Valid: 86.28%, Test: 86.49%
Epoch: 275, Loss: 1934303360.0000, Train: 86.36%, Valid: 86.23%, Test: 86.45%
Epoch: 300, Loss: 6.7651, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 8.7726, Train: 86.38%, Valid: 86.25%, Test: 86.47%
Epoch: 350, Loss: 7.1032, Train: 86.35%, Valid: 86.22%, Test: 86.44%
Epoch: 375, Loss: 491310016.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 1463897161728.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 7.6125, Train: 86.37%, Valid: 86.25%, Test: 86.47%
Epoch: 450, Loss: 7.7760, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 28303200.0000, Train: 86.37%, Valid: 86.25%, Test: 86.47%
Run 01:
Highest Train: 86.75
Highest Valid: 86.79
  Final Train: 86.75
   Final Test: 86.82
All runs:
Highest Train: 86.75, nan
Highest Valid: 86.79, nan
  Final Train: 86.75, nan
   Final Test: 86.82, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.3807, Train: 85.45%, Valid: 85.43%, Test: 85.59%
Epoch: 25, Loss: 11.0696, Train: 86.34%, Valid: 86.28%, Test: 86.41%
Epoch: 50, Loss: 54712888.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 6.4399, Train: 86.51%, Valid: 86.43%, Test: 86.55%
Epoch: 100, Loss: 5.4894, Train: 86.56%, Valid: 86.48%, Test: 86.58%
Epoch: 125, Loss: 5.4420, Train: 86.55%, Valid: 86.48%, Test: 86.58%
Epoch: 150, Loss: 5.4870, Train: 86.55%, Valid: 86.48%, Test: 86.58%
Epoch: 175, Loss: 5.5244, Train: 86.55%, Valid: 86.48%, Test: 86.58%
Epoch: 200, Loss: 5.4813, Train: 86.55%, Valid: 86.47%, Test: 86.57%
Epoch: 225, Loss: 5.5826, Train: 86.55%, Valid: 86.47%, Test: 86.58%
Epoch: 250, Loss: 5.6592, Train: 86.54%, Valid: 86.47%, Test: 86.57%
Epoch: 275, Loss: 5.4790, Train: 86.55%, Valid: 86.47%, Test: 86.58%
Epoch: 300, Loss: 5.5549, Train: 86.58%, Valid: 86.52%, Test: 86.62%
Epoch: 325, Loss: 5.5590, Train: 86.59%, Valid: 86.51%, Test: 86.61%
Epoch: 350, Loss: 5.2941, Train: 86.58%, Valid: 86.51%, Test: 86.60%
Epoch: 375, Loss: 5.4427, Train: 86.59%, Valid: 86.52%, Test: 86.62%
Epoch: 400, Loss: 5.6012, Train: 86.59%, Valid: 86.53%, Test: 86.62%
Epoch: 425, Loss: 5.5378, Train: 86.59%, Valid: 86.53%, Test: 86.62%
Epoch: 450, Loss: 6.1714, Train: 86.59%, Valid: 86.52%, Test: 86.62%
Epoch: 475, Loss: 26.8957, Train: 86.65%, Valid: 86.60%, Test: 86.73%
Run 01:
Highest Train: 86.74
Highest Valid: 86.70
  Final Train: 86.74
   Final Test: 86.81
All runs:
Highest Train: 86.74, nan
Highest Valid: 86.70, nan
  Final Train: 86.74, nan
   Final Test: 86.81, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.6207, Train: 86.23%, Valid: 86.22%, Test: 86.29%
Epoch: 25, Loss: 0.7988, Train: 87.01%, Valid: 87.01%, Test: 87.04%
Epoch: 50, Loss: 0.6504, Train: 86.35%, Valid: 86.36%, Test: 86.43%
Epoch: 75, Loss: 0.3833, Train: 85.84%, Valid: 85.71%, Test: 85.90%
Epoch: 100, Loss: 0.3534, Train: 86.76%, Valid: 86.72%, Test: 86.81%
Epoch: 125, Loss: 0.3426, Train: 87.04%, Valid: 86.98%, Test: 87.08%
Epoch: 150, Loss: 0.3403, Train: 86.40%, Valid: 86.47%, Test: 86.50%
Epoch: 175, Loss: 0.3336, Train: 85.53%, Valid: 85.50%, Test: 85.61%
Epoch: 200, Loss: 0.3281, Train: 85.57%, Valid: 85.57%, Test: 85.65%
Epoch: 225, Loss: 52.6681, Train: 85.37%, Valid: 85.40%, Test: 85.47%
Epoch: 250, Loss: 3.6092, Train: 85.39%, Valid: 85.43%, Test: 85.48%
Epoch: 275, Loss: 3.1655, Train: 85.40%, Valid: 85.43%, Test: 85.48%
Epoch: 300, Loss: 3.1755, Train: 85.40%, Valid: 85.42%, Test: 85.48%
Epoch: 325, Loss: 2.9148, Train: 85.40%, Valid: 85.42%, Test: 85.49%
Epoch: 350, Loss: 2.1241, Train: 85.40%, Valid: 85.43%, Test: 85.49%
Epoch: 375, Loss: 0.3721, Train: 85.82%, Valid: 85.80%, Test: 85.90%
Epoch: 400, Loss: 0.6600, Train: 85.44%, Valid: 85.45%, Test: 85.52%
Epoch: 425, Loss: 0.6028, Train: 85.44%, Valid: 85.45%, Test: 85.52%
Epoch: 450, Loss: 0.5060, Train: 85.49%, Valid: 85.49%, Test: 85.56%
Epoch: 475, Loss: 0.4008, Train: 85.55%, Valid: 85.55%, Test: 85.65%
Run 01:
Highest Train: 87.22
Highest Valid: 87.23
  Final Train: 87.22
   Final Test: 87.27
All runs:
Highest Train: 87.22, nan
Highest Valid: 87.23, nan
  Final Train: 87.22, nan
   Final Test: 87.27, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5286, Train: 86.04%, Valid: 86.00%, Test: 86.20%
Epoch: 25, Loss: 1.1330, Train: 87.40%, Valid: 87.42%, Test: 87.54%
Epoch: 50, Loss: 1.3069, Train: 85.80%, Valid: 85.72%, Test: 85.84%
Epoch: 75, Loss: 7.6830, Train: 85.83%, Valid: 85.75%, Test: 85.88%
Epoch: 100, Loss: 12.5336, Train: 85.94%, Valid: 85.84%, Test: 85.95%
Epoch: 125, Loss: 41.8919, Train: 86.00%, Valid: 85.91%, Test: 86.02%
Epoch: 150, Loss: 2.5653, Train: 85.93%, Valid: 85.85%, Test: 85.94%
Epoch: 175, Loss: 1.7756, Train: 85.95%, Valid: 85.87%, Test: 85.96%
Epoch: 200, Loss: 1.7893, Train: 85.95%, Valid: 85.87%, Test: 85.97%
Epoch: 225, Loss: 1.7836, Train: 85.95%, Valid: 85.87%, Test: 85.97%
Epoch: 250, Loss: 1.7733, Train: 85.96%, Valid: 85.88%, Test: 85.98%
Epoch: 275, Loss: 1.7657, Train: 85.96%, Valid: 85.88%, Test: 85.98%
Epoch: 300, Loss: 1.7682, Train: 85.96%, Valid: 85.88%, Test: 85.98%
Epoch: 325, Loss: 1.7664, Train: 85.97%, Valid: 85.88%, Test: 85.99%
Epoch: 350, Loss: 1.7809, Train: 85.97%, Valid: 85.89%, Test: 85.99%
Epoch: 375, Loss: 1.7727, Train: 85.98%, Valid: 85.90%, Test: 86.00%
Epoch: 400, Loss: 1.7724, Train: 85.98%, Valid: 85.90%, Test: 86.00%
Epoch: 425, Loss: 1.7688, Train: 85.98%, Valid: 85.90%, Test: 86.01%
Epoch: 450, Loss: 1.7687, Train: 85.99%, Valid: 85.91%, Test: 86.01%
Epoch: 475, Loss: 1.7734, Train: 85.99%, Valid: 85.91%, Test: 86.02%
Run 01:
Highest Train: 87.52
Highest Valid: 87.53
  Final Train: 87.52
   Final Test: 87.64
All runs:
Highest Train: 87.52, nan
Highest Valid: 87.53, nan
  Final Train: 87.52, nan
   Final Test: 87.64, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 15.5566, Train: 85.48%, Valid: 85.31%, Test: 85.51%
Epoch: 25, Loss: 0.9570, Train: 87.36%, Valid: 87.40%, Test: 87.38%
Epoch: 50, Loss: 4.1701, Train: 88.00%, Valid: 87.92%, Test: 87.96%
Epoch: 75, Loss: 5.7074, Train: 86.49%, Valid: 86.38%, Test: 86.48%
Epoch: 100, Loss: 1.3288, Train: 86.34%, Valid: 86.20%, Test: 86.34%
Epoch: 125, Loss: 1.3448, Train: 86.35%, Valid: 86.21%, Test: 86.34%
Epoch: 150, Loss: 1.3282, Train: 86.34%, Valid: 86.19%, Test: 86.32%
Epoch: 175, Loss: 1.3115, Train: 86.32%, Valid: 86.17%, Test: 86.30%
Epoch: 200, Loss: 1.3018, Train: 86.31%, Valid: 86.16%, Test: 86.28%
Epoch: 225, Loss: 1.2947, Train: 86.26%, Valid: 86.11%, Test: 86.23%
Epoch: 250, Loss: 1.2823, Train: 86.19%, Valid: 86.05%, Test: 86.17%
Epoch: 275, Loss: 1.2737, Train: 86.13%, Valid: 85.98%, Test: 86.12%
Epoch: 300, Loss: 1.2630, Train: 86.21%, Valid: 86.06%, Test: 86.19%
Epoch: 325, Loss: 1.2483, Train: 86.21%, Valid: 86.07%, Test: 86.19%
Epoch: 350, Loss: 1.2311, Train: 86.17%, Valid: 86.02%, Test: 86.15%
Epoch: 375, Loss: 1.2085, Train: 86.15%, Valid: 86.00%, Test: 86.14%
Epoch: 400, Loss: 1.1961, Train: 86.15%, Valid: 86.00%, Test: 86.14%
Epoch: 425, Loss: 1.1868, Train: 86.12%, Valid: 85.96%, Test: 86.11%
Epoch: 450, Loss: 1.1642, Train: 86.09%, Valid: 85.93%, Test: 86.08%
Epoch: 475, Loss: 1.1419, Train: 86.08%, Valid: 85.91%, Test: 86.06%
Run 01:
Highest Train: 88.07
Highest Valid: 87.97
  Final Train: 88.07
   Final Test: 88.00
All runs:
Highest Train: 88.07, nan
Highest Valid: 87.97, nan
  Final Train: 88.07, nan
   Final Test: 88.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 8.4083, Train: 85.17%, Valid: 85.18%, Test: 85.28%
Epoch: 25, Loss: 25.6472, Train: 86.90%, Valid: 86.91%, Test: 86.93%
Epoch: 50, Loss: 1.2741, Train: 86.65%, Valid: 86.67%, Test: 86.65%
Epoch: 75, Loss: 1.3404, Train: 86.71%, Valid: 86.72%, Test: 86.73%
Epoch: 100, Loss: 1.3061, Train: 86.68%, Valid: 86.71%, Test: 86.71%
Epoch: 125, Loss: 1.2991, Train: 86.67%, Valid: 86.72%, Test: 86.70%
Epoch: 150, Loss: 1.3016, Train: 86.67%, Valid: 86.71%, Test: 86.70%
Epoch: 175, Loss: 1.3119, Train: 86.69%, Valid: 86.72%, Test: 86.71%
Epoch: 200, Loss: 1.3057, Train: 86.69%, Valid: 86.72%, Test: 86.71%
Epoch: 225, Loss: 1.3089, Train: 86.69%, Valid: 86.72%, Test: 86.71%
Epoch: 250, Loss: 1.3071, Train: 86.69%, Valid: 86.72%, Test: 86.71%
Epoch: 275, Loss: 1.2979, Train: 86.69%, Valid: 86.73%, Test: 86.71%
Epoch: 300, Loss: 1.3008, Train: 86.70%, Valid: 86.73%, Test: 86.72%
Epoch: 325, Loss: 1.2944, Train: 86.71%, Valid: 86.74%, Test: 86.73%
Epoch: 350, Loss: 1.2936, Train: 86.71%, Valid: 86.74%, Test: 86.73%
Epoch: 375, Loss: 1.2914, Train: 86.70%, Valid: 86.74%, Test: 86.73%
Epoch: 400, Loss: 1.2957, Train: 86.70%, Valid: 86.74%, Test: 86.73%
Epoch: 425, Loss: 1.2918, Train: 86.71%, Valid: 86.74%, Test: 86.73%
Epoch: 450, Loss: 1.2943, Train: 86.71%, Valid: 86.75%, Test: 86.73%
Epoch: 475, Loss: 1.2867, Train: 86.72%, Valid: 86.75%, Test: 86.74%
Run 01:
Highest Train: 87.50
Highest Valid: 87.53
  Final Train: 87.50
   Final Test: 87.48
All runs:
Highest Train: 87.50, nan
Highest Valid: 87.53, nan
  Final Train: 87.50, nan
   Final Test: 87.48, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.5173, Train: 85.86%, Valid: 85.89%, Test: 86.06%
Epoch: 25, Loss: 0.7356, Train: 87.02%, Valid: 86.98%, Test: 87.11%
Epoch: 50, Loss: 0.4210, Train: 85.93%, Valid: 85.88%, Test: 85.96%
Epoch: 75, Loss: 0.3576, Train: 86.34%, Valid: 86.27%, Test: 86.41%
Epoch: 100, Loss: 0.3506, Train: 85.83%, Valid: 85.70%, Test: 85.95%
Epoch: 125, Loss: 0.3380, Train: 85.53%, Valid: 85.46%, Test: 85.67%
Epoch: 150, Loss: 0.3497, Train: 85.94%, Valid: 85.77%, Test: 86.05%
Epoch: 175, Loss: 0.3352, Train: 86.15%, Valid: 86.04%, Test: 86.29%
Epoch: 200, Loss: 0.3300, Train: 85.99%, Valid: 85.84%, Test: 86.13%
Epoch: 225, Loss: 0.3702, Train: 85.82%, Valid: 85.67%, Test: 85.93%
Epoch: 250, Loss: 1.4911, Train: 85.94%, Valid: 85.85%, Test: 86.10%
Epoch: 275, Loss: 6.0287, Train: 86.02%, Valid: 85.88%, Test: 86.13%
Epoch: 300, Loss: 36.5316, Train: 86.30%, Valid: 86.19%, Test: 86.40%
Epoch: 325, Loss: 25.4282, Train: 86.22%, Valid: 86.09%, Test: 86.31%
Epoch: 350, Loss: 6.1949, Train: 86.20%, Valid: 86.08%, Test: 86.30%
Epoch: 375, Loss: 2.7695, Train: 86.12%, Valid: 86.00%, Test: 86.22%
Epoch: 400, Loss: 2.7718, Train: 86.12%, Valid: 86.00%, Test: 86.22%
Epoch: 425, Loss: 2.7540, Train: 86.13%, Valid: 86.00%, Test: 86.23%
Epoch: 450, Loss: 2.7363, Train: 86.13%, Valid: 86.01%, Test: 86.23%
Epoch: 475, Loss: 2.7181, Train: 86.14%, Valid: 86.02%, Test: 86.24%
Run 01:
Highest Train: 87.37
Highest Valid: 87.35
  Final Train: 87.37
   Final Test: 87.43
All runs:
Highest Train: 87.37, nan
Highest Valid: 87.35, nan
  Final Train: 87.37, nan
   Final Test: 87.43, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4908, Train: 85.16%, Valid: 85.09%, Test: 85.09%
Epoch: 25, Loss: 0.3646, Train: 86.68%, Valid: 86.54%, Test: 86.65%
Epoch: 50, Loss: 0.3606, Train: 85.52%, Valid: 85.37%, Test: 85.56%
Epoch: 75, Loss: 0.3553, Train: 85.77%, Valid: 85.65%, Test: 85.82%
Epoch: 100, Loss: 0.3476, Train: 85.48%, Valid: 85.33%, Test: 85.55%
Epoch: 125, Loss: 0.3466, Train: 85.40%, Valid: 85.19%, Test: 85.44%
Epoch: 150, Loss: 1.1799, Train: 85.51%, Valid: 85.33%, Test: 85.56%
Epoch: 175, Loss: 1.8752, Train: 85.51%, Valid: 85.31%, Test: 85.56%
Epoch: 200, Loss: 2.1331, Train: 85.52%, Valid: 85.33%, Test: 85.58%
Epoch: 225, Loss: 1.9057, Train: 85.53%, Valid: 85.34%, Test: 85.58%
Epoch: 250, Loss: 1.7392, Train: 85.52%, Valid: 85.34%, Test: 85.57%
Epoch: 275, Loss: 1.4849, Train: 85.53%, Valid: 85.34%, Test: 85.58%
Epoch: 300, Loss: 0.7620, Train: 85.34%, Valid: 85.16%, Test: 85.43%
Epoch: 325, Loss: 0.3525, Train: 85.77%, Valid: 85.55%, Test: 85.83%
Epoch: 350, Loss: 0.3343, Train: 85.81%, Valid: 85.63%, Test: 85.89%
Epoch: 375, Loss: 0.3305, Train: 85.82%, Valid: 85.62%, Test: 85.88%
Epoch: 400, Loss: 0.3293, Train: 85.94%, Valid: 85.72%, Test: 85.99%
Epoch: 425, Loss: 1.1127, Train: 86.21%, Valid: 86.20%, Test: 86.38%
Epoch: 450, Loss: 1.1173, Train: 84.90%, Valid: 84.84%, Test: 85.08%
Epoch: 475, Loss: 0.7810, Train: 85.06%, Valid: 85.00%, Test: 85.21%
Run 01:
Highest Train: 86.79
Highest Valid: 86.67
  Final Train: 86.79
   Final Test: 86.77
All runs:
Highest Train: 86.79, nan
Highest Valid: 86.67, nan
  Final Train: 86.79, nan
   Final Test: 86.77, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4491, Train: 86.52%, Valid: 86.50%, Test: 86.66%
Epoch: 25, Loss: 0.6277, Train: 86.53%, Valid: 86.57%, Test: 86.58%
Epoch: 50, Loss: 0.3633, Train: 87.96%, Valid: 88.06%, Test: 87.95%
Epoch: 75, Loss: 0.3568, Train: 87.76%, Valid: 87.84%, Test: 87.79%
Epoch: 100, Loss: 0.3492, Train: 86.68%, Valid: 86.71%, Test: 86.71%
Epoch: 125, Loss: 0.3378, Train: 86.49%, Valid: 86.44%, Test: 86.51%
Epoch: 150, Loss: 0.4631, Train: 85.68%, Valid: 85.70%, Test: 85.75%
Epoch: 175, Loss: 1.1878, Train: 85.66%, Valid: 85.72%, Test: 85.76%
Epoch: 200, Loss: 1.0151, Train: 85.66%, Valid: 85.71%, Test: 85.76%
Epoch: 225, Loss: 0.3437, Train: 86.08%, Valid: 86.08%, Test: 86.19%
Epoch: 250, Loss: 0.3383, Train: 85.54%, Valid: 85.49%, Test: 85.66%
Epoch: 275, Loss: 0.3320, Train: 85.95%, Valid: 85.95%, Test: 86.04%
Epoch: 300, Loss: 0.3280, Train: 85.84%, Valid: 85.82%, Test: 85.92%
Epoch: 325, Loss: 0.5441, Train: 85.30%, Valid: 85.30%, Test: 85.42%
Epoch: 350, Loss: 1.6562, Train: 85.61%, Valid: 85.64%, Test: 85.70%
Epoch: 375, Loss: 1.3665, Train: 85.66%, Valid: 85.70%, Test: 85.78%
Epoch: 400, Loss: 0.5098, Train: 85.63%, Valid: 85.66%, Test: 85.72%
Epoch: 425, Loss: 0.9493, Train: 85.69%, Valid: 85.73%, Test: 85.77%
Epoch: 450, Loss: 0.8286, Train: 85.60%, Valid: 85.63%, Test: 85.70%
Epoch: 475, Loss: 0.6210, Train: 85.59%, Valid: 85.63%, Test: 85.69%
Run 01:
Highest Train: 88.24
Highest Valid: 88.29
  Final Train: 88.24
   Final Test: 88.28
All runs:
Highest Train: 88.24, nan
Highest Valid: 88.29, nan
  Final Train: 88.24, nan
   Final Test: 88.28, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 12.0918, Train: 86.39%, Valid: 86.28%, Test: 86.50%
Epoch: 25, Loss: 0.8250, Train: 87.02%, Valid: 87.03%, Test: 87.09%
Epoch: 50, Loss: 0.6257, Train: 87.51%, Valid: 87.50%, Test: 87.53%
Epoch: 75, Loss: 0.3607, Train: 86.15%, Valid: 85.95%, Test: 86.12%
Epoch: 100, Loss: 0.3511, Train: 85.91%, Valid: 85.73%, Test: 85.99%
Epoch: 125, Loss: 0.3397, Train: 85.75%, Valid: 85.59%, Test: 85.86%
Epoch: 150, Loss: 0.3352, Train: 85.76%, Valid: 85.59%, Test: 85.88%
Epoch: 175, Loss: 1.0093, Train: 87.71%, Valid: 87.64%, Test: 87.68%
Epoch: 200, Loss: 2.4235, Train: 85.90%, Valid: 85.78%, Test: 86.00%
Epoch: 225, Loss: 2.9182, Train: 85.90%, Valid: 85.78%, Test: 85.98%
Epoch: 250, Loss: 4.0612, Train: 85.94%, Valid: 85.82%, Test: 86.00%
Epoch: 275, Loss: 4.8656, Train: 85.89%, Valid: 85.77%, Test: 85.96%
Epoch: 300, Loss: 4.3925, Train: 85.89%, Valid: 85.77%, Test: 85.96%
Epoch: 325, Loss: 3.3322, Train: 85.90%, Valid: 85.78%, Test: 85.97%
Epoch: 350, Loss: 2.3659, Train: 85.90%, Valid: 85.78%, Test: 85.98%
Epoch: 375, Loss: 1.1603, Train: 85.91%, Valid: 85.80%, Test: 85.99%
Epoch: 400, Loss: 0.5235, Train: 85.93%, Valid: 85.82%, Test: 86.02%
Epoch: 425, Loss: 0.3714, Train: 86.09%, Valid: 85.94%, Test: 86.18%
Epoch: 450, Loss: 0.3525, Train: 86.13%, Valid: 85.95%, Test: 86.24%
Epoch: 475, Loss: 0.3512, Train: 86.13%, Valid: 85.95%, Test: 86.22%
Run 01:
Highest Train: 87.73
Highest Valid: 87.76
  Final Train: 87.72
   Final Test: 87.80
All runs:
Highest Train: 87.73, nan
Highest Valid: 87.76, nan
  Final Train: 87.72, nan
   Final Test: 87.80, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.4621, Train: 86.06%, Valid: 86.06%, Test: 86.10%
Epoch: 25, Loss: 1.1083, Train: 87.59%, Valid: 87.53%, Test: 87.56%
Epoch: 50, Loss: 1.2364, Train: 87.08%, Valid: 87.07%, Test: 87.08%
Epoch: 75, Loss: 1.3007, Train: 86.73%, Valid: 86.72%, Test: 86.77%
Epoch: 100, Loss: 1.2737, Train: 86.53%, Valid: 86.53%, Test: 86.56%
Epoch: 125, Loss: 1.2473, Train: 86.46%, Valid: 86.47%, Test: 86.50%
Epoch: 150, Loss: 1.2055, Train: 86.78%, Valid: 86.76%, Test: 86.81%
Epoch: 175, Loss: 1.1706, Train: 86.77%, Valid: 86.76%, Test: 86.80%
Epoch: 200, Loss: 1.0523, Train: 86.76%, Valid: 86.75%, Test: 86.79%
Epoch: 225, Loss: 0.7563, Train: 86.80%, Valid: 86.79%, Test: 86.83%
Epoch: 250, Loss: 0.3720, Train: 86.01%, Valid: 85.85%, Test: 86.07%
Epoch: 275, Loss: 0.3655, Train: 86.45%, Valid: 86.46%, Test: 86.57%
Epoch: 300, Loss: 0.3644, Train: 86.42%, Valid: 86.34%, Test: 86.42%
Epoch: 325, Loss: 0.3640, Train: 85.57%, Valid: 85.42%, Test: 85.63%
Epoch: 350, Loss: 0.3639, Train: 85.54%, Valid: 85.40%, Test: 85.60%
Epoch: 375, Loss: 0.3637, Train: 85.54%, Valid: 85.40%, Test: 85.60%
Epoch: 400, Loss: 0.3636, Train: 85.55%, Valid: 85.41%, Test: 85.61%
Epoch: 425, Loss: 0.3634, Train: 85.56%, Valid: 85.41%, Test: 85.62%
Epoch: 450, Loss: 0.3633, Train: 85.56%, Valid: 85.42%, Test: 85.62%
Epoch: 475, Loss: 0.3632, Train: 85.56%, Valid: 85.42%, Test: 85.62%
Run 01:
Highest Train: 88.12
Highest Valid: 88.00
  Final Train: 88.12
   Final Test: 88.06
All runs:
Highest Train: 88.12, nan
Highest Valid: 88.00, nan
  Final Train: 88.12, nan
   Final Test: 88.06, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 26.9952, Train: 85.15%, Valid: 85.07%, Test: 85.29%
Epoch: 25, Loss: 119209.6172, Train: 83.82%, Valid: 83.64%, Test: 83.90%
Epoch: 50, Loss: 425109.0625, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 191703.4375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 3848.6277, Train: 84.83%, Valid: 84.81%, Test: 84.94%
Epoch: 125, Loss: 5156.2656, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 12938.5977, Train: 15.57%, Valid: 15.62%, Test: 15.41%
Epoch: 175, Loss: 1372.3652, Train: 15.65%, Valid: 15.76%, Test: 15.52%
Epoch: 200, Loss: 1056.4028, Train: 84.99%, Valid: 85.00%, Test: 85.13%
Epoch: 225, Loss: 300.4819, Train: 85.01%, Valid: 85.02%, Test: 85.15%
Epoch: 250, Loss: 75.2299, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 9954.6182, Train: 15.61%, Valid: 15.71%, Test: 15.47%
Epoch: 300, Loss: 24.7420, Train: 84.86%, Valid: 84.90%, Test: 85.00%
Epoch: 325, Loss: 5962.8389, Train: 15.51%, Valid: 15.63%, Test: 15.37%
Epoch: 350, Loss: 407.3131, Train: 15.49%, Valid: 15.55%, Test: 15.33%
Epoch: 375, Loss: 3300.0989, Train: 15.52%, Valid: 15.58%, Test: 15.36%
Epoch: 400, Loss: 143.3341, Train: 15.58%, Valid: 15.62%, Test: 15.41%
Epoch: 425, Loss: 0.5400, Train: 15.52%, Valid: 15.58%, Test: 15.36%
Epoch: 450, Loss: 32.6669, Train: 86.37%, Valid: 86.46%, Test: 86.45%
Epoch: 475, Loss: 924.3669, Train: 13.39%, Valid: 13.47%, Test: 13.30%
Run 01:
Highest Train: 86.74
Highest Valid: 86.79
  Final Train: 86.74
   Final Test: 86.81
All runs:
Highest Train: 86.74, nan
Highest Valid: 86.79, nan
  Final Train: 86.74, nan
   Final Test: 86.81, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.3799, Train: 86.66%, Valid: 86.57%, Test: 86.73%
Epoch: 25, Loss: 2564047.7500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 85887.1250, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 4518202.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 36981616.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 21245.0156, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 11403704.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 785314.5625, Train: 85.63%, Valid: 85.50%, Test: 85.73%
Epoch: 200, Loss: 685.2544, Train: 83.84%, Valid: 83.82%, Test: 83.91%
Epoch: 225, Loss: 13907.7256, Train: 16.35%, Valid: 16.40%, Test: 16.23%
Epoch: 250, Loss: 58074.6172, Train: 17.34%, Valid: 17.26%, Test: 17.29%
Epoch: 275, Loss: 56804.1016, Train: 83.82%, Valid: 83.75%, Test: 83.92%
Epoch: 300, Loss: 190470.3594, Train: 85.00%, Valid: 84.78%, Test: 85.16%
Epoch: 325, Loss: 1681.0381, Train: 84.09%, Valid: 83.89%, Test: 84.23%
Epoch: 350, Loss: 20749.0039, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 6138.6660, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 252421.7188, Train: 16.17%, Valid: 16.23%, Test: 16.07%
Epoch: 425, Loss: 19404.5840, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 5023.2632, Train: 83.55%, Valid: 83.50%, Test: 83.66%
Epoch: 475, Loss: 333335.3438, Train: 17.30%, Valid: 17.22%, Test: 17.26%
Run 01:
Highest Train: 86.66
Highest Valid: 86.57
  Final Train: 86.66
   Final Test: 86.73
All runs:
Highest Train: 86.66, nan
Highest Valid: 86.57, nan
  Final Train: 86.66, nan
   Final Test: 86.73, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.0128, Train: 15.68%, Valid: 15.57%, Test: 15.59%
Epoch: 25, Loss: 10970695.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 246668.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 311139.6875, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 426306272.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 11895.3828, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 751174.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 956909.4375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 261985.7344, Train: 83.72%, Valid: 83.73%, Test: 83.83%
Epoch: 225, Loss: 415753.9688, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 263985.6875, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 139719.2031, Train: 15.45%, Valid: 15.57%, Test: 15.30%
Epoch: 300, Loss: 45523.0430, Train: 83.80%, Valid: 83.82%, Test: 83.93%
Epoch: 325, Loss: 11992.5918, Train: 15.54%, Valid: 15.64%, Test: 15.41%
Epoch: 350, Loss: 9120.0518, Train: 15.56%, Valid: 15.68%, Test: 15.41%
Epoch: 375, Loss: 11153.5146, Train: 87.55%, Valid: 87.45%, Test: 87.48%
Epoch: 400, Loss: 147.9554, Train: 15.11%, Valid: 15.30%, Test: 14.97%
Epoch: 425, Loss: 257.7727, Train: 15.73%, Valid: 15.83%, Test: 15.58%
Epoch: 450, Loss: 203.5308, Train: 85.84%, Valid: 85.74%, Test: 85.85%
Epoch: 475, Loss: 183.6154, Train: 15.99%, Valid: 16.02%, Test: 15.85%
Run 01:
Highest Train: 87.56
Highest Valid: 87.45
  Final Train: 87.55
   Final Test: 87.48
All runs:
Highest Train: 87.56, nan
Highest Valid: 87.45, nan
  Final Train: 87.55, nan
   Final Test: 87.48, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.6290, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 76756918272.0000, Train: 49.98%, Valid: 49.98%, Test: 49.98%
Epoch: 50, Loss: 1773216000.0000, Train: 49.90%, Valid: 49.91%, Test: 49.90%
Epoch: 75, Loss: 502832192.0000, Train: 49.90%, Valid: 49.91%, Test: 49.90%
Epoch: 100, Loss: 759835008.0000, Train: 49.90%, Valid: 49.91%, Test: 49.90%
Epoch: 125, Loss: 983608832.0000, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 150, Loss: 13679013888.0000, Train: 49.90%, Valid: 49.91%, Test: 49.89%
Epoch: 175, Loss: 2314824192.0000, Train: 49.90%, Valid: 49.91%, Test: 49.89%
Epoch: 200, Loss: 28795802.0000, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 225, Loss: 1562567639040.0000, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 250, Loss: 338526880.0000, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 275, Loss: 19734964.0000, Train: 49.90%, Valid: 49.91%, Test: 49.89%
Epoch: 300, Loss: 271286656.0000, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 325, Loss: 218555376.0000, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 350, Loss: 13105.6514, Train: 49.90%, Valid: 49.91%, Test: 49.90%
Epoch: 375, Loss: 3418318.7500, Train: 84.03%, Valid: 83.94%, Test: 84.15%
Epoch: 400, Loss: 97345.8047, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 425, Loss: 5898919424.0000, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 450, Loss: 62514592.0000, Train: 50.10%, Valid: 50.09%, Test: 50.11%
Epoch: 475, Loss: 780068.0000, Train: 49.90%, Valid: 49.91%, Test: 49.90%
Run 01:
Highest Train: 87.23
Highest Valid: 87.32
  Final Train: 87.23
   Final Test: 87.24
All runs:
Highest Train: 87.23, nan
Highest Valid: 87.32, nan
  Final Train: 87.23, nan
   Final Test: 87.24, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5143, Train: 49.99%, Valid: 49.98%, Test: 49.99%
Epoch: 25, Loss: 1437674950113624064.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 67442936119296.0000, Train: 85.01%, Valid: 84.90%, Test: 85.14%
Epoch: 75, Loss: 47507481821328528870735872.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 219792070194533769446162432.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 5675054345163898041139200.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 694168756842315190089486958592.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 103557454623621983120050356224.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 437523839107915231264768.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 949070210785578655416320.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 298758188799036619751424.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 122372020059546460364996608.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 464207405691307032576.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 40400873522816736034816.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 8703958895602696192.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 914194441916460710525665280.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 665285572013224951283712.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 26721270719472147103744.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 27914479174545636851712.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 4128396016689981947904.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.39
Highest Valid: 86.35
  Final Train: 86.39
   Final Test: 86.41
All runs:
Highest Train: 86.39, nan
Highest Valid: 86.35, nan
  Final Train: 86.39, nan
   Final Test: 86.41, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.1887, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 25203599268160471040.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 15809438437764398372093952.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 224871189166169684245288465727488.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: -inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 126697720965723812156781101056.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 25847676965777963986888687616.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 5017996069430250743363796992.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 222337370388568287087689728.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 3227865183831099298767794339840.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 26021789767975400889381520670720.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 8004510358160188899764207616.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 2209530297571902709170217943040.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 195415114059672899873102888960.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 910046433257070085911085056.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 363614927847113130722382053376.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 570750993296200352973040123904.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 1115801195294297540121329664.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 276749829814615728803572350976.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 49924329551851807798930178048.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.00
Highest Valid: 50.00
  Final Train: 50.00
   Final Test: 50.00
All runs:
Highest Train: 50.00, nan
Highest Valid: 50.00, nan
  Final Train: 50.00, nan
   Final Test: 50.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.6919, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: -inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 828953732346460644573184.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 65296331991021266183127040.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 7809586477390317511245824.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 142308569085336197529600.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 46978054547922401889395671040.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 198441089180603459733291008.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 10598414181054069057565753344.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 226723954688.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 548872596813250560.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 135579948047664798498816.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 22371577105767410434048.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 61181366236089937858697143255040.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 954219240978795986944.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 4149984233074534233437502439424.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 194433519684373446656.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 576395782870795882959208448.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 1260479888490496.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 87.94
Highest Valid: 88.02
  Final Train: 87.94
   Final Test: 87.88
All runs:
Highest Train: 87.94, nan
Highest Valid: 88.02, nan
  Final Train: 87.94, nan
   Final Test: 87.88, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.9645, Train: 15.80%, Valid: 15.89%, Test: 15.69%
Epoch: 25, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 50.05
Highest Valid: 50.06
  Final Train: 50.05
   Final Test: 50.05
All runs:
Highest Train: 50.05, nan
Highest Valid: 50.06, nan
  Final Train: 50.05, nan
   Final Test: 50.05, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.1252, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: nan, Train: 83.82%, Valid: 83.76%, Test: 83.93%
Epoch: 50, Loss: 0.4654, Train: 50.22%, Valid: 50.21%, Test: 50.23%
Epoch: 75, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 102520725175438712688416391168.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 13989094793077238412145913233408.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 7015099135472067902042961608704.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 16836410019501278293661843456.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 314298082008460399565455260385280.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 4868460859010657530907983872.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 209519776513855959597056.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 85.90
Highest Valid: 85.71
  Final Train: 85.90
   Final Test: 85.92
All runs:
Highest Train: 85.90, nan
Highest Valid: 85.71, nan
  Final Train: 85.90, nan
   Final Test: 85.92, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4909, Train: 85.25%, Valid: 85.23%, Test: 85.38%
Epoch: 25, Loss: 75834.3516, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 8095.8462, Train: 84.81%, Valid: 84.80%, Test: 84.93%
Epoch: 75, Loss: 33323.7070, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 1844.5969, Train: 86.23%, Valid: 86.28%, Test: 86.31%
Epoch: 125, Loss: 823557.1250, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 365.6562, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 2550.1960, Train: 83.99%, Valid: 83.76%, Test: 84.09%
Epoch: 200, Loss: 100105.6328, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 56325.5703, Train: 83.99%, Valid: 83.76%, Test: 84.09%
Epoch: 250, Loss: 1469.0315, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 928.1226, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 46970.0820, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 31371.7715, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 35024.9453, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 626.1320, Train: 83.67%, Valid: 83.48%, Test: 83.79%
Epoch: 400, Loss: 76.6020, Train: 84.01%, Valid: 83.79%, Test: 84.12%
Epoch: 425, Loss: 96089.3281, Train: 83.81%, Valid: 83.59%, Test: 83.92%
Epoch: 450, Loss: 145.4939, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 103878.2344, Train: 83.93%, Valid: 83.71%, Test: 84.03%
Run 01:
Highest Train: 86.31
Highest Valid: 86.36
  Final Train: 86.31
   Final Test: 86.38
All runs:
Highest Train: 86.31, nan
Highest Valid: 86.36, nan
  Final Train: 86.31, nan
   Final Test: 86.38, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.0379, Train: 14.88%, Valid: 14.94%, Test: 14.82%
Epoch: 25, Loss: 3976.9961, Train: 85.03%, Valid: 84.99%, Test: 85.13%
Epoch: 50, Loss: 54554.6133, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 6434.8442, Train: 85.13%, Valid: 85.08%, Test: 85.24%
Epoch: 100, Loss: 12974.9648, Train: 85.21%, Valid: 85.15%, Test: 85.33%
Epoch: 125, Loss: 1613.9628, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 1087.5225, Train: 84.90%, Valid: 84.85%, Test: 84.99%
Epoch: 175, Loss: 2441.1680, Train: 84.95%, Valid: 84.90%, Test: 85.05%
Epoch: 200, Loss: 11.1269, Train: 86.69%, Valid: 86.71%, Test: 86.76%
Epoch: 225, Loss: 235.3038, Train: 15.91%, Valid: 16.11%, Test: 15.75%
Epoch: 250, Loss: 4.6504, Train: 86.16%, Valid: 86.13%, Test: 86.23%
Epoch: 275, Loss: 441.8539, Train: 86.39%, Valid: 86.40%, Test: 86.46%
Epoch: 300, Loss: 305.8887, Train: 86.78%, Valid: 86.79%, Test: 86.85%
Epoch: 325, Loss: 55.3666, Train: 86.75%, Valid: 86.76%, Test: 86.82%
Epoch: 350, Loss: 1.9409, Train: 86.50%, Valid: 86.51%, Test: 86.56%
Epoch: 375, Loss: 2.9464, Train: 86.34%, Valid: 86.35%, Test: 86.42%
Epoch: 400, Loss: 179.9052, Train: 86.86%, Valid: 86.88%, Test: 86.93%
Epoch: 425, Loss: 3.7087, Train: 86.24%, Valid: 86.22%, Test: 86.32%
Epoch: 450, Loss: 2.3066, Train: 86.67%, Valid: 86.69%, Test: 86.73%
Epoch: 475, Loss: 30.5099, Train: 86.65%, Valid: 86.68%, Test: 86.71%
Run 01:
Highest Train: 87.15
Highest Valid: 87.09
  Final Train: 87.15
   Final Test: 87.18
All runs:
Highest Train: 87.15, nan
Highest Valid: 87.09, nan
  Final Train: 87.15, nan
   Final Test: 87.18, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.1489, Train: 14.05%, Valid: 14.06%, Test: 13.92%
Epoch: 25, Loss: 17320192.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 174166.6562, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 1063368.3750, Train: 85.12%, Valid: 84.95%, Test: 85.19%
Epoch: 100, Loss: 35810.2930, Train: 85.09%, Valid: 84.92%, Test: 85.15%
Epoch: 125, Loss: 33608.5586, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 305366.7500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 550739.9375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 40842.8359, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 5965.2646, Train: 85.05%, Valid: 84.90%, Test: 85.05%
Epoch: 250, Loss: 53423.8594, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 18460.7773, Train: 85.04%, Valid: 84.88%, Test: 85.05%
Epoch: 300, Loss: 6949.5576, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 11102.9355, Train: 85.05%, Valid: 84.88%, Test: 85.14%
Epoch: 350, Loss: 8167.6680, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 2604.5264, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 65613.6016, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 46886.1484, Train: 16.44%, Valid: 16.47%, Test: 16.19%
Epoch: 450, Loss: 6329.8564, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 1582.8588, Train: 86.36%, Valid: 86.19%, Test: 86.30%
Run 01:
Highest Train: 86.36
Highest Valid: 86.20
  Final Train: 86.36
   Final Test: 86.31
All runs:
Highest Train: 86.36, nan
Highest Valid: 86.20, nan
  Final Train: 86.36, nan
   Final Test: 86.31, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.6607, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 2404808448.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 4914.4341, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 276922695680.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 3319720704.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 515733.6562, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 102379290624.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 3430796.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 247450560.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 52826570752.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 10963444736.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 128496418816.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 4562130829312.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 326465536.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 27824692.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 5531977728.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 122134.0078, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 21517.9688, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 4262819.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 80771.0078, Train: 16.31%, Valid: 16.54%, Test: 16.15%
Run 01:
Highest Train: 85.87
Highest Valid: 85.63
  Final Train: 85.87
   Final Test: 85.97
All runs:
Highest Train: 85.87, nan
Highest Valid: 85.63, nan
  Final Train: 85.87, nan
   Final Test: 85.97, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.6442, Train: 84.01%, Valid: 84.01%, Test: 84.12%
Epoch: 25, Loss: 33464019549174607380480.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 6021818230852525490176.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 5854070386139856896.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 798734191146972733241110298624.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: -inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 74473109095083952036222244749312.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 705149757076309072640534913220608.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 96475500983630861513674262052864.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 59793824044478886452686479163392.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 40075666060022508820483239051264.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 431591856218842033572540334473216.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 1503497671640935629760428507136.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 7108282533185053711514726301696.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 646761939751947121632558972928.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.88
Highest Valid: 86.79
  Final Train: 86.88
   Final Test: 86.98
All runs:
Highest Train: 86.88, nan
Highest Valid: 86.79, nan
  Final Train: 86.88, nan
   Final Test: 86.98, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 6.8700, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 7856567315595264.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 6.5226, Train: 85.34%, Valid: 85.12%, Test: 85.38%
Epoch: 75, Loss: 5.9061, Train: 85.35%, Valid: 85.13%, Test: 85.40%
Epoch: 100, Loss: 6.0435, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 125, Loss: 6.0438, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 150, Loss: 6.0780, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 175, Loss: 6.0822, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 200, Loss: 6.0399, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 225, Loss: 6.0965, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 250, Loss: 6.0501, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 275, Loss: 6.0616, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 300, Loss: 6.0855, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 325, Loss: 6.0417, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 350, Loss: 6.0408, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 375, Loss: 6.0463, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 400, Loss: 6.0443, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 425, Loss: 6.0405, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 450, Loss: 6.0169, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Epoch: 475, Loss: 6.0354, Train: 85.36%, Valid: 85.14%, Test: 85.40%
Run 01:
Highest Train: 85.42
Highest Valid: 85.25
  Final Train: 85.42
   Final Test: 85.45
All runs:
Highest Train: 85.42, nan
Highest Valid: 85.25, nan
  Final Train: 85.42, nan
   Final Test: 85.45, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.5288, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 340699807744.0000, Train: 87.08%, Valid: 87.17%, Test: 87.09%
Epoch: 50, Loss: 61605.0469, Train: 86.93%, Valid: 87.04%, Test: 86.94%
Epoch: 75, Loss: 2.2567, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 2.1701, Train: 87.63%, Valid: 87.69%, Test: 87.61%
Epoch: 125, Loss: 2.1953, Train: 87.01%, Valid: 87.11%, Test: 86.99%
Epoch: 150, Loss: 2951001.5000, Train: 86.96%, Valid: 87.06%, Test: 86.96%
Epoch: 175, Loss: 465.0946, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 1413.5873, Train: 16.18%, Valid: 16.33%, Test: 16.08%
Epoch: 225, Loss: 2.2172, Train: 86.93%, Valid: 87.05%, Test: 86.96%
Epoch: 250, Loss: 2.0947, Train: 86.98%, Valid: 87.11%, Test: 87.00%
Epoch: 275, Loss: 1.5912, Train: 86.93%, Valid: 87.04%, Test: 86.93%
Epoch: 300, Loss: 1.2203, Train: 86.99%, Valid: 87.11%, Test: 87.00%
Epoch: 325, Loss: 2.2044, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 19127.0488, Train: 86.91%, Valid: 87.03%, Test: 86.91%
Epoch: 375, Loss: 1.6891, Train: 83.70%, Valid: 83.52%, Test: 83.81%
Epoch: 400, Loss: 2.1982, Train: 87.00%, Valid: 87.09%, Test: 87.00%
Epoch: 425, Loss: 1695028.5000, Train: 86.99%, Valid: 87.08%, Test: 86.98%
Epoch: 450, Loss: 2.2664, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 11996.4170, Train: 16.28%, Valid: 16.47%, Test: 16.18%
Run 01:
Highest Train: 87.98
Highest Valid: 88.04
  Final Train: 87.98
   Final Test: 87.99
All runs:
Highest Train: 87.98, nan
Highest Valid: 88.04, nan
  Final Train: 87.98, nan
   Final Test: 87.99, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 4.4978, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 86.56
Highest Valid: 86.51
  Final Train: 86.56
   Final Test: 86.71
All runs:
Highest Train: 86.56, nan
Highest Valid: 86.51, nan
  Final Train: 86.56, nan
   Final Test: 86.71, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4812, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 85.93
Highest Valid: 85.93
  Final Train: 85.93
   Final Test: 86.04
All runs:
Highest Train: 85.93, nan
Highest Valid: 85.93, nan
  Final Train: 85.93, nan
   Final Test: 86.04, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 10.6754, Train: 86.13%, Valid: 86.17%, Test: 86.22%
Epoch: 25, Loss: 5.4790, Train: 16.13%, Valid: 16.31%, Test: 15.99%
Epoch: 50, Loss: 259.5841, Train: 15.54%, Valid: 15.64%, Test: 15.41%
Epoch: 75, Loss: 80.3394, Train: 16.42%, Valid: 16.58%, Test: 16.33%
Epoch: 100, Loss: 480.0414, Train: 88.29%, Valid: 88.33%, Test: 88.32%
Epoch: 125, Loss: 3092.9910, Train: 88.28%, Valid: 88.32%, Test: 88.32%
Epoch: 150, Loss: 417.7805, Train: 16.34%, Valid: 16.51%, Test: 16.23%
Epoch: 175, Loss: 15.2921, Train: 88.28%, Valid: 88.32%, Test: 88.32%
Epoch: 200, Loss: 19.7317, Train: 84.95%, Valid: 84.94%, Test: 85.10%
Epoch: 225, Loss: 30.5426, Train: 88.22%, Valid: 88.27%, Test: 88.26%
Epoch: 250, Loss: 975.6119, Train: 88.22%, Valid: 88.28%, Test: 88.27%
Epoch: 275, Loss: 5.3961, Train: 88.27%, Valid: 88.30%, Test: 88.28%
Epoch: 300, Loss: 20.9513, Train: 88.26%, Valid: 88.29%, Test: 88.27%
Epoch: 325, Loss: 24.9251, Train: 88.26%, Valid: 88.29%, Test: 88.27%
Epoch: 350, Loss: 32.7379, Train: 88.25%, Valid: 88.29%, Test: 88.26%
Epoch: 375, Loss: 12.8508, Train: 88.26%, Valid: 88.30%, Test: 88.26%
Epoch: 400, Loss: 11.9180, Train: 88.26%, Valid: 88.30%, Test: 88.26%
Epoch: 425, Loss: 11.5932, Train: 88.26%, Valid: 88.30%, Test: 88.26%
Epoch: 450, Loss: 11.5205, Train: 88.26%, Valid: 88.30%, Test: 88.26%
Epoch: 475, Loss: 11.6863, Train: 88.26%, Valid: 88.30%, Test: 88.26%
Run 01:
Highest Train: 88.29
Highest Valid: 88.34
  Final Train: 88.29
   Final Test: 88.33
All runs:
Highest Train: 88.29, nan
Highest Valid: 88.34, nan
  Final Train: 88.29, nan
   Final Test: 88.33, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 6.9200, Train: 86.96%, Valid: 86.90%, Test: 86.93%
Epoch: 25, Loss: 19.8421, Train: 85.99%, Valid: 85.93%, Test: 86.03%
Epoch: 50, Loss: 9.0708, Train: 84.51%, Valid: 84.40%, Test: 84.52%
Epoch: 75, Loss: 22402.3945, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 22869.5293, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 10.9141, Train: 86.94%, Valid: 86.95%, Test: 86.97%
Epoch: 150, Loss: 11.7840, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 175, Loss: 11.8554, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 200, Loss: 11.8674, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 225, Loss: 11.8727, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 250, Loss: 11.8638, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 275, Loss: 11.8729, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 300, Loss: 11.8795, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 325, Loss: 11.8552, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 350, Loss: 11.8699, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 375, Loss: 11.8620, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 400, Loss: 11.8763, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 425, Loss: 11.8711, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 450, Loss: 11.8752, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Epoch: 475, Loss: 11.8675, Train: 86.94%, Valid: 86.96%, Test: 86.97%
Run 01:
Highest Train: 86.96
Highest Valid: 86.96
  Final Train: 86.94
   Final Test: 86.97
All runs:
Highest Train: 86.96, nan
Highest Valid: 86.96, nan
  Final Train: 86.94, nan
   Final Test: 86.97, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 16.1756, Train: 86.85%, Valid: 86.85%, Test: 86.89%
Epoch: 25, Loss: 3832.8313, Train: 85.24%, Valid: 85.16%, Test: 85.31%
Epoch: 50, Loss: 20401.4141, Train: 15.18%, Valid: 15.39%, Test: 15.07%
Epoch: 75, Loss: 3.3704, Train: 86.85%, Valid: 86.92%, Test: 86.95%
Epoch: 100, Loss: 1120.7279, Train: 15.11%, Valid: 15.33%, Test: 15.01%
Epoch: 125, Loss: 25.0834, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 250.9604, Train: 86.62%, Valid: 86.65%, Test: 86.75%
Epoch: 175, Loss: 8.0470, Train: 86.80%, Valid: 86.81%, Test: 86.90%
Epoch: 200, Loss: 7.9287, Train: 85.96%, Valid: 85.98%, Test: 86.11%
Epoch: 225, Loss: 8.0469, Train: 86.74%, Valid: 86.75%, Test: 86.83%
Epoch: 250, Loss: 8.1110, Train: 85.52%, Valid: 85.58%, Test: 85.70%
Epoch: 275, Loss: 8.1271, Train: 86.18%, Valid: 86.19%, Test: 86.34%
Epoch: 300, Loss: 8.1569, Train: 86.48%, Valid: 86.46%, Test: 86.60%
Epoch: 325, Loss: 8.1398, Train: 86.11%, Valid: 86.11%, Test: 86.27%
Epoch: 350, Loss: 8.1494, Train: 85.50%, Valid: 85.54%, Test: 85.67%
Epoch: 375, Loss: 8.1347, Train: 85.55%, Valid: 85.61%, Test: 85.73%
Epoch: 400, Loss: 8.1161, Train: 85.58%, Valid: 85.64%, Test: 85.74%
Epoch: 425, Loss: 8.1088, Train: 85.58%, Valid: 85.62%, Test: 85.71%
Epoch: 450, Loss: 8.1306, Train: 86.71%, Valid: 86.72%, Test: 86.80%
Epoch: 475, Loss: 8.1281, Train: 85.53%, Valid: 85.57%, Test: 85.65%
Run 01:
Highest Train: 87.02
Highest Valid: 87.06
  Final Train: 87.01
   Final Test: 87.10
All runs:
Highest Train: 87.02, nan
Highest Valid: 87.06, nan
  Final Train: 87.01, nan
   Final Test: 87.10, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.3729, Train: 15.44%, Valid: 15.36%, Test: 15.32%
Epoch: 25, Loss: 123730.3281, Train: 15.65%, Valid: 15.66%, Test: 15.57%
Epoch: 50, Loss: 20197.7539, Train: 83.99%, Valid: 83.79%, Test: 84.10%
Epoch: 75, Loss: 888792704.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 673.0163, Train: 84.14%, Valid: 83.95%, Test: 84.22%
Epoch: 125, Loss: 6716.3599, Train: 84.15%, Valid: 83.96%, Test: 84.23%
Epoch: 150, Loss: 174838.6406, Train: 84.15%, Valid: 83.97%, Test: 84.23%
Epoch: 175, Loss: 9764.3271, Train: 84.21%, Valid: 84.00%, Test: 84.33%
Epoch: 200, Loss: 433.7498, Train: 84.15%, Valid: 83.96%, Test: 84.23%
Epoch: 225, Loss: 499.4829, Train: 84.23%, Valid: 84.04%, Test: 84.32%
Epoch: 250, Loss: 629.6683, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 10627.4697, Train: 83.73%, Valid: 83.56%, Test: 83.79%
Epoch: 300, Loss: 69725.8750, Train: 84.08%, Valid: 83.89%, Test: 84.19%
Epoch: 325, Loss: 676.3413, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 542.7072, Train: 15.29%, Valid: 15.12%, Test: 15.19%
Epoch: 375, Loss: 65144.3281, Train: 16.82%, Valid: 16.73%, Test: 16.73%
Epoch: 400, Loss: 203030.7656, Train: 84.03%, Valid: 83.85%, Test: 84.15%
Epoch: 425, Loss: 3696.5706, Train: 84.08%, Valid: 83.90%, Test: 84.20%
Epoch: 450, Loss: 7493.9844, Train: 15.31%, Valid: 15.31%, Test: 15.18%
Epoch: 475, Loss: 56774.1484, Train: 15.79%, Valid: 15.85%, Test: 15.71%
Run 01:
Highest Train: 87.73
Highest Valid: 87.77
  Final Train: 87.73
   Final Test: 87.72
All runs:
Highest Train: 87.73, nan
Highest Valid: 87.77, nan
  Final Train: 87.73, nan
   Final Test: 87.72, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 9.7073, Train: 87.06%, Valid: 87.08%, Test: 87.11%
Epoch: 25, Loss: 1525444.6250, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 790.9208, Train: 85.55%, Valid: 85.37%, Test: 85.62%
Epoch: 75, Loss: 518.3605, Train: 84.44%, Valid: 84.26%, Test: 84.57%
Epoch: 100, Loss: 1417.2585, Train: 15.82%, Valid: 15.82%, Test: 15.71%
Epoch: 125, Loss: 0.5256, Train: 15.84%, Valid: 15.84%, Test: 15.72%
Epoch: 150, Loss: 501.7843, Train: 15.84%, Valid: 15.83%, Test: 15.72%
Epoch: 175, Loss: 671.0323, Train: 15.84%, Valid: 15.84%, Test: 15.72%
Epoch: 200, Loss: 543.3529, Train: 15.87%, Valid: 15.87%, Test: 15.75%
Epoch: 225, Loss: 567.3809, Train: 15.84%, Valid: 15.84%, Test: 15.72%
Epoch: 250, Loss: 530.3614, Train: 15.84%, Valid: 15.84%, Test: 15.72%
Epoch: 275, Loss: 493.3388, Train: 15.87%, Valid: 15.87%, Test: 15.75%
Epoch: 300, Loss: 36.2398, Train: 15.84%, Valid: 15.84%, Test: 15.72%
Epoch: 325, Loss: 892.3042, Train: 15.83%, Valid: 15.83%, Test: 15.71%
Epoch: 350, Loss: 132.6733, Train: 15.85%, Valid: 15.84%, Test: 15.73%
Epoch: 375, Loss: 587.1001, Train: 15.84%, Valid: 15.84%, Test: 15.73%
Epoch: 400, Loss: 5.0280, Train: 15.85%, Valid: 15.85%, Test: 15.73%
Epoch: 425, Loss: 570.3522, Train: 15.85%, Valid: 15.85%, Test: 15.73%
Epoch: 450, Loss: 524.9470, Train: 15.81%, Valid: 15.82%, Test: 15.69%
Epoch: 475, Loss: 693.2094, Train: 15.87%, Valid: 15.87%, Test: 15.75%
Run 01:
Highest Train: 87.06
Highest Valid: 87.08
  Final Train: 87.06
   Final Test: 87.11
All runs:
Highest Train: 87.06, nan
Highest Valid: 87.08, nan
  Final Train: 87.06, nan
   Final Test: 87.11, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 4.4523, Train: 85.40%, Valid: 85.21%, Test: 85.45%
Epoch: 25, Loss: 113.4856, Train: 86.00%, Valid: 85.96%, Test: 86.14%
Epoch: 50, Loss: 145.6018, Train: 85.46%, Valid: 85.27%, Test: 85.57%
Epoch: 75, Loss: 92.4163, Train: 85.45%, Valid: 85.27%, Test: 85.56%
Epoch: 100, Loss: 178.9658, Train: 85.45%, Valid: 85.26%, Test: 85.56%
Epoch: 125, Loss: 127.8263, Train: 85.45%, Valid: 85.25%, Test: 85.56%
Epoch: 150, Loss: 105.5976, Train: 85.47%, Valid: 85.27%, Test: 85.58%
Epoch: 175, Loss: 136.3272, Train: 85.45%, Valid: 85.25%, Test: 85.56%
Epoch: 200, Loss: 122.5562, Train: 85.44%, Valid: 85.25%, Test: 85.56%
Epoch: 225, Loss: 114.3795, Train: 85.46%, Valid: 85.26%, Test: 85.58%
Epoch: 250, Loss: 133.5923, Train: 85.45%, Valid: 85.25%, Test: 85.56%
Epoch: 275, Loss: 175.9654, Train: 85.46%, Valid: 85.27%, Test: 85.58%
Epoch: 300, Loss: 128.3809, Train: 85.46%, Valid: 85.26%, Test: 85.58%
Epoch: 325, Loss: 126.5346, Train: 85.46%, Valid: 85.25%, Test: 85.56%
Epoch: 350, Loss: 123.1405, Train: 85.45%, Valid: 85.25%, Test: 85.56%
Epoch: 375, Loss: 119.7204, Train: 85.45%, Valid: 85.24%, Test: 85.56%
Epoch: 400, Loss: 129.2057, Train: 85.44%, Valid: 85.22%, Test: 85.54%
Epoch: 425, Loss: 176.2825, Train: 85.45%, Valid: 85.25%, Test: 85.57%
Epoch: 450, Loss: 120.0299, Train: 85.46%, Valid: 85.26%, Test: 85.57%
Epoch: 475, Loss: 122.1557, Train: 85.46%, Valid: 85.26%, Test: 85.58%
Run 01:
Highest Train: 86.83
Highest Valid: 86.88
  Final Train: 86.83
   Final Test: 86.94
All runs:
Highest Train: 86.83, nan
Highest Valid: 86.88, nan
  Final Train: 86.83, nan
   Final Test: 86.94, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 12.6800, Train: 86.00%, Valid: 86.04%, Test: 86.00%
Epoch: 25, Loss: 125.2592, Train: 15.41%, Valid: 15.30%, Test: 15.32%
Epoch: 50, Loss: 98.7244, Train: 14.12%, Valid: 14.02%, Test: 14.10%
Epoch: 75, Loss: 67.6941, Train: 37.80%, Valid: 37.67%, Test: 37.53%
Epoch: 100, Loss: 26.0918, Train: 84.07%, Valid: 83.87%, Test: 84.16%
Epoch: 125, Loss: 1.8923, Train: 84.05%, Valid: 83.91%, Test: 84.20%
Epoch: 150, Loss: 8.6967, Train: 84.23%, Valid: 84.03%, Test: 84.39%
Epoch: 175, Loss: 2.5635, Train: 84.21%, Valid: 84.02%, Test: 84.37%
Epoch: 200, Loss: 2.5661, Train: 84.25%, Valid: 84.05%, Test: 84.40%
Epoch: 225, Loss: 2.5629, Train: 84.24%, Valid: 84.05%, Test: 84.39%
Epoch: 250, Loss: 2.5584, Train: 84.23%, Valid: 84.03%, Test: 84.38%
Epoch: 275, Loss: 2.5537, Train: 84.24%, Valid: 84.05%, Test: 84.41%
Epoch: 300, Loss: 2.5487, Train: 84.19%, Valid: 83.96%, Test: 84.35%
Epoch: 325, Loss: 2.5437, Train: 84.22%, Valid: 84.02%, Test: 84.37%
Epoch: 350, Loss: 2.5382, Train: 84.20%, Valid: 84.01%, Test: 84.35%
Epoch: 375, Loss: 2.5327, Train: 84.24%, Valid: 84.04%, Test: 84.40%
Epoch: 400, Loss: 2.5268, Train: 84.21%, Valid: 84.00%, Test: 84.36%
Epoch: 425, Loss: 2.5210, Train: 84.23%, Valid: 84.02%, Test: 84.39%
Epoch: 450, Loss: 2.5150, Train: 84.23%, Valid: 84.00%, Test: 84.37%
Epoch: 475, Loss: 2.5087, Train: 84.19%, Valid: 84.00%, Test: 84.35%
Run 01:
Highest Train: 86.07
Highest Valid: 86.04
  Final Train: 86.00
   Final Test: 86.00
All runs:
Highest Train: 86.07, nan
Highest Valid: 86.04, nan
  Final Train: 86.00, nan
   Final Test: 86.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.9048, Train: 86.33%, Valid: 86.28%, Test: 86.36%
Epoch: 25, Loss: 142387312.0000, Train: 16.04%, Valid: 16.20%, Test: 15.85%
Epoch: 50, Loss: 368.6190, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 75, Loss: 343.6557, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 100, Loss: 386.7552, Train: 15.93%, Valid: 16.10%, Test: 15.76%
Epoch: 125, Loss: 355.3193, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 150, Loss: 355.3816, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 175, Loss: 368.8330, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 200, Loss: 351.2664, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 225, Loss: 24.8706, Train: 16.01%, Valid: 16.19%, Test: 15.84%
Epoch: 250, Loss: 355.7178, Train: 16.00%, Valid: 16.18%, Test: 15.84%
Epoch: 275, Loss: 355.7733, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 300, Loss: 413.4509, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 325, Loss: 357.4818, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 350, Loss: 338.9495, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 375, Loss: 357.0440, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 400, Loss: 358.4433, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 425, Loss: 353.4843, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Epoch: 450, Loss: 349.8352, Train: 15.99%, Valid: 16.17%, Test: 15.82%
Epoch: 475, Loss: 255.4456, Train: 16.00%, Valid: 16.18%, Test: 15.83%
Run 01:
Highest Train: 87.15
Highest Valid: 87.09
  Final Train: 87.14
   Final Test: 87.16
All runs:
Highest Train: 87.15, nan
Highest Valid: 87.09, nan
  Final Train: 87.14, nan
   Final Test: 87.16, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.005, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.2050, Train: 86.14%, Valid: 86.13%, Test: 86.28%
Epoch: 25, Loss: 3.6114, Train: 86.37%, Valid: 86.45%, Test: 86.44%
Epoch: 50, Loss: 27.9799, Train: 86.20%, Valid: 86.33%, Test: 86.25%
Epoch: 75, Loss: 35.1670, Train: 86.02%, Valid: 86.19%, Test: 86.07%
Epoch: 100, Loss: 35.9893, Train: 86.02%, Valid: 86.19%, Test: 86.07%
Epoch: 125, Loss: 38.1632, Train: 86.03%, Valid: 86.19%, Test: 86.08%
Epoch: 150, Loss: 46.3061, Train: 86.04%, Valid: 86.19%, Test: 86.09%
Epoch: 175, Loss: 48.9166, Train: 86.04%, Valid: 86.19%, Test: 86.09%
Epoch: 200, Loss: 54.4036, Train: 86.04%, Valid: 86.19%, Test: 86.09%
Epoch: 225, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 14.1649, Train: 50.06%, Valid: 50.05%, Test: 50.06%
Epoch: 275, Loss: 16.2032, Train: 84.58%, Valid: 84.42%, Test: 84.67%
Epoch: 300, Loss: 144692928.0000, Train: 85.15%, Valid: 85.07%, Test: 85.25%
Epoch: 325, Loss: 28.7146, Train: 84.53%, Valid: 84.38%, Test: 84.62%
Epoch: 350, Loss: 22.8268, Train: 85.22%, Valid: 85.10%, Test: 85.31%
Epoch: 375, Loss: 17.3997, Train: 49.79%, Valid: 49.81%, Test: 49.78%
Epoch: 400, Loss: 14.7745, Train: 49.90%, Valid: 49.91%, Test: 49.90%
Epoch: 425, Loss: 18.0965, Train: 84.59%, Valid: 84.44%, Test: 84.68%
Epoch: 450, Loss: 511179.0625, Train: 49.79%, Valid: 49.81%, Test: 49.79%
Epoch: 475, Loss: 11.3755, Train: 84.43%, Valid: 84.31%, Test: 84.53%
Run 01:
Highest Train: 87.11
Highest Valid: 87.18
  Final Train: 87.11
   Final Test: 87.17
All runs:
Highest Train: 87.11, nan
Highest Valid: 87.18, nan
  Final Train: 87.11, nan
   Final Test: 87.17, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4763, Train: 85.59%, Valid: 85.62%, Test: 85.69%
Epoch: 25, Loss: 0.5087, Train: 86.50%, Valid: 86.47%, Test: 86.58%
Epoch: 50, Loss: 0.3767, Train: 86.81%, Valid: 86.69%, Test: 86.83%
Epoch: 75, Loss: 0.8938, Train: 87.55%, Valid: 87.62%, Test: 87.57%
Epoch: 100, Loss: 0.4873, Train: 86.37%, Valid: 86.44%, Test: 86.39%
Epoch: 125, Loss: 0.4978, Train: 86.19%, Valid: 86.22%, Test: 86.22%
Epoch: 150, Loss: 0.4909, Train: 86.06%, Valid: 86.14%, Test: 86.15%
Epoch: 175, Loss: 0.4469, Train: 86.19%, Valid: 86.24%, Test: 86.25%
Epoch: 200, Loss: 18.4287, Train: 86.28%, Valid: 86.35%, Test: 86.37%
Epoch: 225, Loss: 0.5178, Train: 86.25%, Valid: 86.29%, Test: 86.30%
Epoch: 250, Loss: 4.6391, Train: 14.91%, Valid: 15.05%, Test: 14.82%
Epoch: 275, Loss: 35.6327, Train: 15.72%, Valid: 15.84%, Test: 15.66%
Epoch: 300, Loss: 1.4783, Train: 86.33%, Valid: 86.36%, Test: 86.38%
Epoch: 325, Loss: 1.2866, Train: 86.33%, Valid: 86.36%, Test: 86.38%
Epoch: 350, Loss: 1.2728, Train: 86.27%, Valid: 86.30%, Test: 86.31%
Epoch: 375, Loss: 1.2107, Train: 86.33%, Valid: 86.36%, Test: 86.38%
Epoch: 400, Loss: 1.1921, Train: 86.33%, Valid: 86.36%, Test: 86.38%
Epoch: 425, Loss: 1.2351, Train: 86.27%, Valid: 86.30%, Test: 86.31%
Epoch: 450, Loss: 1.2158, Train: 86.33%, Valid: 86.36%, Test: 86.38%
Epoch: 475, Loss: 1.2932, Train: 86.33%, Valid: 86.36%, Test: 86.38%
Run 01:
Highest Train: 87.77
Highest Valid: 87.85
  Final Train: 87.76
   Final Test: 87.76
All runs:
Highest Train: 87.77, nan
Highest Valid: 87.85, nan
  Final Train: 87.76, nan
   Final Test: 87.76, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.6530, Train: 85.38%, Valid: 85.32%, Test: 85.47%
Epoch: 25, Loss: 0.4488, Train: 85.58%, Valid: 85.45%, Test: 85.68%
Epoch: 50, Loss: 0.4293, Train: 85.66%, Valid: 85.51%, Test: 85.74%
Epoch: 75, Loss: 0.4045, Train: 85.79%, Valid: 85.66%, Test: 85.86%
Epoch: 100, Loss: 0.5831, Train: 86.10%, Valid: 85.99%, Test: 86.15%
Epoch: 125, Loss: 1.0808, Train: 86.11%, Valid: 86.00%, Test: 86.17%
Epoch: 150, Loss: 0.7062, Train: 86.03%, Valid: 85.93%, Test: 86.12%
Epoch: 175, Loss: 0.5024, Train: 85.97%, Valid: 85.85%, Test: 86.05%
Epoch: 200, Loss: 0.4914, Train: 86.02%, Valid: 85.90%, Test: 86.10%
Epoch: 225, Loss: 0.4807, Train: 86.03%, Valid: 85.90%, Test: 86.10%
Epoch: 250, Loss: 0.4583, Train: 86.02%, Valid: 85.90%, Test: 86.10%
Epoch: 275, Loss: 0.4570, Train: 86.02%, Valid: 85.90%, Test: 86.10%
Epoch: 300, Loss: 0.4387, Train: 86.00%, Valid: 85.86%, Test: 86.09%
Epoch: 325, Loss: 0.4699, Train: 86.08%, Valid: 85.95%, Test: 86.15%
Epoch: 350, Loss: 0.4669, Train: 86.02%, Valid: 85.89%, Test: 86.10%
Epoch: 375, Loss: 0.4616, Train: 86.01%, Valid: 85.87%, Test: 86.09%
Epoch: 400, Loss: 0.4578, Train: 86.00%, Valid: 85.87%, Test: 86.10%
Epoch: 425, Loss: 0.4459, Train: 85.95%, Valid: 85.80%, Test: 86.04%
Epoch: 450, Loss: 0.4358, Train: 85.90%, Valid: 85.77%, Test: 86.00%
Epoch: 475, Loss: 0.4384, Train: 85.90%, Valid: 85.76%, Test: 86.00%
Run 01:
Highest Train: 86.29
Highest Valid: 86.23
  Final Train: 86.29
   Final Test: 86.40
All runs:
Highest Train: 86.29, nan
Highest Valid: 86.23, nan
  Final Train: 86.29, nan
   Final Test: 86.40, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.6172, Train: 12.96%, Valid: 13.00%, Test: 12.95%
Epoch: 25, Loss: 0.4012, Train: 85.78%, Valid: 85.65%, Test: 85.76%
Epoch: 50, Loss: 0.4690, Train: 85.68%, Valid: 85.51%, Test: 85.69%
Epoch: 75, Loss: 0.4070, Train: 85.70%, Valid: 85.53%, Test: 85.69%
Epoch: 100, Loss: 0.4196, Train: 85.75%, Valid: 85.59%, Test: 85.75%
Epoch: 125, Loss: 0.4404, Train: 86.07%, Valid: 85.91%, Test: 86.06%
Epoch: 150, Loss: 0.4330, Train: 86.09%, Valid: 85.93%, Test: 86.08%
Epoch: 175, Loss: 0.4342, Train: 86.13%, Valid: 85.98%, Test: 86.12%
Epoch: 200, Loss: 0.4956, Train: 86.33%, Valid: 86.20%, Test: 86.32%
Epoch: 225, Loss: 0.4605, Train: 86.26%, Valid: 86.13%, Test: 86.26%
Epoch: 250, Loss: 0.8613, Train: 86.32%, Valid: 86.18%, Test: 86.32%
Epoch: 275, Loss: 0.5678, Train: 86.31%, Valid: 86.18%, Test: 86.31%
Epoch: 300, Loss: 0.4956, Train: 86.27%, Valid: 86.13%, Test: 86.26%
Epoch: 325, Loss: 0.5036, Train: 86.30%, Valid: 86.18%, Test: 86.29%
Epoch: 350, Loss: 0.4675, Train: 86.27%, Valid: 86.14%, Test: 86.25%
Epoch: 375, Loss: 0.4842, Train: 86.28%, Valid: 86.16%, Test: 86.27%
Epoch: 400, Loss: 0.4842, Train: 86.27%, Valid: 86.15%, Test: 86.26%
Epoch: 425, Loss: 0.4505, Train: 86.10%, Valid: 85.94%, Test: 86.10%
Epoch: 450, Loss: 0.4280, Train: 85.97%, Valid: 85.82%, Test: 85.97%
Epoch: 475, Loss: 0.4376, Train: 86.07%, Valid: 85.91%, Test: 86.07%
Run 01:
Highest Train: 86.62
Highest Valid: 86.64
  Final Train: 86.62
   Final Test: 86.78
All runs:
Highest Train: 86.62, nan
Highest Valid: 86.64, nan
  Final Train: 86.62, nan
   Final Test: 86.78, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.7092, Train: 16.63%, Valid: 16.61%, Test: 16.51%
Epoch: 25, Loss: 0.6524, Train: 86.91%, Valid: 86.95%, Test: 86.97%
Epoch: 50, Loss: 0.4715, Train: 85.77%, Valid: 85.65%, Test: 85.84%
Epoch: 75, Loss: 0.5070, Train: 86.49%, Valid: 86.55%, Test: 86.58%
Epoch: 100, Loss: 0.4648, Train: 86.42%, Valid: 86.46%, Test: 86.51%
Epoch: 125, Loss: 0.4668, Train: 86.45%, Valid: 86.46%, Test: 86.52%
Epoch: 150, Loss: 0.4753, Train: 86.56%, Valid: 86.56%, Test: 86.62%
Epoch: 175, Loss: 0.4594, Train: 86.55%, Valid: 86.57%, Test: 86.61%
Epoch: 200, Loss: 0.4459, Train: 86.55%, Valid: 86.57%, Test: 86.62%
Epoch: 225, Loss: 0.4015, Train: 86.57%, Valid: 86.58%, Test: 86.63%
Epoch: 250, Loss: 0.8489, Train: 86.67%, Valid: 86.67%, Test: 86.71%
Epoch: 275, Loss: 0.8295, Train: 86.69%, Valid: 86.68%, Test: 86.73%
Epoch: 300, Loss: 0.5062, Train: 86.68%, Valid: 86.67%, Test: 86.73%
Epoch: 325, Loss: 0.4784, Train: 86.69%, Valid: 86.67%, Test: 86.73%
Epoch: 350, Loss: 0.4620, Train: 86.77%, Valid: 86.75%, Test: 86.81%
Epoch: 375, Loss: 0.4521, Train: 86.77%, Valid: 86.75%, Test: 86.80%
Epoch: 400, Loss: 0.4527, Train: 86.77%, Valid: 86.76%, Test: 86.81%
Epoch: 425, Loss: 0.4517, Train: 86.78%, Valid: 86.76%, Test: 86.81%
Epoch: 450, Loss: 0.4507, Train: 86.77%, Valid: 86.75%, Test: 86.81%
Epoch: 475, Loss: 0.4468, Train: 86.77%, Valid: 86.76%, Test: 86.81%
Run 01:
Highest Train: 86.94
Highest Valid: 86.98
  Final Train: 86.94
   Final Test: 87.00
All runs:
Highest Train: 86.94, nan
Highest Valid: 86.98, nan
  Final Train: 86.94, nan
   Final Test: 87.00, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.7258, Train: 86.53%, Valid: 86.46%, Test: 86.52%
Epoch: 25, Loss: 1.1538, Train: 87.00%, Valid: 86.95%, Test: 86.98%
Epoch: 50, Loss: 0.9522, Train: 86.75%, Valid: 86.68%, Test: 86.76%
Epoch: 75, Loss: 0.5462, Train: 86.96%, Valid: 86.89%, Test: 86.96%
Epoch: 100, Loss: 0.4935, Train: 86.97%, Valid: 86.90%, Test: 86.97%
Epoch: 125, Loss: 0.4897, Train: 87.02%, Valid: 86.95%, Test: 87.02%
Epoch: 150, Loss: 0.4948, Train: 87.12%, Valid: 87.02%, Test: 87.14%
Epoch: 175, Loss: 0.4882, Train: 87.16%, Valid: 87.07%, Test: 87.19%
Epoch: 200, Loss: 0.4944, Train: 87.34%, Valid: 87.29%, Test: 87.33%
Epoch: 225, Loss: 0.4846, Train: 87.58%, Valid: 87.51%, Test: 87.60%
Epoch: 250, Loss: 0.4955, Train: 87.71%, Valid: 87.68%, Test: 87.71%
Epoch: 275, Loss: 0.4945, Train: 87.72%, Valid: 87.71%, Test: 87.74%
Epoch: 300, Loss: 0.4804, Train: 87.38%, Valid: 87.35%, Test: 87.38%
Epoch: 325, Loss: 0.4606, Train: 87.47%, Valid: 87.44%, Test: 87.47%
Epoch: 350, Loss: 0.5005, Train: 87.66%, Valid: 87.63%, Test: 87.64%
Epoch: 375, Loss: 0.4352, Train: 15.24%, Valid: 15.46%, Test: 15.09%
Epoch: 400, Loss: 607.8431, Train: 84.46%, Valid: 84.36%, Test: 84.59%
Epoch: 425, Loss: 4317842.0000, Train: 84.36%, Valid: 84.26%, Test: 84.48%
Epoch: 450, Loss: 10178584.0000, Train: 84.46%, Valid: 84.36%, Test: 84.59%
Epoch: 475, Loss: 3850.9055, Train: 16.17%, Valid: 16.37%, Test: 16.06%
Run 01:
Highest Train: 87.86
Highest Valid: 87.83
  Final Train: 87.84
   Final Test: 87.89
All runs:
Highest Train: 87.86, nan
Highest Valid: 87.83, nan
  Final Train: 87.84, nan
   Final Test: 87.89, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 2.4467, Train: 14.51%, Valid: 14.68%, Test: 14.44%
Epoch: 25, Loss: 2.9110, Train: 14.26%, Valid: 14.35%, Test: 14.34%
Epoch: 50, Loss: 2.3664, Train: 14.95%, Valid: 15.05%, Test: 15.03%
Epoch: 75, Loss: 0.8467, Train: 84.86%, Valid: 84.92%, Test: 84.98%
Epoch: 100, Loss: 0.5369, Train: 86.18%, Valid: 86.01%, Test: 86.24%
Epoch: 125, Loss: 0.5581, Train: 86.16%, Valid: 86.16%, Test: 86.24%
Epoch: 150, Loss: 0.5290, Train: 86.13%, Valid: 86.13%, Test: 86.22%
Epoch: 175, Loss: 0.4983, Train: 86.06%, Valid: 86.03%, Test: 86.18%
Epoch: 200, Loss: 0.5649, Train: 86.24%, Valid: 86.26%, Test: 86.34%
Epoch: 225, Loss: 0.5146, Train: 86.19%, Valid: 86.19%, Test: 86.30%
Epoch: 250, Loss: 0.4855, Train: 86.08%, Valid: 86.10%, Test: 86.25%
Epoch: 275, Loss: 1.5408, Train: 84.90%, Valid: 84.91%, Test: 85.08%
Epoch: 300, Loss: 1.0885, Train: 86.25%, Valid: 86.25%, Test: 86.35%
Epoch: 325, Loss: 9.2447, Train: 86.69%, Valid: 86.71%, Test: 86.78%
Epoch: 350, Loss: 732363648.0000, Train: 84.43%, Valid: 84.32%, Test: 84.56%
Epoch: 375, Loss: 6890357760.0000, Train: 50.01%, Valid: 50.02%, Test: 50.02%
Epoch: 400, Loss: 20689899520.0000, Train: 49.99%, Valid: 49.98%, Test: 49.99%
Epoch: 425, Loss: 10822343680.0000, Train: 49.99%, Valid: 49.98%, Test: 49.99%
Epoch: 450, Loss: 3814888960.0000, Train: 49.98%, Valid: 49.97%, Test: 49.98%
Epoch: 475, Loss: 39865561088.0000, Train: 50.01%, Valid: 50.02%, Test: 50.01%
Run 01:
Highest Train: 86.69
Highest Valid: 86.71
  Final Train: 86.69
   Final Test: 86.78
All runs:
Highest Train: 86.69, nan
Highest Valid: 86.71, nan
  Final Train: 86.69, nan
   Final Test: 86.78, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.0836, Train: 84.76%, Valid: 84.67%, Test: 84.70%
Epoch: 25, Loss: 0.7180, Train: 85.65%, Valid: 85.48%, Test: 85.64%
Epoch: 50, Loss: 0.4892, Train: 85.51%, Valid: 85.32%, Test: 85.43%
Epoch: 75, Loss: 1.3556, Train: 85.05%, Valid: 84.89%, Test: 85.00%
Epoch: 100, Loss: 1.2657, Train: 84.86%, Valid: 84.70%, Test: 84.83%
Epoch: 125, Loss: 1.1375, Train: 84.49%, Valid: 84.30%, Test: 84.47%
Epoch: 150, Loss: 0.8196, Train: 84.09%, Valid: 83.87%, Test: 84.11%
Epoch: 175, Loss: 0.4977, Train: 84.23%, Valid: 84.01%, Test: 84.31%
Epoch: 200, Loss: 0.4682, Train: 84.27%, Valid: 84.04%, Test: 84.35%
Epoch: 225, Loss: 0.4799, Train: 85.17%, Valid: 85.14%, Test: 85.27%
Epoch: 250, Loss: 0.4791, Train: 85.20%, Valid: 85.17%, Test: 85.30%
Epoch: 275, Loss: 0.4611, Train: 85.20%, Valid: 85.17%, Test: 85.32%
Epoch: 300, Loss: 0.4507, Train: 85.21%, Valid: 85.19%, Test: 85.33%
Epoch: 325, Loss: 0.4726, Train: 85.24%, Valid: 85.23%, Test: 85.37%
Epoch: 350, Loss: 0.4796, Train: 85.26%, Valid: 85.24%, Test: 85.38%
Epoch: 375, Loss: 0.4777, Train: 85.55%, Valid: 85.58%, Test: 85.64%
Epoch: 400, Loss: 0.4729, Train: 85.57%, Valid: 85.60%, Test: 85.65%
Epoch: 425, Loss: 0.4597, Train: 85.57%, Valid: 85.60%, Test: 85.65%
Epoch: 450, Loss: 0.4516, Train: 85.58%, Valid: 85.62%, Test: 85.66%
Epoch: 475, Loss: 0.4447, Train: 85.60%, Valid: 85.65%, Test: 85.69%
Run 01:
Highest Train: 86.59
Highest Valid: 86.40
  Final Train: 86.59
   Final Test: 86.59
All runs:
Highest Train: 86.59, nan
Highest Valid: 86.40, nan
  Final Train: 86.59, nan
   Final Test: 86.59, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.7271, Train: 85.05%, Valid: 85.00%, Test: 85.21%
Epoch: 25, Loss: 0.5290, Train: 85.73%, Valid: 85.61%, Test: 85.78%
Epoch: 50, Loss: 0.4727, Train: 85.55%, Valid: 85.40%, Test: 85.66%
Epoch: 75, Loss: 0.4565, Train: 85.76%, Valid: 85.74%, Test: 85.78%
Epoch: 100, Loss: 0.4592, Train: 86.08%, Valid: 86.03%, Test: 86.11%
Epoch: 125, Loss: 0.4578, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 150, Loss: 0.4608, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 175, Loss: 0.4565, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 200, Loss: 0.4715, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 225, Loss: 0.4635, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 250, Loss: 0.4640, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 275, Loss: 0.4727, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 300, Loss: 0.4692, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 325, Loss: 0.4694, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 350, Loss: 0.4503, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 375, Loss: 0.4722, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 400, Loss: 0.4536, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 425, Loss: 0.4615, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 450, Loss: 0.4587, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Epoch: 475, Loss: 0.4592, Train: 86.10%, Valid: 86.05%, Test: 86.13%
Run 01:
Highest Train: 86.97
Highest Valid: 86.97
  Final Train: 86.97
   Final Test: 86.99
All runs:
Highest Train: 86.97, nan
Highest Valid: 86.97, nan
  Final Train: 86.97, nan
   Final Test: 86.99, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.9232, Train: 85.24%, Valid: 85.30%, Test: 85.40%
Epoch: 25, Loss: 0.5191, Train: 85.91%, Valid: 85.81%, Test: 85.95%
Epoch: 50, Loss: 0.8716, Train: 86.04%, Valid: 85.94%, Test: 86.10%
Epoch: 75, Loss: 0.4645, Train: 85.74%, Valid: 85.65%, Test: 85.88%
Epoch: 100, Loss: 10.7088, Train: 16.17%, Valid: 16.29%, Test: 16.09%
Epoch: 125, Loss: 28.2449, Train: 87.07%, Valid: 86.94%, Test: 87.02%
Epoch: 150, Loss: 0.4326, Train: 86.46%, Valid: 86.43%, Test: 86.58%
Epoch: 175, Loss: 0.4324, Train: 86.45%, Valid: 86.44%, Test: 86.57%
Epoch: 200, Loss: 0.4443, Train: 86.45%, Valid: 86.44%, Test: 86.57%
Epoch: 225, Loss: 0.4375, Train: 86.45%, Valid: 86.44%, Test: 86.57%
Epoch: 250, Loss: 0.4335, Train: 86.36%, Valid: 86.34%, Test: 86.48%
Epoch: 275, Loss: 0.4343, Train: 86.45%, Valid: 86.44%, Test: 86.57%
Epoch: 300, Loss: 0.4361, Train: 86.37%, Valid: 86.35%, Test: 86.49%
Epoch: 325, Loss: 0.4342, Train: 86.45%, Valid: 86.44%, Test: 86.57%
Epoch: 350, Loss: 0.4402, Train: 86.44%, Valid: 86.44%, Test: 86.56%
Epoch: 375, Loss: 0.4471, Train: 86.45%, Valid: 86.44%, Test: 86.57%
Epoch: 400, Loss: 0.4120, Train: 86.44%, Valid: 86.43%, Test: 86.56%
Epoch: 425, Loss: 0.4223, Train: 86.45%, Valid: 86.44%, Test: 86.57%
Epoch: 450, Loss: 0.4334, Train: 86.46%, Valid: 86.45%, Test: 86.58%
Epoch: 475, Loss: 0.4274, Train: 86.45%, Valid: 86.44%, Test: 86.57%
Run 01:
Highest Train: 87.39
Highest Valid: 87.12
  Final Train: 87.39
   Final Test: 87.30
All runs:
Highest Train: 87.39, nan
Highest Valid: 87.12, nan
  Final Train: 87.39, nan
   Final Test: 87.30, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.0034, Train: 15.89%, Valid: 15.90%, Test: 15.74%
Epoch: 25, Loss: 0.4045, Train: 85.82%, Valid: 85.71%, Test: 85.87%
Epoch: 50, Loss: 0.4053, Train: 85.68%, Valid: 85.53%, Test: 85.73%
Epoch: 75, Loss: 0.3905, Train: 86.59%, Valid: 86.63%, Test: 86.66%
Epoch: 100, Loss: 0.3996, Train: 86.57%, Valid: 86.62%, Test: 86.65%
Epoch: 125, Loss: 0.4825, Train: 86.47%, Valid: 86.53%, Test: 86.54%
Epoch: 150, Loss: 0.4597, Train: 86.11%, Valid: 86.16%, Test: 86.18%
Epoch: 175, Loss: 0.4573, Train: 86.01%, Valid: 86.07%, Test: 86.11%
Epoch: 200, Loss: 0.4569, Train: 85.93%, Valid: 85.97%, Test: 86.02%
Epoch: 225, Loss: 0.4507, Train: 85.76%, Valid: 85.81%, Test: 85.87%
Epoch: 250, Loss: 0.4743, Train: 85.79%, Valid: 85.83%, Test: 85.90%
Epoch: 275, Loss: 0.4746, Train: 85.63%, Valid: 85.69%, Test: 85.77%
Epoch: 300, Loss: 0.4398, Train: 85.48%, Valid: 85.56%, Test: 85.62%
Epoch: 325, Loss: 0.4389, Train: 85.55%, Valid: 85.62%, Test: 85.69%
Epoch: 350, Loss: 0.4463, Train: 85.49%, Valid: 85.57%, Test: 85.63%
Epoch: 375, Loss: 0.4381, Train: 85.41%, Valid: 85.49%, Test: 85.55%
Epoch: 400, Loss: 0.4324, Train: 85.41%, Valid: 85.48%, Test: 85.53%
Epoch: 425, Loss: 0.4276, Train: 85.36%, Valid: 85.42%, Test: 85.48%
Epoch: 450, Loss: 0.4228, Train: 85.33%, Valid: 85.39%, Test: 85.45%
Epoch: 475, Loss: 0.4258, Train: 85.33%, Valid: 85.39%, Test: 85.46%
Run 01:
Highest Train: 86.60
Highest Valid: 86.64
  Final Train: 86.59
   Final Test: 86.67
All runs:
Highest Train: 86.60, nan
Highest Valid: 86.64, nan
  Final Train: 86.59, nan
   Final Test: 86.67, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 1.8465, Train: 86.33%, Valid: 86.41%, Test: 86.35%
Epoch: 25, Loss: 0.4012, Train: 86.43%, Valid: 86.33%, Test: 86.38%
Epoch: 50, Loss: 0.3832, Train: 86.11%, Valid: 85.95%, Test: 86.00%
Epoch: 75, Loss: 0.4396, Train: 86.20%, Valid: 86.20%, Test: 86.22%
Epoch: 100, Loss: 0.5843, Train: 86.45%, Valid: 86.42%, Test: 86.53%
Epoch: 125, Loss: 0.4785, Train: 86.46%, Valid: 86.43%, Test: 86.53%
Epoch: 150, Loss: 0.5270, Train: 86.65%, Valid: 86.61%, Test: 86.68%
Epoch: 175, Loss: 0.5315, Train: 86.47%, Valid: 86.45%, Test: 86.50%
Epoch: 200, Loss: 0.5246, Train: 86.36%, Valid: 86.33%, Test: 86.43%
Epoch: 225, Loss: 0.5199, Train: 86.38%, Valid: 86.32%, Test: 86.43%
Epoch: 250, Loss: 0.5037, Train: 86.15%, Valid: 86.02%, Test: 86.22%
Epoch: 275, Loss: 0.4936, Train: 86.10%, Valid: 85.97%, Test: 86.18%
Epoch: 300, Loss: 0.4900, Train: 85.98%, Valid: 85.85%, Test: 86.07%
Epoch: 325, Loss: 0.4881, Train: 86.00%, Valid: 85.88%, Test: 86.10%
Epoch: 350, Loss: 0.4776, Train: 86.04%, Valid: 85.92%, Test: 86.13%
Epoch: 375, Loss: 0.4629, Train: 85.98%, Valid: 85.87%, Test: 86.07%
Epoch: 400, Loss: 0.4649, Train: 85.97%, Valid: 85.86%, Test: 86.06%
Epoch: 425, Loss: 0.5328, Train: 86.10%, Valid: 85.97%, Test: 86.20%
Epoch: 450, Loss: 0.5790, Train: 86.01%, Valid: 85.88%, Test: 86.10%
Epoch: 475, Loss: 0.5140, Train: 85.91%, Valid: 85.77%, Test: 86.00%
Run 01:
Highest Train: 86.69
Highest Valid: 86.72
  Final Train: 86.69
   Final Test: 86.72
All runs:
Highest Train: 86.69, nan
Highest Valid: 86.72, nan
  Final Train: 86.69, nan
   Final Test: 86.72, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 8.3429, Train: 71.60%, Valid: 71.48%, Test: 71.64%
Epoch: 25, Loss: 13.4935, Train: 16.40%, Valid: 16.37%, Test: 16.28%
Epoch: 50, Loss: 3.3307, Train: 86.90%, Valid: 86.81%, Test: 86.94%
Epoch: 75, Loss: 0.5106, Train: 85.78%, Valid: 85.71%, Test: 85.86%
Epoch: 100, Loss: 0.4970, Train: 85.98%, Valid: 85.92%, Test: 86.09%
Epoch: 125, Loss: 0.4985, Train: 86.07%, Valid: 86.03%, Test: 86.17%
Epoch: 150, Loss: 0.5014, Train: 86.26%, Valid: 86.22%, Test: 86.33%
Epoch: 175, Loss: 0.5044, Train: 86.13%, Valid: 86.09%, Test: 86.22%
Epoch: 200, Loss: 0.5034, Train: 86.15%, Valid: 86.10%, Test: 86.21%
Epoch: 225, Loss: 0.5022, Train: 86.25%, Valid: 86.22%, Test: 86.31%
Epoch: 250, Loss: 0.5005, Train: 86.35%, Valid: 86.33%, Test: 86.41%
Epoch: 275, Loss: 0.4990, Train: 86.35%, Valid: 86.32%, Test: 86.39%
Epoch: 300, Loss: 0.4982, Train: 86.36%, Valid: 86.34%, Test: 86.40%
Epoch: 325, Loss: 0.4817, Train: 86.36%, Valid: 86.32%, Test: 86.41%
Epoch: 350, Loss: 0.4781, Train: 86.40%, Valid: 86.38%, Test: 86.43%
Epoch: 375, Loss: 0.4871, Train: 86.43%, Valid: 86.41%, Test: 86.46%
Epoch: 400, Loss: 0.4944, Train: 86.44%, Valid: 86.42%, Test: 86.47%
Epoch: 425, Loss: 0.4976, Train: 86.44%, Valid: 86.42%, Test: 86.47%
Epoch: 450, Loss: 0.4967, Train: 86.72%, Valid: 86.68%, Test: 86.77%
Epoch: 475, Loss: 0.4877, Train: 86.47%, Valid: 86.45%, Test: 86.50%
Run 01:
Highest Train: 87.02
Highest Valid: 86.94
  Final Train: 87.01
   Final Test: 87.08
All runs:
Highest Train: 87.02, nan
Highest Valid: 86.94, nan
  Final Train: 87.01, nan
   Final Test: 87.08, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.5384, Train: 85.74%, Valid: 85.64%, Test: 85.74%
Epoch: 25, Loss: 0.3880, Train: 85.89%, Valid: 85.86%, Test: 85.94%
Epoch: 50, Loss: 0.4164, Train: 87.37%, Valid: 87.43%, Test: 87.40%
Epoch: 75, Loss: 1.2773, Train: 87.15%, Valid: 87.20%, Test: 87.12%
Epoch: 100, Loss: 0.5135, Train: 87.27%, Valid: 87.31%, Test: 87.26%
Epoch: 125, Loss: 0.4810, Train: 87.16%, Valid: 87.17%, Test: 87.14%
Epoch: 150, Loss: 0.4720, Train: 87.13%, Valid: 87.14%, Test: 87.14%
Epoch: 175, Loss: 0.4736, Train: 86.98%, Valid: 87.00%, Test: 86.99%
Epoch: 200, Loss: 0.4564, Train: 86.86%, Valid: 86.85%, Test: 86.86%
Epoch: 225, Loss: 0.4858, Train: 87.06%, Valid: 87.07%, Test: 87.07%
Epoch: 250, Loss: 0.4808, Train: 86.98%, Valid: 86.99%, Test: 86.98%
Epoch: 275, Loss: 0.4712, Train: 86.96%, Valid: 86.96%, Test: 86.96%
Epoch: 300, Loss: 0.4490, Train: 86.81%, Valid: 86.82%, Test: 86.82%
Epoch: 325, Loss: 0.4548, Train: 86.89%, Valid: 86.88%, Test: 86.88%
Epoch: 350, Loss: 0.4784, Train: 86.90%, Valid: 86.89%, Test: 86.89%
Epoch: 375, Loss: 0.4720, Train: 86.79%, Valid: 86.79%, Test: 86.79%
Epoch: 400, Loss: 0.4582, Train: 86.56%, Valid: 86.60%, Test: 86.57%
Epoch: 425, Loss: 1.6266, Train: 86.63%, Valid: 86.62%, Test: 86.61%
Epoch: 450, Loss: 1.9482, Train: 86.50%, Valid: 86.49%, Test: 86.47%
Epoch: 475, Loss: 0.4526, Train: 86.81%, Valid: 86.80%, Test: 86.84%
Run 01:
Highest Train: 87.61
Highest Valid: 87.66
  Final Train: 87.61
   Final Test: 87.59
All runs:
Highest Train: 87.61, nan
Highest Valid: 87.66, nan
  Final Train: 87.61, nan
   Final Test: 87.59, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4995, Train: 84.15%, Valid: 84.13%, Test: 84.20%
Epoch: 25, Loss: 0.4475, Train: 85.98%, Valid: 85.90%, Test: 86.06%
Epoch: 50, Loss: 0.4194, Train: 85.68%, Valid: 85.53%, Test: 85.75%
Epoch: 75, Loss: 0.3987, Train: 85.64%, Valid: 85.49%, Test: 85.72%
Epoch: 100, Loss: 0.3888, Train: 85.62%, Valid: 85.48%, Test: 85.72%
Epoch: 125, Loss: 0.3714, Train: 85.49%, Valid: 85.33%, Test: 85.58%
Epoch: 150, Loss: 0.3656, Train: 85.45%, Valid: 85.28%, Test: 85.55%
Epoch: 175, Loss: 0.3639, Train: 85.43%, Valid: 85.26%, Test: 85.55%
Epoch: 200, Loss: 0.3632, Train: 85.50%, Valid: 85.33%, Test: 85.62%
Epoch: 225, Loss: 0.3625, Train: 85.49%, Valid: 85.32%, Test: 85.60%
Epoch: 250, Loss: 0.3617, Train: 85.77%, Valid: 85.61%, Test: 85.84%
Epoch: 275, Loss: 0.3607, Train: 85.52%, Valid: 85.34%, Test: 85.65%
Epoch: 300, Loss: 0.3597, Train: 85.61%, Valid: 85.41%, Test: 85.69%
Epoch: 325, Loss: 0.3586, Train: 85.63%, Valid: 85.44%, Test: 85.74%
Epoch: 350, Loss: 0.3572, Train: 85.69%, Valid: 85.53%, Test: 85.79%
Epoch: 375, Loss: 0.3558, Train: 85.71%, Valid: 85.51%, Test: 85.82%
Epoch: 400, Loss: 0.3539, Train: 85.71%, Valid: 85.50%, Test: 85.77%
Epoch: 425, Loss: 0.3519, Train: 85.25%, Valid: 85.16%, Test: 85.39%
Epoch: 450, Loss: 0.3498, Train: 85.43%, Valid: 85.29%, Test: 85.55%
Epoch: 475, Loss: 0.3474, Train: 85.14%, Valid: 85.05%, Test: 85.27%
Run 01:
Highest Train: 86.20
Highest Valid: 86.04
  Final Train: 86.20
   Final Test: 86.23
All runs:
Highest Train: 86.20, nan
Highest Valid: 86.04, nan
  Final Train: 86.20, nan
   Final Test: 86.23, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 12.1055, Train: 13.90%, Valid: 14.00%, Test: 13.90%
Epoch: 25, Loss: 0.3708, Train: 86.02%, Valid: 86.02%, Test: 86.17%
Epoch: 50, Loss: 0.3859, Train: 86.09%, Valid: 86.08%, Test: 86.23%
Epoch: 75, Loss: 0.3865, Train: 86.09%, Valid: 86.09%, Test: 86.23%
Epoch: 100, Loss: 0.3822, Train: 86.13%, Valid: 86.12%, Test: 86.26%
Epoch: 125, Loss: 0.3979, Train: 86.19%, Valid: 86.19%, Test: 86.27%
Epoch: 150, Loss: 0.3932, Train: 86.19%, Valid: 86.19%, Test: 86.26%
Epoch: 175, Loss: 0.3921, Train: 86.19%, Valid: 86.19%, Test: 86.26%
Epoch: 200, Loss: 0.3873, Train: 86.20%, Valid: 86.19%, Test: 86.26%
Epoch: 225, Loss: 0.3859, Train: 86.21%, Valid: 86.20%, Test: 86.25%
Epoch: 250, Loss: 0.3905, Train: 86.33%, Valid: 86.30%, Test: 86.36%
Epoch: 275, Loss: 0.3857, Train: 86.13%, Valid: 86.09%, Test: 86.17%
Epoch: 300, Loss: 0.3767, Train: 85.91%, Valid: 85.87%, Test: 86.01%
Epoch: 325, Loss: 0.4915, Train: 85.97%, Valid: 85.81%, Test: 85.96%
Epoch: 350, Loss: 10.6683, Train: 86.36%, Valid: 86.22%, Test: 86.33%
Epoch: 375, Loss: 15.8822, Train: 86.38%, Valid: 86.24%, Test: 86.35%
Epoch: 400, Loss: 15.8319, Train: 86.39%, Valid: 86.23%, Test: 86.37%
Epoch: 425, Loss: 15.0297, Train: 86.39%, Valid: 86.23%, Test: 86.36%
Epoch: 450, Loss: 14.1407, Train: 86.39%, Valid: 86.23%, Test: 86.36%
Epoch: 475, Loss: 16.2376, Train: 86.40%, Valid: 86.24%, Test: 86.38%
Run 01:
Highest Train: 88.05
Highest Valid: 87.90
  Final Train: 88.05
   Final Test: 88.01
All runs:
Highest Train: 88.05, nan
Highest Valid: 87.90, nan
  Final Train: 88.05, nan
   Final Test: 88.01, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 7.4353, Train: 13.40%, Valid: 13.52%, Test: 13.34%
Epoch: 25, Loss: 0.3875, Train: 85.86%, Valid: 85.93%, Test: 85.91%
Epoch: 50, Loss: 0.4375, Train: 85.75%, Valid: 85.82%, Test: 85.83%
Epoch: 75, Loss: 0.4803, Train: 85.73%, Valid: 85.81%, Test: 85.83%
Epoch: 100, Loss: 0.4550, Train: 85.68%, Valid: 85.77%, Test: 85.77%
Epoch: 125, Loss: 0.4707, Train: 85.69%, Valid: 85.77%, Test: 85.79%
Epoch: 150, Loss: 0.4481, Train: 85.67%, Valid: 85.76%, Test: 85.76%
Epoch: 175, Loss: 0.4533, Train: 85.84%, Valid: 85.95%, Test: 85.94%
Epoch: 200, Loss: 0.4492, Train: 85.87%, Valid: 85.96%, Test: 85.97%
Epoch: 225, Loss: 0.4304, Train: 85.79%, Valid: 85.88%, Test: 85.89%
Epoch: 250, Loss: 0.4197, Train: 86.00%, Valid: 86.09%, Test: 86.11%
Epoch: 275, Loss: 0.4654, Train: 86.02%, Valid: 86.08%, Test: 86.11%
Epoch: 300, Loss: 3.0226, Train: 86.49%, Valid: 86.49%, Test: 86.55%
Epoch: 325, Loss: 3.9415, Train: 86.49%, Valid: 86.48%, Test: 86.54%
Epoch: 350, Loss: 3.9662, Train: 86.48%, Valid: 86.48%, Test: 86.54%
Epoch: 375, Loss: 3.9763, Train: 86.49%, Valid: 86.48%, Test: 86.54%
Epoch: 400, Loss: 3.9615, Train: 86.49%, Valid: 86.49%, Test: 86.54%
Epoch: 425, Loss: 3.9945, Train: 86.49%, Valid: 86.49%, Test: 86.55%
Epoch: 450, Loss: 3.9766, Train: 86.49%, Valid: 86.49%, Test: 86.55%
Epoch: 475, Loss: 3.9582, Train: 86.50%, Valid: 86.50%, Test: 86.56%
Run 01:
Highest Train: 86.96
Highest Valid: 86.99
  Final Train: 86.93
   Final Test: 86.96
All runs:
Highest Train: 86.96, nan
Highest Valid: 86.99, nan
  Final Train: 86.93, nan
   Final Test: 86.96, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.5993, Train: 14.81%, Valid: 14.95%, Test: 14.90%
Epoch: 25, Loss: 0.3677, Train: 86.43%, Valid: 86.39%, Test: 86.59%
Epoch: 50, Loss: 0.3787, Train: 86.52%, Valid: 86.49%, Test: 86.67%
Epoch: 75, Loss: 0.3848, Train: 86.56%, Valid: 86.52%, Test: 86.71%
Epoch: 100, Loss: 0.3757, Train: 86.45%, Valid: 86.42%, Test: 86.60%
Epoch: 125, Loss: 0.4921, Train: 87.47%, Valid: 87.38%, Test: 87.51%
Epoch: 150, Loss: 0.4522, Train: 86.13%, Valid: 86.01%, Test: 86.21%
Epoch: 175, Loss: 0.4551, Train: 86.05%, Valid: 85.96%, Test: 86.15%
Epoch: 200, Loss: 0.4807, Train: 87.44%, Valid: 87.44%, Test: 87.52%
Epoch: 225, Loss: 0.4804, Train: 87.41%, Valid: 87.38%, Test: 87.51%
Epoch: 250, Loss: 0.4720, Train: 87.31%, Valid: 87.21%, Test: 87.40%
Epoch: 275, Loss: 0.4639, Train: 87.20%, Valid: 87.09%, Test: 87.31%
Epoch: 300, Loss: 0.4587, Train: 87.11%, Valid: 87.01%, Test: 87.24%
Epoch: 325, Loss: 0.4545, Train: 87.05%, Valid: 86.94%, Test: 87.15%
Epoch: 350, Loss: 0.4510, Train: 86.97%, Valid: 86.88%, Test: 87.08%
Epoch: 375, Loss: 0.4477, Train: 86.95%, Valid: 86.86%, Test: 87.06%
Epoch: 400, Loss: 0.4485, Train: 86.52%, Valid: 86.40%, Test: 86.59%
Epoch: 425, Loss: 0.4482, Train: 86.53%, Valid: 86.42%, Test: 86.61%
Epoch: 450, Loss: 0.4444, Train: 86.22%, Valid: 86.10%, Test: 86.32%
Epoch: 475, Loss: 0.4405, Train: 86.13%, Valid: 85.99%, Test: 86.23%
Run 01:
Highest Train: 87.66
Highest Valid: 87.62
  Final Train: 87.66
   Final Test: 87.71
All runs:
Highest Train: 87.66, nan
Highest Valid: 87.62, nan
  Final Train: 87.66, nan
   Final Test: 87.71, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 7.4079, Train: 14.61%, Valid: 14.72%, Test: 14.54%
Epoch: 25, Loss: 10.8274, Train: 14.67%, Valid: 14.79%, Test: 14.65%
Epoch: 50, Loss: 4.6533, Train: 15.55%, Valid: 15.59%, Test: 15.58%
Epoch: 75, Loss: 0.3992, Train: 85.90%, Valid: 85.90%, Test: 86.02%
Epoch: 100, Loss: 0.3687, Train: 85.99%, Valid: 86.00%, Test: 86.11%
Epoch: 125, Loss: 0.3670, Train: 85.97%, Valid: 85.98%, Test: 86.10%
Epoch: 150, Loss: 0.3662, Train: 85.93%, Valid: 85.89%, Test: 86.03%
Epoch: 175, Loss: 0.3659, Train: 85.93%, Valid: 85.90%, Test: 86.05%
Epoch: 200, Loss: 0.3656, Train: 86.14%, Valid: 86.08%, Test: 86.27%
Epoch: 225, Loss: 0.3654, Train: 86.12%, Valid: 86.05%, Test: 86.23%
Epoch: 250, Loss: 0.3652, Train: 85.91%, Valid: 85.86%, Test: 86.00%
Epoch: 275, Loss: 0.3650, Train: 86.12%, Valid: 86.06%, Test: 86.24%
Epoch: 300, Loss: 0.3648, Train: 86.16%, Valid: 86.07%, Test: 86.26%
Epoch: 325, Loss: 0.3646, Train: 85.46%, Valid: 85.37%, Test: 85.52%
Epoch: 350, Loss: 0.3644, Train: 86.21%, Valid: 86.12%, Test: 86.31%
Epoch: 375, Loss: 0.3642, Train: 86.09%, Valid: 85.96%, Test: 86.15%
Epoch: 400, Loss: 0.3639, Train: 85.37%, Valid: 85.22%, Test: 85.44%
Epoch: 425, Loss: 0.3637, Train: 86.24%, Valid: 86.18%, Test: 86.36%
Epoch: 450, Loss: 0.3634, Train: 85.45%, Valid: 85.30%, Test: 85.51%
Epoch: 475, Loss: 0.3632, Train: 86.01%, Valid: 85.97%, Test: 86.08%
Run 01:
Highest Train: 86.33
Highest Valid: 86.25
  Final Train: 86.33
   Final Test: 86.41
All runs:
Highest Train: 86.33, nan
Highest Valid: 86.25, nan
  Final Train: 86.33, nan
   Final Test: 86.41, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.5461, Train: 84.25%, Valid: 84.03%, Test: 84.33%
Epoch: 25, Loss: 0.4355, Train: 86.30%, Valid: 86.33%, Test: 86.41%
Epoch: 50, Loss: 0.4323, Train: 85.34%, Valid: 85.35%, Test: 85.44%
Epoch: 75, Loss: 0.4241, Train: 85.46%, Valid: 85.51%, Test: 85.56%
Epoch: 100, Loss: 0.4042, Train: 85.36%, Valid: 85.39%, Test: 85.46%
Epoch: 125, Loss: 0.3869, Train: 85.44%, Valid: 85.48%, Test: 85.56%
Epoch: 150, Loss: 0.3731, Train: 85.39%, Valid: 85.42%, Test: 85.51%
Epoch: 175, Loss: 0.3618, Train: 85.68%, Valid: 85.67%, Test: 85.76%
Epoch: 200, Loss: 0.3606, Train: 86.51%, Valid: 86.49%, Test: 86.60%
Epoch: 225, Loss: 0.3592, Train: 85.30%, Valid: 85.29%, Test: 85.39%
Epoch: 250, Loss: 0.3568, Train: 86.29%, Valid: 86.31%, Test: 86.35%
Epoch: 275, Loss: 0.3544, Train: 86.77%, Valid: 86.79%, Test: 86.83%
Epoch: 300, Loss: 0.3517, Train: 86.15%, Valid: 86.19%, Test: 86.21%
Epoch: 325, Loss: 0.3489, Train: 86.68%, Valid: 86.71%, Test: 86.75%
Epoch: 350, Loss: 0.3453, Train: 85.57%, Valid: 85.60%, Test: 85.65%
Epoch: 375, Loss: 0.3423, Train: 85.13%, Valid: 85.13%, Test: 85.23%
Epoch: 400, Loss: 0.3398, Train: 85.13%, Valid: 85.12%, Test: 85.22%
Epoch: 425, Loss: 0.3388, Train: 85.02%, Valid: 85.03%, Test: 85.11%
Epoch: 450, Loss: 0.3360, Train: 86.87%, Valid: 86.70%, Test: 86.88%
Epoch: 475, Loss: 0.3343, Train: 84.93%, Valid: 84.92%, Test: 85.01%
Run 01:
Highest Train: 87.92
Highest Valid: 87.90
  Final Train: 87.92
   Final Test: 87.94
All runs:
Highest Train: 87.92, nan
Highest Valid: 87.90, nan
  Final Train: 87.92, nan
   Final Test: 87.94, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 3.1317, Train: 80.45%, Valid: 80.50%, Test: 80.50%
Epoch: 25, Loss: 0.4012, Train: 86.70%, Valid: 86.49%, Test: 86.73%
Epoch: 50, Loss: 0.3945, Train: 85.91%, Valid: 85.74%, Test: 85.99%
Epoch: 75, Loss: 0.3786, Train: 86.06%, Valid: 85.93%, Test: 86.11%
Epoch: 100, Loss: 0.3668, Train: 85.33%, Valid: 85.20%, Test: 85.44%
Epoch: 125, Loss: 0.3631, Train: 85.52%, Valid: 85.38%, Test: 85.61%
Epoch: 150, Loss: 0.3620, Train: 85.52%, Valid: 85.37%, Test: 85.62%
Epoch: 175, Loss: 0.3608, Train: 85.51%, Valid: 85.36%, Test: 85.62%
Epoch: 200, Loss: 0.3597, Train: 85.48%, Valid: 85.32%, Test: 85.59%
Epoch: 225, Loss: 0.3584, Train: 85.28%, Valid: 85.17%, Test: 85.38%
Epoch: 250, Loss: 0.3568, Train: 85.44%, Valid: 85.32%, Test: 85.55%
Epoch: 275, Loss: 0.3550, Train: 85.89%, Valid: 85.87%, Test: 85.93%
Epoch: 300, Loss: 0.3534, Train: 85.96%, Valid: 85.88%, Test: 86.06%
Epoch: 325, Loss: 0.3516, Train: 85.68%, Valid: 85.61%, Test: 85.79%
Epoch: 350, Loss: 0.3501, Train: 85.61%, Valid: 85.49%, Test: 85.68%
Epoch: 375, Loss: 0.3482, Train: 86.04%, Valid: 85.97%, Test: 86.17%
Epoch: 400, Loss: 0.3454, Train: 85.60%, Valid: 85.45%, Test: 85.71%
Epoch: 425, Loss: 0.3429, Train: 85.65%, Valid: 85.48%, Test: 85.75%
Epoch: 450, Loss: 0.3405, Train: 85.63%, Valid: 85.46%, Test: 85.74%
Epoch: 475, Loss: 0.3375, Train: 85.61%, Valid: 85.44%, Test: 85.72%
Run 01:
Highest Train: 86.74
Highest Valid: 86.54
  Final Train: 86.74
   Final Test: 86.80
All runs:
Highest Train: 86.74, nan
Highest Valid: 86.54, nan
  Final Train: 86.74, nan
   Final Test: 86.80, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=1, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.8183, Train: 84.92%, Valid: 84.82%, Test: 85.01%
Epoch: 25, Loss: 0.3827, Train: 86.59%, Valid: 86.48%, Test: 86.59%
Epoch: 50, Loss: 0.3750, Train: 86.75%, Valid: 86.66%, Test: 86.75%
Epoch: 75, Loss: 0.3653, Train: 85.44%, Valid: 85.30%, Test: 85.49%
Epoch: 100, Loss: 0.3642, Train: 85.57%, Valid: 85.41%, Test: 85.60%
Epoch: 125, Loss: 0.3632, Train: 85.76%, Valid: 85.64%, Test: 85.79%
Epoch: 150, Loss: 0.3621, Train: 85.60%, Valid: 85.45%, Test: 85.63%
Epoch: 175, Loss: 0.3608, Train: 85.57%, Valid: 85.42%, Test: 85.61%
Epoch: 200, Loss: 0.3592, Train: 85.58%, Valid: 85.42%, Test: 85.61%
Epoch: 225, Loss: 0.3575, Train: 85.57%, Valid: 85.41%, Test: 85.61%
Epoch: 250, Loss: 0.3555, Train: 85.56%, Valid: 85.41%, Test: 85.61%
Epoch: 275, Loss: 0.3533, Train: 85.54%, Valid: 85.40%, Test: 85.60%
Epoch: 300, Loss: 0.3506, Train: 85.52%, Valid: 85.37%, Test: 85.57%
Epoch: 325, Loss: 0.3477, Train: 85.45%, Valid: 85.29%, Test: 85.50%
Epoch: 350, Loss: 0.3450, Train: 85.46%, Valid: 85.29%, Test: 85.51%
Epoch: 375, Loss: 0.3420, Train: 85.45%, Valid: 85.28%, Test: 85.51%
Epoch: 400, Loss: 0.3392, Train: 85.44%, Valid: 85.26%, Test: 85.50%
Epoch: 425, Loss: 0.3368, Train: 85.43%, Valid: 85.25%, Test: 85.49%
Epoch: 450, Loss: 0.3342, Train: 85.47%, Valid: 85.28%, Test: 85.52%
Epoch: 475, Loss: 0.3323, Train: 85.48%, Valid: 85.28%, Test: 85.54%
Run 01:
Highest Train: 87.00
Highest Valid: 86.85
  Final Train: 86.99
   Final Test: 86.94
All runs:
Highest Train: 87.00, nan
Highest Valid: 86.85, nan
  Final Train: 86.99, nan
   Final Test: 86.94, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.8312, Train: 85.29%, Valid: 85.17%, Test: 85.47%
Epoch: 25, Loss: 0.3715, Train: 85.00%, Valid: 84.84%, Test: 85.01%
Epoch: 50, Loss: 0.3679, Train: 85.06%, Valid: 84.84%, Test: 85.06%
Epoch: 75, Loss: 0.3638, Train: 84.96%, Valid: 84.91%, Test: 85.04%
Epoch: 100, Loss: 0.3625, Train: 85.51%, Valid: 85.53%, Test: 85.60%
Epoch: 125, Loss: 0.3613, Train: 85.48%, Valid: 85.48%, Test: 85.57%
Epoch: 150, Loss: 0.3598, Train: 85.51%, Valid: 85.52%, Test: 85.60%
Epoch: 175, Loss: 0.3582, Train: 85.49%, Valid: 85.52%, Test: 85.62%
Epoch: 200, Loss: 0.3563, Train: 85.60%, Valid: 85.60%, Test: 85.74%
Epoch: 225, Loss: 0.3541, Train: 85.61%, Valid: 85.63%, Test: 85.74%
Epoch: 250, Loss: 0.3516, Train: 85.76%, Valid: 85.73%, Test: 85.85%
Epoch: 275, Loss: 0.3486, Train: 85.74%, Valid: 85.72%, Test: 85.83%
Epoch: 300, Loss: 0.3455, Train: 85.56%, Valid: 85.56%, Test: 85.68%
Epoch: 325, Loss: 0.3419, Train: 85.45%, Valid: 85.43%, Test: 85.56%
Epoch: 350, Loss: 0.3382, Train: 85.36%, Valid: 85.37%, Test: 85.48%
Epoch: 375, Loss: 0.3354, Train: 85.41%, Valid: 85.42%, Test: 85.50%
Epoch: 400, Loss: 0.3329, Train: 85.48%, Valid: 85.47%, Test: 85.55%
Epoch: 425, Loss: 0.3310, Train: 85.39%, Valid: 85.19%, Test: 85.41%
Epoch: 450, Loss: 0.3373, Train: 85.70%, Valid: 85.70%, Test: 85.81%
Epoch: 475, Loss: 0.3326, Train: 85.65%, Valid: 85.67%, Test: 85.74%
Run 01:
Highest Train: 86.93
Highest Valid: 86.96
  Final Train: 86.93
   Final Test: 87.04
All runs:
Highest Train: 86.93, nan
Highest Valid: 86.96, nan
  Final Train: 86.93, nan
   Final Test: 87.04, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4277, Train: 84.86%, Valid: 84.78%, Test: 84.99%
Epoch: 25, Loss: 0.4313, Train: 85.79%, Valid: 85.66%, Test: 85.89%
Epoch: 50, Loss: 0.3674, Train: 86.59%, Valid: 86.56%, Test: 86.58%
Epoch: 75, Loss: 0.3640, Train: 85.64%, Valid: 85.53%, Test: 85.80%
Epoch: 100, Loss: 0.3631, Train: 85.61%, Valid: 85.52%, Test: 85.79%
Epoch: 125, Loss: 0.3622, Train: 85.70%, Valid: 85.60%, Test: 85.87%
Epoch: 150, Loss: 0.3612, Train: 85.70%, Valid: 85.61%, Test: 85.88%
Epoch: 175, Loss: 0.3602, Train: 85.75%, Valid: 85.67%, Test: 85.93%
Epoch: 200, Loss: 0.3590, Train: 85.66%, Valid: 85.55%, Test: 85.82%
Epoch: 225, Loss: 0.3577, Train: 85.71%, Valid: 85.65%, Test: 85.92%
Epoch: 250, Loss: 0.3562, Train: 85.63%, Valid: 85.52%, Test: 85.80%
Epoch: 275, Loss: 0.3541, Train: 85.70%, Valid: 85.59%, Test: 85.87%
Epoch: 300, Loss: 0.3520, Train: 85.68%, Valid: 85.57%, Test: 85.85%
Epoch: 325, Loss: 0.3497, Train: 85.64%, Valid: 85.53%, Test: 85.79%
Epoch: 350, Loss: 0.3472, Train: 85.58%, Valid: 85.45%, Test: 85.74%
Epoch: 375, Loss: 0.3444, Train: 85.60%, Valid: 85.47%, Test: 85.76%
Epoch: 400, Loss: 0.3415, Train: 85.56%, Valid: 85.40%, Test: 85.70%
Epoch: 425, Loss: 0.3392, Train: 85.52%, Valid: 85.34%, Test: 85.64%
Epoch: 450, Loss: 0.3372, Train: 85.47%, Valid: 85.29%, Test: 85.58%
Epoch: 475, Loss: 0.3355, Train: 85.45%, Valid: 85.27%, Test: 85.57%
Run 01:
Highest Train: 86.60
Highest Valid: 86.57
  Final Train: 86.60
   Final Test: 86.59
All runs:
Highest Train: 86.60, nan
Highest Valid: 86.57, nan
  Final Train: 86.60, nan
   Final Test: 86.59, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4786, Train: 85.05%, Valid: 84.87%, Test: 85.09%
Epoch: 25, Loss: 0.3676, Train: 85.54%, Valid: 85.37%, Test: 85.57%
Epoch: 50, Loss: 0.3652, Train: 85.52%, Valid: 85.38%, Test: 85.57%
Epoch: 75, Loss: 0.3640, Train: 85.57%, Valid: 85.42%, Test: 85.62%
Epoch: 100, Loss: 0.3629, Train: 85.56%, Valid: 85.41%, Test: 85.62%
Epoch: 125, Loss: 0.3615, Train: 85.56%, Valid: 85.42%, Test: 85.62%
Epoch: 150, Loss: 0.3599, Train: 85.56%, Valid: 85.42%, Test: 85.62%
Epoch: 175, Loss: 0.3579, Train: 85.56%, Valid: 85.42%, Test: 85.62%
Epoch: 200, Loss: 0.3555, Train: 85.53%, Valid: 85.38%, Test: 85.58%
Epoch: 225, Loss: 0.3530, Train: 85.49%, Valid: 85.33%, Test: 85.54%
Epoch: 250, Loss: 0.3503, Train: 85.39%, Valid: 85.23%, Test: 85.44%
Epoch: 275, Loss: 0.3476, Train: 85.31%, Valid: 85.14%, Test: 85.36%
Epoch: 300, Loss: 0.3450, Train: 85.23%, Valid: 85.06%, Test: 85.30%
Epoch: 325, Loss: 0.3421, Train: 85.18%, Valid: 85.01%, Test: 85.25%
Epoch: 350, Loss: 0.3397, Train: 85.13%, Valid: 84.95%, Test: 85.20%
Epoch: 375, Loss: 0.3374, Train: 85.11%, Valid: 84.93%, Test: 85.17%
Epoch: 400, Loss: 0.3354, Train: 85.12%, Valid: 84.94%, Test: 85.19%
Epoch: 425, Loss: 0.3334, Train: 85.12%, Valid: 84.94%, Test: 85.19%
Epoch: 450, Loss: 0.3315, Train: 85.13%, Valid: 84.94%, Test: 85.19%
Epoch: 475, Loss: 0.5241, Train: 85.47%, Valid: 85.30%, Test: 85.55%
Run 01:
Highest Train: 86.75
Highest Valid: 86.68
  Final Train: 86.75
   Final Test: 86.86
All runs:
Highest Train: 86.75, nan
Highest Valid: 86.68, nan
  Final Train: 86.75, nan
   Final Test: 86.86, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 5.3495, Train: 83.59%, Valid: 83.43%, Test: 83.55%
Epoch: 25, Loss: 0.3961, Train: 86.85%, Valid: 86.71%, Test: 86.86%
Epoch: 50, Loss: 0.3918, Train: 86.65%, Valid: 86.51%, Test: 86.66%
Epoch: 75, Loss: 0.3753, Train: 86.60%, Valid: 86.45%, Test: 86.61%
Epoch: 100, Loss: 0.3654, Train: 85.60%, Valid: 85.65%, Test: 85.69%
Epoch: 125, Loss: 0.3646, Train: 85.64%, Valid: 85.67%, Test: 85.71%
Epoch: 150, Loss: 0.3636, Train: 85.58%, Valid: 85.61%, Test: 85.63%
Epoch: 175, Loss: 0.3625, Train: 85.65%, Valid: 85.69%, Test: 85.72%
Epoch: 200, Loss: 0.3612, Train: 85.67%, Valid: 85.71%, Test: 85.73%
Epoch: 225, Loss: 0.3597, Train: 85.69%, Valid: 85.72%, Test: 85.76%
Epoch: 250, Loss: 0.3581, Train: 84.96%, Valid: 84.97%, Test: 85.04%
Epoch: 275, Loss: 0.3562, Train: 84.95%, Valid: 84.96%, Test: 85.02%
Epoch: 300, Loss: 0.3539, Train: 85.59%, Valid: 85.62%, Test: 85.66%
Epoch: 325, Loss: 0.3512, Train: 85.62%, Valid: 85.63%, Test: 85.70%
Epoch: 350, Loss: 0.3482, Train: 85.60%, Valid: 85.60%, Test: 85.67%
Epoch: 375, Loss: 0.3453, Train: 85.59%, Valid: 85.59%, Test: 85.68%
Epoch: 400, Loss: 0.3423, Train: 85.57%, Valid: 85.57%, Test: 85.67%
Epoch: 425, Loss: 0.3394, Train: 85.48%, Valid: 85.48%, Test: 85.57%
Epoch: 450, Loss: 0.3370, Train: 85.47%, Valid: 85.48%, Test: 85.57%
Epoch: 475, Loss: 0.3347, Train: 85.46%, Valid: 85.50%, Test: 85.56%
Run 01:
Highest Train: 87.10
Highest Valid: 86.94
  Final Train: 87.10
   Final Test: 87.07
All runs:
Highest Train: 87.10, nan
Highest Valid: 86.94, nan
  Final Train: 87.10, nan
   Final Test: 87.07, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4844, Train: 86.59%, Valid: 86.61%, Test: 86.62%
Epoch: 25, Loss: 0.3698, Train: 85.74%, Valid: 85.69%, Test: 85.89%
Epoch: 50, Loss: 0.3654, Train: 85.23%, Valid: 85.15%, Test: 85.37%
Epoch: 75, Loss: 0.3638, Train: 85.48%, Valid: 85.34%, Test: 85.59%
Epoch: 100, Loss: 0.3624, Train: 85.57%, Valid: 85.42%, Test: 85.67%
Epoch: 125, Loss: 0.3608, Train: 85.62%, Valid: 85.46%, Test: 85.71%
Epoch: 150, Loss: 0.3591, Train: 85.59%, Valid: 85.45%, Test: 85.70%
Epoch: 175, Loss: 0.3571, Train: 85.61%, Valid: 85.46%, Test: 85.70%
Epoch: 200, Loss: 0.3546, Train: 85.60%, Valid: 85.46%, Test: 85.70%
Epoch: 225, Loss: 0.3520, Train: 85.58%, Valid: 85.44%, Test: 85.68%
Epoch: 250, Loss: 0.3492, Train: 85.53%, Valid: 85.37%, Test: 85.63%
Epoch: 275, Loss: 0.3464, Train: 85.47%, Valid: 85.31%, Test: 85.57%
Epoch: 300, Loss: 0.3439, Train: 85.47%, Valid: 85.30%, Test: 85.57%
Epoch: 325, Loss: 0.3414, Train: 85.46%, Valid: 85.30%, Test: 85.57%
Epoch: 350, Loss: 0.3390, Train: 85.50%, Valid: 85.34%, Test: 85.62%
Epoch: 375, Loss: 0.3363, Train: 85.56%, Valid: 85.42%, Test: 85.70%
Epoch: 400, Loss: 0.3335, Train: 86.05%, Valid: 85.94%, Test: 86.14%
Epoch: 425, Loss: 0.3313, Train: 86.17%, Valid: 86.06%, Test: 86.26%
Epoch: 450, Loss: 0.3297, Train: 86.25%, Valid: 86.14%, Test: 86.34%
Epoch: 475, Loss: 0.3440, Train: 86.54%, Valid: 86.38%, Test: 86.60%
Run 01:
Highest Train: 87.34
Highest Valid: 87.23
  Final Train: 87.34
   Final Test: 87.45
All runs:
Highest Train: 87.34, nan
Highest Valid: 87.23, nan
  Final Train: 87.34, nan
   Final Test: 87.45, nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.0001, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=3, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
  (fc3): Linear(in_features=256, out_features=256, bias=True)
)
Epoch: 00, Loss: 0.4238, Train: 85.38%, Valid: 85.19%, Test: 85.45%
Epoch: 25, Loss: 0.3656, Train: 85.44%, Valid: 85.28%, Test: 85.51%
Epoch: 50, Loss: 0.3644, Train: 85.36%, Valid: 85.21%, Test: 85.45%
Epoch: 75, Loss: 0.3632, Train: 85.38%, Valid: 85.24%, Test: 85.47%
Epoch: 100, Loss: 0.3620, Train: 85.36%, Valid: 85.22%, Test: 85.45%
Epoch: 125, Loss: 0.3607, Train: 85.38%, Valid: 85.25%, Test: 85.47%
Epoch: 150, Loss: 0.3592, Train: 85.43%, Valid: 85.29%, Test: 85.51%
Epoch: 175, Loss: 0.3576, Train: 85.41%, Valid: 85.26%, Test: 85.49%
Epoch: 200, Loss: 0.3558, Train: 85.43%, Valid: 85.28%, Test: 85.51%
Epoch: 225, Loss: 0.3538, Train: 85.49%, Valid: 85.34%, Test: 85.56%
Epoch: 250, Loss: 0.3517, Train: 85.56%, Valid: 85.42%, Test: 85.62%
Epoch: 275, Loss: 0.3494, Train: 85.48%, Valid: 85.33%, Test: 85.54%
Epoch: 300, Loss: 0.3472, Train: 85.47%, Valid: 85.31%, Test: 85.52%
Epoch: 325, Loss: 0.3449, Train: 85.40%, Valid: 85.24%, Test: 85.47%
Epoch: 350, Loss: 0.3423, Train: 85.52%, Valid: 85.35%, Test: 85.56%
Epoch: 375, Loss: 0.3398, Train: 85.49%, Valid: 85.33%, Test: 85.54%
Epoch: 400, Loss: 0.3376, Train: 85.46%, Valid: 85.30%, Test: 85.52%
Epoch: 425, Loss: 0.3361, Train: 85.50%, Valid: 85.31%, Test: 85.55%
Epoch: 450, Loss: 0.3342, Train: 85.47%, Valid: 85.28%, Test: 85.54%
Epoch: 475, Loss: 0.3323, Train: 85.57%, Valid: 85.39%, Test: 85.63%
Run 01:
Highest Train: 87.68
Highest Valid: 87.57
  Final Train: 87.68
   Final Test: 87.61
All runs:
Highest Train: 87.68, nan
Highest Valid: 87.57, nan
  Final Train: 87.68, nan
   Final Test: 87.61, nan
Saving results to results/genius.csv
20211123-14:16 ---> 20211123-18:02 Totl:13613 seconds
