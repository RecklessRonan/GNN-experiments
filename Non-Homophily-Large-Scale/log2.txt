nohup: ignoring input
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6926, Train: 52.96%, Valid: 52.94%, Test: 53.10%
Epoch: 25, Loss: 0.6680, Train: 59.72%, Valid: 59.31%, Test: 59.37%
Epoch: 50, Loss: 0.6665, Train: 59.86%, Valid: 59.51%, Test: 59.44%
Epoch: 75, Loss: 0.6650, Train: 60.01%, Valid: 59.62%, Test: 59.71%
Epoch: 100, Loss: 0.6626, Train: 60.58%, Valid: 60.36%, Test: 60.25%
Epoch: 125, Loss: 0.6624, Train: 60.66%, Valid: 60.55%, Test: 60.34%
Epoch: 150, Loss: 0.6577, Train: 60.88%, Valid: 60.72%, Test: 60.57%
Epoch: 175, Loss: 0.6561, Train: 61.00%, Valid: 60.79%, Test: 60.62%
Epoch: 200, Loss: 0.6557, Train: 61.05%, Valid: 60.76%, Test: 60.62%
Epoch: 225, Loss: 0.6547, Train: 61.33%, Valid: 61.12%, Test: 61.04%
Epoch: 250, Loss: 0.6547, Train: 61.31%, Valid: 61.11%, Test: 60.92%
Epoch: 275, Loss: 0.6531, Train: 61.43%, Valid: 61.30%, Test: 61.17%
Epoch: 300, Loss: 0.6526, Train: 61.51%, Valid: 61.35%, Test: 61.09%
Epoch: 325, Loss: 0.6527, Train: 61.52%, Valid: 61.33%, Test: 61.15%
Epoch: 350, Loss: 0.6525, Train: 61.51%, Valid: 61.37%, Test: 61.17%
Epoch: 375, Loss: 0.6520, Train: 61.55%, Valid: 61.28%, Test: 61.08%
Epoch: 400, Loss: 0.6532, Train: 61.55%, Valid: 61.34%, Test: 61.12%
Epoch: 425, Loss: 0.6520, Train: 61.53%, Valid: 61.38%, Test: 61.16%
Epoch: 450, Loss: 0.6518, Train: 61.53%, Valid: 61.15%, Test: 60.96%
Epoch: 475, Loss: 0.6523, Train: 61.52%, Valid: 61.25%, Test: 61.08%
Epoch: 500, Loss: 0.6515, Train: 61.53%, Valid: 61.33%, Test: 61.12%
Epoch: 525, Loss: 0.6529, Train: 61.54%, Valid: 61.41%, Test: 61.20%
Epoch: 550, Loss: 0.6513, Train: 61.62%, Valid: 61.33%, Test: 61.15%
Epoch: 575, Loss: 0.6520, Train: 61.48%, Valid: 61.34%, Test: 61.16%
Epoch: 600, Loss: 0.6515, Train: 61.54%, Valid: 61.33%, Test: 61.08%
Epoch: 625, Loss: 0.6537, Train: 61.36%, Valid: 61.09%, Test: 61.16%
Epoch: 650, Loss: 0.6513, Train: 61.57%, Valid: 61.34%, Test: 61.09%
Epoch: 675, Loss: 0.6510, Train: 61.65%, Valid: 61.25%, Test: 60.99%
Epoch: 700, Loss: 0.6530, Train: 61.54%, Valid: 61.36%, Test: 61.18%
Epoch: 725, Loss: 0.6508, Train: 61.66%, Valid: 61.34%, Test: 61.09%
Epoch: 750, Loss: 0.6537, Train: 61.62%, Valid: 61.29%, Test: 60.97%
Epoch: 775, Loss: 0.6513, Train: 61.59%, Valid: 61.30%, Test: 61.14%
Epoch: 800, Loss: 0.6509, Train: 61.62%, Valid: 61.32%, Test: 61.05%
Epoch: 825, Loss: 0.6516, Train: 61.65%, Valid: 61.24%, Test: 61.01%
Epoch: 850, Loss: 0.6509, Train: 61.60%, Valid: 61.37%, Test: 61.11%
Epoch: 875, Loss: 0.6510, Train: 61.70%, Valid: 61.31%, Test: 61.06%
Epoch: 900, Loss: 0.6506, Train: 61.68%, Valid: 61.26%, Test: 61.04%
Epoch: 925, Loss: 0.6522, Train: 61.48%, Valid: 61.20%, Test: 61.06%
Epoch: 950, Loss: 0.6505, Train: 61.63%, Valid: 61.40%, Test: 61.22%
Epoch: 975, Loss: 0.6515, Train: 61.63%, Valid: 61.32%, Test: 61.11%
Run 01:
Highest Train: 61.78
Highest Valid: 61.46
  Final Train: 61.64
   Final Test: 61.24
All runs:
Highest Train: 61.78 ± nan
Highest Valid: 61.46 ± nan
  Final Train: 61.64 ± nan
   Final Test: 61.24 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6987, Train: 53.06%, Valid: 53.13%, Test: 53.24%
Epoch: 25, Loss: 0.6672, Train: 59.85%, Valid: 59.43%, Test: 59.54%
Epoch: 50, Loss: 0.6665, Train: 59.87%, Valid: 59.43%, Test: 59.52%
Epoch: 75, Loss: 0.6653, Train: 59.96%, Valid: 59.52%, Test: 59.61%
Epoch: 100, Loss: 0.6642, Train: 60.14%, Valid: 59.87%, Test: 60.05%
Epoch: 125, Loss: 0.6631, Train: 60.27%, Valid: 59.93%, Test: 60.12%
Epoch: 150, Loss: 0.6616, Train: 60.41%, Valid: 60.12%, Test: 60.33%
Epoch: 175, Loss: 0.6630, Train: 60.91%, Valid: 60.63%, Test: 60.78%
Epoch: 200, Loss: 0.6578, Train: 61.01%, Valid: 60.70%, Test: 60.90%
Epoch: 225, Loss: 0.6586, Train: 61.13%, Valid: 60.74%, Test: 61.04%
Epoch: 250, Loss: 0.6560, Train: 61.10%, Valid: 60.88%, Test: 60.91%
Epoch: 275, Loss: 0.6543, Train: 61.27%, Valid: 60.95%, Test: 61.17%
Epoch: 300, Loss: 0.6532, Train: 61.34%, Valid: 61.23%, Test: 61.15%
Epoch: 325, Loss: 0.6523, Train: 61.58%, Valid: 61.38%, Test: 61.55%
Epoch: 350, Loss: 0.6515, Train: 61.68%, Valid: 61.44%, Test: 61.44%
Epoch: 375, Loss: 0.6509, Train: 61.66%, Valid: 61.47%, Test: 61.48%
Epoch: 400, Loss: 0.6506, Train: 61.75%, Valid: 61.50%, Test: 61.49%
Epoch: 425, Loss: 0.6558, Train: 61.48%, Valid: 61.42%, Test: 61.05%
Epoch: 450, Loss: 0.6511, Train: 61.81%, Valid: 61.54%, Test: 61.48%
Epoch: 475, Loss: 0.6507, Train: 61.54%, Valid: 61.16%, Test: 61.22%
Epoch: 500, Loss: 0.6504, Train: 61.74%, Valid: 61.51%, Test: 61.62%
Epoch: 525, Loss: 0.6498, Train: 61.81%, Valid: 61.54%, Test: 61.42%
Epoch: 550, Loss: 0.6507, Train: 61.78%, Valid: 61.51%, Test: 61.51%
Epoch: 575, Loss: 0.6495, Train: 61.88%, Valid: 61.64%, Test: 61.54%
Epoch: 600, Loss: 0.6524, Train: 61.61%, Valid: 61.41%, Test: 61.25%
Epoch: 625, Loss: 0.6497, Train: 61.84%, Valid: 61.53%, Test: 61.56%
Epoch: 650, Loss: 0.6512, Train: 61.74%, Valid: 61.47%, Test: 61.46%
Epoch: 675, Loss: 0.6495, Train: 61.82%, Valid: 61.59%, Test: 61.52%
Epoch: 700, Loss: 0.6517, Train: 61.85%, Valid: 61.60%, Test: 61.50%
Epoch: 725, Loss: 0.6490, Train: 61.86%, Valid: 61.49%, Test: 61.54%
Epoch: 750, Loss: 0.6529, Train: 61.82%, Valid: 61.59%, Test: 61.46%
Epoch: 775, Loss: 0.6505, Train: 61.89%, Valid: 61.56%, Test: 61.55%
Epoch: 800, Loss: 0.6527, Train: 60.60%, Valid: 60.29%, Test: 60.43%
Epoch: 825, Loss: 0.6506, Train: 61.79%, Valid: 61.47%, Test: 61.55%
Epoch: 850, Loss: 0.6490, Train: 61.86%, Valid: 61.61%, Test: 61.53%
Epoch: 875, Loss: 0.6506, Train: 61.82%, Valid: 61.61%, Test: 61.52%
Epoch: 900, Loss: 0.6489, Train: 61.89%, Valid: 61.63%, Test: 61.54%
Epoch: 925, Loss: 0.6494, Train: 61.87%, Valid: 61.54%, Test: 61.43%
Epoch: 950, Loss: 0.6497, Train: 61.86%, Valid: 61.62%, Test: 61.57%
Epoch: 975, Loss: 0.6491, Train: 61.80%, Valid: 61.52%, Test: 61.33%
Run 01:
Highest Train: 61.97
Highest Valid: 61.71
  Final Train: 61.83
   Final Test: 61.49
All runs:
Highest Train: 61.97 ± nan
Highest Valid: 61.71 ± nan
  Final Train: 61.83 ± nan
   Final Test: 61.49 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.2917, Train: 47.38%, Valid: 47.35%, Test: 47.28%
Epoch: 25, Loss: 0.9813, Train: 48.10%, Valid: 48.32%, Test: 48.24%
Epoch: 50, Loss: 0.8995, Train: 48.94%, Valid: 49.15%, Test: 49.36%
Epoch: 75, Loss: 0.8287, Train: 49.55%, Valid: 49.70%, Test: 49.78%
Epoch: 100, Loss: 0.7437, Train: 49.94%, Valid: 50.19%, Test: 50.30%
Epoch: 125, Loss: 0.6979, Train: 51.41%, Valid: 51.58%, Test: 51.45%
Epoch: 150, Loss: 0.7008, Train: 52.95%, Valid: 52.92%, Test: 53.08%
Epoch: 175, Loss: 0.6878, Train: 55.49%, Valid: 55.52%, Test: 55.21%
Epoch: 200, Loss: 0.6842, Train: 54.51%, Valid: 54.13%, Test: 54.43%
Epoch: 225, Loss: 0.6781, Train: 57.14%, Valid: 56.76%, Test: 57.28%
Epoch: 250, Loss: 0.7325, Train: 55.87%, Valid: 55.84%, Test: 55.99%
Epoch: 275, Loss: 0.6829, Train: 55.09%, Valid: 54.73%, Test: 55.00%
Epoch: 300, Loss: 0.6791, Train: 56.35%, Valid: 56.03%, Test: 56.21%
Epoch: 325, Loss: 0.6750, Train: 57.31%, Valid: 56.82%, Test: 57.45%
Epoch: 350, Loss: 0.6940, Train: 54.35%, Valid: 54.29%, Test: 54.43%
Epoch: 375, Loss: 0.6783, Train: 55.06%, Valid: 54.82%, Test: 55.05%
Epoch: 400, Loss: 0.6751, Train: 57.31%, Valid: 56.95%, Test: 57.28%
Epoch: 425, Loss: 0.6724, Train: 57.93%, Valid: 57.63%, Test: 58.01%
Epoch: 450, Loss: 0.6696, Train: 59.32%, Valid: 59.02%, Test: 59.19%
Epoch: 475, Loss: 0.6974, Train: 56.70%, Valid: 56.72%, Test: 57.01%
Epoch: 500, Loss: 0.6722, Train: 59.13%, Valid: 58.66%, Test: 58.97%
Epoch: 525, Loss: 0.6697, Train: 59.16%, Valid: 58.79%, Test: 58.94%
Epoch: 550, Loss: 0.6672, Train: 59.75%, Valid: 59.37%, Test: 59.51%
Epoch: 575, Loss: 0.6957, Train: 58.17%, Valid: 58.15%, Test: 58.40%
Epoch: 600, Loss: 0.6699, Train: 60.06%, Valid: 59.87%, Test: 59.87%
Epoch: 625, Loss: 0.6783, Train: 59.64%, Valid: 59.16%, Test: 59.31%
Epoch: 650, Loss: 0.6816, Train: 59.77%, Valid: 59.61%, Test: 59.52%
Epoch: 675, Loss: 0.6680, Train: 59.55%, Valid: 59.23%, Test: 59.24%
Epoch: 700, Loss: 0.6697, Train: 60.35%, Valid: 59.96%, Test: 60.11%
Epoch: 725, Loss: 0.6656, Train: 60.19%, Valid: 59.76%, Test: 59.98%
Epoch: 750, Loss: 0.6754, Train: 59.88%, Valid: 59.35%, Test: 59.64%
Epoch: 775, Loss: 0.6651, Train: 60.27%, Valid: 59.98%, Test: 60.19%
Epoch: 800, Loss: 0.6834, Train: 60.04%, Valid: 59.66%, Test: 59.87%
Epoch: 825, Loss: 0.6701, Train: 59.90%, Valid: 59.48%, Test: 59.67%
Epoch: 850, Loss: 0.6653, Train: 60.25%, Valid: 59.74%, Test: 60.02%
Epoch: 875, Loss: 0.6729, Train: 59.38%, Valid: 59.21%, Test: 59.39%
Epoch: 900, Loss: 0.6666, Train: 59.78%, Valid: 59.37%, Test: 59.51%
Epoch: 925, Loss: 0.6653, Train: 60.19%, Valid: 59.65%, Test: 59.93%
Epoch: 950, Loss: 0.6893, Train: 60.06%, Valid: 59.87%, Test: 59.74%
Epoch: 975, Loss: 0.6669, Train: 59.91%, Valid: 59.43%, Test: 59.67%
Run 01:
Highest Train: 60.65
Highest Valid: 60.18
  Final Train: 60.65
   Final Test: 60.38
All runs:
Highest Train: 60.65 ± nan
Highest Valid: 60.18 ± nan
  Final Train: 60.65 ± nan
   Final Test: 60.38 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6960, Train: 56.90%, Valid: 56.81%, Test: 57.10%
Epoch: 25, Loss: 0.6679, Train: 59.83%, Valid: 59.45%, Test: 59.40%
Epoch: 50, Loss: 0.6661, Train: 59.85%, Valid: 59.51%, Test: 59.60%
Epoch: 75, Loss: 0.6644, Train: 60.00%, Valid: 59.75%, Test: 59.75%
Epoch: 100, Loss: 0.6625, Train: 60.37%, Valid: 60.21%, Test: 60.10%
Epoch: 125, Loss: 0.6600, Train: 60.78%, Valid: 60.57%, Test: 60.48%
Epoch: 150, Loss: 0.6576, Train: 60.99%, Valid: 60.77%, Test: 60.67%
Epoch: 175, Loss: 0.6563, Train: 61.06%, Valid: 60.86%, Test: 60.82%
Epoch: 200, Loss: 0.6576, Train: 61.30%, Valid: 61.13%, Test: 61.04%
Epoch: 225, Loss: 0.6543, Train: 61.41%, Valid: 61.25%, Test: 61.12%
Epoch: 250, Loss: 0.6542, Train: 61.15%, Valid: 60.79%, Test: 60.84%
Epoch: 275, Loss: 0.6534, Train: 61.44%, Valid: 61.34%, Test: 61.17%
Epoch: 300, Loss: 0.6531, Train: 61.43%, Valid: 61.21%, Test: 61.03%
Epoch: 325, Loss: 0.6523, Train: 61.50%, Valid: 61.29%, Test: 61.09%
Epoch: 350, Loss: 0.6552, Train: 61.48%, Valid: 61.18%, Test: 60.98%
Epoch: 375, Loss: 0.6528, Train: 61.50%, Valid: 61.36%, Test: 61.13%
Epoch: 400, Loss: 0.6519, Train: 61.56%, Valid: 61.34%, Test: 61.14%
Epoch: 425, Loss: 0.6516, Train: 61.55%, Valid: 61.30%, Test: 61.13%
Epoch: 450, Loss: 0.6533, Train: 61.08%, Valid: 60.86%, Test: 60.66%
Epoch: 475, Loss: 0.6520, Train: 61.55%, Valid: 61.31%, Test: 61.17%
Epoch: 500, Loss: 0.6510, Train: 61.57%, Valid: 61.39%, Test: 61.18%
Epoch: 525, Loss: 0.6520, Train: 61.56%, Valid: 61.36%, Test: 61.27%
Epoch: 550, Loss: 0.6515, Train: 61.56%, Valid: 61.39%, Test: 61.19%
Epoch: 575, Loss: 0.6608, Train: 59.89%, Valid: 59.61%, Test: 58.99%
Epoch: 600, Loss: 0.6511, Train: 61.60%, Valid: 61.34%, Test: 61.15%
Epoch: 625, Loss: 0.6505, Train: 61.67%, Valid: 61.32%, Test: 61.15%
Epoch: 650, Loss: 0.6649, Train: 61.67%, Valid: 61.29%, Test: 61.14%
Epoch: 675, Loss: 0.6526, Train: 61.54%, Valid: 61.36%, Test: 61.16%
Epoch: 700, Loss: 0.6503, Train: 61.72%, Valid: 61.41%, Test: 61.25%
Epoch: 725, Loss: 0.6508, Train: 61.59%, Valid: 61.32%, Test: 61.17%
Epoch: 750, Loss: 0.6503, Train: 61.65%, Valid: 61.32%, Test: 61.10%
Epoch: 775, Loss: 0.6499, Train: 61.73%, Valid: 61.29%, Test: 61.15%
Epoch: 800, Loss: 0.6511, Train: 61.77%, Valid: 61.27%, Test: 61.01%
Epoch: 825, Loss: 0.6496, Train: 61.76%, Valid: 61.39%, Test: 61.11%
Epoch: 850, Loss: 0.6504, Train: 61.79%, Valid: 61.36%, Test: 61.16%
Epoch: 875, Loss: 0.6512, Train: 61.70%, Valid: 61.34%, Test: 61.11%
Epoch: 900, Loss: 0.6489, Train: 61.87%, Valid: 61.45%, Test: 61.36%
Epoch: 925, Loss: 0.6502, Train: 61.65%, Valid: 61.31%, Test: 61.20%
Epoch: 950, Loss: 0.6483, Train: 61.87%, Valid: 61.44%, Test: 61.26%
Epoch: 975, Loss: 0.6557, Train: 60.54%, Valid: 60.26%, Test: 59.77%
Run 01:
Highest Train: 61.97
Highest Valid: 61.56
  Final Train: 61.69
   Final Test: 61.33
All runs:
Highest Train: 61.97 ± nan
Highest Valid: 61.56 ± nan
  Final Train: 61.69 ± nan
   Final Test: 61.33 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7255, Train: 57.73%, Valid: 57.64%, Test: 57.79%
Epoch: 25, Loss: 0.6660, Train: 60.09%, Valid: 59.71%, Test: 59.76%
Epoch: 50, Loss: 0.6644, Train: 60.13%, Valid: 59.80%, Test: 59.96%
Epoch: 75, Loss: 0.6627, Train: 60.35%, Valid: 60.01%, Test: 60.18%
Epoch: 100, Loss: 0.6607, Train: 60.81%, Valid: 60.48%, Test: 60.60%
Epoch: 125, Loss: 0.6584, Train: 61.03%, Valid: 60.74%, Test: 60.80%
Epoch: 150, Loss: 0.6568, Train: 60.95%, Valid: 60.81%, Test: 60.74%
Epoch: 175, Loss: 0.6556, Train: 61.12%, Valid: 60.87%, Test: 60.93%
Epoch: 200, Loss: 0.6543, Train: 61.45%, Valid: 61.18%, Test: 61.29%
Epoch: 225, Loss: 0.6540, Train: 61.37%, Valid: 61.17%, Test: 61.15%
Epoch: 250, Loss: 0.6524, Train: 61.57%, Valid: 61.37%, Test: 61.39%
Epoch: 275, Loss: 0.6517, Train: 61.70%, Valid: 61.49%, Test: 61.55%
Epoch: 300, Loss: 0.6523, Train: 61.74%, Valid: 61.53%, Test: 61.47%
Epoch: 325, Loss: 0.6531, Train: 61.14%, Valid: 60.76%, Test: 60.90%
Epoch: 350, Loss: 0.6509, Train: 61.78%, Valid: 61.48%, Test: 61.53%
Epoch: 375, Loss: 0.6499, Train: 61.87%, Valid: 61.58%, Test: 61.45%
Epoch: 400, Loss: 0.6511, Train: 61.70%, Valid: 61.41%, Test: 61.52%
Epoch: 425, Loss: 0.6555, Train: 61.67%, Valid: 61.50%, Test: 61.36%
Epoch: 450, Loss: 0.6501, Train: 61.80%, Valid: 61.62%, Test: 61.39%
Epoch: 475, Loss: 0.6494, Train: 61.91%, Valid: 61.66%, Test: 61.59%
Epoch: 500, Loss: 0.6528, Train: 61.70%, Valid: 61.54%, Test: 61.42%
Epoch: 525, Loss: 0.6501, Train: 61.80%, Valid: 61.57%, Test: 61.57%
Epoch: 550, Loss: 0.6491, Train: 61.88%, Valid: 61.56%, Test: 61.60%
Epoch: 575, Loss: 0.6495, Train: 61.77%, Valid: 61.49%, Test: 61.39%
Epoch: 600, Loss: 0.6504, Train: 61.83%, Valid: 61.58%, Test: 61.56%
Epoch: 625, Loss: 0.6582, Train: 61.73%, Valid: 61.55%, Test: 61.37%
Epoch: 650, Loss: 0.6498, Train: 61.87%, Valid: 61.62%, Test: 61.58%
Epoch: 675, Loss: 0.6486, Train: 61.96%, Valid: 61.68%, Test: 61.63%
Epoch: 700, Loss: 0.6504, Train: 61.92%, Valid: 61.73%, Test: 61.60%
Epoch: 725, Loss: 0.6484, Train: 61.91%, Valid: 61.59%, Test: 61.51%
Epoch: 750, Loss: 0.6497, Train: 61.41%, Valid: 61.21%, Test: 60.97%
Epoch: 775, Loss: 0.6485, Train: 61.89%, Valid: 61.56%, Test: 61.48%
Epoch: 800, Loss: 0.6507, Train: 61.68%, Valid: 61.41%, Test: 61.50%
Epoch: 825, Loss: 0.6493, Train: 61.93%, Valid: 61.62%, Test: 61.70%
Epoch: 850, Loss: 0.6489, Train: 61.98%, Valid: 61.64%, Test: 61.69%
Epoch: 875, Loss: 0.6494, Train: 62.01%, Valid: 61.75%, Test: 61.53%
Epoch: 900, Loss: 0.6487, Train: 62.02%, Valid: 61.69%, Test: 61.65%
Epoch: 925, Loss: 0.6488, Train: 61.90%, Valid: 61.66%, Test: 61.62%
Epoch: 950, Loss: 0.6482, Train: 61.87%, Valid: 61.58%, Test: 61.45%
Epoch: 975, Loss: 0.6486, Train: 61.92%, Valid: 61.76%, Test: 61.52%
Run 01:
Highest Train: 62.11
Highest Valid: 61.88
  Final Train: 62.02
   Final Test: 61.70
All runs:
Highest Train: 62.11 ± nan
Highest Valid: 61.88 ± nan
  Final Train: 62.02 ± nan
   Final Test: 61.70 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 3.5750, Train: 51.53%, Valid: 51.41%, Test: 51.56%
Epoch: 25, Loss: 0.8610, Train: 54.24%, Valid: 54.32%, Test: 54.57%
Epoch: 50, Loss: 0.7487, Train: 55.85%, Valid: 55.87%, Test: 55.61%
Epoch: 75, Loss: 0.6964, Train: 56.89%, Valid: 56.73%, Test: 56.45%
Epoch: 100, Loss: 0.7080, Train: 55.67%, Valid: 55.43%, Test: 55.30%
Epoch: 125, Loss: 0.6852, Train: 58.42%, Valid: 58.24%, Test: 58.26%
Epoch: 150, Loss: 0.6855, Train: 58.96%, Valid: 58.88%, Test: 58.93%
Epoch: 175, Loss: 0.6771, Train: 58.44%, Valid: 58.08%, Test: 58.36%
Epoch: 200, Loss: 0.6733, Train: 59.29%, Valid: 58.92%, Test: 59.10%
Epoch: 225, Loss: 0.6774, Train: 59.57%, Valid: 59.26%, Test: 59.41%
Epoch: 250, Loss: 0.6730, Train: 58.65%, Valid: 58.52%, Test: 58.45%
Epoch: 275, Loss: 0.6954, Train: 57.69%, Valid: 57.67%, Test: 57.47%
Epoch: 300, Loss: 0.6711, Train: 59.65%, Valid: 59.35%, Test: 59.53%
Epoch: 325, Loss: 0.6927, Train: 58.32%, Valid: 57.98%, Test: 58.03%
Epoch: 350, Loss: 0.6713, Train: 59.36%, Valid: 59.05%, Test: 59.27%
Epoch: 375, Loss: 0.6730, Train: 59.64%, Valid: 59.36%, Test: 59.57%
Epoch: 400, Loss: 0.6673, Train: 59.62%, Valid: 59.26%, Test: 59.41%
Epoch: 425, Loss: 0.6754, Train: 59.25%, Valid: 58.79%, Test: 59.14%
Epoch: 450, Loss: 0.6678, Train: 59.70%, Valid: 59.26%, Test: 59.51%
Epoch: 475, Loss: 0.6702, Train: 59.81%, Valid: 59.23%, Test: 59.69%
Epoch: 500, Loss: 0.6868, Train: 57.25%, Valid: 57.21%, Test: 57.42%
Epoch: 525, Loss: 0.6677, Train: 59.81%, Valid: 59.42%, Test: 59.69%
Epoch: 550, Loss: 0.6705, Train: 59.84%, Valid: 59.44%, Test: 59.64%
Epoch: 575, Loss: 0.6654, Train: 59.90%, Valid: 59.47%, Test: 59.68%
Epoch: 600, Loss: 0.6710, Train: 59.76%, Valid: 59.28%, Test: 59.42%
Epoch: 625, Loss: 0.6660, Train: 59.94%, Valid: 59.62%, Test: 59.66%
Epoch: 650, Loss: 0.6666, Train: 59.90%, Valid: 59.40%, Test: 59.62%
Epoch: 675, Loss: 0.6743, Train: 59.14%, Valid: 59.01%, Test: 58.85%
Epoch: 700, Loss: 0.6651, Train: 59.92%, Valid: 59.58%, Test: 59.82%
Epoch: 725, Loss: 0.6654, Train: 59.97%, Valid: 59.56%, Test: 59.72%
Epoch: 750, Loss: 0.6696, Train: 59.92%, Valid: 59.58%, Test: 59.61%
Epoch: 775, Loss: 0.6651, Train: 60.03%, Valid: 59.69%, Test: 59.74%
Epoch: 800, Loss: 0.6667, Train: 59.87%, Valid: 59.47%, Test: 59.72%
Epoch: 825, Loss: 0.6666, Train: 60.06%, Valid: 59.70%, Test: 59.75%
Epoch: 850, Loss: 0.6797, Train: 59.57%, Valid: 59.33%, Test: 59.29%
Epoch: 875, Loss: 0.6644, Train: 60.06%, Valid: 59.63%, Test: 59.84%
Epoch: 900, Loss: 0.6650, Train: 60.11%, Valid: 59.71%, Test: 59.80%
Epoch: 925, Loss: 0.6736, Train: 59.86%, Valid: 59.52%, Test: 59.47%
Epoch: 950, Loss: 0.6661, Train: 60.07%, Valid: 59.69%, Test: 59.90%
Epoch: 975, Loss: 0.6655, Train: 60.13%, Valid: 59.75%, Test: 59.95%
Run 01:
Highest Train: 60.20
Highest Valid: 59.84
  Final Train: 60.06
   Final Test: 59.99
All runs:
Highest Train: 60.20 ± nan
Highest Valid: 59.84 ± nan
  Final Train: 60.06 ± nan
   Final Test: 59.99 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6986, Train: 59.02%, Valid: 58.72%, Test: 58.85%
Epoch: 25, Loss: 0.6685, Train: 59.58%, Valid: 59.15%, Test: 59.14%
Epoch: 50, Loss: 0.6661, Train: 59.89%, Valid: 59.54%, Test: 59.58%
Epoch: 75, Loss: 0.6646, Train: 60.25%, Valid: 60.03%, Test: 59.94%
Epoch: 100, Loss: 0.6622, Train: 60.63%, Valid: 60.38%, Test: 60.29%
Epoch: 125, Loss: 0.6595, Train: 60.89%, Valid: 60.66%, Test: 60.58%
Epoch: 150, Loss: 0.6580, Train: 61.08%, Valid: 60.77%, Test: 60.68%
Epoch: 175, Loss: 0.6553, Train: 61.16%, Valid: 60.88%, Test: 60.81%
Epoch: 200, Loss: 0.6549, Train: 61.30%, Valid: 60.95%, Test: 60.99%
Epoch: 225, Loss: 0.6610, Train: 61.46%, Valid: 61.19%, Test: 61.28%
Epoch: 250, Loss: 0.6527, Train: 61.63%, Valid: 61.41%, Test: 61.50%
Epoch: 275, Loss: 0.6536, Train: 61.22%, Valid: 60.90%, Test: 60.98%
Epoch: 300, Loss: 0.6521, Train: 61.58%, Valid: 61.36%, Test: 61.29%
Epoch: 325, Loss: 0.6510, Train: 61.67%, Valid: 61.42%, Test: 61.43%
Epoch: 350, Loss: 0.6605, Train: 61.11%, Valid: 60.97%, Test: 60.86%
Epoch: 375, Loss: 0.6515, Train: 61.64%, Valid: 61.45%, Test: 61.41%
Epoch: 400, Loss: 0.6517, Train: 61.14%, Valid: 60.91%, Test: 60.92%
Epoch: 425, Loss: 0.6510, Train: 61.70%, Valid: 61.45%, Test: 61.40%
Epoch: 450, Loss: 0.6492, Train: 61.83%, Valid: 61.60%, Test: 61.71%
Epoch: 475, Loss: 0.6501, Train: 61.80%, Valid: 61.55%, Test: 61.54%
Epoch: 500, Loss: 0.6517, Train: 61.82%, Valid: 61.50%, Test: 61.52%
Epoch: 525, Loss: 0.6524, Train: 61.81%, Valid: 61.55%, Test: 61.53%
Epoch: 550, Loss: 0.6488, Train: 61.78%, Valid: 61.64%, Test: 61.31%
Epoch: 575, Loss: 0.6493, Train: 61.83%, Valid: 61.59%, Test: 61.65%
Epoch: 600, Loss: 0.6520, Train: 61.70%, Valid: 61.44%, Test: 61.38%
Epoch: 625, Loss: 0.6492, Train: 61.82%, Valid: 61.61%, Test: 61.65%
Epoch: 650, Loss: 0.6565, Train: 61.90%, Valid: 61.51%, Test: 61.55%
Epoch: 675, Loss: 0.6487, Train: 61.86%, Valid: 61.68%, Test: 61.62%
Epoch: 700, Loss: 0.6514, Train: 61.77%, Valid: 61.55%, Test: 61.57%
Epoch: 725, Loss: 0.6476, Train: 61.99%, Valid: 61.79%, Test: 61.76%
Epoch: 750, Loss: 0.6480, Train: 61.98%, Valid: 61.71%, Test: 61.52%
Epoch: 775, Loss: 0.6484, Train: 61.89%, Valid: 61.65%, Test: 61.70%
Epoch: 800, Loss: 0.6523, Train: 61.51%, Valid: 61.23%, Test: 61.07%
Epoch: 825, Loss: 0.6491, Train: 61.87%, Valid: 61.58%, Test: 61.55%
Epoch: 850, Loss: 0.6469, Train: 62.03%, Valid: 61.80%, Test: 61.81%
Epoch: 875, Loss: 0.6487, Train: 61.87%, Valid: 61.62%, Test: 61.58%
Epoch: 900, Loss: 0.6507, Train: 62.03%, Valid: 61.74%, Test: 61.62%
Epoch: 925, Loss: 0.6469, Train: 62.06%, Valid: 61.82%, Test: 61.76%
Epoch: 950, Loss: 0.6472, Train: 61.86%, Valid: 61.61%, Test: 61.52%
Epoch: 975, Loss: 0.6519, Train: 62.03%, Valid: 61.60%, Test: 61.69%
Run 01:
Highest Train: 62.17
Highest Valid: 61.94
  Final Train: 62.10
   Final Test: 61.87
All runs:
Highest Train: 62.17 ± nan
Highest Valid: 61.94 ± nan
  Final Train: 62.10 ± nan
   Final Test: 61.87 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7810, Train: 52.96%, Valid: 52.94%, Test: 53.10%
Epoch: 25, Loss: 0.6784, Train: 59.78%, Valid: 59.43%, Test: 59.55%
Epoch: 50, Loss: 0.6659, Train: 59.53%, Valid: 59.07%, Test: 59.31%
Epoch: 75, Loss: 0.6642, Train: 60.02%, Valid: 59.75%, Test: 59.92%
Epoch: 100, Loss: 0.6629, Train: 60.33%, Valid: 59.85%, Test: 60.11%
Epoch: 125, Loss: 0.6631, Train: 60.23%, Valid: 60.00%, Test: 60.01%
Epoch: 150, Loss: 0.6607, Train: 60.61%, Valid: 60.22%, Test: 60.35%
Epoch: 175, Loss: 0.6597, Train: 60.73%, Valid: 60.46%, Test: 60.57%
Epoch: 200, Loss: 0.6584, Train: 61.00%, Valid: 60.69%, Test: 60.80%
Epoch: 225, Loss: 0.6582, Train: 61.07%, Valid: 60.75%, Test: 60.82%
Epoch: 250, Loss: 0.6567, Train: 61.04%, Valid: 60.72%, Test: 60.86%
Epoch: 275, Loss: 0.6587, Train: 61.12%, Valid: 60.83%, Test: 60.95%
Epoch: 300, Loss: 0.6557, Train: 61.21%, Valid: 60.83%, Test: 61.03%
Epoch: 325, Loss: 0.6567, Train: 61.02%, Valid: 60.69%, Test: 60.73%
Epoch: 350, Loss: 0.6563, Train: 61.34%, Valid: 60.96%, Test: 61.09%
Epoch: 375, Loss: 0.6541, Train: 61.31%, Valid: 60.95%, Test: 61.07%
Epoch: 400, Loss: 0.6542, Train: 61.22%, Valid: 60.92%, Test: 60.92%
Epoch: 425, Loss: 0.6567, Train: 61.36%, Valid: 61.00%, Test: 61.14%
Epoch: 450, Loss: 0.6538, Train: 61.45%, Valid: 61.06%, Test: 61.35%
Epoch: 475, Loss: 0.6542, Train: 61.41%, Valid: 61.00%, Test: 61.22%
Epoch: 500, Loss: 0.6548, Train: 61.26%, Valid: 60.99%, Test: 60.97%
Epoch: 525, Loss: 0.6542, Train: 61.52%, Valid: 61.21%, Test: 61.28%
Epoch: 550, Loss: 0.6556, Train: 60.60%, Valid: 60.48%, Test: 60.26%
Epoch: 575, Loss: 0.6540, Train: 61.52%, Valid: 61.09%, Test: 61.29%
Epoch: 600, Loss: 0.6520, Train: 61.55%, Valid: 61.23%, Test: 61.27%
Epoch: 625, Loss: 0.6543, Train: 60.90%, Valid: 60.67%, Test: 60.52%
Epoch: 650, Loss: 0.6544, Train: 61.59%, Valid: 61.27%, Test: 61.36%
Epoch: 675, Loss: 0.6512, Train: 61.80%, Valid: 61.44%, Test: 61.59%
Epoch: 700, Loss: 0.6517, Train: 61.65%, Valid: 61.37%, Test: 61.47%
Epoch: 725, Loss: 0.6659, Train: 60.70%, Valid: 60.41%, Test: 60.38%
Epoch: 750, Loss: 0.6520, Train: 61.60%, Valid: 61.26%, Test: 61.40%
Epoch: 775, Loss: 0.6502, Train: 61.95%, Valid: 61.69%, Test: 61.67%
Epoch: 800, Loss: 0.6495, Train: 61.97%, Valid: 61.72%, Test: 61.75%
Epoch: 825, Loss: 0.6503, Train: 61.71%, Valid: 61.48%, Test: 61.42%
Epoch: 850, Loss: 0.6524, Train: 61.87%, Valid: 61.83%, Test: 61.55%
Epoch: 875, Loss: 0.6497, Train: 61.86%, Valid: 61.66%, Test: 61.55%
Epoch: 900, Loss: 0.6492, Train: 62.11%, Valid: 61.87%, Test: 61.92%
Epoch: 925, Loss: 0.6511, Train: 61.77%, Valid: 61.62%, Test: 61.52%
Epoch: 950, Loss: 0.6508, Train: 61.98%, Valid: 61.72%, Test: 61.80%
Epoch: 975, Loss: 0.6754, Train: 60.79%, Valid: 60.33%, Test: 60.48%
Run 01:
Highest Train: 62.11
Highest Valid: 61.97
  Final Train: 62.01
   Final Test: 61.75
All runs:
Highest Train: 62.11 ± nan
Highest Valid: 61.97 ± nan
  Final Train: 62.01 ± nan
   Final Test: 61.75 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 20.8611, Train: 48.35%, Valid: 48.40%, Test: 48.17%
Epoch: 25, Loss: 1.4985, Train: 49.73%, Valid: 50.02%, Test: 49.92%
Epoch: 50, Loss: 1.1270, Train: 49.35%, Valid: 49.62%, Test: 49.22%
Epoch: 75, Loss: 0.9385, Train: 52.17%, Valid: 52.19%, Test: 52.11%
Epoch: 100, Loss: 0.8352, Train: 55.08%, Valid: 54.93%, Test: 54.93%
Epoch: 125, Loss: 0.7821, Train: 54.76%, Valid: 54.52%, Test: 54.47%
Epoch: 150, Loss: 0.7244, Train: 56.03%, Valid: 55.63%, Test: 55.82%
Epoch: 175, Loss: 0.7491, Train: 58.12%, Valid: 57.74%, Test: 58.04%
Epoch: 200, Loss: 0.6934, Train: 58.85%, Valid: 58.61%, Test: 58.49%
Epoch: 225, Loss: 0.6938, Train: 59.44%, Valid: 59.19%, Test: 59.27%
Epoch: 250, Loss: 0.7001, Train: 58.99%, Valid: 58.72%, Test: 58.72%
Epoch: 275, Loss: 0.6838, Train: 59.58%, Valid: 59.31%, Test: 59.21%
Epoch: 300, Loss: 0.8003, Train: 53.77%, Valid: 53.72%, Test: 53.83%
Epoch: 325, Loss: 0.7403, Train: 55.61%, Valid: 55.47%, Test: 55.59%
Epoch: 350, Loss: 0.7133, Train: 57.08%, Valid: 56.84%, Test: 56.62%
Epoch: 375, Loss: 0.6907, Train: 58.44%, Valid: 58.22%, Test: 58.01%
Epoch: 400, Loss: 0.6743, Train: 59.22%, Valid: 58.91%, Test: 58.96%
Epoch: 425, Loss: 0.7325, Train: 58.15%, Valid: 58.02%, Test: 58.06%
Epoch: 450, Loss: 0.7112, Train: 55.58%, Valid: 55.42%, Test: 55.52%
Epoch: 475, Loss: 0.6882, Train: 58.11%, Valid: 57.73%, Test: 57.53%
Epoch: 500, Loss: 0.6732, Train: 59.40%, Valid: 59.00%, Test: 59.09%
Epoch: 525, Loss: 0.6685, Train: 59.76%, Valid: 59.44%, Test: 59.28%
Epoch: 550, Loss: 0.6871, Train: 57.76%, Valid: 57.44%, Test: 57.57%
Epoch: 575, Loss: 0.6741, Train: 59.60%, Valid: 59.28%, Test: 59.25%
Epoch: 600, Loss: 0.6679, Train: 60.01%, Valid: 59.57%, Test: 59.64%
Epoch: 625, Loss: 0.6699, Train: 59.91%, Valid: 59.43%, Test: 59.51%
Epoch: 650, Loss: 0.6668, Train: 60.15%, Valid: 59.78%, Test: 59.82%
Epoch: 675, Loss: 0.6983, Train: 54.73%, Valid: 54.55%, Test: 54.60%
Epoch: 700, Loss: 0.6773, Train: 59.64%, Valid: 59.22%, Test: 59.14%
Epoch: 725, Loss: 0.6679, Train: 60.01%, Valid: 59.49%, Test: 59.68%
Epoch: 750, Loss: 0.6675, Train: 59.26%, Valid: 59.11%, Test: 59.07%
Epoch: 775, Loss: 0.6665, Train: 60.37%, Valid: 59.79%, Test: 59.95%
Epoch: 800, Loss: 0.6797, Train: 59.44%, Valid: 59.01%, Test: 58.96%
Epoch: 825, Loss: 0.6767, Train: 59.41%, Valid: 58.99%, Test: 59.03%
Epoch: 850, Loss: 0.6670, Train: 60.14%, Valid: 59.76%, Test: 59.76%
Epoch: 875, Loss: 0.7287, Train: 58.10%, Valid: 57.95%, Test: 57.69%
Epoch: 900, Loss: 0.6838, Train: 56.27%, Valid: 56.11%, Test: 56.19%
Epoch: 925, Loss: 0.6688, Train: 59.89%, Valid: 59.48%, Test: 59.58%
Epoch: 950, Loss: 0.6657, Train: 60.31%, Valid: 59.98%, Test: 60.01%
Epoch: 975, Loss: 0.6724, Train: 59.83%, Valid: 59.42%, Test: 59.48%
Run 01:
Highest Train: 60.44
Highest Valid: 60.29
  Final Train: 60.41
   Final Test: 60.07
All runs:
Highest Train: 60.44 ± nan
Highest Valid: 60.29 ± nan
  Final Train: 60.41 ± nan
   Final Test: 60.07 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6977, Train: 55.24%, Valid: 55.52%, Test: 55.40%
Epoch: 25, Loss: 0.6686, Train: 59.79%, Valid: 59.27%, Test: 59.44%
Epoch: 50, Loss: 0.6671, Train: 59.74%, Valid: 59.37%, Test: 59.38%
Epoch: 75, Loss: 0.6666, Train: 59.73%, Valid: 59.38%, Test: 59.35%
Epoch: 100, Loss: 0.6658, Train: 59.97%, Valid: 59.65%, Test: 59.67%
Epoch: 125, Loss: 0.6648, Train: 60.04%, Valid: 59.70%, Test: 59.69%
Epoch: 150, Loss: 0.6632, Train: 60.12%, Valid: 59.99%, Test: 59.95%
Epoch: 175, Loss: 0.6604, Train: 60.69%, Valid: 60.42%, Test: 60.32%
Epoch: 200, Loss: 0.6587, Train: 60.82%, Valid: 60.51%, Test: 60.53%
Epoch: 225, Loss: 0.6572, Train: 60.92%, Valid: 60.60%, Test: 60.67%
Epoch: 250, Loss: 0.6556, Train: 61.12%, Valid: 60.80%, Test: 60.88%
Epoch: 275, Loss: 0.6551, Train: 61.25%, Valid: 60.97%, Test: 60.98%
Epoch: 300, Loss: 0.6534, Train: 61.28%, Valid: 61.00%, Test: 61.06%
Epoch: 325, Loss: 0.6659, Train: 61.66%, Valid: 61.34%, Test: 61.42%
Epoch: 350, Loss: 0.6528, Train: 61.42%, Valid: 61.15%, Test: 61.28%
Epoch: 375, Loss: 0.6575, Train: 61.55%, Valid: 61.38%, Test: 61.33%
Epoch: 400, Loss: 0.6526, Train: 61.51%, Valid: 61.27%, Test: 61.29%
Epoch: 425, Loss: 0.6510, Train: 61.71%, Valid: 61.42%, Test: 61.50%
Epoch: 450, Loss: 0.6528, Train: 60.30%, Valid: 60.39%, Test: 59.88%
Epoch: 475, Loss: 0.6506, Train: 61.75%, Valid: 61.52%, Test: 61.53%
Epoch: 500, Loss: 0.6501, Train: 61.66%, Valid: 61.50%, Test: 61.41%
Epoch: 525, Loss: 0.6513, Train: 61.67%, Valid: 61.42%, Test: 61.43%
Epoch: 550, Loss: 0.6496, Train: 61.80%, Valid: 61.47%, Test: 61.55%
Epoch: 575, Loss: 0.6640, Train: 61.69%, Valid: 61.40%, Test: 61.48%
Epoch: 600, Loss: 0.6507, Train: 61.74%, Valid: 61.49%, Test: 61.61%
Epoch: 625, Loss: 0.6489, Train: 61.89%, Valid: 61.67%, Test: 61.61%
Epoch: 650, Loss: 0.6502, Train: 61.70%, Valid: 61.51%, Test: 61.53%
Epoch: 675, Loss: 0.6482, Train: 61.93%, Valid: 61.69%, Test: 61.73%
Epoch: 700, Loss: 0.6496, Train: 61.77%, Valid: 61.43%, Test: 61.59%
Epoch: 725, Loss: 0.6695, Train: 61.70%, Valid: 61.09%, Test: 61.35%
Epoch: 750, Loss: 0.6508, Train: 61.74%, Valid: 61.43%, Test: 61.52%
Epoch: 775, Loss: 0.6487, Train: 61.89%, Valid: 61.60%, Test: 61.61%
Epoch: 800, Loss: 0.6503, Train: 61.62%, Valid: 61.47%, Test: 61.22%
Epoch: 825, Loss: 0.6483, Train: 61.84%, Valid: 61.58%, Test: 61.48%
Epoch: 850, Loss: 0.6483, Train: 61.79%, Valid: 61.60%, Test: 61.57%
Epoch: 875, Loss: 0.6471, Train: 62.00%, Valid: 61.78%, Test: 61.83%
Epoch: 900, Loss: 0.6482, Train: 61.95%, Valid: 61.61%, Test: 61.63%
Epoch: 925, Loss: 0.6581, Train: 61.41%, Valid: 61.08%, Test: 60.73%
Epoch: 950, Loss: 0.6482, Train: 61.89%, Valid: 61.67%, Test: 61.72%
Epoch: 975, Loss: 0.6482, Train: 61.69%, Valid: 61.59%, Test: 61.46%
Run 01:
Highest Train: 62.13
Highest Valid: 61.90
  Final Train: 62.13
   Final Test: 61.90
All runs:
Highest Train: 62.13 ± nan
Highest Valid: 61.90 ± nan
  Final Train: 62.13 ± nan
   Final Test: 61.90 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.3602, Train: 51.44%, Valid: 51.28%, Test: 51.76%
Epoch: 25, Loss: 0.7791, Train: 58.39%, Valid: 58.18%, Test: 58.18%
Epoch: 50, Loss: 0.7144, Train: 57.63%, Valid: 57.40%, Test: 57.53%
Epoch: 75, Loss: 0.6885, Train: 57.61%, Valid: 57.46%, Test: 57.51%
Epoch: 100, Loss: 0.6788, Train: 58.69%, Valid: 58.35%, Test: 58.76%
Epoch: 125, Loss: 0.6701, Train: 59.24%, Valid: 58.74%, Test: 59.08%
Epoch: 150, Loss: 0.6679, Train: 59.57%, Valid: 59.07%, Test: 59.33%
Epoch: 175, Loss: 0.6671, Train: 59.94%, Valid: 59.36%, Test: 59.65%
Epoch: 200, Loss: 0.6666, Train: 59.97%, Valid: 59.57%, Test: 59.74%
Epoch: 225, Loss: 0.6662, Train: 60.08%, Valid: 59.65%, Test: 59.79%
Epoch: 250, Loss: 0.6659, Train: 60.14%, Valid: 59.68%, Test: 59.84%
Epoch: 275, Loss: 0.6656, Train: 60.16%, Valid: 59.67%, Test: 59.85%
Epoch: 300, Loss: 0.6653, Train: 60.17%, Valid: 59.68%, Test: 59.84%
Epoch: 325, Loss: 0.6650, Train: 60.18%, Valid: 59.66%, Test: 59.84%
Epoch: 350, Loss: 0.6648, Train: 60.19%, Valid: 59.67%, Test: 59.85%
Epoch: 375, Loss: 0.6646, Train: 60.20%, Valid: 59.69%, Test: 59.89%
Epoch: 400, Loss: 0.6644, Train: 60.22%, Valid: 59.73%, Test: 59.90%
Epoch: 425, Loss: 0.6642, Train: 60.25%, Valid: 59.79%, Test: 59.95%
Epoch: 450, Loss: 0.6640, Train: 60.29%, Valid: 59.80%, Test: 59.98%
Epoch: 475, Loss: 0.6637, Train: 60.33%, Valid: 59.83%, Test: 60.02%
Epoch: 500, Loss: 0.6636, Train: 60.38%, Valid: 59.90%, Test: 60.10%
Epoch: 525, Loss: 0.6634, Train: 60.43%, Valid: 60.00%, Test: 60.13%
Epoch: 550, Loss: 0.6632, Train: 60.46%, Valid: 60.06%, Test: 60.20%
Epoch: 575, Loss: 0.6630, Train: 60.49%, Valid: 60.12%, Test: 60.29%
Epoch: 600, Loss: 0.6628, Train: 60.53%, Valid: 60.18%, Test: 60.36%
Epoch: 625, Loss: 0.6626, Train: 60.55%, Valid: 60.23%, Test: 60.40%
Epoch: 650, Loss: 0.6625, Train: 60.57%, Valid: 60.25%, Test: 60.39%
Epoch: 675, Loss: 0.6623, Train: 60.63%, Valid: 60.29%, Test: 60.46%
Epoch: 700, Loss: 0.6621, Train: 60.67%, Valid: 60.31%, Test: 60.47%
Epoch: 725, Loss: 0.6619, Train: 60.72%, Valid: 60.34%, Test: 60.50%
Epoch: 750, Loss: 0.6619, Train: 60.73%, Valid: 60.37%, Test: 60.51%
Epoch: 775, Loss: 0.6615, Train: 60.73%, Valid: 60.37%, Test: 60.52%
Epoch: 800, Loss: 0.6614, Train: 60.77%, Valid: 60.38%, Test: 60.53%
Epoch: 825, Loss: 0.6613, Train: 60.72%, Valid: 60.33%, Test: 60.50%
Epoch: 850, Loss: 0.6610, Train: 60.79%, Valid: 60.40%, Test: 60.52%
Epoch: 875, Loss: 0.6609, Train: 60.77%, Valid: 60.47%, Test: 60.58%
Epoch: 900, Loss: 0.6608, Train: 60.76%, Valid: 60.40%, Test: 60.52%
Epoch: 925, Loss: 0.6606, Train: 60.82%, Valid: 60.40%, Test: 60.55%
Epoch: 950, Loss: 0.6604, Train: 60.83%, Valid: 60.46%, Test: 60.58%
Epoch: 975, Loss: 0.6603, Train: 60.86%, Valid: 60.48%, Test: 60.60%
Run 01:
Highest Train: 60.91
Highest Valid: 60.55
  Final Train: 60.91
   Final Test: 60.71
All runs:
Highest Train: 60.91 ± nan
Highest Valid: 60.55 ± nan
  Final Train: 60.91 ± nan
   Final Test: 60.71 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 199.3177, Train: 48.64%, Valid: 48.82%, Test: 48.42%
Epoch: 25, Loss: 1.6610, Train: 51.41%, Valid: 51.62%, Test: 51.16%
Epoch: 50, Loss: 1.5044, Train: 51.56%, Valid: 51.76%, Test: 51.29%
Epoch: 75, Loss: 1.3012, Train: 50.02%, Valid: 50.32%, Test: 49.63%
Epoch: 100, Loss: 1.1851, Train: 49.95%, Valid: 50.25%, Test: 49.46%
Epoch: 125, Loss: 1.0809, Train: 49.70%, Valid: 49.95%, Test: 49.23%
Epoch: 150, Loss: 0.9879, Train: 49.09%, Valid: 49.10%, Test: 48.87%
Epoch: 175, Loss: 0.9066, Train: 48.42%, Valid: 48.49%, Test: 48.40%
Epoch: 200, Loss: 0.8397, Train: 47.66%, Valid: 47.81%, Test: 47.72%
Epoch: 225, Loss: 0.8026, Train: 47.08%, Valid: 47.43%, Test: 47.48%
Epoch: 250, Loss: 0.7966, Train: 47.10%, Valid: 47.33%, Test: 47.51%
Epoch: 275, Loss: 0.7919, Train: 47.25%, Valid: 47.50%, Test: 47.60%
Epoch: 300, Loss: 0.7875, Train: 47.36%, Valid: 47.58%, Test: 47.69%
Epoch: 325, Loss: 0.7830, Train: 47.46%, Valid: 47.69%, Test: 47.89%
Epoch: 350, Loss: 0.7785, Train: 47.59%, Valid: 47.90%, Test: 48.06%
Epoch: 375, Loss: 0.7741, Train: 47.74%, Valid: 48.03%, Test: 48.18%
Epoch: 400, Loss: 0.7697, Train: 47.91%, Valid: 48.13%, Test: 48.29%
Epoch: 425, Loss: 0.7654, Train: 48.10%, Valid: 48.30%, Test: 48.49%
Epoch: 450, Loss: 0.7612, Train: 48.25%, Valid: 48.44%, Test: 48.69%
Epoch: 475, Loss: 0.7570, Train: 48.54%, Valid: 48.71%, Test: 48.93%
Epoch: 500, Loss: 0.7530, Train: 48.69%, Valid: 49.00%, Test: 49.16%
Epoch: 525, Loss: 0.7501, Train: 49.16%, Valid: 49.25%, Test: 49.66%
Epoch: 550, Loss: 0.7455, Train: 49.23%, Valid: 49.43%, Test: 49.78%
Epoch: 575, Loss: 0.7424, Train: 49.86%, Valid: 50.00%, Test: 50.49%
Epoch: 600, Loss: 0.7383, Train: 49.94%, Valid: 50.05%, Test: 50.62%
Epoch: 625, Loss: 0.7385, Train: 49.99%, Valid: 50.16%, Test: 50.55%
Epoch: 650, Loss: 0.7316, Train: 50.61%, Valid: 50.71%, Test: 51.32%
Epoch: 675, Loss: 0.7299, Train: 51.35%, Valid: 51.58%, Test: 51.77%
Epoch: 700, Loss: 0.7253, Train: 51.44%, Valid: 51.66%, Test: 52.10%
Epoch: 725, Loss: 0.7237, Train: 51.47%, Valid: 51.73%, Test: 52.13%
Epoch: 750, Loss: 0.7197, Train: 52.35%, Valid: 52.48%, Test: 52.90%
Epoch: 775, Loss: 0.7213, Train: 51.97%, Valid: 51.97%, Test: 52.61%
Epoch: 800, Loss: 0.7152, Train: 53.25%, Valid: 53.48%, Test: 53.56%
Epoch: 825, Loss: 0.7112, Train: 53.67%, Valid: 53.97%, Test: 54.20%
Epoch: 850, Loss: 0.7088, Train: 54.14%, Valid: 54.50%, Test: 54.71%
Epoch: 875, Loss: 0.7057, Train: 54.65%, Valid: 54.84%, Test: 55.32%
Epoch: 900, Loss: 0.7034, Train: 55.32%, Valid: 55.59%, Test: 55.86%
Epoch: 925, Loss: 0.7053, Train: 55.43%, Valid: 55.45%, Test: 55.77%
Epoch: 950, Loss: 0.7019, Train: 55.90%, Valid: 56.02%, Test: 56.40%
Epoch: 975, Loss: 0.6974, Train: 56.47%, Valid: 56.59%, Test: 56.83%
Run 01:
Highest Train: 57.07
Highest Valid: 57.31
  Final Train: 57.07
   Final Test: 57.68
All runs:
Highest Train: 57.07 ± nan
Highest Valid: 57.31 ± nan
  Final Train: 57.07 ± nan
   Final Test: 57.68 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6860, Train: 53.94%, Valid: 53.77%, Test: 53.46%
Epoch: 25, Loss: 0.6673, Train: 59.61%, Valid: 59.15%, Test: 59.30%
Epoch: 50, Loss: 0.6662, Train: 59.92%, Valid: 59.45%, Test: 59.59%
Epoch: 75, Loss: 0.6648, Train: 60.15%, Valid: 59.60%, Test: 59.84%
Epoch: 100, Loss: 0.6618, Train: 60.96%, Valid: 60.60%, Test: 60.62%
Epoch: 125, Loss: 0.6649, Train: 60.22%, Valid: 59.76%, Test: 59.87%
Epoch: 150, Loss: 0.6588, Train: 61.27%, Valid: 60.92%, Test: 60.99%
Epoch: 175, Loss: 0.6579, Train: 61.15%, Valid: 60.81%, Test: 61.01%
Epoch: 200, Loss: 0.6652, Train: 60.46%, Valid: 60.10%, Test: 60.11%
Epoch: 225, Loss: 0.6602, Train: 61.05%, Valid: 60.69%, Test: 60.72%
Epoch: 250, Loss: 0.6570, Train: 61.32%, Valid: 60.99%, Test: 61.16%
Epoch: 275, Loss: 0.6592, Train: 61.35%, Valid: 61.03%, Test: 61.13%
Epoch: 300, Loss: 0.6551, Train: 61.50%, Valid: 61.19%, Test: 61.31%
Epoch: 325, Loss: 0.6533, Train: 61.59%, Valid: 61.34%, Test: 61.52%
Epoch: 350, Loss: 0.6542, Train: 61.52%, Valid: 61.26%, Test: 61.37%
Epoch: 375, Loss: 0.6542, Train: 61.55%, Valid: 61.47%, Test: 61.45%
Epoch: 400, Loss: 0.6537, Train: 61.86%, Valid: 61.57%, Test: 61.68%
Epoch: 425, Loss: 0.6548, Train: 61.43%, Valid: 61.35%, Test: 61.02%
Epoch: 450, Loss: 0.6512, Train: 62.08%, Valid: 61.67%, Test: 61.84%
Epoch: 475, Loss: 0.6510, Train: 61.95%, Valid: 61.66%, Test: 61.72%
Epoch: 500, Loss: 0.6552, Train: 61.92%, Valid: 61.43%, Test: 61.73%
Epoch: 525, Loss: 0.6489, Train: 62.06%, Valid: 61.83%, Test: 61.94%
Epoch: 550, Loss: 0.6497, Train: 62.16%, Valid: 61.81%, Test: 61.95%
Epoch: 575, Loss: 0.6508, Train: 62.09%, Valid: 61.82%, Test: 61.85%
Epoch: 600, Loss: 0.6478, Train: 62.15%, Valid: 62.02%, Test: 62.11%
Epoch: 625, Loss: 0.6518, Train: 61.84%, Valid: 61.56%, Test: 61.60%
Epoch: 650, Loss: 0.6492, Train: 62.14%, Valid: 61.95%, Test: 61.99%
Epoch: 675, Loss: 0.6485, Train: 62.13%, Valid: 61.92%, Test: 62.00%
Epoch: 700, Loss: 0.6472, Train: 62.18%, Valid: 61.90%, Test: 61.99%
Epoch: 725, Loss: 0.6496, Train: 61.94%, Valid: 61.67%, Test: 61.71%
Epoch: 750, Loss: 0.6529, Train: 61.70%, Valid: 61.33%, Test: 61.42%
Epoch: 775, Loss: 0.6471, Train: 62.15%, Valid: 61.83%, Test: 61.99%
Epoch: 800, Loss: 0.6494, Train: 62.14%, Valid: 61.72%, Test: 61.82%
Epoch: 825, Loss: 0.6477, Train: 62.17%, Valid: 61.94%, Test: 62.04%
Epoch: 850, Loss: 0.6492, Train: 62.16%, Valid: 61.91%, Test: 61.90%
Epoch: 875, Loss: 0.6466, Train: 62.21%, Valid: 61.94%, Test: 62.04%
Epoch: 900, Loss: 0.6498, Train: 62.07%, Valid: 61.77%, Test: 61.80%
Epoch: 925, Loss: 0.6472, Train: 62.12%, Valid: 61.90%, Test: 61.97%
Epoch: 950, Loss: 0.6480, Train: 62.25%, Valid: 61.98%, Test: 61.91%
Epoch: 975, Loss: 0.6463, Train: 62.19%, Valid: 61.96%, Test: 62.04%
Run 01:
Highest Train: 62.36
Highest Valid: 62.15
  Final Train: 62.29
   Final Test: 62.05
All runs:
Highest Train: 62.36 ± nan
Highest Valid: 62.15 ± nan
  Final Train: 62.29 ± nan
   Final Test: 62.05 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 2.4506, Train: 48.15%, Valid: 47.89%, Test: 48.02%
Epoch: 25, Loss: 0.8872, Train: 52.10%, Valid: 52.06%, Test: 52.18%
Epoch: 50, Loss: 0.7907, Train: 59.72%, Valid: 59.27%, Test: 59.59%
Epoch: 75, Loss: 0.7522, Train: 59.50%, Valid: 59.00%, Test: 59.20%
Epoch: 100, Loss: 0.7111, Train: 59.69%, Valid: 59.19%, Test: 59.31%
Epoch: 125, Loss: 0.6708, Train: 59.81%, Valid: 59.32%, Test: 59.39%
Epoch: 150, Loss: 0.6690, Train: 59.98%, Valid: 59.56%, Test: 59.51%
Epoch: 175, Loss: 0.6654, Train: 60.08%, Valid: 59.66%, Test: 59.74%
Epoch: 200, Loss: 0.6649, Train: 60.16%, Valid: 59.78%, Test: 59.83%
Epoch: 225, Loss: 0.6646, Train: 60.21%, Valid: 59.76%, Test: 59.90%
Epoch: 250, Loss: 0.6644, Train: 60.21%, Valid: 59.79%, Test: 59.92%
Epoch: 275, Loss: 0.6642, Train: 60.22%, Valid: 59.81%, Test: 59.93%
Epoch: 300, Loss: 0.6640, Train: 60.24%, Valid: 59.85%, Test: 59.98%
Epoch: 325, Loss: 0.6637, Train: 60.30%, Valid: 59.88%, Test: 60.05%
Epoch: 350, Loss: 0.6635, Train: 60.34%, Valid: 59.90%, Test: 60.08%
Epoch: 375, Loss: 0.6631, Train: 60.40%, Valid: 59.87%, Test: 60.08%
Epoch: 400, Loss: 0.6624, Train: 60.49%, Valid: 59.85%, Test: 60.09%
Epoch: 425, Loss: 0.6623, Train: 60.43%, Valid: 59.89%, Test: 60.06%
Epoch: 450, Loss: 0.6626, Train: 60.20%, Valid: 59.82%, Test: 59.93%
Epoch: 475, Loss: 0.6630, Train: 60.39%, Valid: 59.88%, Test: 60.02%
Epoch: 500, Loss: 0.6612, Train: 60.76%, Valid: 60.13%, Test: 60.26%
Epoch: 525, Loss: 0.6615, Train: 60.47%, Valid: 60.02%, Test: 60.08%
Epoch: 550, Loss: 0.6607, Train: 60.72%, Valid: 60.27%, Test: 60.26%
Epoch: 575, Loss: 0.6600, Train: 60.53%, Valid: 60.15%, Test: 60.17%
Epoch: 600, Loss: 0.6632, Train: 60.74%, Valid: 60.17%, Test: 60.34%
Epoch: 625, Loss: 0.6603, Train: 60.89%, Valid: 60.39%, Test: 60.53%
Epoch: 650, Loss: 0.6603, Train: 60.86%, Valid: 60.41%, Test: 60.57%
Epoch: 675, Loss: 0.6598, Train: 60.82%, Valid: 60.36%, Test: 60.53%
Epoch: 700, Loss: 0.6587, Train: 60.96%, Valid: 60.57%, Test: 60.63%
Epoch: 725, Loss: 0.6595, Train: 60.97%, Valid: 60.60%, Test: 60.69%
Epoch: 750, Loss: 0.6595, Train: 61.01%, Valid: 60.62%, Test: 60.67%
Epoch: 775, Loss: 0.6599, Train: 60.84%, Valid: 60.47%, Test: 60.60%
Epoch: 800, Loss: 0.6597, Train: 61.03%, Valid: 60.62%, Test: 60.75%
Epoch: 825, Loss: 0.6578, Train: 60.88%, Valid: 60.34%, Test: 60.55%
Epoch: 850, Loss: 0.6576, Train: 61.11%, Valid: 60.72%, Test: 60.83%
Epoch: 875, Loss: 0.6578, Train: 61.13%, Valid: 60.75%, Test: 60.90%
Epoch: 900, Loss: 0.6594, Train: 61.18%, Valid: 60.82%, Test: 60.96%
Epoch: 925, Loss: 0.6572, Train: 61.08%, Valid: 60.76%, Test: 60.88%
Epoch: 950, Loss: 0.6572, Train: 61.21%, Valid: 60.82%, Test: 60.96%
Epoch: 975, Loss: 0.6562, Train: 61.26%, Valid: 60.92%, Test: 61.06%
Run 01:
Highest Train: 61.31
Highest Valid: 61.03
  Final Train: 61.19
   Final Test: 60.97
All runs:
Highest Train: 61.31 ± nan
Highest Valid: 61.03 ± nan
  Final Train: 61.19 ± nan
   Final Test: 60.97 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 462.4420, Train: 48.08%, Valid: 48.43%, Test: 47.92%
Epoch: 25, Loss: 2.8093, Train: 49.46%, Valid: 49.51%, Test: 49.58%
Epoch: 50, Loss: 2.2152, Train: 48.47%, Valid: 48.76%, Test: 48.89%
Epoch: 75, Loss: 2.0369, Train: 48.43%, Valid: 48.76%, Test: 48.85%
Epoch: 100, Loss: 1.8845, Train: 48.55%, Valid: 48.92%, Test: 48.96%
Epoch: 125, Loss: 1.7448, Train: 48.66%, Valid: 49.09%, Test: 49.14%
Epoch: 150, Loss: 1.6180, Train: 49.03%, Valid: 49.43%, Test: 49.48%
Epoch: 175, Loss: 1.5062, Train: 49.32%, Valid: 49.60%, Test: 49.71%
Epoch: 200, Loss: 1.4101, Train: 49.65%, Valid: 49.83%, Test: 50.11%
Epoch: 225, Loss: 1.3322, Train: 50.05%, Valid: 50.18%, Test: 50.63%
Epoch: 250, Loss: 1.2750, Train: 50.37%, Valid: 50.67%, Test: 50.99%
Epoch: 275, Loss: 1.2333, Train: 50.64%, Valid: 50.89%, Test: 51.23%
Epoch: 300, Loss: 1.2002, Train: 50.76%, Valid: 51.02%, Test: 51.21%
Epoch: 325, Loss: 1.1712, Train: 50.91%, Valid: 51.12%, Test: 51.33%
Epoch: 350, Loss: 1.1439, Train: 51.02%, Valid: 51.23%, Test: 51.40%
Epoch: 375, Loss: 1.1173, Train: 51.15%, Valid: 51.33%, Test: 51.52%
Epoch: 400, Loss: 1.0909, Train: 51.36%, Valid: 51.52%, Test: 51.72%
Epoch: 425, Loss: 1.0648, Train: 51.54%, Valid: 51.68%, Test: 51.83%
Epoch: 450, Loss: 1.0391, Train: 51.70%, Valid: 51.93%, Test: 52.00%
Epoch: 475, Loss: 1.0137, Train: 51.93%, Valid: 52.13%, Test: 52.34%
Epoch: 500, Loss: 0.9887, Train: 52.22%, Valid: 52.45%, Test: 52.62%
Epoch: 525, Loss: 0.9647, Train: 52.56%, Valid: 52.81%, Test: 52.93%
Epoch: 550, Loss: 0.9419, Train: 53.02%, Valid: 53.32%, Test: 53.35%
Epoch: 575, Loss: 0.9208, Train: 53.79%, Valid: 53.99%, Test: 54.02%
Epoch: 600, Loss: 0.9014, Train: 54.52%, Valid: 54.59%, Test: 54.94%
Epoch: 625, Loss: 0.8837, Train: 55.33%, Valid: 55.55%, Test: 55.83%
Epoch: 650, Loss: 0.8678, Train: 56.07%, Valid: 56.30%, Test: 56.58%
Epoch: 675, Loss: 0.8530, Train: 56.71%, Valid: 56.95%, Test: 57.22%
Epoch: 700, Loss: 0.8393, Train: 57.29%, Valid: 57.41%, Test: 57.71%
Epoch: 725, Loss: 0.8264, Train: 57.81%, Valid: 57.83%, Test: 58.07%
Epoch: 750, Loss: 0.8142, Train: 58.24%, Valid: 58.17%, Test: 58.51%
Epoch: 775, Loss: 0.8024, Train: 58.53%, Valid: 58.24%, Test: 58.71%
Epoch: 800, Loss: 0.7908, Train: 58.65%, Valid: 58.43%, Test: 58.71%
Epoch: 825, Loss: 0.7793, Train: 58.83%, Valid: 58.59%, Test: 58.84%
Epoch: 850, Loss: 0.7680, Train: 59.10%, Valid: 58.97%, Test: 59.16%
Epoch: 875, Loss: 0.7573, Train: 59.27%, Valid: 59.30%, Test: 59.41%
Epoch: 900, Loss: 0.7472, Train: 59.38%, Valid: 59.31%, Test: 59.54%
Epoch: 925, Loss: 0.7380, Train: 59.34%, Valid: 59.31%, Test: 59.43%
Epoch: 950, Loss: 0.7460, Train: 58.88%, Valid: 58.71%, Test: 58.88%
Epoch: 975, Loss: 0.7333, Train: 58.54%, Valid: 58.44%, Test: 58.63%
Run 01:
Highest Train: 59.49
Highest Valid: 59.49
  Final Train: 59.43
   Final Test: 59.48
All runs:
Highest Train: 59.49 ± nan
Highest Valid: 59.49 ± nan
  Final Train: 59.43 ± nan
   Final Test: 59.48 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7616, Train: 53.18%, Valid: 53.11%, Test: 53.29%
Epoch: 25, Loss: 0.6649, Train: 59.83%, Valid: 59.33%, Test: 59.42%
Epoch: 50, Loss: 0.6624, Train: 60.67%, Valid: 60.05%, Test: 60.30%
Epoch: 75, Loss: 0.6621, Train: 60.45%, Valid: 60.08%, Test: 60.27%
Epoch: 100, Loss: 0.6637, Train: 60.69%, Valid: 60.29%, Test: 60.50%
Epoch: 125, Loss: 0.6606, Train: 60.69%, Valid: 60.34%, Test: 60.32%
Epoch: 150, Loss: 0.6593, Train: 61.05%, Valid: 60.59%, Test: 60.82%
Epoch: 175, Loss: 0.6562, Train: 61.42%, Valid: 61.05%, Test: 61.23%
Epoch: 200, Loss: 0.6578, Train: 61.45%, Valid: 60.92%, Test: 61.18%
Epoch: 225, Loss: 0.6556, Train: 61.42%, Valid: 60.97%, Test: 61.23%
Epoch: 250, Loss: 0.6622, Train: 60.83%, Valid: 60.44%, Test: 60.40%
Epoch: 275, Loss: 0.6563, Train: 61.16%, Valid: 60.86%, Test: 60.92%
Epoch: 300, Loss: 0.6644, Train: 60.70%, Valid: 60.29%, Test: 60.28%
Epoch: 325, Loss: 0.6529, Train: 61.70%, Valid: 61.28%, Test: 61.49%
Epoch: 350, Loss: 0.6591, Train: 61.50%, Valid: 61.03%, Test: 61.36%
Epoch: 375, Loss: 0.6523, Train: 61.71%, Valid: 61.33%, Test: 61.55%
Epoch: 400, Loss: 0.6526, Train: 61.71%, Valid: 61.38%, Test: 61.51%
Epoch: 425, Loss: 0.6679, Train: 60.88%, Valid: 60.43%, Test: 60.47%
Epoch: 450, Loss: 0.6539, Train: 61.68%, Valid: 61.44%, Test: 61.44%
Epoch: 475, Loss: 0.6521, Train: 61.82%, Valid: 61.31%, Test: 61.59%
Epoch: 500, Loss: 0.6506, Train: 62.05%, Valid: 61.72%, Test: 61.87%
Epoch: 525, Loss: 0.6515, Train: 61.81%, Valid: 61.37%, Test: 61.55%
Epoch: 550, Loss: 0.6589, Train: 61.83%, Valid: 61.67%, Test: 61.74%
Epoch: 575, Loss: 0.6513, Train: 62.04%, Valid: 61.84%, Test: 61.90%
Epoch: 600, Loss: 0.6489, Train: 61.95%, Valid: 61.59%, Test: 61.91%
Epoch: 625, Loss: 0.6543, Train: 61.74%, Valid: 61.13%, Test: 61.37%
Epoch: 650, Loss: 0.6512, Train: 61.97%, Valid: 61.47%, Test: 61.73%
Epoch: 675, Loss: 0.6500, Train: 62.12%, Valid: 61.79%, Test: 61.96%
Epoch: 700, Loss: 0.6529, Train: 62.01%, Valid: 61.63%, Test: 61.79%
Epoch: 725, Loss: 0.6498, Train: 62.29%, Valid: 61.84%, Test: 62.06%
Epoch: 750, Loss: 0.6479, Train: 62.28%, Valid: 62.12%, Test: 62.16%
Epoch: 775, Loss: 0.6495, Train: 62.14%, Valid: 61.96%, Test: 62.05%
Epoch: 800, Loss: 0.6479, Train: 62.27%, Valid: 62.12%, Test: 62.21%
Epoch: 825, Loss: 0.6560, Train: 61.67%, Valid: 61.14%, Test: 61.34%
Epoch: 850, Loss: 0.6507, Train: 61.80%, Valid: 61.32%, Test: 61.42%
Epoch: 875, Loss: 0.6497, Train: 62.15%, Valid: 61.74%, Test: 61.89%
Epoch: 900, Loss: 0.6490, Train: 62.23%, Valid: 61.85%, Test: 61.97%
Epoch: 925, Loss: 0.6485, Train: 62.29%, Valid: 61.93%, Test: 62.05%
Epoch: 950, Loss: 0.6520, Train: 62.07%, Valid: 61.67%, Test: 61.88%
Epoch: 975, Loss: 0.6485, Train: 61.91%, Valid: 61.57%, Test: 61.83%
Run 01:
Highest Train: 62.38
Highest Valid: 62.30
  Final Train: 62.36
   Final Test: 62.19
All runs:
Highest Train: 62.38 ± nan
Highest Valid: 62.30 ± nan
  Final Train: 62.36 ± nan
   Final Test: 62.19 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 8.3403, Train: 55.94%, Valid: 56.10%, Test: 55.53%
Epoch: 25, Loss: 1.1497, Train: 59.57%, Valid: 58.93%, Test: 59.46%
Epoch: 50, Loss: 0.8599, Train: 59.23%, Valid: 58.73%, Test: 59.13%
Epoch: 75, Loss: 0.7579, Train: 58.09%, Valid: 57.97%, Test: 57.91%
Epoch: 100, Loss: 0.7024, Train: 59.41%, Valid: 58.88%, Test: 59.06%
Epoch: 125, Loss: 0.6952, Train: 59.29%, Valid: 58.85%, Test: 58.98%
Epoch: 150, Loss: 0.6922, Train: 60.03%, Valid: 59.32%, Test: 59.61%
Epoch: 175, Loss: 0.6995, Train: 58.62%, Valid: 58.32%, Test: 58.22%
Epoch: 200, Loss: 0.6949, Train: 60.23%, Valid: 59.46%, Test: 59.72%
Epoch: 225, Loss: 0.6897, Train: 60.32%, Valid: 59.54%, Test: 59.85%
Epoch: 250, Loss: 0.6858, Train: 59.98%, Valid: 59.40%, Test: 59.63%
Epoch: 275, Loss: 0.6860, Train: 60.29%, Valid: 59.45%, Test: 59.76%
Epoch: 300, Loss: 0.6835, Train: 60.12%, Valid: 59.56%, Test: 59.79%
Epoch: 325, Loss: 0.6856, Train: 60.44%, Valid: 59.95%, Test: 59.94%
Epoch: 350, Loss: 0.6809, Train: 60.51%, Valid: 59.94%, Test: 60.09%
Epoch: 375, Loss: 0.6789, Train: 60.45%, Valid: 59.86%, Test: 60.13%
Epoch: 400, Loss: 0.6805, Train: 60.62%, Valid: 60.07%, Test: 60.17%
Epoch: 425, Loss: 0.6759, Train: 60.70%, Valid: 60.18%, Test: 60.23%
Epoch: 450, Loss: 0.6731, Train: 60.76%, Valid: 60.13%, Test: 60.28%
Epoch: 475, Loss: 0.6694, Train: 60.69%, Valid: 60.23%, Test: 60.41%
Epoch: 500, Loss: 0.6736, Train: 60.52%, Valid: 59.98%, Test: 60.12%
Epoch: 525, Loss: 0.6662, Train: 60.88%, Valid: 60.43%, Test: 60.57%
Epoch: 550, Loss: 0.6656, Train: 60.86%, Valid: 60.15%, Test: 60.39%
Epoch: 575, Loss: 0.6633, Train: 61.09%, Valid: 60.56%, Test: 60.66%
Epoch: 600, Loss: 0.6637, Train: 61.14%, Valid: 60.61%, Test: 60.74%
Epoch: 625, Loss: 0.6629, Train: 61.04%, Valid: 60.65%, Test: 60.69%
Epoch: 650, Loss: 0.6684, Train: 60.67%, Valid: 60.20%, Test: 60.23%
Epoch: 675, Loss: 0.6620, Train: 60.98%, Valid: 60.43%, Test: 60.63%
Epoch: 700, Loss: 0.6646, Train: 60.80%, Valid: 60.32%, Test: 60.29%
Epoch: 725, Loss: 0.6598, Train: 61.09%, Valid: 60.65%, Test: 60.79%
Epoch: 750, Loss: 0.6588, Train: 61.21%, Valid: 60.77%, Test: 60.82%
Epoch: 775, Loss: 0.6683, Train: 60.56%, Valid: 60.15%, Test: 60.14%
Epoch: 800, Loss: 0.6596, Train: 61.11%, Valid: 60.72%, Test: 60.73%
Epoch: 825, Loss: 0.6587, Train: 60.92%, Valid: 60.58%, Test: 60.59%
Epoch: 850, Loss: 0.6601, Train: 60.88%, Valid: 60.48%, Test: 60.58%
Epoch: 875, Loss: 0.6573, Train: 61.27%, Valid: 60.90%, Test: 60.92%
Epoch: 900, Loss: 0.6591, Train: 61.20%, Valid: 60.97%, Test: 60.97%
Epoch: 925, Loss: 0.6645, Train: 60.17%, Valid: 59.80%, Test: 59.79%
Epoch: 950, Loss: 0.6580, Train: 61.30%, Valid: 60.96%, Test: 61.01%
Epoch: 975, Loss: 0.6669, Train: 60.05%, Valid: 59.79%, Test: 59.69%
Run 01:
Highest Train: 61.46
Highest Valid: 61.18
  Final Train: 61.43
   Final Test: 61.16
All runs:
Highest Train: 61.46 ± nan
Highest Valid: 61.18 ± nan
  Final Train: 61.43 ± nan
   Final Test: 61.16 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 2528.2593, Train: 48.01%, Valid: 48.06%, Test: 47.79%
Epoch: 25, Loss: 20.9924, Train: 48.15%, Valid: 48.63%, Test: 47.96%
Epoch: 50, Loss: 11.9766, Train: 49.13%, Valid: 49.28%, Test: 49.09%
Epoch: 75, Loss: 8.3930, Train: 49.45%, Valid: 49.59%, Test: 49.47%
Epoch: 100, Loss: 6.3087, Train: 49.56%, Valid: 49.67%, Test: 49.97%
Epoch: 125, Loss: 5.1960, Train: 49.80%, Valid: 49.92%, Test: 49.99%
Epoch: 150, Loss: 4.6365, Train: 49.92%, Valid: 50.07%, Test: 50.31%
Epoch: 175, Loss: 4.3183, Train: 50.05%, Valid: 50.32%, Test: 50.55%
Epoch: 200, Loss: 4.1005, Train: 50.21%, Valid: 50.41%, Test: 50.63%
Epoch: 225, Loss: 3.9205, Train: 50.33%, Valid: 50.51%, Test: 50.67%
Epoch: 250, Loss: 3.7540, Train: 50.46%, Valid: 50.54%, Test: 50.72%
Epoch: 275, Loss: 3.5954, Train: 50.50%, Valid: 50.64%, Test: 50.83%
Epoch: 300, Loss: 3.4443, Train: 50.55%, Valid: 50.74%, Test: 50.91%
Epoch: 325, Loss: 3.3003, Train: 50.65%, Valid: 50.78%, Test: 50.96%
Epoch: 350, Loss: 3.1632, Train: 50.74%, Valid: 50.93%, Test: 51.08%
Epoch: 375, Loss: 3.0322, Train: 50.85%, Valid: 50.97%, Test: 51.22%
Epoch: 400, Loss: 2.9057, Train: 50.87%, Valid: 50.95%, Test: 51.30%
Epoch: 425, Loss: 2.7875, Train: 51.00%, Valid: 50.99%, Test: 51.42%
Epoch: 450, Loss: 2.6770, Train: 51.05%, Valid: 51.10%, Test: 51.58%
Epoch: 475, Loss: 2.5736, Train: 51.12%, Valid: 51.16%, Test: 51.65%
Epoch: 500, Loss: 2.4765, Train: 51.22%, Valid: 51.20%, Test: 51.68%
Epoch: 525, Loss: 2.3847, Train: 51.25%, Valid: 51.23%, Test: 51.80%
Epoch: 550, Loss: 2.2980, Train: 51.34%, Valid: 51.29%, Test: 51.85%
Epoch: 575, Loss: 2.2163, Train: 51.44%, Valid: 51.32%, Test: 51.90%
Epoch: 600, Loss: 2.1393, Train: 51.52%, Valid: 51.42%, Test: 52.02%
Epoch: 625, Loss: 2.0667, Train: 51.65%, Valid: 51.50%, Test: 52.10%
Epoch: 650, Loss: 1.9980, Train: 51.75%, Valid: 51.59%, Test: 52.15%
Epoch: 675, Loss: 1.9328, Train: 51.83%, Valid: 51.75%, Test: 52.22%
Epoch: 700, Loss: 1.8711, Train: 51.89%, Valid: 51.88%, Test: 52.28%
Epoch: 725, Loss: 1.8126, Train: 51.96%, Valid: 51.88%, Test: 52.29%
Epoch: 750, Loss: 1.7568, Train: 51.98%, Valid: 52.05%, Test: 52.35%
Epoch: 775, Loss: 1.7030, Train: 52.05%, Valid: 52.06%, Test: 52.29%
Epoch: 800, Loss: 1.6512, Train: 52.06%, Valid: 52.18%, Test: 52.36%
Epoch: 825, Loss: 1.6011, Train: 52.07%, Valid: 52.27%, Test: 52.40%
Epoch: 850, Loss: 1.5522, Train: 52.12%, Valid: 52.27%, Test: 52.47%
Epoch: 875, Loss: 1.5041, Train: 52.22%, Valid: 52.26%, Test: 52.51%
Epoch: 900, Loss: 1.4571, Train: 52.25%, Valid: 52.27%, Test: 52.49%
Epoch: 925, Loss: 1.4103, Train: 52.29%, Valid: 52.31%, Test: 52.48%
Epoch: 950, Loss: 1.3637, Train: 52.35%, Valid: 52.36%, Test: 52.51%
Epoch: 975, Loss: 1.3178, Train: 52.40%, Valid: 52.35%, Test: 52.52%
Run 01:
Highest Train: 52.45
Highest Valid: 52.38
  Final Train: 52.35
   Final Test: 52.52
All runs:
Highest Train: 52.45 ± nan
Highest Valid: 52.38 ± nan
  Final Train: 52.35 ± nan
   Final Test: 52.52 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.9028, Train: 51.77%, Valid: 51.60%, Test: 51.66%
Epoch: 25, Loss: 0.7184, Train: 56.90%, Valid: 56.66%, Test: 56.55%
Epoch: 50, Loss: 0.6844, Train: 58.62%, Valid: 58.37%, Test: 58.36%
Epoch: 75, Loss: 0.6800, Train: 58.80%, Valid: 58.42%, Test: 58.65%
Epoch: 100, Loss: 0.6724, Train: 58.95%, Valid: 58.54%, Test: 58.66%
Epoch: 125, Loss: 0.6690, Train: 59.43%, Valid: 58.81%, Test: 59.13%
Epoch: 150, Loss: 0.6647, Train: 60.75%, Valid: 60.42%, Test: 60.54%
Epoch: 175, Loss: 0.6722, Train: 60.41%, Valid: 60.09%, Test: 60.10%
Epoch: 200, Loss: 0.6621, Train: 61.03%, Valid: 60.55%, Test: 61.09%
Epoch: 225, Loss: 0.6629, Train: 61.01%, Valid: 60.52%, Test: 60.81%
Epoch: 250, Loss: 0.6613, Train: 61.17%, Valid: 60.86%, Test: 60.99%
Epoch: 275, Loss: 0.6607, Train: 61.05%, Valid: 60.55%, Test: 60.95%
Epoch: 300, Loss: 0.6615, Train: 60.96%, Valid: 60.66%, Test: 60.70%
Epoch: 325, Loss: 0.6600, Train: 61.25%, Valid: 60.86%, Test: 61.02%
Epoch: 350, Loss: 0.6611, Train: 60.97%, Valid: 60.59%, Test: 60.73%
Epoch: 375, Loss: 0.6748, Train: 59.83%, Valid: 59.46%, Test: 59.44%
Epoch: 400, Loss: 0.6617, Train: 60.94%, Valid: 60.40%, Test: 60.85%
Epoch: 425, Loss: 0.6594, Train: 60.36%, Valid: 60.00%, Test: 60.05%
Epoch: 450, Loss: 0.6635, Train: 60.74%, Valid: 60.32%, Test: 60.49%
Epoch: 475, Loss: 0.6598, Train: 61.21%, Valid: 60.86%, Test: 60.97%
Epoch: 500, Loss: 0.6643, Train: 60.78%, Valid: 60.40%, Test: 60.51%
Epoch: 525, Loss: 0.6594, Train: 61.26%, Valid: 60.72%, Test: 60.96%
Epoch: 550, Loss: 0.6627, Train: 60.82%, Valid: 60.36%, Test: 60.60%
Epoch: 575, Loss: 0.6593, Train: 61.15%, Valid: 60.58%, Test: 60.96%
Epoch: 600, Loss: 0.6659, Train: 61.00%, Valid: 60.54%, Test: 60.79%
Epoch: 625, Loss: 0.6586, Train: 61.16%, Valid: 60.82%, Test: 61.09%
Epoch: 650, Loss: 0.6602, Train: 61.36%, Valid: 61.03%, Test: 61.15%
Epoch: 675, Loss: 0.6564, Train: 61.51%, Valid: 61.22%, Test: 61.43%
Epoch: 700, Loss: 0.6566, Train: 61.59%, Valid: 61.28%, Test: 61.50%
Epoch: 725, Loss: 0.6605, Train: 61.10%, Valid: 60.62%, Test: 60.93%
Epoch: 750, Loss: 0.6569, Train: 61.49%, Valid: 61.05%, Test: 61.29%
Epoch: 775, Loss: 0.6598, Train: 61.23%, Valid: 60.81%, Test: 61.17%
Epoch: 800, Loss: 0.6562, Train: 61.65%, Valid: 61.25%, Test: 61.45%
Epoch: 825, Loss: 0.6581, Train: 61.34%, Valid: 60.97%, Test: 61.21%
Epoch: 850, Loss: 0.6554, Train: 61.62%, Valid: 61.29%, Test: 61.57%
Epoch: 875, Loss: 0.6575, Train: 61.56%, Valid: 61.09%, Test: 61.36%
Epoch: 900, Loss: 0.6547, Train: 61.73%, Valid: 61.42%, Test: 61.65%
Epoch: 925, Loss: 0.6623, Train: 61.08%, Valid: 60.70%, Test: 60.78%
Epoch: 950, Loss: 0.6577, Train: 61.27%, Valid: 60.84%, Test: 61.05%
Epoch: 975, Loss: 0.6624, Train: 60.79%, Valid: 60.53%, Test: 60.66%
Run 01:
Highest Train: 61.80
Highest Valid: 61.57
  Final Train: 61.78
   Final Test: 61.71
All runs:
Highest Train: 61.80 ± nan
Highest Valid: 61.57 ± nan
  Final Train: 61.78 ± nan
   Final Test: 61.71 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 54.0237, Train: 52.90%, Valid: 52.86%, Test: 53.04%
Epoch: 25, Loss: 4.1126, Train: 52.55%, Valid: 52.40%, Test: 52.58%
Epoch: 50, Loss: 1.9265, Train: 52.21%, Valid: 52.16%, Test: 52.12%
Epoch: 75, Loss: 1.5874, Train: 52.54%, Valid: 52.32%, Test: 52.42%
Epoch: 100, Loss: 1.4272, Train: 53.04%, Valid: 52.70%, Test: 52.87%
Epoch: 125, Loss: 1.3396, Train: 54.26%, Valid: 53.87%, Test: 54.16%
Epoch: 150, Loss: 1.2583, Train: 55.02%, Valid: 54.45%, Test: 54.89%
Epoch: 175, Loss: 1.1740, Train: 55.72%, Valid: 55.15%, Test: 55.46%
Epoch: 200, Loss: 1.0524, Train: 57.10%, Valid: 57.00%, Test: 57.06%
Epoch: 225, Loss: 1.0517, Train: 54.95%, Valid: 54.72%, Test: 54.75%
Epoch: 250, Loss: 1.2440, Train: 51.42%, Valid: 51.12%, Test: 51.17%
Epoch: 275, Loss: 0.9846, Train: 56.09%, Valid: 55.81%, Test: 56.03%
Epoch: 300, Loss: 0.8990, Train: 55.86%, Valid: 55.95%, Test: 55.94%
Epoch: 325, Loss: 0.9017, Train: 56.39%, Valid: 56.48%, Test: 56.44%
Epoch: 350, Loss: 0.8858, Train: 56.18%, Valid: 56.22%, Test: 56.18%
Epoch: 375, Loss: 0.8646, Train: 55.68%, Valid: 55.71%, Test: 55.83%
Epoch: 400, Loss: 0.8480, Train: 56.45%, Valid: 56.54%, Test: 56.54%
Epoch: 425, Loss: 0.8377, Train: 56.40%, Valid: 56.63%, Test: 56.67%
Epoch: 450, Loss: 0.8281, Train: 56.65%, Valid: 56.86%, Test: 56.93%
Epoch: 475, Loss: 0.8528, Train: 56.09%, Valid: 56.21%, Test: 56.19%
Epoch: 500, Loss: 1.3074, Train: 52.42%, Valid: 52.34%, Test: 52.49%
Epoch: 525, Loss: 1.0357, Train: 49.39%, Valid: 49.44%, Test: 49.03%
Epoch: 550, Loss: 0.9661, Train: 49.10%, Valid: 49.08%, Test: 48.88%
Epoch: 575, Loss: 0.9215, Train: 49.11%, Valid: 49.24%, Test: 48.94%
Epoch: 600, Loss: 0.8852, Train: 49.06%, Valid: 49.25%, Test: 49.03%
Epoch: 625, Loss: 0.8538, Train: 49.05%, Valid: 49.25%, Test: 49.26%
Epoch: 650, Loss: 0.8253, Train: 48.85%, Valid: 49.15%, Test: 49.15%
Epoch: 675, Loss: 0.7987, Train: 48.86%, Valid: 49.08%, Test: 49.14%
Epoch: 700, Loss: 0.7734, Train: 49.05%, Valid: 49.20%, Test: 49.18%
Epoch: 725, Loss: 0.7478, Train: 49.69%, Valid: 49.84%, Test: 49.81%
Epoch: 750, Loss: 0.7259, Train: 52.17%, Valid: 52.51%, Test: 52.47%
Epoch: 775, Loss: 0.7127, Train: 53.21%, Valid: 53.29%, Test: 53.18%
Epoch: 800, Loss: 0.7006, Train: 54.45%, Valid: 54.44%, Test: 54.22%
Epoch: 825, Loss: 0.6958, Train: 55.44%, Valid: 55.47%, Test: 55.15%
Epoch: 850, Loss: 0.6937, Train: 55.31%, Valid: 55.33%, Test: 55.10%
Epoch: 875, Loss: 0.6921, Train: 55.54%, Valid: 55.58%, Test: 55.34%
Epoch: 900, Loss: 0.6907, Train: 55.63%, Valid: 55.63%, Test: 55.58%
Epoch: 925, Loss: 0.6896, Train: 55.84%, Valid: 55.81%, Test: 55.93%
Epoch: 950, Loss: 0.6887, Train: 56.13%, Valid: 56.23%, Test: 56.34%
Epoch: 975, Loss: 0.6880, Train: 56.45%, Valid: 56.54%, Test: 56.60%
Run 01:
Highest Train: 58.46
Highest Valid: 58.49
  Final Train: 58.46
   Final Test: 58.40
All runs:
Highest Train: 58.46 ± nan
Highest Valid: 58.49 ± nan
  Final Train: 58.46 ± nan
   Final Test: 58.40 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 20864.6089, Train: 51.98%, Valid: 51.63%, Test: 52.22%
Epoch: 25, Loss: 150.6195, Train: 53.96%, Valid: 53.56%, Test: 53.79%
Epoch: 50, Loss: 84.6293, Train: 53.52%, Valid: 53.44%, Test: 53.27%
Epoch: 75, Loss: 66.3077, Train: 53.18%, Valid: 53.12%, Test: 52.84%
Epoch: 100, Loss: 54.3156, Train: 53.19%, Valid: 53.09%, Test: 52.84%
Epoch: 125, Loss: 45.7590, Train: 53.04%, Valid: 53.00%, Test: 52.50%
Epoch: 150, Loss: 39.3185, Train: 52.87%, Valid: 52.78%, Test: 52.34%
Epoch: 175, Loss: 34.2517, Train: 52.76%, Valid: 52.67%, Test: 52.21%
Epoch: 200, Loss: 30.0908, Train: 52.65%, Valid: 52.65%, Test: 52.09%
Epoch: 225, Loss: 26.5875, Train: 52.52%, Valid: 52.59%, Test: 52.07%
Epoch: 250, Loss: 23.5601, Train: 52.43%, Valid: 52.57%, Test: 52.06%
Epoch: 275, Loss: 20.8943, Train: 52.35%, Valid: 52.50%, Test: 51.97%
Epoch: 300, Loss: 18.5184, Train: 52.31%, Valid: 52.47%, Test: 51.96%
Epoch: 325, Loss: 16.3814, Train: 52.27%, Valid: 52.31%, Test: 51.90%
Epoch: 350, Loss: 14.4471, Train: 52.22%, Valid: 52.22%, Test: 51.81%
Epoch: 375, Loss: 12.6828, Train: 52.16%, Valid: 52.17%, Test: 51.75%
Epoch: 400, Loss: 11.0685, Train: 52.11%, Valid: 52.08%, Test: 51.69%
Epoch: 425, Loss: 9.5990, Train: 52.11%, Valid: 51.93%, Test: 51.53%
Epoch: 450, Loss: 8.2667, Train: 52.01%, Valid: 51.84%, Test: 51.47%
Epoch: 475, Loss: 7.0688, Train: 51.88%, Valid: 51.71%, Test: 51.47%
Epoch: 500, Loss: 6.0362, Train: 51.79%, Valid: 51.57%, Test: 51.30%
Epoch: 525, Loss: 5.2014, Train: 51.53%, Valid: 51.39%, Test: 51.01%
Epoch: 550, Loss: 4.5748, Train: 51.37%, Valid: 51.27%, Test: 50.89%
Epoch: 575, Loss: 4.1159, Train: 51.25%, Valid: 51.12%, Test: 50.78%
Epoch: 600, Loss: 3.7596, Train: 51.08%, Valid: 50.97%, Test: 50.68%
Epoch: 625, Loss: 3.4568, Train: 51.04%, Valid: 50.90%, Test: 50.68%
Epoch: 650, Loss: 3.1866, Train: 51.04%, Valid: 50.85%, Test: 50.64%
Epoch: 675, Loss: 2.9409, Train: 51.01%, Valid: 50.89%, Test: 50.65%
Epoch: 700, Loss: 2.7153, Train: 50.99%, Valid: 50.87%, Test: 50.67%
Epoch: 725, Loss: 2.5074, Train: 50.98%, Valid: 50.89%, Test: 50.65%
Epoch: 750, Loss: 2.3157, Train: 51.05%, Valid: 50.89%, Test: 50.62%
Epoch: 775, Loss: 2.1389, Train: 51.10%, Valid: 50.98%, Test: 50.68%
Epoch: 800, Loss: 1.9761, Train: 51.13%, Valid: 51.02%, Test: 50.75%
Epoch: 825, Loss: 1.8265, Train: 51.17%, Valid: 51.04%, Test: 50.78%
Epoch: 850, Loss: 1.6898, Train: 51.22%, Valid: 51.06%, Test: 50.86%
Epoch: 875, Loss: 1.5655, Train: 51.29%, Valid: 51.12%, Test: 50.92%
Epoch: 900, Loss: 1.4533, Train: 51.35%, Valid: 51.12%, Test: 51.01%
Epoch: 925, Loss: 1.3532, Train: 51.42%, Valid: 51.28%, Test: 51.12%
Epoch: 950, Loss: 1.2649, Train: 51.64%, Valid: 51.39%, Test: 51.31%
Epoch: 975, Loss: 1.1884, Train: 51.83%, Valid: 51.52%, Test: 51.47%
Run 01:
Highest Train: 53.97
Highest Valid: 53.93
  Final Train: 53.94
   Final Test: 53.91
All runs:
Highest Train: 53.97 ± nan
Highest Valid: 53.93 ± nan
  Final Train: 53.94 ± nan
   Final Test: 53.91 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.9676, Train: 51.14%, Valid: 50.84%, Test: 51.14%
Epoch: 25, Loss: 0.7129, Train: 59.69%, Valid: 59.11%, Test: 59.19%
Epoch: 50, Loss: 0.6798, Train: 60.02%, Valid: 59.58%, Test: 59.81%
Epoch: 75, Loss: 0.6700, Train: 60.42%, Valid: 59.86%, Test: 60.10%
Epoch: 100, Loss: 0.6898, Train: 59.56%, Valid: 59.33%, Test: 59.36%
Epoch: 125, Loss: 0.6687, Train: 60.19%, Valid: 59.53%, Test: 59.68%
Epoch: 150, Loss: 0.6629, Train: 60.64%, Valid: 59.94%, Test: 60.19%
Epoch: 175, Loss: 0.6613, Train: 60.60%, Valid: 59.99%, Test: 60.23%
Epoch: 200, Loss: 0.6596, Train: 60.94%, Valid: 60.52%, Test: 60.66%
Epoch: 225, Loss: 0.6614, Train: 60.54%, Valid: 59.91%, Test: 60.19%
Epoch: 250, Loss: 0.6591, Train: 61.03%, Valid: 60.46%, Test: 60.78%
Epoch: 275, Loss: 0.6591, Train: 60.96%, Valid: 60.47%, Test: 60.60%
Epoch: 300, Loss: 0.6664, Train: 60.25%, Valid: 59.65%, Test: 59.86%
Epoch: 325, Loss: 0.6591, Train: 60.86%, Valid: 60.32%, Test: 60.51%
Epoch: 350, Loss: 0.6583, Train: 61.09%, Valid: 60.70%, Test: 60.86%
Epoch: 375, Loss: 0.6613, Train: 60.64%, Valid: 60.17%, Test: 60.33%
Epoch: 400, Loss: 0.6563, Train: 61.56%, Valid: 61.23%, Test: 61.46%
Epoch: 425, Loss: 0.6598, Train: 61.18%, Valid: 60.75%, Test: 60.90%
Epoch: 450, Loss: 0.6566, Train: 61.59%, Valid: 61.32%, Test: 61.44%
Epoch: 475, Loss: 0.6568, Train: 61.36%, Valid: 60.88%, Test: 61.10%
Epoch: 500, Loss: 0.6559, Train: 61.27%, Valid: 61.08%, Test: 61.02%
Epoch: 525, Loss: 0.6562, Train: 61.46%, Valid: 61.19%, Test: 61.29%
Epoch: 550, Loss: 0.6666, Train: 61.20%, Valid: 60.98%, Test: 61.39%
Epoch: 575, Loss: 0.6661, Train: 60.88%, Valid: 60.29%, Test: 60.52%
Epoch: 600, Loss: 0.6577, Train: 61.20%, Valid: 60.87%, Test: 61.05%
Epoch: 625, Loss: 0.6525, Train: 62.09%, Valid: 62.10%, Test: 62.03%
Epoch: 650, Loss: 0.6594, Train: 61.24%, Valid: 60.65%, Test: 61.04%
Epoch: 675, Loss: 0.6556, Train: 61.66%, Valid: 61.19%, Test: 61.42%
Epoch: 700, Loss: 0.6590, Train: 60.96%, Valid: 60.69%, Test: 60.81%
Epoch: 725, Loss: 0.6529, Train: 61.86%, Valid: 61.49%, Test: 61.79%
Epoch: 750, Loss: 0.6528, Train: 61.87%, Valid: 61.78%, Test: 61.84%
Epoch: 775, Loss: 0.6609, Train: 61.34%, Valid: 60.89%, Test: 61.17%
Epoch: 800, Loss: 0.6520, Train: 62.00%, Valid: 61.80%, Test: 61.99%
Epoch: 825, Loss: 0.6508, Train: 62.10%, Valid: 62.21%, Test: 62.13%
Epoch: 850, Loss: 0.6497, Train: 62.30%, Valid: 62.40%, Test: 62.30%
Epoch: 875, Loss: 0.6510, Train: 62.19%, Valid: 61.95%, Test: 61.88%
Epoch: 900, Loss: 0.6502, Train: 62.37%, Valid: 62.54%, Test: 62.28%
Epoch: 925, Loss: 0.6544, Train: 61.69%, Valid: 61.16%, Test: 61.40%
Epoch: 950, Loss: 0.6496, Train: 62.30%, Valid: 62.49%, Test: 62.38%
Epoch: 975, Loss: 0.6499, Train: 62.28%, Valid: 62.28%, Test: 62.18%
Run 01:
Highest Train: 62.50
Highest Valid: 62.61
  Final Train: 62.36
   Final Test: 62.55
All runs:
Highest Train: 62.50 ± nan
Highest Valid: 62.61 ± nan
  Final Train: 62.36 ± nan
   Final Test: 62.55 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 29.9423, Train: 47.26%, Valid: 47.37%, Test: 47.18%
Epoch: 25, Loss: 7.5672, Train: 47.36%, Valid: 47.34%, Test: 47.26%
Epoch: 50, Loss: 4.9152, Train: 46.32%, Valid: 46.55%, Test: 46.29%
Epoch: 75, Loss: 3.3099, Train: 43.52%, Valid: 43.92%, Test: 43.65%
Epoch: 100, Loss: 2.4608, Train: 42.78%, Valid: 43.19%, Test: 43.09%
Epoch: 125, Loss: 1.7851, Train: 43.07%, Valid: 43.28%, Test: 43.41%
Epoch: 150, Loss: 1.2052, Train: 45.84%, Valid: 45.79%, Test: 45.57%
Epoch: 175, Loss: 0.9432, Train: 48.84%, Valid: 48.75%, Test: 48.56%
Epoch: 200, Loss: 0.8554, Train: 51.56%, Valid: 51.06%, Test: 51.26%
Epoch: 225, Loss: 0.7982, Train: 54.04%, Valid: 53.64%, Test: 53.82%
Epoch: 250, Loss: 1.1068, Train: 52.12%, Valid: 52.08%, Test: 52.09%
Epoch: 275, Loss: 0.8771, Train: 53.03%, Valid: 52.99%, Test: 53.04%
Epoch: 300, Loss: 0.8219, Train: 53.72%, Valid: 53.56%, Test: 53.61%
Epoch: 325, Loss: 0.7259, Train: 54.13%, Valid: 54.07%, Test: 53.95%
Epoch: 350, Loss: 0.6980, Train: 53.79%, Valid: 53.74%, Test: 53.22%
Epoch: 375, Loss: 0.6906, Train: 54.45%, Valid: 54.41%, Test: 54.01%
Epoch: 400, Loss: 0.6867, Train: 55.68%, Valid: 55.54%, Test: 55.37%
Epoch: 425, Loss: 0.6839, Train: 56.55%, Valid: 56.38%, Test: 56.17%
Epoch: 450, Loss: 0.6818, Train: 57.04%, Valid: 56.80%, Test: 56.82%
Epoch: 475, Loss: 0.6802, Train: 57.31%, Valid: 57.00%, Test: 57.23%
Epoch: 500, Loss: 0.6790, Train: 57.44%, Valid: 57.10%, Test: 57.22%
Epoch: 525, Loss: 0.6779, Train: 57.50%, Valid: 57.19%, Test: 57.27%
Epoch: 550, Loss: 0.6771, Train: 57.56%, Valid: 57.28%, Test: 57.30%
Epoch: 575, Loss: 0.6763, Train: 57.67%, Valid: 57.33%, Test: 57.36%
Epoch: 600, Loss: 0.6757, Train: 57.73%, Valid: 57.47%, Test: 57.47%
Epoch: 625, Loss: 0.6751, Train: 57.76%, Valid: 57.56%, Test: 57.53%
Epoch: 650, Loss: 0.6746, Train: 57.82%, Valid: 57.60%, Test: 57.65%
Epoch: 675, Loss: 0.6742, Train: 57.91%, Valid: 57.63%, Test: 57.77%
Epoch: 700, Loss: 0.6738, Train: 57.95%, Valid: 57.66%, Test: 57.83%
Epoch: 725, Loss: 0.6734, Train: 57.99%, Valid: 57.70%, Test: 57.84%
Epoch: 750, Loss: 0.6731, Train: 58.02%, Valid: 57.74%, Test: 57.95%
Epoch: 775, Loss: 0.6728, Train: 58.12%, Valid: 57.78%, Test: 58.03%
Epoch: 800, Loss: 0.6725, Train: 58.21%, Valid: 57.84%, Test: 58.07%
Epoch: 825, Loss: 0.6722, Train: 58.29%, Valid: 57.94%, Test: 58.11%
Epoch: 850, Loss: 0.6719, Train: 58.36%, Valid: 58.02%, Test: 58.24%
Epoch: 875, Loss: 0.6716, Train: 58.44%, Valid: 58.09%, Test: 58.29%
Epoch: 900, Loss: 0.6713, Train: 58.51%, Valid: 58.14%, Test: 58.31%
Epoch: 925, Loss: 0.6711, Train: 58.57%, Valid: 58.19%, Test: 58.39%
Epoch: 950, Loss: 0.6708, Train: 58.65%, Valid: 58.27%, Test: 58.43%
Epoch: 975, Loss: 0.6706, Train: 58.71%, Valid: 58.29%, Test: 58.47%
Run 01:
Highest Train: 58.79
Highest Valid: 58.35
  Final Train: 58.78
   Final Test: 58.54
All runs:
Highest Train: 58.79 ± nan
Highest Valid: 58.35 ± nan
  Final Train: 58.78 ± nan
   Final Test: 58.54 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 21684.4124, Train: 52.96%, Valid: 52.94%, Test: 53.10%
Epoch: 25, Loss: 358.4200, Train: 49.39%, Valid: 49.53%, Test: 49.15%
Epoch: 50, Loss: 81.1819, Train: 49.15%, Valid: 49.39%, Test: 49.05%
Epoch: 75, Loss: 65.4721, Train: 47.83%, Valid: 47.94%, Test: 47.90%
Epoch: 100, Loss: 55.1402, Train: 48.31%, Valid: 48.16%, Test: 48.39%
Epoch: 125, Loss: 45.6979, Train: 48.36%, Valid: 48.22%, Test: 48.50%
Epoch: 150, Loss: 36.6603, Train: 48.78%, Valid: 48.57%, Test: 48.78%
Epoch: 175, Loss: 28.1216, Train: 49.14%, Valid: 49.01%, Test: 49.17%
Epoch: 200, Loss: 20.2138, Train: 49.72%, Valid: 49.70%, Test: 49.83%
Epoch: 225, Loss: 13.2953, Train: 50.48%, Valid: 50.43%, Test: 50.89%
Epoch: 250, Loss: 8.4640, Train: 51.39%, Valid: 51.30%, Test: 51.54%
Epoch: 275, Loss: 6.2393, Train: 51.86%, Valid: 51.89%, Test: 52.10%
Epoch: 300, Loss: 5.2770, Train: 52.23%, Valid: 52.29%, Test: 52.67%
Epoch: 325, Loss: 4.7286, Train: 52.57%, Valid: 52.55%, Test: 52.96%
Epoch: 350, Loss: 4.3299, Train: 52.78%, Valid: 52.74%, Test: 53.16%
Epoch: 375, Loss: 3.9861, Train: 52.90%, Valid: 52.89%, Test: 53.28%
Epoch: 400, Loss: 3.6700, Train: 53.01%, Valid: 53.00%, Test: 53.38%
Epoch: 425, Loss: 3.3719, Train: 53.09%, Valid: 53.08%, Test: 53.45%
Epoch: 450, Loss: 3.0905, Train: 53.21%, Valid: 53.10%, Test: 53.54%
Epoch: 475, Loss: 2.8270, Train: 53.24%, Valid: 53.14%, Test: 53.57%
Epoch: 500, Loss: 2.5835, Train: 53.24%, Valid: 53.22%, Test: 53.52%
Epoch: 525, Loss: 2.3638, Train: 53.31%, Valid: 53.17%, Test: 53.52%
Epoch: 550, Loss: 2.1728, Train: 53.26%, Valid: 53.06%, Test: 53.55%
Epoch: 575, Loss: 2.0151, Train: 53.18%, Valid: 52.84%, Test: 53.44%
Epoch: 600, Loss: 1.8927, Train: 53.12%, Valid: 52.64%, Test: 53.18%
Epoch: 625, Loss: 1.8032, Train: 53.01%, Valid: 52.51%, Test: 52.99%
Epoch: 650, Loss: 1.7410, Train: 52.91%, Valid: 52.44%, Test: 52.81%
Epoch: 675, Loss: 1.6989, Train: 52.91%, Valid: 52.29%, Test: 52.75%
Epoch: 700, Loss: 1.6708, Train: 52.82%, Valid: 52.27%, Test: 52.62%
Epoch: 725, Loss: 1.6518, Train: 52.77%, Valid: 52.06%, Test: 52.64%
Epoch: 750, Loss: 1.6388, Train: 52.69%, Valid: 52.01%, Test: 52.65%
Epoch: 775, Loss: 1.6294, Train: 52.67%, Valid: 52.08%, Test: 52.61%
Epoch: 800, Loss: 1.6225, Train: 52.62%, Valid: 52.05%, Test: 52.58%
Epoch: 825, Loss: 1.6170, Train: 52.60%, Valid: 52.13%, Test: 52.57%
Epoch: 850, Loss: 1.6126, Train: 52.58%, Valid: 52.17%, Test: 52.63%
Epoch: 875, Loss: 1.6089, Train: 52.58%, Valid: 52.19%, Test: 52.60%
Epoch: 900, Loss: 1.6056, Train: 52.56%, Valid: 52.23%, Test: 52.59%
Epoch: 925, Loss: 1.6027, Train: 52.60%, Valid: 52.28%, Test: 52.61%
Epoch: 950, Loss: 1.6001, Train: 52.60%, Valid: 52.31%, Test: 52.63%
Epoch: 975, Loss: 1.5976, Train: 52.61%, Valid: 52.34%, Test: 52.63%
Run 01:
Highest Train: 53.33
Highest Valid: 53.25
  Final Train: 53.21
   Final Test: 53.53
All runs:
Highest Train: 53.33 ± nan
Highest Valid: 53.25 ± nan
  Final Train: 53.21 ± nan
   Final Test: 53.53 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.8286, Train: 52.96%, Valid: 52.94%, Test: 53.10%
Epoch: 25, Loss: 0.8110, Train: 55.85%, Valid: 55.42%, Test: 55.36%
Epoch: 50, Loss: 0.7523, Train: 58.52%, Valid: 57.98%, Test: 58.03%
Epoch: 75, Loss: 0.7370, Train: 58.89%, Valid: 58.29%, Test: 58.44%
Epoch: 100, Loss: 0.7289, Train: 59.25%, Valid: 58.66%, Test: 58.70%
Epoch: 125, Loss: 0.7169, Train: 59.68%, Valid: 59.23%, Test: 59.16%
Epoch: 150, Loss: 0.7017, Train: 59.87%, Valid: 59.41%, Test: 59.44%
Epoch: 175, Loss: 0.6771, Train: 59.94%, Valid: 59.49%, Test: 59.62%
Epoch: 200, Loss: 0.6664, Train: 60.01%, Valid: 59.54%, Test: 59.65%
Epoch: 225, Loss: 0.6635, Train: 60.34%, Valid: 59.80%, Test: 59.88%
Epoch: 250, Loss: 0.6623, Train: 60.48%, Valid: 59.95%, Test: 60.06%
Epoch: 275, Loss: 0.6616, Train: 60.60%, Valid: 59.98%, Test: 60.20%
Epoch: 300, Loss: 0.6608, Train: 60.71%, Valid: 60.09%, Test: 60.28%
Epoch: 325, Loss: 0.6601, Train: 60.80%, Valid: 60.19%, Test: 60.42%
Epoch: 350, Loss: 0.6592, Train: 60.88%, Valid: 60.34%, Test: 60.52%
Epoch: 375, Loss: 0.6583, Train: 61.03%, Valid: 60.39%, Test: 60.60%
Epoch: 400, Loss: 0.6574, Train: 61.11%, Valid: 60.52%, Test: 60.77%
Epoch: 425, Loss: 0.6565, Train: 61.24%, Valid: 60.77%, Test: 60.98%
Epoch: 450, Loss: 0.6561, Train: 61.04%, Valid: 60.63%, Test: 60.75%
Epoch: 475, Loss: 0.6554, Train: 61.31%, Valid: 60.78%, Test: 61.11%
Epoch: 500, Loss: 0.6594, Train: 61.20%, Valid: 60.88%, Test: 60.88%
Epoch: 525, Loss: 0.6549, Train: 61.44%, Valid: 60.95%, Test: 61.16%
Epoch: 550, Loss: 0.6538, Train: 61.58%, Valid: 61.07%, Test: 61.36%
Epoch: 575, Loss: 0.6539, Train: 61.25%, Valid: 60.86%, Test: 60.89%
Epoch: 600, Loss: 0.6531, Train: 61.61%, Valid: 61.04%, Test: 61.33%
Epoch: 625, Loss: 0.6602, Train: 61.58%, Valid: 60.96%, Test: 61.25%
Epoch: 650, Loss: 0.6532, Train: 61.73%, Valid: 61.12%, Test: 61.34%
Epoch: 675, Loss: 0.6522, Train: 61.75%, Valid: 61.24%, Test: 61.49%
Epoch: 700, Loss: 0.6516, Train: 61.89%, Valid: 61.52%, Test: 61.65%
Epoch: 725, Loss: 0.6530, Train: 61.76%, Valid: 61.16%, Test: 61.37%
Epoch: 750, Loss: 0.6515, Train: 61.85%, Valid: 61.29%, Test: 61.51%
Epoch: 775, Loss: 0.6509, Train: 61.91%, Valid: 61.45%, Test: 61.65%
Epoch: 800, Loss: 0.6506, Train: 62.04%, Valid: 61.62%, Test: 61.73%
Epoch: 825, Loss: 0.6537, Train: 61.77%, Valid: 61.43%, Test: 61.43%
Epoch: 850, Loss: 0.6503, Train: 62.09%, Valid: 61.65%, Test: 61.77%
Epoch: 875, Loss: 0.6511, Train: 61.77%, Valid: 61.26%, Test: 61.49%
Epoch: 900, Loss: 0.6500, Train: 62.10%, Valid: 61.67%, Test: 61.78%
Epoch: 925, Loss: 0.6497, Train: 62.07%, Valid: 61.64%, Test: 61.84%
Epoch: 950, Loss: 0.6499, Train: 62.03%, Valid: 61.59%, Test: 61.78%
Epoch: 975, Loss: 0.6493, Train: 62.14%, Valid: 61.72%, Test: 61.95%
Run 01:
Highest Train: 62.25
Highest Valid: 61.88
  Final Train: 62.19
   Final Test: 61.91
All runs:
Highest Train: 62.25 ± nan
Highest Valid: 61.88 ± nan
  Final Train: 62.19 ± nan
   Final Test: 61.91 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 15.1998, Train: 47.04%, Valid: 47.06%, Test: 46.90%
Epoch: 25, Loss: 7.6996, Train: 47.03%, Valid: 47.24%, Test: 47.17%
Epoch: 50, Loss: 6.7014, Train: 47.11%, Valid: 47.52%, Test: 47.29%
Epoch: 75, Loss: 5.6115, Train: 47.49%, Valid: 47.90%, Test: 47.56%
Epoch: 100, Loss: 4.6986, Train: 47.83%, Valid: 48.09%, Test: 47.83%
Epoch: 125, Loss: 3.9524, Train: 48.16%, Valid: 48.30%, Test: 48.10%
Epoch: 150, Loss: 3.3364, Train: 48.44%, Valid: 48.59%, Test: 48.39%
Epoch: 175, Loss: 2.8124, Train: 48.80%, Valid: 48.87%, Test: 48.74%
Epoch: 200, Loss: 2.3613, Train: 49.24%, Valid: 49.26%, Test: 48.98%
Epoch: 225, Loss: 1.9884, Train: 50.05%, Valid: 49.89%, Test: 49.65%
Epoch: 250, Loss: 1.6846, Train: 51.98%, Valid: 51.77%, Test: 51.66%
Epoch: 275, Loss: 1.4170, Train: 53.24%, Valid: 53.00%, Test: 52.96%
Epoch: 300, Loss: 1.1911, Train: 55.23%, Valid: 54.94%, Test: 54.94%
Epoch: 325, Loss: 1.0322, Train: 56.70%, Valid: 56.45%, Test: 56.58%
Epoch: 350, Loss: 0.9140, Train: 57.54%, Valid: 57.53%, Test: 57.56%
Epoch: 375, Loss: 0.8402, Train: 57.80%, Valid: 57.77%, Test: 57.71%
Epoch: 400, Loss: 0.8230, Train: 58.00%, Valid: 57.58%, Test: 57.86%
Epoch: 425, Loss: 0.8000, Train: 58.17%, Valid: 58.04%, Test: 58.04%
Epoch: 450, Loss: 0.9482, Train: 57.49%, Valid: 57.13%, Test: 57.29%
Epoch: 475, Loss: 0.9178, Train: 57.86%, Valid: 57.58%, Test: 57.78%
Epoch: 500, Loss: 0.8370, Train: 58.28%, Valid: 58.12%, Test: 58.07%
Epoch: 525, Loss: 0.7065, Train: 58.40%, Valid: 58.31%, Test: 58.67%
Epoch: 550, Loss: 1.0155, Train: 57.20%, Valid: 56.94%, Test: 57.41%
Epoch: 575, Loss: 0.9510, Train: 58.11%, Valid: 58.06%, Test: 58.14%
Epoch: 600, Loss: 0.9109, Train: 58.22%, Valid: 58.01%, Test: 58.22%
Epoch: 625, Loss: 0.8795, Train: 58.47%, Valid: 58.28%, Test: 58.37%
Epoch: 650, Loss: 0.8486, Train: 58.85%, Valid: 58.73%, Test: 58.78%
Epoch: 675, Loss: 0.7903, Train: 58.01%, Valid: 58.05%, Test: 57.92%
Epoch: 700, Loss: 0.8522, Train: 56.49%, Valid: 56.54%, Test: 56.30%
Epoch: 725, Loss: 0.8547, Train: 55.52%, Valid: 55.41%, Test: 55.62%
Epoch: 750, Loss: 0.8127, Train: 56.43%, Valid: 55.99%, Test: 56.23%
Epoch: 775, Loss: 0.7861, Train: 56.84%, Valid: 56.38%, Test: 56.57%
Epoch: 800, Loss: 0.7570, Train: 56.47%, Valid: 56.21%, Test: 56.37%
Epoch: 825, Loss: 0.7225, Train: 56.26%, Valid: 56.12%, Test: 56.12%
Epoch: 850, Loss: 0.6921, Train: 56.79%, Valid: 56.74%, Test: 56.31%
Epoch: 875, Loss: 0.6800, Train: 58.53%, Valid: 58.27%, Test: 58.10%
Epoch: 900, Loss: 0.6754, Train: 59.45%, Valid: 59.23%, Test: 59.28%
Epoch: 925, Loss: 0.6736, Train: 59.78%, Valid: 59.53%, Test: 59.62%
Epoch: 950, Loss: 0.6726, Train: 59.92%, Valid: 59.64%, Test: 59.78%
Epoch: 975, Loss: 0.6720, Train: 60.09%, Valid: 59.78%, Test: 59.88%
Run 01:
Highest Train: 60.10
Highest Valid: 59.88
  Final Train: 60.10
   Final Test: 59.90
All runs:
Highest Train: 60.10 ± nan
Highest Valid: 59.88 ± nan
  Final Train: 60.10 ± nan
   Final Test: 59.90 ± nan
Saving results to results/twitch-gamer.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='twitch-gamer', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 168114 | num classes 2 | num node feats 7
MODEL: MLPNORM(
  (fc1): Linear(in_features=7, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 7715.5360, Train: 47.04%, Valid: 47.06%, Test: 46.90%
Epoch: 25, Loss: 414.9681, Train: 48.52%, Valid: 48.68%, Test: 48.41%
Epoch: 50, Loss: 85.1502, Train: 48.32%, Valid: 48.47%, Test: 48.08%
Epoch: 75, Loss: 66.3895, Train: 47.44%, Valid: 47.70%, Test: 47.25%
Epoch: 100, Loss: 52.9872, Train: 47.77%, Valid: 47.93%, Test: 47.60%
Epoch: 125, Loss: 46.0236, Train: 48.21%, Valid: 48.43%, Test: 47.89%
Epoch: 150, Loss: 40.8823, Train: 48.08%, Valid: 48.17%, Test: 47.73%
Epoch: 175, Loss: 36.4346, Train: 48.65%, Valid: 48.50%, Test: 48.34%
Epoch: 200, Loss: 31.5133, Train: 47.86%, Valid: 47.98%, Test: 47.45%
Epoch: 225, Loss: 28.0113, Train: 48.01%, Valid: 47.88%, Test: 47.78%
Epoch: 250, Loss: 21.5026, Train: 46.40%, Valid: 46.42%, Test: 46.05%
Epoch: 275, Loss: 15.6426, Train: 46.53%, Valid: 46.68%, Test: 46.27%
Epoch: 300, Loss: 21.3243, Train: 46.91%, Valid: 47.09%, Test: 46.92%
Epoch: 325, Loss: 13.6078, Train: 43.98%, Valid: 44.21%, Test: 44.24%
Epoch: 350, Loss: 20.1615, Train: 44.92%, Valid: 45.08%, Test: 44.93%
Epoch: 375, Loss: 17.9834, Train: 46.49%, Valid: 46.58%, Test: 46.35%
Epoch: 400, Loss: 12.2823, Train: 42.54%, Valid: 42.68%, Test: 42.28%
Epoch: 425, Loss: 14.7557, Train: 46.38%, Valid: 46.48%, Test: 46.23%
Epoch: 450, Loss: 14.0445, Train: 46.56%, Valid: 46.63%, Test: 46.40%
Epoch: 475, Loss: 12.3909, Train: 43.73%, Valid: 44.04%, Test: 43.96%
Epoch: 500, Loss: 13.5188, Train: 43.37%, Valid: 43.67%, Test: 43.68%
Epoch: 525, Loss: 11.1743, Train: 46.95%, Valid: 46.97%, Test: 46.77%
Epoch: 550, Loss: 7.8188, Train: 47.03%, Valid: 47.05%, Test: 46.88%
Epoch: 575, Loss: 10.8729, Train: 44.10%, Valid: 44.31%, Test: 44.28%
Epoch: 600, Loss: 14.4302, Train: 44.31%, Valid: 44.50%, Test: 44.53%
Epoch: 625, Loss: 15.0215, Train: 43.24%, Valid: 43.59%, Test: 43.11%
Epoch: 650, Loss: 9.0216, Train: 47.02%, Valid: 47.06%, Test: 46.86%
Epoch: 675, Loss: 12.0936, Train: 47.04%, Valid: 47.06%, Test: 46.90%
Epoch: 700, Loss: 12.1708, Train: 46.72%, Valid: 46.78%, Test: 46.47%
Epoch: 725, Loss: 6.4612, Train: 43.87%, Valid: 44.08%, Test: 44.26%
Epoch: 750, Loss: 8.7556, Train: 47.31%, Valid: 47.35%, Test: 47.11%
Epoch: 775, Loss: 8.5218, Train: 47.42%, Valid: 47.35%, Test: 47.21%
Epoch: 800, Loss: 8.1321, Train: 47.47%, Valid: 47.51%, Test: 47.30%
Epoch: 825, Loss: 7.8197, Train: 47.48%, Valid: 47.53%, Test: 47.35%
Epoch: 850, Loss: 7.0266, Train: 46.64%, Valid: 46.92%, Test: 46.52%
Epoch: 875, Loss: 5.9759, Train: 46.90%, Valid: 47.21%, Test: 46.78%
Epoch: 900, Loss: 5.9378, Train: 46.74%, Valid: 47.07%, Test: 46.55%
Epoch: 925, Loss: 5.9196, Train: 46.83%, Valid: 47.11%, Test: 46.71%
Epoch: 950, Loss: 5.8948, Train: 46.79%, Valid: 47.07%, Test: 46.67%
Epoch: 975, Loss: 5.8740, Train: 46.70%, Valid: 47.05%, Test: 46.56%
Run 01:
Highest Train: 51.90
Highest Valid: 51.80
  Final Train: 51.90
   Final Test: 52.05
All runs:
Highest Train: 51.90 ± nan
Highest Valid: 51.80 ± nan
  Final Train: 51.90 ± nan
   Final Test: 52.05 ± nan
Saving results to results/twitch-gamer.csv
20211116-23:26 ---> 20211117-01:17 Totl:6683 seconds
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6932, Train: 54.09%, Valid: 52.90%, Test: 53.40%
Epoch: 25, Loss: 0.3640, Train: 81.84%, Valid: 72.67%, Test: 73.47%
Epoch: 50, Loss: 0.3163, Train: 84.98%, Valid: 72.88%, Test: 73.19%
Epoch: 75, Loss: 0.1821, Train: 92.15%, Valid: 70.90%, Test: 71.29%
Epoch: 100, Loss: 0.0845, Train: 96.97%, Valid: 69.69%, Test: 69.99%
Epoch: 125, Loss: 0.0445, Train: 98.06%, Valid: 69.36%, Test: 70.26%
Epoch: 150, Loss: 0.0294, Train: 98.77%, Valid: 69.56%, Test: 70.14%
Epoch: 175, Loss: 0.0260, Train: 98.84%, Valid: 69.39%, Test: 69.82%
Epoch: 200, Loss: 0.0258, Train: 98.89%, Valid: 69.24%, Test: 69.73%
Epoch: 225, Loss: 0.0202, Train: 98.93%, Valid: 69.25%, Test: 69.82%
Epoch: 250, Loss: 0.0229, Train: 98.91%, Valid: 69.43%, Test: 69.98%
Epoch: 275, Loss: 0.0227, Train: 98.84%, Valid: 69.02%, Test: 69.48%
Epoch: 300, Loss: 0.0208, Train: 98.91%, Valid: 69.09%, Test: 69.63%
Epoch: 325, Loss: 0.0250, Train: 98.83%, Valid: 69.06%, Test: 69.51%
Epoch: 350, Loss: 0.0196, Train: 98.84%, Valid: 69.27%, Test: 69.88%
Epoch: 375, Loss: 0.0216, Train: 98.91%, Valid: 69.12%, Test: 69.63%
Epoch: 400, Loss: 0.0181, Train: 98.92%, Valid: 69.22%, Test: 69.91%
Epoch: 425, Loss: 0.0191, Train: 98.88%, Valid: 69.22%, Test: 69.87%
Epoch: 450, Loss: 0.0208, Train: 98.62%, Valid: 69.15%, Test: 69.29%
Epoch: 475, Loss: 0.0182, Train: 98.91%, Valid: 69.12%, Test: 69.87%
Epoch: 500, Loss: 0.0178, Train: 98.94%, Valid: 69.07%, Test: 69.68%
Epoch: 525, Loss: 0.0181, Train: 98.89%, Valid: 69.23%, Test: 69.90%
Epoch: 550, Loss: 0.0183, Train: 98.93%, Valid: 69.11%, Test: 69.55%
Epoch: 575, Loss: 0.0202, Train: 98.86%, Valid: 69.22%, Test: 69.92%
Epoch: 600, Loss: 0.0220, Train: 98.86%, Valid: 69.17%, Test: 69.88%
Epoch: 625, Loss: 0.0185, Train: 98.92%, Valid: 69.16%, Test: 69.43%
Epoch: 650, Loss: 0.0198, Train: 98.87%, Valid: 69.16%, Test: 69.79%
Epoch: 675, Loss: 0.0208, Train: 98.83%, Valid: 69.16%, Test: 69.81%
Epoch: 700, Loss: 0.0178, Train: 98.93%, Valid: 69.00%, Test: 69.44%
Epoch: 725, Loss: 0.0189, Train: 98.86%, Valid: 69.15%, Test: 69.76%
Epoch: 750, Loss: 0.0179, Train: 98.94%, Valid: 68.96%, Test: 69.53%
Epoch: 775, Loss: 0.0182, Train: 98.94%, Valid: 69.06%, Test: 69.49%
Epoch: 800, Loss: 0.0182, Train: 98.93%, Valid: 68.98%, Test: 69.49%
Epoch: 825, Loss: 0.0180, Train: 98.93%, Valid: 69.07%, Test: 69.78%
Epoch: 850, Loss: 0.0177, Train: 98.94%, Valid: 68.95%, Test: 69.51%
Epoch: 875, Loss: 0.0180, Train: 98.90%, Valid: 69.04%, Test: 69.84%
Epoch: 900, Loss: 0.0182, Train: 98.93%, Valid: 68.94%, Test: 69.54%
Epoch: 925, Loss: 0.0186, Train: 98.83%, Valid: 69.00%, Test: 69.86%
Epoch: 950, Loss: 0.0176, Train: 98.94%, Valid: 68.92%, Test: 69.49%
Epoch: 975, Loss: 0.0181, Train: 98.90%, Valid: 69.03%, Test: 69.90%
Run 01:
Highest Train: 98.94
Highest Valid: 73.87
  Final Train: 80.42
   Final Test: 74.44
All runs:
Highest Train: 98.94 ± nan
Highest Valid: 73.87 ± nan
  Final Train: 80.42 ± nan
   Final Test: 74.44 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6976, Train: 47.18%, Valid: 48.03%, Test: 47.26%
Epoch: 25, Loss: 0.3917, Train: 81.60%, Valid: 73.69%, Test: 74.15%
Epoch: 50, Loss: 0.2797, Train: 88.02%, Valid: 73.06%, Test: 73.22%
Epoch: 75, Loss: 0.0809, Train: 97.41%, Valid: 71.52%, Test: 70.66%
Epoch: 100, Loss: 0.0255, Train: 98.86%, Valid: 70.74%, Test: 70.29%
Epoch: 125, Loss: 0.0193, Train: 98.93%, Valid: 70.61%, Test: 70.16%
Epoch: 150, Loss: 0.0187, Train: 98.92%, Valid: 70.52%, Test: 70.04%
Epoch: 175, Loss: 0.0189, Train: 98.93%, Valid: 70.53%, Test: 70.44%
Epoch: 200, Loss: 0.0189, Train: 98.89%, Valid: 70.42%, Test: 70.39%
Epoch: 225, Loss: 0.0183, Train: 98.94%, Valid: 70.32%, Test: 70.24%
Epoch: 250, Loss: 0.0177, Train: 98.93%, Valid: 70.34%, Test: 70.18%
Epoch: 275, Loss: 0.0181, Train: 98.89%, Valid: 70.25%, Test: 70.32%
Epoch: 300, Loss: 0.0187, Train: 98.91%, Valid: 70.36%, Test: 70.06%
Epoch: 325, Loss: 0.0187, Train: 98.90%, Valid: 70.22%, Test: 70.29%
Epoch: 350, Loss: 0.0187, Train: 98.93%, Valid: 70.24%, Test: 70.15%
Epoch: 375, Loss: 0.0184, Train: 98.89%, Valid: 70.11%, Test: 70.31%
Epoch: 400, Loss: 0.0175, Train: 98.94%, Valid: 70.30%, Test: 70.14%
Epoch: 425, Loss: 0.0184, Train: 98.93%, Valid: 70.15%, Test: 70.15%
Epoch: 450, Loss: 0.0175, Train: 98.94%, Valid: 70.17%, Test: 70.24%
Epoch: 475, Loss: 0.0181, Train: 98.92%, Valid: 70.13%, Test: 70.27%
Epoch: 500, Loss: 0.0174, Train: 98.94%, Valid: 70.21%, Test: 70.13%
Epoch: 525, Loss: 0.0180, Train: 98.94%, Valid: 70.18%, Test: 70.08%
Epoch: 550, Loss: 0.0176, Train: 98.94%, Valid: 70.28%, Test: 70.28%
Epoch: 575, Loss: 0.0174, Train: 98.94%, Valid: 70.28%, Test: 70.25%
Epoch: 600, Loss: 0.0182, Train: 98.91%, Valid: 70.22%, Test: 70.14%
Epoch: 625, Loss: 0.0177, Train: 98.94%, Valid: 70.23%, Test: 70.24%
Epoch: 650, Loss: 0.0176, Train: 98.94%, Valid: 70.19%, Test: 70.24%
Epoch: 675, Loss: 0.0174, Train: 98.94%, Valid: 70.24%, Test: 70.16%
Epoch: 700, Loss: 0.0178, Train: 98.94%, Valid: 70.22%, Test: 70.13%
Epoch: 725, Loss: 0.0174, Train: 98.96%, Valid: 70.29%, Test: 70.16%
Epoch: 750, Loss: 0.0185, Train: 98.91%, Valid: 70.30%, Test: 70.15%
Epoch: 775, Loss: 0.0174, Train: 98.94%, Valid: 70.07%, Test: 70.07%
Epoch: 800, Loss: 0.0174, Train: 98.93%, Valid: 70.22%, Test: 70.21%
Epoch: 825, Loss: 0.0184, Train: 98.94%, Valid: 70.13%, Test: 70.18%
Epoch: 850, Loss: 0.0175, Train: 98.94%, Valid: 70.17%, Test: 70.11%
Epoch: 875, Loss: 0.0174, Train: 98.94%, Valid: 70.31%, Test: 70.29%
Epoch: 900, Loss: 0.0174, Train: 98.94%, Valid: 70.34%, Test: 70.28%
Epoch: 925, Loss: 0.0179, Train: 98.93%, Valid: 70.12%, Test: 70.28%
Epoch: 950, Loss: 0.0176, Train: 98.94%, Valid: 70.24%, Test: 70.20%
Epoch: 975, Loss: 0.0177, Train: 98.92%, Valid: 70.11%, Test: 70.33%
Run 01:
Highest Train: 98.96
Highest Valid: 74.57
  Final Train: 80.23
   Final Test: 74.48
All runs:
Highest Train: 98.96 ± nan
Highest Valid: 74.57 ± nan
  Final Train: 80.23 ± nan
   Final Test: 74.48 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.8882, Train: 47.57%, Valid: 48.46%, Test: 47.35%
Epoch: 25, Loss: 0.6992, Train: 57.25%, Valid: 55.88%, Test: 55.68%
Epoch: 50, Loss: 0.6450, Train: 64.35%, Valid: 62.01%, Test: 60.95%
Epoch: 75, Loss: 0.5874, Train: 72.22%, Valid: 67.44%, Test: 66.84%
Epoch: 100, Loss: 0.4936, Train: 78.03%, Valid: 71.66%, Test: 71.95%
Epoch: 125, Loss: 0.4031, Train: 81.01%, Valid: 73.71%, Test: 73.84%
Epoch: 150, Loss: 0.3637, Train: 82.71%, Valid: 73.62%, Test: 74.01%
Epoch: 175, Loss: 0.3404, Train: 83.51%, Valid: 73.13%, Test: 73.91%
Epoch: 200, Loss: 0.3181, Train: 84.80%, Valid: 72.80%, Test: 73.74%
Epoch: 225, Loss: 0.2863, Train: 86.86%, Valid: 72.67%, Test: 73.06%
Epoch: 250, Loss: 0.2306, Train: 90.48%, Valid: 72.27%, Test: 72.15%
Epoch: 275, Loss: 0.1537, Train: 94.32%, Valid: 71.11%, Test: 70.86%
Epoch: 300, Loss: 0.0885, Train: 96.86%, Valid: 70.06%, Test: 69.89%
Epoch: 325, Loss: 0.0511, Train: 98.17%, Valid: 69.81%, Test: 69.38%
Epoch: 350, Loss: 0.0359, Train: 98.68%, Valid: 69.59%, Test: 69.07%
Epoch: 375, Loss: 0.0264, Train: 98.85%, Valid: 69.43%, Test: 69.05%
Epoch: 400, Loss: 0.0226, Train: 98.89%, Valid: 69.57%, Test: 68.82%
Epoch: 425, Loss: 0.0231, Train: 98.78%, Valid: 69.38%, Test: 68.52%
Epoch: 450, Loss: 0.0203, Train: 98.93%, Valid: 69.36%, Test: 69.02%
Epoch: 475, Loss: 0.0197, Train: 98.91%, Valid: 69.27%, Test: 68.96%
Epoch: 500, Loss: 0.0194, Train: 98.87%, Valid: 69.26%, Test: 68.85%
Epoch: 525, Loss: 0.0191, Train: 98.93%, Valid: 69.30%, Test: 68.73%
Epoch: 550, Loss: 0.0194, Train: 98.93%, Valid: 69.27%, Test: 69.00%
Epoch: 575, Loss: 0.0191, Train: 98.85%, Valid: 69.07%, Test: 69.14%
Epoch: 600, Loss: 0.0195, Train: 98.92%, Valid: 69.25%, Test: 68.74%
Epoch: 625, Loss: 0.0183, Train: 98.97%, Valid: 69.20%, Test: 68.97%
Epoch: 650, Loss: 0.0188, Train: 98.85%, Valid: 69.20%, Test: 69.16%
Epoch: 675, Loss: 0.0193, Train: 98.92%, Valid: 69.15%, Test: 68.73%
Epoch: 700, Loss: 0.0184, Train: 98.95%, Valid: 69.15%, Test: 69.09%
Epoch: 725, Loss: 0.0180, Train: 98.91%, Valid: 69.07%, Test: 69.00%
Epoch: 750, Loss: 0.0192, Train: 98.90%, Valid: 69.17%, Test: 68.60%
Epoch: 775, Loss: 0.0190, Train: 98.90%, Valid: 68.98%, Test: 69.06%
Epoch: 800, Loss: 0.0181, Train: 98.94%, Valid: 69.07%, Test: 68.79%
Epoch: 825, Loss: 0.0176, Train: 98.95%, Valid: 68.98%, Test: 68.78%
Epoch: 850, Loss: 0.0181, Train: 98.89%, Valid: 68.83%, Test: 69.12%
Epoch: 875, Loss: 0.0186, Train: 98.89%, Valid: 69.06%, Test: 68.73%
Epoch: 900, Loss: 0.0187, Train: 98.86%, Valid: 68.80%, Test: 69.14%
Epoch: 925, Loss: 0.0190, Train: 98.89%, Valid: 68.96%, Test: 68.75%
Epoch: 950, Loss: 0.0189, Train: 98.89%, Valid: 68.91%, Test: 69.13%
Epoch: 975, Loss: 0.0189, Train: 98.89%, Valid: 68.94%, Test: 68.81%
Run 01:
Highest Train: 99.00
Highest Valid: 73.86
  Final Train: 81.70
   Final Test: 74.32
All runs:
Highest Train: 99.00 ± nan
Highest Valid: 73.86 ± nan
  Final Train: 81.70 ± nan
   Final Test: 74.32 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6938, Train: 54.53%, Valid: 53.23%, Test: 53.75%
Epoch: 25, Loss: 0.3294, Train: 84.56%, Valid: 73.15%, Test: 73.56%
Epoch: 50, Loss: 0.1660, Train: 94.52%, Valid: 72.04%, Test: 72.29%
Epoch: 75, Loss: 0.0468, Train: 98.33%, Valid: 70.61%, Test: 70.70%
Epoch: 100, Loss: 0.0221, Train: 98.91%, Valid: 70.56%, Test: 70.49%
Epoch: 125, Loss: 0.0209, Train: 98.85%, Valid: 70.37%, Test: 70.25%
Epoch: 150, Loss: 0.0180, Train: 98.93%, Valid: 70.29%, Test: 70.53%
Epoch: 175, Loss: 0.0197, Train: 98.93%, Valid: 70.26%, Test: 70.46%
Epoch: 200, Loss: 0.0192, Train: 98.90%, Valid: 70.26%, Test: 70.33%
Epoch: 225, Loss: 0.0181, Train: 98.94%, Valid: 70.37%, Test: 70.69%
Epoch: 250, Loss: 0.0180, Train: 98.91%, Valid: 70.22%, Test: 70.80%
Epoch: 275, Loss: 0.0188, Train: 98.91%, Valid: 70.28%, Test: 70.40%
Epoch: 300, Loss: 0.0185, Train: 98.89%, Valid: 70.18%, Test: 70.79%
Epoch: 325, Loss: 0.0186, Train: 98.93%, Valid: 70.22%, Test: 70.40%
Epoch: 350, Loss: 0.0178, Train: 98.92%, Valid: 70.16%, Test: 70.80%
Epoch: 375, Loss: 0.0175, Train: 98.94%, Valid: 70.28%, Test: 70.49%
Epoch: 400, Loss: 0.0181, Train: 98.93%, Valid: 70.21%, Test: 70.37%
Epoch: 425, Loss: 0.0178, Train: 98.92%, Valid: 70.16%, Test: 70.72%
Epoch: 450, Loss: 0.0178, Train: 98.93%, Valid: 70.24%, Test: 70.43%
Epoch: 475, Loss: 0.0191, Train: 98.84%, Valid: 70.05%, Test: 70.78%
Epoch: 500, Loss: 0.0177, Train: 98.92%, Valid: 70.17%, Test: 70.63%
Epoch: 525, Loss: 0.0176, Train: 98.94%, Valid: 70.30%, Test: 70.43%
Epoch: 550, Loss: 0.0177, Train: 98.92%, Valid: 70.04%, Test: 70.70%
Epoch: 575, Loss: 0.0174, Train: 98.94%, Valid: 70.19%, Test: 70.71%
Epoch: 600, Loss: 0.0175, Train: 98.94%, Valid: 70.17%, Test: 70.49%
Epoch: 625, Loss: 0.0175, Train: 98.94%, Valid: 70.15%, Test: 70.45%
Epoch: 650, Loss: 0.0200, Train: 98.87%, Valid: 70.22%, Test: 70.15%
Epoch: 675, Loss: 0.0175, Train: 98.93%, Valid: 69.93%, Test: 70.56%
Epoch: 700, Loss: 0.0175, Train: 98.94%, Valid: 70.05%, Test: 70.40%
Epoch: 725, Loss: 0.0181, Train: 98.93%, Valid: 70.10%, Test: 70.50%
Epoch: 750, Loss: 0.0176, Train: 98.94%, Valid: 70.00%, Test: 70.56%
Epoch: 775, Loss: 0.0174, Train: 98.94%, Valid: 70.07%, Test: 70.43%
Epoch: 800, Loss: 0.0175, Train: 98.93%, Valid: 70.04%, Test: 70.41%
Epoch: 825, Loss: 0.0175, Train: 98.94%, Valid: 70.03%, Test: 70.38%
Epoch: 850, Loss: 0.0177, Train: 98.92%, Valid: 70.08%, Test: 70.73%
Epoch: 875, Loss: 0.0176, Train: 98.94%, Valid: 70.01%, Test: 70.42%
Epoch: 900, Loss: 0.0177, Train: 98.92%, Valid: 70.12%, Test: 70.57%
Epoch: 925, Loss: 0.0176, Train: 98.94%, Valid: 70.23%, Test: 70.51%
Epoch: 950, Loss: 0.0180, Train: 98.94%, Valid: 69.97%, Test: 70.46%
Epoch: 975, Loss: 0.0174, Train: 98.94%, Valid: 70.15%, Test: 70.54%
Run 01:
Highest Train: 98.94
Highest Valid: 73.99
  Final Train: 81.25
   Final Test: 74.76
All runs:
Highest Train: 98.94 ± nan
Highest Valid: 73.99 ± nan
  Final Train: 81.25 ± nan
   Final Test: 74.76 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6977, Train: 57.23%, Valid: 57.46%, Test: 57.55%
Epoch: 25, Loss: 0.3379, Train: 84.39%, Valid: 73.10%, Test: 73.68%
Epoch: 50, Loss: 0.1501, Train: 94.80%, Valid: 71.51%, Test: 72.42%
Epoch: 75, Loss: 0.0348, Train: 98.71%, Valid: 70.87%, Test: 70.72%
Epoch: 100, Loss: 0.0202, Train: 98.89%, Valid: 70.17%, Test: 70.74%
Epoch: 125, Loss: 0.0202, Train: 98.92%, Valid: 70.13%, Test: 70.65%
Epoch: 150, Loss: 0.0180, Train: 98.95%, Valid: 70.08%, Test: 70.80%
Epoch: 175, Loss: 0.0189, Train: 98.93%, Valid: 70.05%, Test: 70.66%
Epoch: 200, Loss: 0.0184, Train: 98.91%, Valid: 70.15%, Test: 70.62%
Epoch: 225, Loss: 0.0175, Train: 98.94%, Valid: 69.97%, Test: 70.69%
Epoch: 250, Loss: 0.0176, Train: 98.93%, Valid: 70.05%, Test: 70.78%
Epoch: 275, Loss: 0.0178, Train: 98.93%, Valid: 70.05%, Test: 70.67%
Epoch: 300, Loss: 0.0177, Train: 98.92%, Valid: 70.09%, Test: 70.88%
Epoch: 325, Loss: 0.0174, Train: 98.94%, Valid: 69.99%, Test: 70.73%
Epoch: 350, Loss: 0.0176, Train: 98.94%, Valid: 70.01%, Test: 70.71%
Epoch: 375, Loss: 0.0185, Train: 98.90%, Valid: 70.14%, Test: 70.91%
Epoch: 400, Loss: 0.0176, Train: 98.94%, Valid: 70.11%, Test: 70.81%
Epoch: 425, Loss: 0.0175, Train: 98.92%, Valid: 69.97%, Test: 70.73%
Epoch: 450, Loss: 0.0186, Train: 98.94%, Valid: 70.09%, Test: 70.96%
Epoch: 475, Loss: 0.0174, Train: 99.01%, Valid: 70.04%, Test: 70.79%
Epoch: 500, Loss: 0.0172, Train: 98.99%, Valid: 70.15%, Test: 70.84%
Epoch: 525, Loss: 0.0175, Train: 98.94%, Valid: 69.94%, Test: 70.53%
Epoch: 550, Loss: 0.0174, Train: 98.95%, Valid: 70.07%, Test: 70.69%
Epoch: 575, Loss: 0.0168, Train: 99.04%, Valid: 70.14%, Test: 70.78%
Epoch: 600, Loss: 0.0176, Train: 98.93%, Valid: 70.19%, Test: 70.78%
Epoch: 625, Loss: 0.0174, Train: 98.97%, Valid: 70.13%, Test: 70.76%
Epoch: 650, Loss: 0.0173, Train: 98.95%, Valid: 70.14%, Test: 70.84%
Epoch: 675, Loss: 0.0173, Train: 98.98%, Valid: 70.25%, Test: 70.97%
Epoch: 700, Loss: 0.0179, Train: 98.94%, Valid: 69.97%, Test: 70.60%
Epoch: 725, Loss: 0.0171, Train: 99.00%, Valid: 70.17%, Test: 70.79%
Epoch: 750, Loss: 0.0169, Train: 99.06%, Valid: 70.05%, Test: 70.60%
Epoch: 775, Loss: 0.0171, Train: 98.97%, Valid: 70.29%, Test: 70.97%
Epoch: 800, Loss: 0.0170, Train: 98.96%, Valid: 70.44%, Test: 70.57%
Epoch: 825, Loss: 0.0163, Train: 99.06%, Valid: 70.50%, Test: 70.95%
Epoch: 850, Loss: 0.0177, Train: 98.94%, Valid: 70.46%, Test: 70.76%
Epoch: 875, Loss: 0.0173, Train: 99.00%, Valid: 70.44%, Test: 70.76%
Epoch: 900, Loss: 0.0172, Train: 98.95%, Valid: 70.46%, Test: 70.66%
Epoch: 925, Loss: 0.0171, Train: 98.96%, Valid: 70.36%, Test: 70.45%
Epoch: 950, Loss: 0.0171, Train: 98.93%, Valid: 70.05%, Test: 70.24%
Epoch: 975, Loss: 0.0167, Train: 99.04%, Valid: 69.76%, Test: 69.80%
Run 01:
Highest Train: 99.19
Highest Valid: 74.15
  Final Train: 80.74
   Final Test: 73.99
All runs:
Highest Train: 99.19 ± nan
Highest Valid: 74.15 ± nan
  Final Train: 80.74 ± nan
   Final Test: 73.99 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 2.2300, Train: 47.09%, Valid: 48.05%, Test: 47.20%
Epoch: 25, Loss: 1.3169, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 50, Loss: 0.8024, Train: 47.95%, Valid: 48.61%, Test: 47.98%
Epoch: 75, Loss: 0.7141, Train: 58.05%, Valid: 55.32%, Test: 54.12%
Epoch: 100, Loss: 0.6089, Train: 72.72%, Valid: 66.92%, Test: 65.82%
Epoch: 125, Loss: 0.5496, Train: 77.91%, Valid: 71.42%, Test: 70.93%
Epoch: 150, Loss: 0.4734, Train: 79.95%, Valid: 72.71%, Test: 72.67%
Epoch: 175, Loss: 0.4128, Train: 81.18%, Valid: 72.98%, Test: 73.38%
Epoch: 200, Loss: 0.3800, Train: 82.16%, Valid: 72.98%, Test: 73.81%
Epoch: 225, Loss: 0.3612, Train: 82.78%, Valid: 73.04%, Test: 73.72%
Epoch: 250, Loss: 0.3485, Train: 83.35%, Valid: 72.87%, Test: 73.72%
Epoch: 275, Loss: 0.3384, Train: 83.80%, Valid: 72.81%, Test: 73.52%
Epoch: 300, Loss: 0.3294, Train: 84.29%, Valid: 72.69%, Test: 73.44%
Epoch: 325, Loss: 0.3207, Train: 84.87%, Valid: 72.68%, Test: 73.45%
Epoch: 350, Loss: 0.3120, Train: 85.31%, Valid: 72.57%, Test: 73.20%
Epoch: 375, Loss: 0.3032, Train: 85.84%, Valid: 72.53%, Test: 73.07%
Epoch: 400, Loss: 0.2942, Train: 86.41%, Valid: 72.55%, Test: 72.90%
Epoch: 425, Loss: 0.2850, Train: 86.90%, Valid: 72.45%, Test: 72.68%
Epoch: 450, Loss: 0.2755, Train: 87.54%, Valid: 72.49%, Test: 72.66%
Epoch: 475, Loss: 0.2659, Train: 88.10%, Valid: 72.09%, Test: 72.34%
Epoch: 500, Loss: 0.2559, Train: 88.73%, Valid: 72.06%, Test: 72.26%
Epoch: 525, Loss: 0.2460, Train: 89.29%, Valid: 72.01%, Test: 72.19%
Epoch: 550, Loss: 0.2360, Train: 89.98%, Valid: 71.87%, Test: 72.19%
Epoch: 575, Loss: 0.2259, Train: 90.55%, Valid: 71.71%, Test: 72.08%
Epoch: 600, Loss: 0.2160, Train: 91.26%, Valid: 71.57%, Test: 71.96%
Epoch: 625, Loss: 0.2061, Train: 91.81%, Valid: 71.64%, Test: 71.82%
Epoch: 650, Loss: 0.1963, Train: 92.29%, Valid: 71.58%, Test: 71.54%
Epoch: 675, Loss: 0.1868, Train: 92.81%, Valid: 71.41%, Test: 71.44%
Epoch: 700, Loss: 0.1777, Train: 93.17%, Valid: 71.44%, Test: 71.25%
Epoch: 725, Loss: 0.1690, Train: 93.53%, Valid: 71.38%, Test: 71.14%
Epoch: 750, Loss: 0.1606, Train: 94.00%, Valid: 71.14%, Test: 71.09%
Epoch: 775, Loss: 0.1527, Train: 94.41%, Valid: 71.15%, Test: 70.98%
Epoch: 800, Loss: 0.1450, Train: 94.80%, Valid: 71.04%, Test: 70.93%
Epoch: 825, Loss: 0.1377, Train: 95.12%, Valid: 70.84%, Test: 70.73%
Epoch: 850, Loss: 0.1308, Train: 95.48%, Valid: 70.72%, Test: 70.70%
Epoch: 875, Loss: 0.1242, Train: 95.79%, Valid: 70.80%, Test: 70.66%
Epoch: 900, Loss: 0.1177, Train: 96.09%, Valid: 70.71%, Test: 70.54%
Epoch: 925, Loss: 0.1116, Train: 96.33%, Valid: 70.58%, Test: 70.38%
Epoch: 950, Loss: 0.1057, Train: 96.57%, Valid: 70.51%, Test: 70.24%
Epoch: 975, Loss: 0.1000, Train: 96.78%, Valid: 70.37%, Test: 70.15%
Run 01:
Highest Train: 96.93
Highest Valid: 73.11
  Final Train: 82.27
   Final Test: 73.77
All runs:
Highest Train: 96.93 ± nan
Highest Valid: 73.11 ± nan
  Final Train: 82.27 ± nan
   Final Test: 73.77 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6942, Train: 53.55%, Valid: 52.42%, Test: 53.10%
Epoch: 25, Loss: 0.2880, Train: 87.87%, Valid: 72.95%, Test: 73.34%
Epoch: 50, Loss: 0.1116, Train: 96.78%, Valid: 71.67%, Test: 71.97%
Epoch: 75, Loss: 0.0403, Train: 98.68%, Valid: 70.82%, Test: 71.47%
Epoch: 100, Loss: 0.0220, Train: 98.93%, Valid: 70.70%, Test: 70.94%
Epoch: 125, Loss: 0.0187, Train: 98.93%, Valid: 70.52%, Test: 70.82%
Epoch: 150, Loss: 0.0183, Train: 98.92%, Valid: 70.43%, Test: 70.72%
Epoch: 175, Loss: 0.0178, Train: 98.94%, Valid: 70.50%, Test: 70.96%
Epoch: 200, Loss: 0.0187, Train: 98.90%, Valid: 70.78%, Test: 71.18%
Epoch: 225, Loss: 0.0177, Train: 98.94%, Valid: 70.42%, Test: 70.80%
Epoch: 250, Loss: 0.0175, Train: 98.94%, Valid: 70.45%, Test: 70.74%
Epoch: 275, Loss: 0.0175, Train: 98.94%, Valid: 70.57%, Test: 70.76%
Epoch: 300, Loss: 0.0178, Train: 98.94%, Valid: 70.64%, Test: 71.07%
Epoch: 325, Loss: 0.0185, Train: 98.93%, Valid: 70.51%, Test: 70.73%
Epoch: 350, Loss: 0.0176, Train: 98.93%, Valid: 70.60%, Test: 71.07%
Epoch: 375, Loss: 0.0174, Train: 98.94%, Valid: 70.66%, Test: 70.91%
Epoch: 400, Loss: 0.0182, Train: 98.92%, Valid: 70.56%, Test: 70.78%
Epoch: 425, Loss: 0.0174, Train: 98.94%, Valid: 70.63%, Test: 70.98%
Epoch: 450, Loss: 0.0180, Train: 98.90%, Valid: 70.75%, Test: 71.18%
Epoch: 475, Loss: 0.0176, Train: 98.93%, Valid: 70.49%, Test: 70.89%
Epoch: 500, Loss: 0.0185, Train: 98.88%, Valid: 70.66%, Test: 71.35%
Epoch: 525, Loss: 0.0175, Train: 98.94%, Valid: 70.68%, Test: 71.17%
Epoch: 550, Loss: 0.0174, Train: 98.95%, Valid: 70.65%, Test: 70.99%
Epoch: 575, Loss: 0.0176, Train: 98.88%, Valid: 70.57%, Test: 71.17%
Epoch: 600, Loss: 0.0174, Train: 98.94%, Valid: 70.49%, Test: 70.93%
Epoch: 625, Loss: 0.0174, Train: 98.94%, Valid: 70.58%, Test: 71.15%
Epoch: 650, Loss: 0.0179, Train: 98.89%, Valid: 70.68%, Test: 71.20%
Epoch: 675, Loss: 0.0174, Train: 98.94%, Valid: 70.52%, Test: 70.90%
Epoch: 700, Loss: 0.0174, Train: 98.94%, Valid: 70.56%, Test: 71.00%
Epoch: 725, Loss: 0.0175, Train: 98.94%, Valid: 70.51%, Test: 71.04%
Epoch: 750, Loss: 0.0176, Train: 98.92%, Valid: 70.51%, Test: 71.12%
Epoch: 775, Loss: 0.0174, Train: 98.94%, Valid: 70.36%, Test: 70.87%
Epoch: 800, Loss: 0.0187, Train: 98.91%, Valid: 70.32%, Test: 70.76%
Epoch: 825, Loss: 0.0183, Train: 98.88%, Valid: 70.60%, Test: 70.98%
Epoch: 850, Loss: 0.0172, Train: 99.12%, Valid: 70.42%, Test: 70.69%
Epoch: 875, Loss: 0.0178, Train: 98.94%, Valid: 70.25%, Test: 70.61%
Epoch: 900, Loss: 0.0180, Train: 98.98%, Valid: 70.15%, Test: 70.66%
Epoch: 925, Loss: 0.0183, Train: 98.94%, Valid: 70.26%, Test: 70.58%
Epoch: 950, Loss: 0.0170, Train: 99.07%, Valid: 70.22%, Test: 70.47%
Epoch: 975, Loss: 0.0180, Train: 98.92%, Valid: 70.10%, Test: 70.59%
Run 01:
Highest Train: 99.25
Highest Valid: 73.73
  Final Train: 80.97
   Final Test: 74.08
All runs:
Highest Train: 99.25 ± nan
Highest Valid: 73.73 ± nan
  Final Train: 80.97 ± nan
   Final Test: 74.08 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7286, Train: 57.19%, Valid: 56.58%, Test: 56.35%
Epoch: 25, Loss: 0.3198, Train: 85.31%, Valid: 72.85%, Test: 73.86%
Epoch: 50, Loss: 0.1587, Train: 94.85%, Valid: 72.31%, Test: 72.44%
Epoch: 75, Loss: 0.0672, Train: 98.12%, Valid: 71.51%, Test: 71.42%
Epoch: 100, Loss: 0.0382, Train: 98.77%, Valid: 71.54%, Test: 71.17%
Epoch: 125, Loss: 0.0281, Train: 98.89%, Valid: 71.49%, Test: 70.82%
Epoch: 150, Loss: 0.0238, Train: 98.90%, Valid: 71.42%, Test: 71.09%
Epoch: 175, Loss: 0.0217, Train: 98.92%, Valid: 71.41%, Test: 71.16%
Epoch: 200, Loss: 0.0204, Train: 98.94%, Valid: 71.38%, Test: 71.06%
Epoch: 225, Loss: 0.0196, Train: 98.93%, Valid: 71.48%, Test: 71.04%
Epoch: 250, Loss: 0.0192, Train: 98.94%, Valid: 71.34%, Test: 70.94%
Epoch: 275, Loss: 0.0188, Train: 98.93%, Valid: 71.48%, Test: 70.96%
Epoch: 300, Loss: 0.0186, Train: 98.93%, Valid: 71.29%, Test: 70.82%
Epoch: 325, Loss: 0.0183, Train: 98.93%, Valid: 71.40%, Test: 70.96%
Epoch: 350, Loss: 0.0181, Train: 98.93%, Valid: 71.35%, Test: 70.93%
Epoch: 375, Loss: 0.0182, Train: 98.93%, Valid: 71.42%, Test: 70.82%
Epoch: 400, Loss: 0.0182, Train: 98.92%, Valid: 71.44%, Test: 71.09%
Epoch: 425, Loss: 0.0179, Train: 98.93%, Valid: 71.38%, Test: 70.81%
Epoch: 450, Loss: 0.0178, Train: 98.92%, Valid: 71.31%, Test: 70.94%
Epoch: 475, Loss: 0.0181, Train: 98.93%, Valid: 71.50%, Test: 71.08%
Epoch: 500, Loss: 0.0178, Train: 98.93%, Valid: 71.37%, Test: 70.84%
Epoch: 525, Loss: 0.0176, Train: 98.91%, Valid: 71.38%, Test: 70.99%
Epoch: 550, Loss: 0.0180, Train: 98.92%, Valid: 71.48%, Test: 71.06%
Epoch: 575, Loss: 0.0175, Train: 98.91%, Valid: 71.37%, Test: 70.92%
Epoch: 600, Loss: 0.0180, Train: 98.94%, Valid: 71.27%, Test: 70.79%
Epoch: 625, Loss: 0.0175, Train: 98.94%, Valid: 71.49%, Test: 70.84%
Epoch: 650, Loss: 0.0177, Train: 98.92%, Valid: 71.45%, Test: 71.01%
Epoch: 675, Loss: 0.0178, Train: 98.93%, Valid: 71.50%, Test: 71.00%
Epoch: 700, Loss: 0.0175, Train: 98.89%, Valid: 71.39%, Test: 70.76%
Epoch: 725, Loss: 0.0177, Train: 98.93%, Valid: 71.29%, Test: 70.67%
Epoch: 750, Loss: 0.0179, Train: 98.94%, Valid: 71.30%, Test: 70.61%
Epoch: 775, Loss: 0.0175, Train: 98.92%, Valid: 71.41%, Test: 70.91%
Epoch: 800, Loss: 0.0174, Train: 98.94%, Valid: 71.46%, Test: 70.81%
Epoch: 825, Loss: 0.0179, Train: 98.93%, Valid: 71.28%, Test: 70.70%
Epoch: 850, Loss: 0.0175, Train: 98.93%, Valid: 71.26%, Test: 70.79%
Epoch: 875, Loss: 0.0174, Train: 98.93%, Valid: 71.37%, Test: 70.96%
Epoch: 900, Loss: 0.0174, Train: 98.93%, Valid: 71.33%, Test: 70.98%
Epoch: 925, Loss: 0.0176, Train: 98.93%, Valid: 71.30%, Test: 71.03%
Epoch: 950, Loss: 0.0178, Train: 98.92%, Valid: 71.30%, Test: 71.00%
Epoch: 975, Loss: 0.0175, Train: 98.94%, Valid: 71.35%, Test: 70.93%
Run 01:
Highest Train: 98.98
Highest Valid: 74.31
  Final Train: 80.52
   Final Test: 74.69
All runs:
Highest Train: 98.98 ± nan
Highest Valid: 74.31 ± nan
  Final Train: 80.52 ± nan
   Final Test: 74.69 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 3.6766, Train: 52.88%, Valid: 52.00%, Test: 52.59%
Epoch: 25, Loss: 1.2005, Train: 55.97%, Valid: 55.36%, Test: 55.80%
Epoch: 50, Loss: 0.7266, Train: 59.90%, Valid: 58.77%, Test: 59.27%
Epoch: 75, Loss: 0.6470, Train: 60.75%, Valid: 58.09%, Test: 58.53%
Epoch: 100, Loss: 0.6104, Train: 68.47%, Valid: 64.22%, Test: 64.23%
Epoch: 125, Loss: 0.5917, Train: 71.81%, Valid: 65.81%, Test: 66.55%
Epoch: 150, Loss: 0.4722, Train: 79.65%, Valid: 73.02%, Test: 73.58%
Epoch: 175, Loss: 0.4163, Train: 81.41%, Valid: 73.86%, Test: 74.31%
Epoch: 200, Loss: 0.3699, Train: 83.02%, Valid: 73.51%, Test: 73.87%
Epoch: 225, Loss: 0.3318, Train: 85.01%, Valid: 73.04%, Test: 73.68%
Epoch: 250, Loss: 0.3001, Train: 86.73%, Valid: 72.64%, Test: 73.21%
Epoch: 275, Loss: 0.2737, Train: 87.96%, Valid: 71.86%, Test: 72.53%
Epoch: 300, Loss: 0.2523, Train: 89.05%, Valid: 71.40%, Test: 72.41%
Epoch: 325, Loss: 0.2351, Train: 89.96%, Valid: 70.92%, Test: 71.87%
Epoch: 350, Loss: 0.2207, Train: 90.85%, Valid: 70.53%, Test: 71.54%
Epoch: 375, Loss: 0.2089, Train: 91.34%, Valid: 70.50%, Test: 71.30%
Epoch: 400, Loss: 0.1989, Train: 91.82%, Valid: 70.22%, Test: 71.11%
Epoch: 425, Loss: 0.1902, Train: 92.33%, Valid: 70.03%, Test: 70.82%
Epoch: 450, Loss: 0.1825, Train: 92.59%, Valid: 69.84%, Test: 70.76%
Epoch: 475, Loss: 0.1753, Train: 92.93%, Valid: 69.77%, Test: 70.35%
Epoch: 500, Loss: 0.1684, Train: 93.21%, Valid: 69.61%, Test: 70.03%
Epoch: 525, Loss: 0.1619, Train: 93.57%, Valid: 69.57%, Test: 69.91%
Epoch: 550, Loss: 0.1554, Train: 93.85%, Valid: 69.50%, Test: 69.83%
Epoch: 575, Loss: 0.1490, Train: 94.13%, Valid: 69.40%, Test: 69.67%
Epoch: 600, Loss: 0.1426, Train: 94.48%, Valid: 69.31%, Test: 69.62%
Epoch: 625, Loss: 0.1363, Train: 94.75%, Valid: 69.29%, Test: 69.60%
Epoch: 650, Loss: 0.1301, Train: 95.03%, Valid: 69.34%, Test: 69.51%
Epoch: 675, Loss: 0.1239, Train: 95.24%, Valid: 69.24%, Test: 69.30%
Epoch: 700, Loss: 0.1180, Train: 95.60%, Valid: 69.14%, Test: 69.26%
Epoch: 725, Loss: 0.1124, Train: 95.84%, Valid: 69.06%, Test: 69.17%
Epoch: 750, Loss: 0.1070, Train: 96.07%, Valid: 68.85%, Test: 69.26%
Epoch: 775, Loss: 0.1020, Train: 96.32%, Valid: 68.92%, Test: 69.33%
Epoch: 800, Loss: 0.0972, Train: 96.47%, Valid: 68.80%, Test: 69.46%
Epoch: 825, Loss: 0.0928, Train: 96.61%, Valid: 68.66%, Test: 69.34%
Epoch: 850, Loss: 0.0887, Train: 96.81%, Valid: 68.70%, Test: 69.15%
Epoch: 875, Loss: 0.0849, Train: 96.97%, Valid: 68.61%, Test: 68.94%
Epoch: 900, Loss: 0.0814, Train: 97.15%, Valid: 68.71%, Test: 69.08%
Epoch: 925, Loss: 0.0781, Train: 97.26%, Valid: 68.70%, Test: 69.03%
Epoch: 950, Loss: 0.0751, Train: 97.36%, Valid: 68.67%, Test: 69.04%
Epoch: 975, Loss: 0.0722, Train: 97.48%, Valid: 68.45%, Test: 68.94%
Run 01:
Highest Train: 97.58
Highest Valid: 73.93
  Final Train: 81.70
   Final Test: 74.30
All runs:
Highest Train: 97.58 ± nan
Highest Valid: 73.93 ± nan
  Final Train: 81.70 ± nan
   Final Test: 74.30 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6993, Train: 55.89%, Valid: 55.54%, Test: 55.49%
Epoch: 25, Loss: 0.4161, Train: 80.86%, Valid: 74.28%, Test: 74.57%
Epoch: 50, Loss: 0.3018, Train: 86.39%, Valid: 73.36%, Test: 73.69%
Epoch: 75, Loss: 0.1120, Train: 95.89%, Valid: 71.72%, Test: 71.13%
Epoch: 100, Loss: 0.0332, Train: 98.75%, Valid: 70.78%, Test: 70.39%
Epoch: 125, Loss: 0.0203, Train: 98.91%, Valid: 70.99%, Test: 70.27%
Epoch: 150, Loss: 0.0197, Train: 98.92%, Valid: 70.86%, Test: 70.53%
Epoch: 175, Loss: 0.0198, Train: 98.85%, Valid: 70.82%, Test: 70.63%
Epoch: 200, Loss: 0.0194, Train: 98.88%, Valid: 70.73%, Test: 70.67%
Epoch: 225, Loss: 0.0178, Train: 98.95%, Valid: 70.72%, Test: 70.65%
Epoch: 250, Loss: 0.0196, Train: 98.91%, Valid: 70.76%, Test: 70.54%
Epoch: 275, Loss: 0.0180, Train: 98.92%, Valid: 70.75%, Test: 70.52%
Epoch: 300, Loss: 0.0189, Train: 98.90%, Valid: 70.74%, Test: 70.72%
Epoch: 325, Loss: 0.0191, Train: 98.91%, Valid: 70.72%, Test: 70.40%
Epoch: 350, Loss: 0.0189, Train: 98.90%, Valid: 70.76%, Test: 70.67%
Epoch: 375, Loss: 0.0185, Train: 98.93%, Valid: 70.58%, Test: 70.47%
Epoch: 400, Loss: 0.0181, Train: 98.89%, Valid: 70.87%, Test: 70.72%
Epoch: 425, Loss: 0.0176, Train: 98.93%, Valid: 70.68%, Test: 70.49%
Epoch: 450, Loss: 0.0176, Train: 98.94%, Valid: 70.76%, Test: 70.46%
Epoch: 475, Loss: 0.0181, Train: 98.89%, Valid: 70.71%, Test: 70.64%
Epoch: 500, Loss: 0.0174, Train: 98.94%, Valid: 70.70%, Test: 70.43%
Epoch: 525, Loss: 0.0184, Train: 98.92%, Valid: 70.76%, Test: 70.35%
Epoch: 550, Loss: 0.0174, Train: 98.94%, Valid: 70.78%, Test: 70.62%
Epoch: 575, Loss: 0.0185, Train: 98.90%, Valid: 70.62%, Test: 70.71%
Epoch: 600, Loss: 0.0175, Train: 98.94%, Valid: 70.76%, Test: 70.65%
Epoch: 625, Loss: 0.0180, Train: 98.93%, Valid: 70.73%, Test: 70.38%
Epoch: 650, Loss: 0.0186, Train: 98.93%, Valid: 70.69%, Test: 70.38%
Epoch: 675, Loss: 0.0174, Train: 98.94%, Valid: 70.60%, Test: 70.63%
Epoch: 700, Loss: 0.0177, Train: 98.92%, Valid: 70.57%, Test: 70.75%
Epoch: 725, Loss: 0.0184, Train: 98.90%, Valid: 70.64%, Test: 70.78%
Epoch: 750, Loss: 0.0177, Train: 98.94%, Valid: 70.77%, Test: 70.61%
Epoch: 775, Loss: 0.0174, Train: 98.96%, Valid: 70.71%, Test: 70.40%
Epoch: 800, Loss: 0.0176, Train: 98.93%, Valid: 70.55%, Test: 70.41%
Epoch: 825, Loss: 0.0181, Train: 98.93%, Valid: 70.58%, Test: 70.42%
Epoch: 850, Loss: 0.0187, Train: 98.89%, Valid: 70.64%, Test: 70.77%
Epoch: 875, Loss: 0.0174, Train: 98.94%, Valid: 70.55%, Test: 70.37%
Epoch: 900, Loss: 0.0175, Train: 98.94%, Valid: 70.60%, Test: 70.62%
Epoch: 925, Loss: 0.0175, Train: 98.94%, Valid: 70.67%, Test: 70.65%
Epoch: 950, Loss: 0.0174, Train: 98.94%, Valid: 70.62%, Test: 70.63%
Epoch: 975, Loss: 0.0180, Train: 98.92%, Valid: 70.50%, Test: 70.67%
Run 01:
Highest Train: 99.00
Highest Valid: 74.38
  Final Train: 81.13
   Final Test: 74.59
All runs:
Highest Train: 99.00 ± nan
Highest Valid: 74.38 ± nan
  Final Train: 81.13 ± nan
   Final Test: 74.59 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 2.9426, Train: 51.26%, Valid: 51.80%, Test: 50.94%
Epoch: 25, Loss: 0.7081, Train: 57.64%, Valid: 57.09%, Test: 57.57%
Epoch: 50, Loss: 0.6380, Train: 62.02%, Valid: 61.31%, Test: 61.17%
Epoch: 75, Loss: 0.6216, Train: 63.97%, Valid: 62.85%, Test: 63.08%
Epoch: 100, Loss: 0.6319, Train: 63.55%, Valid: 62.68%, Test: 62.72%
Epoch: 125, Loss: 0.5861, Train: 68.62%, Valid: 66.96%, Test: 67.07%
Epoch: 150, Loss: 0.5483, Train: 72.70%, Valid: 69.91%, Test: 70.48%
Epoch: 175, Loss: 0.5439, Train: 71.57%, Valid: 68.42%, Test: 68.77%
Epoch: 200, Loss: 0.5121, Train: 74.74%, Valid: 70.51%, Test: 71.08%
Epoch: 225, Loss: 0.4942, Train: 76.58%, Valid: 71.86%, Test: 72.83%
Epoch: 250, Loss: 0.4776, Train: 77.90%, Valid: 72.44%, Test: 73.63%
Epoch: 275, Loss: 0.4637, Train: 79.43%, Valid: 73.39%, Test: 73.44%
Epoch: 300, Loss: 0.4334, Train: 82.07%, Valid: 75.31%, Test: 75.50%
Epoch: 325, Loss: 0.3954, Train: 84.11%, Valid: 76.33%, Test: 76.70%
Epoch: 350, Loss: 0.3483, Train: 86.11%, Valid: 77.11%, Test: 77.41%
Epoch: 375, Loss: 0.2929, Train: 87.77%, Valid: 76.22%, Test: 76.50%
Epoch: 400, Loss: 0.2250, Train: 91.42%, Valid: 75.75%, Test: 76.16%
Epoch: 425, Loss: 0.1597, Train: 93.40%, Valid: 74.39%, Test: 74.92%
Epoch: 450, Loss: 0.0979, Train: 96.79%, Valid: 73.90%, Test: 74.02%
Epoch: 475, Loss: 0.0604, Train: 98.14%, Valid: 73.26%, Test: 73.62%
Epoch: 500, Loss: 0.0901, Train: 95.04%, Valid: 72.37%, Test: 72.25%
Epoch: 525, Loss: 0.0505, Train: 98.37%, Valid: 72.00%, Test: 72.50%
Epoch: 550, Loss: 0.0334, Train: 98.93%, Valid: 71.59%, Test: 72.07%
Epoch: 575, Loss: 0.0270, Train: 99.17%, Valid: 71.50%, Test: 72.14%
Epoch: 600, Loss: 0.0229, Train: 99.26%, Valid: 71.30%, Test: 71.96%
Epoch: 625, Loss: 0.0202, Train: 99.30%, Valid: 70.96%, Test: 71.63%
Epoch: 650, Loss: 0.0182, Train: 99.36%, Valid: 70.77%, Test: 71.67%
Epoch: 675, Loss: 0.0167, Train: 99.41%, Valid: 70.85%, Test: 71.54%
Epoch: 700, Loss: 0.0155, Train: 99.45%, Valid: 70.73%, Test: 71.44%
Epoch: 725, Loss: 0.0144, Train: 99.49%, Valid: 70.68%, Test: 71.21%
Epoch: 750, Loss: 0.0136, Train: 99.50%, Valid: 70.33%, Test: 71.05%
Epoch: 775, Loss: 0.0129, Train: 99.52%, Valid: 70.23%, Test: 70.79%
Epoch: 800, Loss: 0.0122, Train: 99.56%, Valid: 70.06%, Test: 70.69%
Epoch: 825, Loss: 0.0116, Train: 99.58%, Valid: 69.95%, Test: 70.54%
Epoch: 850, Loss: 0.0111, Train: 99.60%, Valid: 69.81%, Test: 70.20%
Epoch: 875, Loss: 0.0106, Train: 99.62%, Valid: 69.54%, Test: 70.20%
Epoch: 900, Loss: 0.0102, Train: 99.64%, Valid: 69.52%, Test: 70.05%
Epoch: 925, Loss: 0.0097, Train: 99.68%, Valid: 69.27%, Test: 69.95%
Epoch: 950, Loss: 0.0093, Train: 99.70%, Valid: 69.21%, Test: 69.80%
Epoch: 975, Loss: 0.0090, Train: 99.72%, Valid: 69.02%, Test: 69.53%
Run 01:
Highest Train: 99.73
Highest Valid: 77.13
  Final Train: 86.02
   Final Test: 77.44
All runs:
Highest Train: 99.73 ± nan
Highest Valid: 77.13 ± nan
  Final Train: 86.02 ± nan
   Final Test: 77.44 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 243.8232, Train: 48.24%, Valid: 48.89%, Test: 47.49%
Epoch: 25, Loss: 2.5866, Train: 54.18%, Valid: 53.36%, Test: 53.98%
Epoch: 50, Loss: 2.0611, Train: 55.22%, Valid: 55.18%, Test: 55.25%
Epoch: 75, Loss: 1.5810, Train: 56.21%, Valid: 56.03%, Test: 56.02%
Epoch: 100, Loss: 1.3879, Train: 56.48%, Valid: 56.16%, Test: 56.31%
Epoch: 125, Loss: 1.2937, Train: 57.79%, Valid: 57.51%, Test: 57.29%
Epoch: 150, Loss: 1.2358, Train: 57.97%, Valid: 57.32%, Test: 57.09%
Epoch: 175, Loss: 1.1790, Train: 58.50%, Valid: 57.76%, Test: 57.60%
Epoch: 200, Loss: 0.9471, Train: 55.73%, Valid: 54.68%, Test: 54.95%
Epoch: 225, Loss: 0.6909, Train: 60.06%, Valid: 59.81%, Test: 59.26%
Epoch: 250, Loss: 0.6632, Train: 62.16%, Valid: 60.92%, Test: 60.43%
Epoch: 275, Loss: 0.6497, Train: 64.21%, Valid: 62.65%, Test: 62.57%
Epoch: 300, Loss: 0.6367, Train: 66.40%, Valid: 64.29%, Test: 64.34%
Epoch: 325, Loss: 0.6621, Train: 67.70%, Valid: 65.75%, Test: 66.05%
Epoch: 350, Loss: 0.6159, Train: 69.36%, Valid: 67.16%, Test: 67.49%
Epoch: 375, Loss: 0.6184, Train: 68.35%, Valid: 66.24%, Test: 66.38%
Epoch: 400, Loss: 0.6084, Train: 68.84%, Valid: 66.71%, Test: 66.43%
Epoch: 425, Loss: 0.6090, Train: 69.42%, Valid: 67.71%, Test: 67.52%
Epoch: 450, Loss: 0.5990, Train: 69.49%, Valid: 67.60%, Test: 67.30%
Epoch: 475, Loss: 0.6021, Train: 69.95%, Valid: 68.35%, Test: 68.11%
Epoch: 500, Loss: 0.5921, Train: 69.77%, Valid: 68.35%, Test: 67.95%
Epoch: 525, Loss: 0.5965, Train: 70.35%, Valid: 69.06%, Test: 68.35%
Epoch: 550, Loss: 0.5864, Train: 70.16%, Valid: 68.62%, Test: 68.11%
Epoch: 575, Loss: 0.5920, Train: 70.64%, Valid: 69.28%, Test: 68.76%
Epoch: 600, Loss: 0.5817, Train: 70.45%, Valid: 68.75%, Test: 68.41%
Epoch: 625, Loss: 0.5880, Train: 71.05%, Valid: 69.59%, Test: 69.30%
Epoch: 650, Loss: 0.5774, Train: 70.76%, Valid: 69.13%, Test: 68.78%
Epoch: 675, Loss: 0.5842, Train: 71.23%, Valid: 69.85%, Test: 69.53%
Epoch: 700, Loss: 0.5735, Train: 70.94%, Valid: 69.25%, Test: 68.92%
Epoch: 725, Loss: 0.5804, Train: 71.49%, Valid: 70.11%, Test: 69.80%
Epoch: 750, Loss: 0.5697, Train: 71.21%, Valid: 69.56%, Test: 69.08%
Epoch: 775, Loss: 0.5769, Train: 71.65%, Valid: 70.37%, Test: 69.99%
Epoch: 800, Loss: 0.5661, Train: 71.38%, Valid: 69.69%, Test: 69.17%
Epoch: 825, Loss: 0.5735, Train: 71.76%, Valid: 70.40%, Test: 70.19%
Epoch: 850, Loss: 0.5628, Train: 71.55%, Valid: 69.89%, Test: 69.39%
Epoch: 875, Loss: 0.5701, Train: 71.94%, Valid: 70.75%, Test: 70.46%
Epoch: 900, Loss: 0.5593, Train: 71.62%, Valid: 70.21%, Test: 69.54%
Epoch: 925, Loss: 0.5669, Train: 71.97%, Valid: 70.82%, Test: 70.55%
Epoch: 950, Loss: 0.5562, Train: 71.83%, Valid: 70.44%, Test: 69.76%
Epoch: 975, Loss: 0.5637, Train: 72.15%, Valid: 70.81%, Test: 70.83%
Run 01:
Highest Train: 72.24
Highest Valid: 70.91
  Final Train: 72.10
   Final Test: 70.72
All runs:
Highest Train: 72.24 ± nan
Highest Valid: 70.91 ± nan
  Final Train: 72.10 ± nan
   Final Test: 70.72 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7218, Train: 60.26%, Valid: 59.86%, Test: 59.91%
Epoch: 25, Loss: 0.3613, Train: 82.63%, Valid: 73.16%, Test: 73.59%
Epoch: 50, Loss: 0.2471, Train: 90.22%, Valid: 72.78%, Test: 72.98%
Epoch: 75, Loss: 0.0958, Train: 97.02%, Valid: 70.97%, Test: 70.61%
Epoch: 100, Loss: 0.0306, Train: 98.69%, Valid: 70.32%, Test: 69.75%
Epoch: 125, Loss: 0.0201, Train: 99.18%, Valid: 70.14%, Test: 69.63%
Epoch: 150, Loss: 0.0266, Train: 98.81%, Valid: 70.07%, Test: 69.75%
Epoch: 175, Loss: 0.0185, Train: 98.94%, Valid: 70.02%, Test: 69.49%
Epoch: 200, Loss: 0.0188, Train: 98.92%, Valid: 69.82%, Test: 69.39%
Epoch: 225, Loss: 0.0178, Train: 98.95%, Valid: 69.78%, Test: 69.40%
Epoch: 250, Loss: 0.0189, Train: 98.94%, Valid: 69.89%, Test: 69.55%
Epoch: 275, Loss: 0.0187, Train: 98.92%, Valid: 69.62%, Test: 69.38%
Epoch: 300, Loss: 0.0178, Train: 98.92%, Valid: 69.68%, Test: 69.78%
Epoch: 325, Loss: 0.0203, Train: 98.85%, Valid: 69.58%, Test: 69.81%
Epoch: 350, Loss: 0.0180, Train: 98.93%, Valid: 69.55%, Test: 69.52%
Epoch: 375, Loss: 0.0181, Train: 98.92%, Valid: 69.52%, Test: 69.52%
Epoch: 400, Loss: 0.0180, Train: 98.91%, Valid: 69.46%, Test: 69.76%
Epoch: 425, Loss: 0.0188, Train: 98.93%, Valid: 69.44%, Test: 69.48%
Epoch: 450, Loss: 0.0174, Train: 98.94%, Valid: 69.31%, Test: 69.52%
Epoch: 475, Loss: 0.0197, Train: 98.87%, Valid: 69.36%, Test: 69.13%
Epoch: 500, Loss: 0.0176, Train: 99.00%, Valid: 69.33%, Test: 69.39%
Epoch: 525, Loss: 0.0180, Train: 98.91%, Valid: 69.21%, Test: 69.48%
Epoch: 550, Loss: 0.0176, Train: 98.94%, Valid: 69.27%, Test: 69.38%
Epoch: 575, Loss: 0.0193, Train: 98.92%, Valid: 69.11%, Test: 68.94%
Epoch: 600, Loss: 0.0175, Train: 98.94%, Valid: 69.09%, Test: 69.00%
Epoch: 625, Loss: 0.0175, Train: 98.94%, Valid: 68.92%, Test: 68.87%
Epoch: 650, Loss: 0.0173, Train: 99.04%, Valid: 68.82%, Test: 68.69%
Epoch: 675, Loss: 0.0204, Train: 98.78%, Valid: 69.42%, Test: 69.36%
Epoch: 700, Loss: 0.0179, Train: 98.87%, Valid: 69.29%, Test: 69.00%
Epoch: 725, Loss: 0.0176, Train: 98.93%, Valid: 69.18%, Test: 69.04%
Epoch: 750, Loss: 0.0174, Train: 98.98%, Valid: 68.96%, Test: 68.92%
Epoch: 775, Loss: 0.0173, Train: 99.03%, Valid: 69.00%, Test: 68.97%
Epoch: 800, Loss: 0.0186, Train: 98.85%, Valid: 68.72%, Test: 68.94%
Epoch: 825, Loss: 0.0181, Train: 98.94%, Valid: 68.53%, Test: 68.53%
Epoch: 850, Loss: 0.0177, Train: 98.94%, Valid: 68.47%, Test: 68.50%
Epoch: 875, Loss: 0.0173, Train: 98.99%, Valid: 68.55%, Test: 68.71%
Epoch: 900, Loss: 0.0179, Train: 98.95%, Valid: 68.39%, Test: 68.59%
Epoch: 925, Loss: 0.0172, Train: 98.94%, Valid: 68.21%, Test: 68.40%
Epoch: 950, Loss: 0.0173, Train: 98.95%, Valid: 68.30%, Test: 68.44%
Epoch: 975, Loss: 0.0196, Train: 98.83%, Valid: 67.62%, Test: 68.08%
Run 01:
Highest Train: 99.28
Highest Valid: 73.67
  Final Train: 80.52
   Final Test: 73.88
All runs:
Highest Train: 99.28 ± nan
Highest Valid: 73.67 ± nan
  Final Train: 80.52 ± nan
   Final Test: 73.88 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.0712, Train: 47.69%, Valid: 48.73%, Test: 47.77%
Epoch: 25, Loss: 0.6325, Train: 67.44%, Valid: 64.88%, Test: 64.21%
Epoch: 50, Loss: 0.4458, Train: 81.00%, Valid: 76.09%, Test: 76.13%
Epoch: 75, Loss: 0.3743, Train: 82.99%, Valid: 75.20%, Test: 75.59%
Epoch: 100, Loss: 0.3340, Train: 84.89%, Valid: 74.70%, Test: 75.12%
Epoch: 125, Loss: 0.2988, Train: 86.82%, Valid: 74.28%, Test: 74.74%
Epoch: 150, Loss: 0.2633, Train: 88.95%, Valid: 74.11%, Test: 74.34%
Epoch: 175, Loss: 0.2294, Train: 90.81%, Valid: 73.87%, Test: 73.81%
Epoch: 200, Loss: 0.1993, Train: 92.36%, Valid: 73.45%, Test: 73.33%
Epoch: 225, Loss: 0.1733, Train: 93.48%, Valid: 73.15%, Test: 72.89%
Epoch: 250, Loss: 0.1516, Train: 94.41%, Valid: 72.44%, Test: 72.54%
Epoch: 275, Loss: 0.1337, Train: 95.14%, Valid: 72.19%, Test: 72.11%
Epoch: 300, Loss: 0.1185, Train: 95.87%, Valid: 71.96%, Test: 71.88%
Epoch: 325, Loss: 0.1056, Train: 96.41%, Valid: 71.87%, Test: 71.66%
Epoch: 350, Loss: 0.0941, Train: 96.84%, Valid: 71.83%, Test: 71.46%
Epoch: 375, Loss: 0.0839, Train: 97.31%, Valid: 71.57%, Test: 71.30%
Epoch: 400, Loss: 0.0752, Train: 97.52%, Valid: 71.61%, Test: 71.14%
Epoch: 425, Loss: 0.0676, Train: 97.82%, Valid: 71.36%, Test: 70.94%
Epoch: 450, Loss: 0.0608, Train: 98.02%, Valid: 71.13%, Test: 70.86%
Epoch: 475, Loss: 0.0551, Train: 98.17%, Valid: 70.99%, Test: 70.99%
Epoch: 500, Loss: 0.0502, Train: 98.32%, Valid: 70.86%, Test: 70.86%
Epoch: 525, Loss: 0.0461, Train: 98.45%, Valid: 70.67%, Test: 70.60%
Epoch: 550, Loss: 0.0426, Train: 98.51%, Valid: 70.64%, Test: 70.49%
Epoch: 575, Loss: 0.0395, Train: 98.58%, Valid: 70.55%, Test: 70.40%
Epoch: 600, Loss: 0.0368, Train: 98.63%, Valid: 70.60%, Test: 70.21%
Epoch: 625, Loss: 0.0343, Train: 98.66%, Valid: 70.36%, Test: 70.35%
Epoch: 650, Loss: 0.0322, Train: 98.69%, Valid: 70.14%, Test: 70.25%
Epoch: 675, Loss: 0.0303, Train: 98.78%, Valid: 69.95%, Test: 70.11%
Epoch: 700, Loss: 0.0285, Train: 98.80%, Valid: 69.82%, Test: 70.14%
Epoch: 725, Loss: 0.0270, Train: 98.83%, Valid: 69.68%, Test: 70.07%
Epoch: 750, Loss: 0.0257, Train: 98.85%, Valid: 69.63%, Test: 69.89%
Epoch: 775, Loss: 0.0246, Train: 98.93%, Valid: 69.59%, Test: 69.71%
Epoch: 800, Loss: 0.0237, Train: 98.93%, Valid: 69.34%, Test: 69.59%
Epoch: 825, Loss: 0.0228, Train: 98.95%, Valid: 69.36%, Test: 69.44%
Epoch: 850, Loss: 0.0220, Train: 98.97%, Valid: 69.32%, Test: 69.48%
Epoch: 875, Loss: 0.0213, Train: 98.96%, Valid: 69.16%, Test: 69.27%
Epoch: 900, Loss: 0.0208, Train: 98.99%, Valid: 69.12%, Test: 69.28%
Epoch: 925, Loss: 0.0202, Train: 99.00%, Valid: 68.98%, Test: 69.13%
Epoch: 950, Loss: 0.0198, Train: 99.03%, Valid: 68.78%, Test: 69.08%
Epoch: 975, Loss: 0.0195, Train: 99.01%, Valid: 68.65%, Test: 68.79%
Run 01:
Highest Train: 99.08
Highest Valid: 76.23
  Final Train: 80.63
   Final Test: 76.22
All runs:
Highest Train: 99.08 ± nan
Highest Valid: 76.23 ± nan
  Final Train: 80.63 ± nan
   Final Test: 76.22 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 151.6746, Train: 47.34%, Valid: 48.14%, Test: 47.50%
Epoch: 25, Loss: 4.3074, Train: 46.33%, Valid: 46.47%, Test: 46.17%
Epoch: 50, Loss: 3.0169, Train: 47.08%, Valid: 47.11%, Test: 46.74%
Epoch: 75, Loss: 2.6969, Train: 46.82%, Valid: 47.50%, Test: 46.52%
Epoch: 100, Loss: 2.4413, Train: 47.45%, Valid: 48.17%, Test: 46.74%
Epoch: 125, Loss: 2.2006, Train: 47.82%, Valid: 48.58%, Test: 47.00%
Epoch: 150, Loss: 1.9814, Train: 48.57%, Valid: 49.29%, Test: 47.50%
Epoch: 175, Loss: 1.7023, Train: 49.59%, Valid: 49.99%, Test: 48.69%
Epoch: 200, Loss: 1.0263, Train: 51.14%, Valid: 51.24%, Test: 50.21%
Epoch: 225, Loss: 0.8456, Train: 53.00%, Valid: 52.91%, Test: 51.75%
Epoch: 250, Loss: 0.7736, Train: 54.67%, Valid: 54.36%, Test: 52.95%
Epoch: 275, Loss: 0.7209, Train: 56.82%, Valid: 56.14%, Test: 54.66%
Epoch: 300, Loss: 0.6888, Train: 58.55%, Valid: 56.94%, Test: 56.34%
Epoch: 325, Loss: 0.6591, Train: 60.13%, Valid: 58.88%, Test: 58.08%
Epoch: 350, Loss: 0.6292, Train: 62.38%, Valid: 60.80%, Test: 60.03%
Epoch: 375, Loss: 0.7253, Train: 59.89%, Valid: 58.26%, Test: 57.83%
Epoch: 400, Loss: 0.6215, Train: 63.73%, Valid: 61.85%, Test: 61.46%
Epoch: 425, Loss: 0.5900, Train: 65.57%, Valid: 63.24%, Test: 62.85%
Epoch: 450, Loss: 0.5852, Train: 65.91%, Valid: 63.31%, Test: 63.25%
Epoch: 475, Loss: 0.5626, Train: 67.83%, Valid: 65.33%, Test: 65.16%
Epoch: 500, Loss: 0.7525, Train: 61.70%, Valid: 60.23%, Test: 59.56%
Epoch: 525, Loss: 0.5780, Train: 66.34%, Valid: 63.78%, Test: 63.44%
Epoch: 550, Loss: 0.5625, Train: 69.90%, Valid: 66.60%, Test: 66.50%
Epoch: 575, Loss: 0.5485, Train: 71.18%, Valid: 67.69%, Test: 67.60%
Epoch: 600, Loss: 0.5367, Train: 72.39%, Valid: 68.68%, Test: 68.99%
Epoch: 625, Loss: 0.5654, Train: 66.23%, Valid: 64.11%, Test: 63.63%
Epoch: 650, Loss: 0.5515, Train: 71.96%, Valid: 68.39%, Test: 68.49%
Epoch: 675, Loss: 0.5336, Train: 73.80%, Valid: 70.05%, Test: 70.48%
Epoch: 700, Loss: 0.5217, Train: 74.85%, Valid: 71.11%, Test: 71.51%
Epoch: 725, Loss: 0.9153, Train: 65.12%, Valid: 62.96%, Test: 63.10%
Epoch: 750, Loss: 0.6024, Train: 69.06%, Valid: 65.39%, Test: 65.27%
Epoch: 775, Loss: 0.5569, Train: 73.66%, Valid: 69.15%, Test: 69.73%
Epoch: 800, Loss: 0.5418, Train: 75.33%, Valid: 70.53%, Test: 71.32%
Epoch: 825, Loss: 0.5310, Train: 76.59%, Valid: 71.82%, Test: 72.34%
Epoch: 850, Loss: 0.5219, Train: 77.06%, Valid: 72.65%, Test: 72.57%
Epoch: 875, Loss: 0.5137, Train: 77.54%, Valid: 73.08%, Test: 73.00%
Epoch: 900, Loss: 0.5058, Train: 77.83%, Valid: 73.59%, Test: 73.42%
Epoch: 925, Loss: 0.6427, Train: 67.17%, Valid: 63.69%, Test: 63.68%
Epoch: 950, Loss: 0.5242, Train: 76.26%, Valid: 71.88%, Test: 71.44%
Epoch: 975, Loss: 0.5113, Train: 78.09%, Valid: 73.20%, Test: 73.32%
Run 01:
Highest Train: 78.48
Highest Valid: 74.02
  Final Train: 78.48
   Final Test: 73.90
All runs:
Highest Train: 78.48 ± nan
Highest Valid: 74.02 ± nan
  Final Train: 78.48 ± nan
   Final Test: 73.90 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6953, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.3557, Train: 83.34%, Valid: 72.75%, Test: 72.96%
Epoch: 50, Loss: 0.2248, Train: 91.87%, Valid: 72.62%, Test: 72.42%
Epoch: 75, Loss: 0.1056, Train: 97.21%, Valid: 72.05%, Test: 71.59%
Epoch: 100, Loss: 0.0534, Train: 98.51%, Valid: 71.54%, Test: 71.20%
Epoch: 125, Loss: 0.0353, Train: 98.82%, Valid: 71.39%, Test: 71.09%
Epoch: 150, Loss: 0.0281, Train: 98.90%, Valid: 71.35%, Test: 70.89%
Epoch: 175, Loss: 0.0245, Train: 98.93%, Valid: 71.08%, Test: 70.73%
Epoch: 200, Loss: 0.0224, Train: 98.90%, Valid: 71.01%, Test: 70.72%
Epoch: 225, Loss: 0.0211, Train: 98.94%, Valid: 70.92%, Test: 70.77%
Epoch: 250, Loss: 0.0203, Train: 98.94%, Valid: 70.83%, Test: 70.67%
Epoch: 275, Loss: 0.0197, Train: 98.93%, Valid: 70.94%, Test: 70.69%
Epoch: 300, Loss: 0.0192, Train: 98.94%, Valid: 70.78%, Test: 70.52%
Epoch: 325, Loss: 0.0189, Train: 98.93%, Valid: 70.75%, Test: 70.65%
Epoch: 350, Loss: 0.0187, Train: 98.92%, Valid: 70.65%, Test: 70.49%
Epoch: 375, Loss: 0.0184, Train: 98.93%, Valid: 70.67%, Test: 70.65%
Epoch: 400, Loss: 0.0182, Train: 98.93%, Valid: 70.55%, Test: 70.51%
Epoch: 425, Loss: 0.0184, Train: 98.93%, Valid: 70.36%, Test: 70.37%
Epoch: 450, Loss: 0.0180, Train: 98.94%, Valid: 70.41%, Test: 70.56%
Epoch: 475, Loss: 0.0181, Train: 98.93%, Valid: 70.23%, Test: 70.28%
Epoch: 500, Loss: 0.0179, Train: 98.95%, Valid: 70.37%, Test: 70.42%
Epoch: 525, Loss: 0.0177, Train: 98.94%, Valid: 70.18%, Test: 70.25%
Epoch: 550, Loss: 0.0180, Train: 98.93%, Valid: 70.22%, Test: 70.09%
Epoch: 575, Loss: 0.0176, Train: 98.97%, Valid: 70.19%, Test: 70.21%
Epoch: 600, Loss: 0.0180, Train: 98.93%, Valid: 70.19%, Test: 70.32%
Epoch: 625, Loss: 0.0175, Train: 98.94%, Valid: 70.03%, Test: 69.80%
Epoch: 650, Loss: 0.0179, Train: 98.94%, Valid: 69.92%, Test: 69.88%
Epoch: 675, Loss: 0.0174, Train: 98.96%, Valid: 69.99%, Test: 69.89%
Epoch: 700, Loss: 0.0177, Train: 98.95%, Valid: 69.77%, Test: 69.85%
Epoch: 725, Loss: 0.0172, Train: 98.99%, Valid: 69.05%, Test: 69.25%
Epoch: 750, Loss: 0.0171, Train: 99.00%, Valid: 68.89%, Test: 68.90%
Epoch: 775, Loss: 0.0154, Train: 99.03%, Valid: 69.62%, Test: 69.23%
Epoch: 800, Loss: 0.0127, Train: 99.27%, Valid: 69.57%, Test: 69.57%
Epoch: 825, Loss: 0.0115, Train: 99.40%, Valid: 69.52%, Test: 69.67%
Epoch: 850, Loss: 0.0169, Train: 99.23%, Valid: 68.41%, Test: 68.56%
Epoch: 875, Loss: 0.0265, Train: 98.81%, Valid: 69.94%, Test: 69.67%
Epoch: 900, Loss: 0.0187, Train: 98.99%, Valid: 68.61%, Test: 68.65%
Epoch: 925, Loss: 0.0167, Train: 99.03%, Valid: 67.91%, Test: 68.33%
Epoch: 950, Loss: 0.0166, Train: 99.18%, Valid: 67.50%, Test: 68.01%
Epoch: 975, Loss: 0.0164, Train: 99.25%, Valid: 67.19%, Test: 67.32%
Run 01:
Highest Train: 99.84
Highest Valid: 74.02
  Final Train: 80.48
   Final Test: 73.79
All runs:
Highest Train: 99.84 ± nan
Highest Valid: 74.02 ± nan
  Final Train: 80.48 ± nan
   Final Test: 73.79 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 5.6660, Train: 52.70%, Valid: 52.00%, Test: 53.34%
Epoch: 25, Loss: 1.0951, Train: 56.42%, Valid: 55.09%, Test: 55.95%
Epoch: 50, Loss: 0.7719, Train: 70.56%, Valid: 65.11%, Test: 65.38%
Epoch: 75, Loss: 0.6197, Train: 73.90%, Valid: 68.61%, Test: 68.24%
Epoch: 100, Loss: 0.4070, Train: 82.33%, Valid: 75.42%, Test: 75.46%
Epoch: 125, Loss: 0.3485, Train: 84.67%, Valid: 75.17%, Test: 75.24%
Epoch: 150, Loss: 0.3140, Train: 86.38%, Valid: 74.65%, Test: 74.88%
Epoch: 175, Loss: 0.2847, Train: 87.98%, Valid: 74.35%, Test: 74.40%
Epoch: 200, Loss: 0.2577, Train: 89.44%, Valid: 73.83%, Test: 73.98%
Epoch: 225, Loss: 0.2330, Train: 90.76%, Valid: 73.56%, Test: 73.56%
Epoch: 250, Loss: 0.2105, Train: 92.00%, Valid: 73.24%, Test: 73.17%
Epoch: 275, Loss: 0.1904, Train: 93.07%, Valid: 73.17%, Test: 73.22%
Epoch: 300, Loss: 0.1725, Train: 93.79%, Valid: 72.70%, Test: 72.83%
Epoch: 325, Loss: 0.1567, Train: 94.35%, Valid: 72.60%, Test: 72.68%
Epoch: 350, Loss: 0.1427, Train: 95.09%, Valid: 72.35%, Test: 72.38%
Epoch: 375, Loss: 0.1302, Train: 95.59%, Valid: 72.34%, Test: 72.04%
Epoch: 400, Loss: 0.1192, Train: 96.09%, Valid: 72.34%, Test: 71.80%
Epoch: 425, Loss: 0.1096, Train: 96.48%, Valid: 72.11%, Test: 71.66%
Epoch: 450, Loss: 0.1009, Train: 96.75%, Valid: 72.05%, Test: 71.49%
Epoch: 475, Loss: 0.0932, Train: 97.02%, Valid: 71.92%, Test: 71.53%
Epoch: 500, Loss: 0.0864, Train: 97.30%, Valid: 71.90%, Test: 71.60%
Epoch: 525, Loss: 0.0803, Train: 97.54%, Valid: 71.86%, Test: 71.50%
Epoch: 550, Loss: 0.0749, Train: 97.73%, Valid: 71.63%, Test: 71.35%
Epoch: 575, Loss: 0.0700, Train: 97.88%, Valid: 71.54%, Test: 71.45%
Epoch: 600, Loss: 0.0658, Train: 98.06%, Valid: 71.53%, Test: 71.48%
Epoch: 625, Loss: 0.0619, Train: 98.20%, Valid: 71.51%, Test: 71.37%
Epoch: 650, Loss: 0.0584, Train: 98.29%, Valid: 71.33%, Test: 71.22%
Epoch: 675, Loss: 0.0553, Train: 98.39%, Valid: 71.44%, Test: 71.18%
Epoch: 700, Loss: 0.0524, Train: 98.47%, Valid: 71.33%, Test: 71.01%
Epoch: 725, Loss: 0.0499, Train: 98.51%, Valid: 71.52%, Test: 70.99%
Epoch: 750, Loss: 0.0476, Train: 98.55%, Valid: 71.35%, Test: 70.98%
Epoch: 775, Loss: 0.0454, Train: 98.63%, Valid: 71.44%, Test: 71.03%
Epoch: 800, Loss: 0.0434, Train: 98.68%, Valid: 71.36%, Test: 70.96%
Epoch: 825, Loss: 0.0418, Train: 98.70%, Valid: 71.43%, Test: 71.06%
Epoch: 850, Loss: 0.0400, Train: 98.72%, Valid: 71.40%, Test: 70.91%
Epoch: 875, Loss: 0.0389, Train: 98.74%, Valid: 71.41%, Test: 70.85%
Epoch: 900, Loss: 0.0375, Train: 98.80%, Valid: 71.25%, Test: 70.88%
Epoch: 925, Loss: 0.0363, Train: 98.79%, Valid: 71.44%, Test: 70.78%
Epoch: 950, Loss: 0.0349, Train: 98.86%, Valid: 71.32%, Test: 70.74%
Epoch: 975, Loss: 0.0343, Train: 98.80%, Valid: 71.40%, Test: 70.81%
Run 01:
Highest Train: 98.89
Highest Valid: 75.56
  Final Train: 83.25
   Final Test: 75.41
All runs:
Highest Train: 98.89 ± nan
Highest Valid: 75.56 ± nan
  Final Train: 83.25 ± nan
   Final Test: 75.41 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 10.7470, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 9.7824, Train: 54.24%, Valid: 54.12%, Test: 54.42%
Epoch: 50, Loss: 4.9340, Train: 56.14%, Valid: 55.30%, Test: 56.11%
Epoch: 75, Loss: 3.7038, Train: 57.43%, Valid: 56.74%, Test: 57.37%
Epoch: 100, Loss: 2.8661, Train: 57.93%, Valid: 57.39%, Test: 57.68%
Epoch: 125, Loss: 2.2816, Train: 59.10%, Valid: 58.32%, Test: 58.55%
Epoch: 150, Loss: 1.8200, Train: 59.73%, Valid: 58.66%, Test: 58.84%
Epoch: 175, Loss: 1.6285, Train: 61.25%, Valid: 60.34%, Test: 60.83%
Epoch: 200, Loss: 1.1573, Train: 63.25%, Valid: 61.94%, Test: 62.29%
Epoch: 225, Loss: 0.9184, Train: 61.88%, Valid: 60.17%, Test: 60.76%
Epoch: 250, Loss: 0.8403, Train: 66.13%, Valid: 64.52%, Test: 64.70%
Epoch: 275, Loss: 0.6650, Train: 68.72%, Valid: 66.28%, Test: 66.42%
Epoch: 300, Loss: 0.5804, Train: 67.87%, Valid: 64.76%, Test: 65.44%
Epoch: 325, Loss: 0.6151, Train: 71.06%, Valid: 67.59%, Test: 68.18%
Epoch: 350, Loss: 0.5483, Train: 73.51%, Valid: 69.13%, Test: 69.50%
Epoch: 375, Loss: 0.5232, Train: 71.12%, Valid: 66.72%, Test: 67.20%
Epoch: 400, Loss: 0.5860, Train: 73.53%, Valid: 69.06%, Test: 69.17%
Epoch: 425, Loss: 0.5234, Train: 76.29%, Valid: 70.83%, Test: 71.34%
Epoch: 450, Loss: 0.4880, Train: 73.42%, Valid: 68.05%, Test: 68.59%
Epoch: 475, Loss: 0.5294, Train: 75.81%, Valid: 70.76%, Test: 70.67%
Epoch: 500, Loss: 0.5067, Train: 77.71%, Valid: 72.09%, Test: 72.11%
Epoch: 525, Loss: 0.4617, Train: 75.89%, Valid: 70.02%, Test: 70.31%
Epoch: 550, Loss: 0.5227, Train: 76.11%, Valid: 71.02%, Test: 70.63%
Epoch: 575, Loss: 0.4693, Train: 79.19%, Valid: 72.82%, Test: 72.88%
Epoch: 600, Loss: 0.4594, Train: 76.43%, Valid: 70.17%, Test: 70.32%
Epoch: 625, Loss: 0.5042, Train: 79.28%, Valid: 72.80%, Test: 72.72%
Epoch: 650, Loss: 0.4528, Train: 79.93%, Valid: 73.30%, Test: 73.42%
Epoch: 675, Loss: 0.4286, Train: 81.17%, Valid: 74.31%, Test: 74.08%
Epoch: 700, Loss: 0.4190, Train: 81.60%, Valid: 74.54%, Test: 74.50%
Epoch: 725, Loss: 0.6360, Train: 75.61%, Valid: 70.64%, Test: 69.62%
Epoch: 750, Loss: 0.4354, Train: 81.15%, Valid: 73.82%, Test: 73.60%
Epoch: 775, Loss: 0.4148, Train: 82.05%, Valid: 74.29%, Test: 74.33%
Epoch: 800, Loss: 0.4079, Train: 82.71%, Valid: 75.29%, Test: 74.90%
Epoch: 825, Loss: 0.4407, Train: 80.88%, Valid: 73.48%, Test: 73.61%
Epoch: 850, Loss: 0.4076, Train: 82.39%, Valid: 74.91%, Test: 74.36%
Epoch: 875, Loss: 0.4138, Train: 83.08%, Valid: 75.04%, Test: 74.81%
Epoch: 900, Loss: 0.3935, Train: 82.96%, Valid: 74.86%, Test: 74.79%
Epoch: 925, Loss: 0.3928, Train: 83.73%, Valid: 75.33%, Test: 75.06%
Epoch: 950, Loss: 0.5341, Train: 81.76%, Valid: 73.69%, Test: 73.84%
Epoch: 975, Loss: 0.4027, Train: 83.16%, Valid: 74.85%, Test: 74.56%
Run 01:
Highest Train: 84.34
Highest Valid: 75.85
  Final Train: 84.25
   Final Test: 75.36
All runs:
Highest Train: 84.34 ± nan
Highest Valid: 75.85 ± nan
  Final Train: 84.25 ± nan
   Final Test: 75.36 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.0261, Train: 53.66%, Valid: 52.99%, Test: 53.69%
Epoch: 25, Loss: 0.5184, Train: 77.97%, Valid: 75.97%, Test: 76.50%
Epoch: 50, Loss: 0.4523, Train: 83.74%, Valid: 79.54%, Test: 79.70%
Epoch: 75, Loss: 0.4071, Train: 85.90%, Valid: 80.09%, Test: 80.21%
Epoch: 100, Loss: 0.3850, Train: 86.54%, Valid: 79.45%, Test: 79.23%
Epoch: 125, Loss: 0.3782, Train: 84.08%, Valid: 76.07%, Test: 75.27%
Epoch: 150, Loss: 0.2936, Train: 90.40%, Valid: 77.54%, Test: 77.35%
Epoch: 175, Loss: 0.2952, Train: 89.10%, Valid: 74.71%, Test: 74.31%
Epoch: 200, Loss: 0.2080, Train: 94.74%, Valid: 72.97%, Test: 73.18%
Epoch: 225, Loss: 0.1678, Train: 95.49%, Valid: 69.44%, Test: 69.74%
Epoch: 250, Loss: 0.1539, Train: 96.79%, Valid: 67.72%, Test: 67.66%
Epoch: 275, Loss: 0.1911, Train: 96.00%, Valid: 66.25%, Test: 66.70%
Epoch: 300, Loss: 0.0677, Train: 99.27%, Valid: 64.11%, Test: 64.53%
Epoch: 325, Loss: 0.0379, Train: 99.61%, Valid: 63.33%, Test: 63.35%
Epoch: 350, Loss: 0.0153, Train: 99.87%, Valid: 63.12%, Test: 62.85%
Epoch: 375, Loss: 0.0075, Train: 99.95%, Valid: 63.55%, Test: 63.13%
Epoch: 400, Loss: 0.0042, Train: 99.97%, Valid: 63.93%, Test: 63.65%
Epoch: 425, Loss: 0.0028, Train: 99.99%, Valid: 64.49%, Test: 63.94%
Epoch: 450, Loss: 0.0020, Train: 99.99%, Valid: 64.71%, Test: 64.21%
Epoch: 475, Loss: 0.0016, Train: 99.99%, Valid: 64.97%, Test: 64.66%
Epoch: 500, Loss: 0.0012, Train: 99.99%, Valid: 65.16%, Test: 64.85%
Epoch: 525, Loss: 0.0010, Train: 99.99%, Valid: 65.20%, Test: 65.01%
Epoch: 550, Loss: 0.0008, Train: 99.99%, Valid: 65.26%, Test: 65.11%
Epoch: 575, Loss: 0.0007, Train: 99.99%, Valid: 65.37%, Test: 65.20%
Epoch: 600, Loss: 0.0006, Train: 100.00%, Valid: 65.65%, Test: 65.33%
Epoch: 625, Loss: 0.0005, Train: 100.00%, Valid: 65.76%, Test: 65.40%
Epoch: 650, Loss: 0.0005, Train: 100.00%, Valid: 65.76%, Test: 65.50%
Epoch: 675, Loss: 0.0004, Train: 100.00%, Valid: 65.90%, Test: 65.62%
Epoch: 700, Loss: 0.0004, Train: 100.00%, Valid: 65.98%, Test: 65.64%
Epoch: 725, Loss: 0.0003, Train: 100.00%, Valid: 66.17%, Test: 65.78%
Epoch: 750, Loss: 0.0003, Train: 100.00%, Valid: 66.27%, Test: 65.81%
Epoch: 775, Loss: 0.0003, Train: 100.00%, Valid: 66.29%, Test: 65.81%
Epoch: 800, Loss: 0.0002, Train: 100.00%, Valid: 66.31%, Test: 65.91%
Epoch: 825, Loss: 0.0002, Train: 100.00%, Valid: 66.34%, Test: 65.99%
Epoch: 850, Loss: 0.0002, Train: 100.00%, Valid: 66.38%, Test: 66.11%
Epoch: 875, Loss: 0.0002, Train: 100.00%, Valid: 66.55%, Test: 66.23%
Epoch: 900, Loss: 0.0002, Train: 100.00%, Valid: 66.54%, Test: 66.34%
Epoch: 925, Loss: 0.0002, Train: 100.00%, Valid: 66.59%, Test: 66.38%
Epoch: 950, Loss: 0.0002, Train: 100.00%, Valid: 66.59%, Test: 66.51%
Epoch: 975, Loss: 0.0001, Train: 100.00%, Valid: 66.58%, Test: 66.55%
Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 86.01
   Final Test: 80.71
All runs:
Highest Train: 100.00 ± nan
Highest Valid: 80.80 ± nan
  Final Train: 86.01 ± nan
   Final Test: 80.71 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 25.3200, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 2.4251, Train: 48.95%, Valid: 48.67%, Test: 48.48%
Epoch: 50, Loss: 1.3789, Train: 53.05%, Valid: 53.38%, Test: 52.21%
Epoch: 75, Loss: 1.1462, Train: 59.39%, Valid: 58.81%, Test: 59.27%
Epoch: 100, Loss: 1.0202, Train: 62.81%, Valid: 61.86%, Test: 62.55%
Epoch: 125, Loss: 0.8392, Train: 65.87%, Valid: 64.71%, Test: 65.12%
Epoch: 150, Loss: 0.5815, Train: 71.81%, Valid: 70.75%, Test: 70.95%
Epoch: 175, Loss: 0.5108, Train: 75.72%, Valid: 75.07%, Test: 74.20%
Epoch: 200, Loss: 0.4906, Train: 77.38%, Valid: 76.38%, Test: 75.92%
Epoch: 225, Loss: 0.4718, Train: 78.17%, Valid: 76.81%, Test: 76.39%
Epoch: 250, Loss: 0.4626, Train: 79.19%, Valid: 77.40%, Test: 77.21%
Epoch: 275, Loss: 0.4705, Train: 78.90%, Valid: 77.22%, Test: 76.83%
Epoch: 300, Loss: 0.4530, Train: 79.51%, Valid: 77.51%, Test: 77.43%
Epoch: 325, Loss: 0.4651, Train: 78.90%, Valid: 77.22%, Test: 77.04%
Epoch: 350, Loss: 0.5058, Train: 76.21%, Valid: 74.84%, Test: 74.24%
Epoch: 375, Loss: 0.4476, Train: 79.51%, Valid: 77.67%, Test: 77.40%
Epoch: 400, Loss: 0.4393, Train: 79.81%, Valid: 77.79%, Test: 77.61%
Epoch: 425, Loss: 0.5523, Train: 78.41%, Valid: 76.20%, Test: 75.53%
Epoch: 450, Loss: 0.4317, Train: 80.01%, Valid: 77.76%, Test: 77.66%
Epoch: 475, Loss: 0.4250, Train: 80.66%, Valid: 78.12%, Test: 78.09%
Epoch: 500, Loss: 0.5389, Train: 79.37%, Valid: 77.25%, Test: 76.84%
Epoch: 525, Loss: 0.4176, Train: 80.40%, Valid: 78.12%, Test: 77.90%
Epoch: 550, Loss: 0.4100, Train: 81.23%, Valid: 78.37%, Test: 78.33%
Epoch: 575, Loss: 0.5551, Train: 78.55%, Valid: 76.45%, Test: 76.29%
Epoch: 600, Loss: 0.4201, Train: 80.91%, Valid: 78.36%, Test: 78.57%
Epoch: 625, Loss: 0.3978, Train: 81.57%, Valid: 78.90%, Test: 79.00%
Epoch: 650, Loss: 0.4362, Train: 80.20%, Valid: 77.97%, Test: 77.67%
Epoch: 675, Loss: 0.4009, Train: 81.94%, Valid: 78.86%, Test: 79.16%
Epoch: 700, Loss: 0.3865, Train: 82.25%, Valid: 79.43%, Test: 79.47%
Epoch: 725, Loss: 0.3744, Train: 82.60%, Valid: 79.65%, Test: 79.54%
Epoch: 750, Loss: 0.3879, Train: 82.87%, Valid: 79.71%, Test: 79.74%
Epoch: 775, Loss: 0.3549, Train: 83.70%, Valid: 79.91%, Test: 79.92%
Epoch: 800, Loss: 0.3910, Train: 82.76%, Valid: 79.39%, Test: 79.90%
Epoch: 825, Loss: 0.3599, Train: 83.75%, Valid: 80.14%, Test: 80.00%
Epoch: 850, Loss: 0.3434, Train: 84.41%, Valid: 80.21%, Test: 80.34%
Epoch: 875, Loss: 0.5787, Train: 83.25%, Valid: 79.09%, Test: 79.04%
Epoch: 900, Loss: 0.3521, Train: 83.61%, Valid: 79.43%, Test: 79.96%
Epoch: 925, Loss: 0.3289, Train: 85.08%, Valid: 80.73%, Test: 80.72%
Epoch: 950, Loss: 0.3132, Train: 85.98%, Valid: 80.61%, Test: 80.67%
Epoch: 975, Loss: 0.3969, Train: 83.75%, Valid: 79.47%, Test: 79.56%
Run 01:
Highest Train: 86.26
Highest Valid: 80.82
  Final Train: 85.09
   Final Test: 80.41
All runs:
Highest Train: 86.26 ± nan
Highest Valid: 80.82 ± nan
  Final Train: 85.09 ± nan
   Final Test: 80.41 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 565.8608, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 107.0206, Train: 47.45%, Valid: 47.01%, Test: 48.15%
Epoch: 50, Loss: 47.1791, Train: 46.39%, Valid: 46.09%, Test: 46.81%
Epoch: 75, Loss: 15.2204, Train: 46.43%, Valid: 46.29%, Test: 46.91%
Epoch: 100, Loss: 12.4071, Train: 52.85%, Valid: 53.39%, Test: 52.41%
Epoch: 125, Loss: 5.4086, Train: 52.37%, Valid: 53.19%, Test: 51.83%
Epoch: 150, Loss: 6.4632, Train: 52.51%, Valid: 53.14%, Test: 51.91%
Epoch: 175, Loss: 3.0879, Train: 49.16%, Valid: 49.90%, Test: 48.95%
Epoch: 200, Loss: 5.1511, Train: 52.29%, Valid: 52.93%, Test: 51.65%
Epoch: 225, Loss: 3.0944, Train: 45.89%, Valid: 46.49%, Test: 45.79%
Epoch: 250, Loss: 2.1618, Train: 45.88%, Valid: 46.11%, Test: 45.69%
Epoch: 275, Loss: 4.4861, Train: 45.20%, Valid: 45.23%, Test: 45.66%
Epoch: 300, Loss: 1.3700, Train: 47.40%, Valid: 48.16%, Test: 46.73%
Epoch: 325, Loss: 1.0550, Train: 46.13%, Valid: 47.26%, Test: 46.18%
Epoch: 350, Loss: 0.9706, Train: 46.99%, Valid: 47.81%, Test: 46.25%
Epoch: 375, Loss: 0.9275, Train: 47.11%, Valid: 48.11%, Test: 46.69%
Epoch: 400, Loss: 0.8995, Train: 47.41%, Valid: 48.17%, Test: 47.12%
Epoch: 425, Loss: 0.8781, Train: 47.48%, Valid: 48.54%, Test: 47.38%
Epoch: 450, Loss: 0.8612, Train: 47.54%, Valid: 48.25%, Test: 47.82%
Epoch: 475, Loss: 0.8475, Train: 47.69%, Valid: 48.56%, Test: 47.94%
Epoch: 500, Loss: 0.8363, Train: 47.96%, Valid: 48.63%, Test: 48.27%
Epoch: 525, Loss: 0.8269, Train: 48.13%, Valid: 48.79%, Test: 48.23%
Epoch: 550, Loss: 0.8191, Train: 48.23%, Valid: 49.02%, Test: 48.61%
Epoch: 575, Loss: 0.8124, Train: 48.38%, Valid: 49.44%, Test: 48.67%
Epoch: 600, Loss: 0.8068, Train: 48.59%, Valid: 49.73%, Test: 48.83%
Epoch: 625, Loss: 0.8020, Train: 48.73%, Valid: 49.94%, Test: 48.99%
Epoch: 650, Loss: 0.7979, Train: 48.83%, Valid: 50.19%, Test: 49.08%
Epoch: 675, Loss: 0.7943, Train: 48.92%, Valid: 50.38%, Test: 49.15%
Epoch: 700, Loss: 0.7912, Train: 49.03%, Valid: 50.54%, Test: 49.28%
Epoch: 725, Loss: 0.7883, Train: 49.16%, Valid: 50.60%, Test: 49.39%
Epoch: 750, Loss: 0.7858, Train: 49.25%, Valid: 50.52%, Test: 49.42%
Epoch: 775, Loss: 0.7834, Train: 49.34%, Valid: 50.62%, Test: 49.59%
Epoch: 800, Loss: 0.7813, Train: 49.44%, Valid: 50.73%, Test: 49.73%
Epoch: 825, Loss: 0.7792, Train: 49.51%, Valid: 50.78%, Test: 49.75%
Epoch: 850, Loss: 0.7773, Train: 49.59%, Valid: 50.82%, Test: 49.90%
Epoch: 875, Loss: 0.7755, Train: 49.64%, Valid: 50.80%, Test: 49.91%
Epoch: 900, Loss: 0.7738, Train: 49.79%, Valid: 50.81%, Test: 49.97%
Epoch: 925, Loss: 0.7722, Train: 49.90%, Valid: 50.97%, Test: 50.09%
Epoch: 950, Loss: 0.7706, Train: 49.96%, Valid: 51.09%, Test: 50.17%
Epoch: 975, Loss: 0.7690, Train: 50.00%, Valid: 51.00%, Test: 50.15%
Run 01:
Highest Train: 52.89
Highest Valid: 53.47
  Final Train: 52.88
   Final Test: 52.27
All runs:
Highest Train: 52.89 ± nan
Highest Valid: 53.47 ± nan
  Final Train: 52.88 ± nan
   Final Test: 52.27 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.3628, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 0.4501, Train: 83.05%, Valid: 79.93%, Test: 79.46%
Epoch: 50, Loss: 0.3924, Train: 86.18%, Valid: 80.79%, Test: 81.00%
Epoch: 75, Loss: 0.3408, Train: 89.05%, Valid: 81.20%, Test: 81.12%
Epoch: 100, Loss: 0.3014, Train: 91.08%, Valid: 80.91%, Test: 80.43%
Epoch: 125, Loss: 0.2604, Train: 93.00%, Valid: 80.38%, Test: 80.13%
Epoch: 150, Loss: 0.2532, Train: 90.64%, Valid: 77.87%, Test: 77.84%
Epoch: 175, Loss: 0.2043, Train: 94.71%, Valid: 77.92%, Test: 78.22%
Epoch: 200, Loss: 0.1865, Train: 93.69%, Valid: 76.05%, Test: 75.88%
Epoch: 225, Loss: 0.1545, Train: 96.75%, Valid: 76.17%, Test: 76.23%
Epoch: 250, Loss: 0.1689, Train: 94.54%, Valid: 73.45%, Test: 73.58%
Epoch: 275, Loss: 0.1247, Train: 97.95%, Valid: 74.07%, Test: 74.47%
Epoch: 300, Loss: 0.1789, Train: 92.32%, Valid: 71.10%, Test: 71.25%
Epoch: 325, Loss: 0.1081, Train: 98.44%, Valid: 72.51%, Test: 72.82%
Epoch: 350, Loss: 0.0809, Train: 99.13%, Valid: 71.16%, Test: 71.59%
Epoch: 375, Loss: 0.0624, Train: 99.48%, Valid: 69.52%, Test: 70.17%
Epoch: 400, Loss: 0.1113, Train: 98.29%, Valid: 68.81%, Test: 69.26%
Epoch: 425, Loss: 0.0658, Train: 99.44%, Valid: 69.20%, Test: 69.88%
Epoch: 450, Loss: 0.0492, Train: 99.68%, Valid: 68.27%, Test: 68.95%
Epoch: 475, Loss: 0.0383, Train: 99.79%, Valid: 67.71%, Test: 68.05%
Epoch: 500, Loss: 0.1720, Train: 95.42%, Valid: 66.75%, Test: 67.40%
Epoch: 525, Loss: 0.0508, Train: 99.45%, Valid: 66.70%, Test: 67.54%
Epoch: 550, Loss: 0.0351, Train: 99.81%, Valid: 66.64%, Test: 67.15%
Epoch: 575, Loss: 0.0269, Train: 99.86%, Valid: 66.18%, Test: 66.16%
Epoch: 600, Loss: 0.0215, Train: 99.89%, Valid: 65.68%, Test: 65.58%
Epoch: 625, Loss: 0.0174, Train: 99.92%, Valid: 65.17%, Test: 65.42%
Epoch: 650, Loss: 0.0142, Train: 99.94%, Valid: 64.94%, Test: 65.11%
Epoch: 675, Loss: 0.0115, Train: 99.95%, Valid: 64.70%, Test: 64.91%
Epoch: 700, Loss: 0.0094, Train: 99.96%, Valid: 64.63%, Test: 64.85%
Epoch: 725, Loss: 0.0076, Train: 99.97%, Valid: 64.40%, Test: 64.72%
Epoch: 750, Loss: 0.0062, Train: 99.97%, Valid: 64.26%, Test: 64.46%
Epoch: 775, Loss: 0.0050, Train: 99.99%, Valid: 64.11%, Test: 64.29%
Epoch: 800, Loss: 0.0041, Train: 99.99%, Valid: 64.02%, Test: 64.17%
Epoch: 825, Loss: 0.0034, Train: 99.99%, Valid: 63.96%, Test: 64.06%
Epoch: 850, Loss: 0.0028, Train: 99.99%, Valid: 64.10%, Test: 64.02%
Epoch: 875, Loss: 0.0023, Train: 99.99%, Valid: 64.20%, Test: 64.01%
Epoch: 900, Loss: 0.0020, Train: 99.99%, Valid: 64.28%, Test: 64.15%
Epoch: 925, Loss: 0.0017, Train: 100.00%, Valid: 64.35%, Test: 64.25%
Epoch: 950, Loss: 0.0014, Train: 100.00%, Valid: 64.33%, Test: 64.31%
Epoch: 975, Loss: 0.0012, Train: 100.00%, Valid: 64.45%, Test: 64.54%
Run 01:
Highest Train: 100.00
Highest Valid: 81.46
  Final Train: 90.43
   Final Test: 80.82
All runs:
Highest Train: 100.00 ± nan
Highest Valid: 81.46 ± nan
  Final Train: 90.43 ± nan
   Final Test: 80.82 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 17.0293, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 1.9807, Train: 55.24%, Valid: 55.08%, Test: 54.40%
Epoch: 50, Loss: 0.9008, Train: 69.51%, Valid: 68.83%, Test: 69.08%
Epoch: 75, Loss: 0.6555, Train: 72.42%, Valid: 71.38%, Test: 71.43%
Epoch: 100, Loss: 0.5733, Train: 75.55%, Valid: 74.49%, Test: 74.82%
Epoch: 125, Loss: 0.5050, Train: 78.11%, Valid: 76.70%, Test: 76.86%
Epoch: 150, Loss: 0.4361, Train: 80.63%, Valid: 78.27%, Test: 77.94%
Epoch: 175, Loss: 0.4164, Train: 80.57%, Valid: 77.79%, Test: 77.55%
Epoch: 200, Loss: 0.3887, Train: 82.92%, Valid: 79.68%, Test: 80.01%
Epoch: 225, Loss: 0.3680, Train: 84.04%, Valid: 80.23%, Test: 80.52%
Epoch: 250, Loss: 0.3551, Train: 84.96%, Valid: 80.60%, Test: 80.55%
Epoch: 275, Loss: 0.4903, Train: 81.23%, Valid: 77.52%, Test: 77.53%
Epoch: 300, Loss: 0.3593, Train: 84.57%, Valid: 80.42%, Test: 80.52%
Epoch: 325, Loss: 0.3342, Train: 85.83%, Valid: 80.77%, Test: 81.20%
Epoch: 350, Loss: 0.3216, Train: 86.24%, Valid: 81.09%, Test: 81.30%
Epoch: 375, Loss: 0.3099, Train: 86.82%, Valid: 81.28%, Test: 81.49%
Epoch: 400, Loss: 0.2978, Train: 87.32%, Valid: 81.38%, Test: 81.59%
Epoch: 425, Loss: 0.2851, Train: 88.01%, Valid: 81.54%, Test: 81.43%
Epoch: 450, Loss: 0.2722, Train: 88.61%, Valid: 81.59%, Test: 81.59%
Epoch: 475, Loss: 0.2602, Train: 89.17%, Valid: 81.66%, Test: 81.61%
Epoch: 500, Loss: 0.2496, Train: 89.55%, Valid: 81.55%, Test: 81.49%
Epoch: 525, Loss: 0.2406, Train: 90.08%, Valid: 81.61%, Test: 81.34%
Epoch: 550, Loss: 0.2327, Train: 90.47%, Valid: 81.58%, Test: 81.27%
Epoch: 575, Loss: 0.2256, Train: 90.97%, Valid: 81.59%, Test: 81.20%
Epoch: 600, Loss: 0.2192, Train: 91.32%, Valid: 81.55%, Test: 81.24%
Epoch: 625, Loss: 0.2129, Train: 91.70%, Valid: 81.54%, Test: 81.12%
Epoch: 650, Loss: 0.2066, Train: 92.08%, Valid: 81.46%, Test: 81.04%
Epoch: 675, Loss: 0.2005, Train: 92.48%, Valid: 81.50%, Test: 81.00%
Epoch: 700, Loss: 0.1941, Train: 92.84%, Valid: 81.58%, Test: 81.01%
Epoch: 725, Loss: 0.1884, Train: 93.11%, Valid: 81.38%, Test: 80.99%
Epoch: 750, Loss: 0.1816, Train: 93.55%, Valid: 81.41%, Test: 81.02%
Epoch: 775, Loss: 0.1847, Train: 93.13%, Valid: 80.60%, Test: 80.44%
Epoch: 800, Loss: 0.1757, Train: 93.78%, Valid: 81.04%, Test: 80.65%
Epoch: 825, Loss: 0.1653, Train: 94.37%, Valid: 81.03%, Test: 80.81%
Epoch: 850, Loss: 0.1593, Train: 94.60%, Valid: 81.08%, Test: 80.89%
Epoch: 875, Loss: 0.1539, Train: 94.84%, Valid: 81.16%, Test: 80.78%
Epoch: 900, Loss: 0.1490, Train: 95.15%, Valid: 81.04%, Test: 80.44%
Epoch: 925, Loss: 0.1841, Train: 93.51%, Valid: 80.38%, Test: 79.63%
Epoch: 950, Loss: 0.1519, Train: 94.82%, Valid: 80.35%, Test: 79.65%
Epoch: 975, Loss: 0.1428, Train: 95.39%, Valid: 80.43%, Test: 80.02%
Run 01:
Highest Train: 95.62
Highest Valid: 81.75
  Final Train: 89.15
   Final Test: 81.60
All runs:
Highest Train: 95.62 ± nan
Highest Valid: 81.75 ± nan
  Final Train: 89.15 ± nan
   Final Test: 81.60 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1232.6694, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 215.1940, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 50, Loss: 9.1910, Train: 45.27%, Valid: 45.51%, Test: 45.79%
Epoch: 75, Loss: 4.9602, Train: 43.82%, Valid: 44.00%, Test: 43.85%
Epoch: 100, Loss: 4.0706, Train: 46.97%, Valid: 48.05%, Test: 47.07%
Epoch: 125, Loss: 3.9008, Train: 46.38%, Valid: 47.15%, Test: 46.45%
Epoch: 150, Loss: 6.1876, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 175, Loss: 3.4948, Train: 46.58%, Valid: 47.40%, Test: 46.60%
Epoch: 200, Loss: 7.5099, Train: 45.97%, Valid: 46.03%, Test: 45.66%
Epoch: 225, Loss: 3.9126, Train: 44.89%, Valid: 45.56%, Test: 44.31%
Epoch: 250, Loss: 3.5653, Train: 44.66%, Valid: 44.49%, Test: 43.72%
Epoch: 275, Loss: 3.5744, Train: 44.75%, Valid: 44.67%, Test: 43.99%
Epoch: 300, Loss: 2.8790, Train: 46.27%, Valid: 46.83%, Test: 46.41%
Epoch: 325, Loss: 14.6712, Train: 49.02%, Valid: 48.41%, Test: 48.95%
Epoch: 350, Loss: 7.9014, Train: 47.51%, Valid: 47.32%, Test: 46.45%
Epoch: 375, Loss: 2.9884, Train: 48.62%, Valid: 48.49%, Test: 47.60%
Epoch: 400, Loss: 2.0337, Train: 51.35%, Valid: 50.41%, Test: 50.23%
Epoch: 425, Loss: 1.7197, Train: 52.53%, Valid: 51.42%, Test: 51.46%
Epoch: 450, Loss: 1.5320, Train: 53.33%, Valid: 52.60%, Test: 52.54%
Epoch: 475, Loss: 1.4039, Train: 54.19%, Valid: 53.52%, Test: 53.25%
Epoch: 500, Loss: 1.3056, Train: 55.04%, Valid: 54.28%, Test: 53.69%
Epoch: 525, Loss: 1.2232, Train: 55.84%, Valid: 55.49%, Test: 54.43%
Epoch: 550, Loss: 1.1536, Train: 56.68%, Valid: 56.43%, Test: 55.22%
Epoch: 575, Loss: 1.0917, Train: 57.67%, Valid: 57.22%, Test: 56.34%
Epoch: 600, Loss: 1.0510, Train: 58.12%, Valid: 57.83%, Test: 56.77%
Epoch: 625, Loss: 1.0064, Train: 59.24%, Valid: 58.28%, Test: 58.03%
Epoch: 650, Loss: 0.9781, Train: 59.89%, Valid: 59.22%, Test: 58.61%
Epoch: 675, Loss: 1.3270, Train: 59.24%, Valid: 59.07%, Test: 58.44%
Epoch: 700, Loss: 0.9411, Train: 58.92%, Valid: 58.50%, Test: 57.63%
Epoch: 725, Loss: 0.9035, Train: 61.42%, Valid: 60.79%, Test: 60.16%
Epoch: 750, Loss: 0.8888, Train: 61.38%, Valid: 60.65%, Test: 60.25%
Epoch: 775, Loss: 0.8610, Train: 62.12%, Valid: 61.65%, Test: 60.98%
Epoch: 800, Loss: 0.8434, Train: 62.72%, Valid: 62.14%, Test: 61.41%
Epoch: 825, Loss: 0.8247, Train: 63.04%, Valid: 62.48%, Test: 61.65%
Epoch: 850, Loss: 0.8363, Train: 63.25%, Valid: 62.69%, Test: 61.88%
Epoch: 875, Loss: 0.8010, Train: 63.75%, Valid: 63.28%, Test: 62.27%
Epoch: 900, Loss: 0.8513, Train: 61.75%, Valid: 61.39%, Test: 60.43%
Epoch: 925, Loss: 0.9161, Train: 63.48%, Valid: 62.67%, Test: 61.71%
Epoch: 950, Loss: 0.7670, Train: 63.73%, Valid: 63.20%, Test: 62.34%
Epoch: 975, Loss: 0.7532, Train: 64.73%, Valid: 64.07%, Test: 62.94%
Run 01:
Highest Train: 65.21
Highest Valid: 64.41
  Final Train: 65.21
   Final Test: 63.25
All runs:
Highest Train: 65.21 ± nan
Highest Valid: 64.41 ± nan
  Final Train: 65.21 ± nan
   Final Test: 63.25 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7349, Train: 52.92%, Valid: 51.94%, Test: 52.80%
Epoch: 25, Loss: 0.5921, Train: 72.18%, Valid: 68.45%, Test: 68.56%
Epoch: 50, Loss: 0.4043, Train: 82.51%, Valid: 76.45%, Test: 76.08%
Epoch: 75, Loss: 0.3489, Train: 84.87%, Valid: 75.68%, Test: 76.09%
Epoch: 100, Loss: 0.3182, Train: 86.54%, Valid: 75.24%, Test: 75.54%
Epoch: 125, Loss: 0.2856, Train: 88.61%, Valid: 74.77%, Test: 74.87%
Epoch: 150, Loss: 0.2503, Train: 90.81%, Valid: 74.12%, Test: 74.01%
Epoch: 175, Loss: 0.2152, Train: 92.74%, Valid: 73.26%, Test: 73.56%
Epoch: 200, Loss: 0.1830, Train: 94.32%, Valid: 72.41%, Test: 72.42%
Epoch: 225, Loss: 0.1550, Train: 95.55%, Valid: 71.67%, Test: 71.84%
Epoch: 250, Loss: 0.1313, Train: 96.60%, Valid: 71.26%, Test: 71.38%
Epoch: 275, Loss: 0.1114, Train: 97.37%, Valid: 70.62%, Test: 70.56%
Epoch: 300, Loss: 0.0950, Train: 97.95%, Valid: 70.11%, Test: 70.07%
Epoch: 325, Loss: 0.0816, Train: 98.36%, Valid: 69.39%, Test: 69.71%
Epoch: 350, Loss: 0.0708, Train: 98.60%, Valid: 68.74%, Test: 69.17%
Epoch: 375, Loss: 0.0620, Train: 98.79%, Valid: 68.55%, Test: 68.48%
Epoch: 400, Loss: 0.0549, Train: 98.97%, Valid: 68.16%, Test: 68.08%
Epoch: 425, Loss: 0.0490, Train: 99.08%, Valid: 67.66%, Test: 67.83%
Epoch: 450, Loss: 0.0442, Train: 99.17%, Valid: 67.35%, Test: 67.40%
Epoch: 475, Loss: 0.0401, Train: 99.25%, Valid: 66.98%, Test: 67.13%
Epoch: 500, Loss: 0.0366, Train: 99.35%, Valid: 66.72%, Test: 66.91%
Epoch: 525, Loss: 0.0335, Train: 99.41%, Valid: 66.75%, Test: 66.47%
Epoch: 550, Loss: 0.0308, Train: 99.48%, Valid: 66.47%, Test: 66.35%
Epoch: 575, Loss: 0.0285, Train: 99.54%, Valid: 66.38%, Test: 66.32%
Epoch: 600, Loss: 0.0263, Train: 99.59%, Valid: 66.04%, Test: 66.20%
Epoch: 625, Loss: 0.0245, Train: 99.61%, Valid: 65.88%, Test: 65.90%
Epoch: 650, Loss: 0.0228, Train: 99.65%, Valid: 65.72%, Test: 65.84%
Epoch: 675, Loss: 0.0213, Train: 99.68%, Valid: 65.63%, Test: 65.76%
Epoch: 700, Loss: 0.0199, Train: 99.70%, Valid: 65.58%, Test: 65.60%
Epoch: 725, Loss: 0.0187, Train: 99.72%, Valid: 65.27%, Test: 65.24%
Epoch: 750, Loss: 0.0175, Train: 99.74%, Valid: 65.40%, Test: 65.01%
Epoch: 775, Loss: 0.0165, Train: 99.75%, Valid: 65.27%, Test: 64.88%
Epoch: 800, Loss: 0.0156, Train: 99.76%, Valid: 65.01%, Test: 64.82%
Epoch: 825, Loss: 0.0147, Train: 99.79%, Valid: 65.02%, Test: 64.78%
Epoch: 850, Loss: 0.0139, Train: 99.81%, Valid: 65.00%, Test: 64.64%
Epoch: 875, Loss: 0.0132, Train: 99.84%, Valid: 64.88%, Test: 64.51%
Epoch: 900, Loss: 0.0125, Train: 99.85%, Valid: 64.76%, Test: 64.55%
Epoch: 925, Loss: 0.0118, Train: 99.86%, Valid: 64.67%, Test: 64.49%
Epoch: 950, Loss: 0.0112, Train: 99.86%, Valid: 64.54%, Test: 64.50%
Epoch: 975, Loss: 0.0107, Train: 99.87%, Valid: 64.43%, Test: 64.34%
Run 01:
Highest Train: 99.88
Highest Valid: 76.64
  Final Train: 82.21
   Final Test: 75.90
All runs:
Highest Train: 99.88 ± nan
Highest Valid: 76.64 ± nan
  Final Train: 82.21 ± nan
   Final Test: 75.90 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 13.7104, Train: 47.08%, Valid: 48.06%, Test: 47.20%
Epoch: 25, Loss: 7.1454, Train: 49.68%, Valid: 50.29%, Test: 49.77%
Epoch: 50, Loss: 3.5480, Train: 55.77%, Valid: 56.08%, Test: 55.17%
Epoch: 75, Loss: 1.4380, Train: 60.35%, Valid: 59.90%, Test: 59.37%
Epoch: 100, Loss: 0.9808, Train: 63.45%, Valid: 61.92%, Test: 62.31%
Epoch: 125, Loss: 0.7567, Train: 66.02%, Valid: 64.53%, Test: 64.42%
Epoch: 150, Loss: 0.6141, Train: 69.24%, Valid: 67.42%, Test: 67.42%
Epoch: 175, Loss: 0.5241, Train: 72.76%, Valid: 70.82%, Test: 69.99%
Epoch: 200, Loss: 0.4700, Train: 76.10%, Valid: 73.71%, Test: 72.98%
Epoch: 225, Loss: 0.4369, Train: 78.74%, Valid: 76.24%, Test: 75.21%
Epoch: 250, Loss: 0.4149, Train: 80.45%, Valid: 77.43%, Test: 76.86%
Epoch: 275, Loss: 0.3989, Train: 81.51%, Valid: 78.40%, Test: 77.75%
Epoch: 300, Loss: 0.3861, Train: 82.43%, Valid: 79.13%, Test: 78.60%
Epoch: 325, Loss: 0.3757, Train: 83.16%, Valid: 79.58%, Test: 79.32%
Epoch: 350, Loss: 0.3670, Train: 83.67%, Valid: 80.05%, Test: 79.45%
Epoch: 375, Loss: 0.3592, Train: 84.05%, Valid: 80.35%, Test: 79.63%
Epoch: 400, Loss: 0.3521, Train: 84.53%, Valid: 80.41%, Test: 79.72%
Epoch: 425, Loss: 0.3455, Train: 84.89%, Valid: 80.61%, Test: 79.86%
Epoch: 450, Loss: 0.3394, Train: 85.25%, Valid: 80.78%, Test: 79.98%
Epoch: 475, Loss: 0.3337, Train: 85.58%, Valid: 80.99%, Test: 80.25%
Epoch: 500, Loss: 0.3284, Train: 85.82%, Valid: 81.14%, Test: 80.38%
Epoch: 525, Loss: 0.3233, Train: 86.01%, Valid: 81.27%, Test: 80.39%
Epoch: 550, Loss: 0.3185, Train: 86.29%, Valid: 81.25%, Test: 80.58%
Epoch: 575, Loss: 0.3140, Train: 86.48%, Valid: 81.27%, Test: 80.72%
Epoch: 600, Loss: 0.3096, Train: 86.65%, Valid: 81.30%, Test: 80.86%
Epoch: 625, Loss: 0.3055, Train: 86.85%, Valid: 81.35%, Test: 80.92%
Epoch: 650, Loss: 0.3015, Train: 87.07%, Valid: 81.30%, Test: 80.81%
Epoch: 675, Loss: 0.2977, Train: 87.23%, Valid: 81.35%, Test: 80.86%
Epoch: 700, Loss: 0.2940, Train: 87.42%, Valid: 81.43%, Test: 80.91%
Epoch: 725, Loss: 0.2905, Train: 87.52%, Valid: 81.38%, Test: 80.89%
Epoch: 750, Loss: 0.2871, Train: 87.70%, Valid: 81.34%, Test: 80.88%
Epoch: 775, Loss: 0.2838, Train: 87.83%, Valid: 81.42%, Test: 80.79%
Epoch: 800, Loss: 0.2806, Train: 88.06%, Valid: 81.50%, Test: 80.87%
Epoch: 825, Loss: 0.2774, Train: 88.23%, Valid: 81.57%, Test: 80.88%
Epoch: 850, Loss: 0.2742, Train: 88.41%, Valid: 81.56%, Test: 80.92%
Epoch: 875, Loss: 0.2719, Train: 88.49%, Valid: 81.45%, Test: 80.90%
Epoch: 900, Loss: 0.3106, Train: 80.13%, Valid: 74.90%, Test: 74.09%
Epoch: 925, Loss: 0.3030, Train: 86.65%, Valid: 79.78%, Test: 79.01%
Epoch: 950, Loss: 0.2760, Train: 88.10%, Valid: 81.22%, Test: 80.49%
Epoch: 975, Loss: 0.2678, Train: 88.41%, Valid: 81.55%, Test: 80.68%
Run 01:
Highest Train: 88.60
Highest Valid: 81.60
  Final Train: 88.60
   Final Test: 80.79
All runs:
Highest Train: 88.60 ± nan
Highest Valid: 81.60 ± nan
  Final Train: 88.60 ± nan
   Final Test: 80.79 ± nan
Saving results to results/fb100.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='fb100', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='Penn94', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 41554 | num classes 2 | num node feats 4814
MODEL: MLPNORM(
  (fc1): Linear(in_features=4814, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1030.3718, Train: 46.76%, Valid: 46.88%, Test: 47.03%
Epoch: 25, Loss: 22.9465, Train: 49.89%, Valid: 49.26%, Test: 50.41%
Epoch: 50, Loss: 6.6901, Train: 51.80%, Valid: 51.60%, Test: 51.74%
Epoch: 75, Loss: 2.2393, Train: 53.06%, Valid: 52.28%, Test: 52.05%
Epoch: 100, Loss: 1.0479, Train: 53.08%, Valid: 51.96%, Test: 52.15%
Epoch: 125, Loss: 0.8711, Train: 53.09%, Valid: 51.63%, Test: 52.50%
Epoch: 150, Loss: 0.8200, Train: 54.37%, Valid: 52.22%, Test: 52.76%
Epoch: 175, Loss: 0.7908, Train: 55.41%, Valid: 52.55%, Test: 53.26%
Epoch: 200, Loss: 0.7674, Train: 56.39%, Valid: 53.09%, Test: 53.69%
Epoch: 225, Loss: 0.7467, Train: 57.49%, Valid: 53.83%, Test: 54.13%
Epoch: 250, Loss: 0.7277, Train: 58.61%, Valid: 54.56%, Test: 54.61%
Epoch: 275, Loss: 0.7100, Train: 59.49%, Valid: 55.30%, Test: 55.38%
Epoch: 300, Loss: 0.6928, Train: 60.58%, Valid: 56.07%, Test: 56.05%
Epoch: 325, Loss: 0.6762, Train: 61.70%, Valid: 57.04%, Test: 57.04%
Epoch: 350, Loss: 0.6639, Train: 63.02%, Valid: 58.15%, Test: 57.81%
Epoch: 375, Loss: 0.6487, Train: 64.13%, Valid: 59.11%, Test: 58.96%
Epoch: 400, Loss: 0.6397, Train: 64.78%, Valid: 59.58%, Test: 59.19%
Epoch: 425, Loss: 0.6228, Train: 66.98%, Valid: 61.69%, Test: 61.35%
Epoch: 450, Loss: 0.6118, Train: 67.72%, Valid: 61.94%, Test: 61.60%
Epoch: 475, Loss: 0.5991, Train: 69.50%, Valid: 63.64%, Test: 63.78%
Epoch: 500, Loss: 0.5880, Train: 70.18%, Valid: 63.98%, Test: 63.88%
Epoch: 525, Loss: 0.5763, Train: 71.49%, Valid: 65.36%, Test: 65.37%
Epoch: 550, Loss: 0.5666, Train: 71.93%, Valid: 65.68%, Test: 65.76%
Epoch: 575, Loss: 0.5558, Train: 73.20%, Valid: 67.04%, Test: 66.80%
Epoch: 600, Loss: 0.5467, Train: 73.44%, Valid: 66.96%, Test: 67.23%
Epoch: 625, Loss: 0.5366, Train: 74.57%, Valid: 68.38%, Test: 68.20%
Epoch: 650, Loss: 0.5280, Train: 74.93%, Valid: 68.11%, Test: 68.47%
Epoch: 675, Loss: 0.5186, Train: 75.87%, Valid: 69.36%, Test: 69.18%
Epoch: 700, Loss: 0.5104, Train: 76.14%, Valid: 69.41%, Test: 69.63%
Epoch: 725, Loss: 0.5015, Train: 76.92%, Valid: 70.22%, Test: 70.31%
Epoch: 750, Loss: 0.4936, Train: 77.31%, Valid: 70.46%, Test: 70.74%
Epoch: 775, Loss: 0.4851, Train: 77.97%, Valid: 71.07%, Test: 71.18%
Epoch: 800, Loss: 0.4778, Train: 78.21%, Valid: 71.24%, Test: 71.63%
Epoch: 825, Loss: 0.4699, Train: 78.76%, Valid: 71.86%, Test: 71.89%
Epoch: 850, Loss: 0.4633, Train: 79.14%, Valid: 72.18%, Test: 72.36%
Epoch: 875, Loss: 0.4559, Train: 79.52%, Valid: 72.61%, Test: 72.59%
Epoch: 900, Loss: 0.4499, Train: 79.68%, Valid: 72.93%, Test: 73.02%
Epoch: 925, Loss: 0.4430, Train: 80.16%, Valid: 73.24%, Test: 73.20%
Epoch: 950, Loss: 0.4375, Train: 80.33%, Valid: 73.47%, Test: 73.68%
Epoch: 975, Loss: 0.4311, Train: 80.72%, Valid: 73.80%, Test: 73.76%
Run 01:
Highest Train: 81.03
Highest Valid: 73.99
  Final Train: 81.01
   Final Test: 74.10
All runs:
Highest Train: 81.03 ± nan
Highest Valid: 73.99 ± nan
  Final Train: 81.01 ± nan
   Final Test: 74.10 ± nan
Saving results to results/fb100.csv
20211117-01:17 ---> 20211117-02:05 Totl:2881 seconds
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6111, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.5023, Train: 34.22%, Valid: 34.03%, Test: 34.36%
Epoch: 50, Loss: 1.4839, Train: 35.17%, Valid: 34.61%, Test: 35.03%
Epoch: 75, Loss: 1.4734, Train: 35.79%, Valid: 35.10%, Test: 35.47%
Epoch: 100, Loss: 1.4621, Train: 36.30%, Valid: 35.39%, Test: 35.91%
Epoch: 125, Loss: 1.4495, Train: 37.03%, Valid: 36.07%, Test: 36.45%
Epoch: 150, Loss: 1.4389, Train: 37.65%, Valid: 36.14%, Test: 36.54%
Epoch: 175, Loss: 1.4333, Train: 38.32%, Valid: 36.04%, Test: 36.46%
Epoch: 200, Loss: 1.4209, Train: 38.69%, Valid: 36.27%, Test: 36.49%
Epoch: 225, Loss: 1.4151, Train: 39.18%, Valid: 35.93%, Test: 36.38%
Epoch: 250, Loss: 1.4038, Train: 39.26%, Valid: 36.23%, Test: 36.48%
Epoch: 275, Loss: 1.4047, Train: 39.60%, Valid: 36.29%, Test: 36.61%
Epoch: 300, Loss: 1.4098, Train: 40.10%, Valid: 36.03%, Test: 36.33%
Epoch: 325, Loss: 1.3835, Train: 40.58%, Valid: 35.85%, Test: 36.16%
Epoch: 350, Loss: 1.3790, Train: 40.66%, Valid: 35.52%, Test: 35.90%
Epoch: 375, Loss: 1.3869, Train: 39.86%, Valid: 34.86%, Test: 35.06%
Epoch: 400, Loss: 1.3697, Train: 41.45%, Valid: 35.32%, Test: 35.78%
Epoch: 425, Loss: 1.3663, Train: 41.20%, Valid: 35.72%, Test: 35.84%
Epoch: 450, Loss: 1.3767, Train: 41.77%, Valid: 35.43%, Test: 35.58%
Epoch: 475, Loss: 1.3539, Train: 41.92%, Valid: 35.35%, Test: 35.65%
Epoch: 500, Loss: 1.3495, Train: 41.98%, Valid: 34.92%, Test: 35.24%
Epoch: 525, Loss: 1.3449, Train: 42.74%, Valid: 34.44%, Test: 34.62%
Epoch: 550, Loss: 1.3704, Train: 41.02%, Valid: 35.28%, Test: 35.36%
Epoch: 575, Loss: 1.3385, Train: 42.89%, Valid: 35.12%, Test: 35.35%
Epoch: 600, Loss: 1.3473, Train: 41.75%, Valid: 35.46%, Test: 35.40%
Epoch: 625, Loss: 1.3313, Train: 43.32%, Valid: 34.97%, Test: 35.00%
Epoch: 650, Loss: 1.3500, Train: 42.35%, Valid: 35.12%, Test: 35.32%
Epoch: 675, Loss: 1.3254, Train: 43.63%, Valid: 34.22%, Test: 34.33%
Epoch: 700, Loss: 1.3353, Train: 42.57%, Valid: 34.52%, Test: 35.01%
Epoch: 725, Loss: 1.3196, Train: 43.59%, Valid: 34.45%, Test: 34.39%
Epoch: 750, Loss: 1.3372, Train: 43.74%, Valid: 33.85%, Test: 34.11%
Epoch: 775, Loss: 1.3162, Train: 44.18%, Valid: 33.83%, Test: 34.20%
Epoch: 800, Loss: 1.3113, Train: 44.50%, Valid: 34.39%, Test: 34.38%
Epoch: 825, Loss: 1.3157, Train: 43.26%, Valid: 32.90%, Test: 33.02%
Epoch: 850, Loss: 1.3187, Train: 44.32%, Valid: 34.04%, Test: 34.38%
Epoch: 875, Loss: 1.3093, Train: 42.96%, Valid: 32.04%, Test: 32.05%
Epoch: 900, Loss: 1.4087, Train: 39.73%, Valid: 35.09%, Test: 35.16%
Epoch: 925, Loss: 1.3544, Train: 42.39%, Valid: 34.74%, Test: 34.94%
Epoch: 950, Loss: 1.3166, Train: 44.23%, Valid: 34.36%, Test: 34.27%
Epoch: 975, Loss: 1.3032, Train: 44.83%, Valid: 33.86%, Test: 33.80%
Run 01:
Highest Train: 45.14
Highest Valid: 36.43
  Final Train: 39.19
   Final Test: 36.61
All runs:
Highest Train: 45.14 ± nan
Highest Valid: 36.43 ± nan
  Final Train: 39.19 ± nan
   Final Test: 36.61 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6095, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.5025, Train: 34.21%, Valid: 34.01%, Test: 34.24%
Epoch: 50, Loss: 1.4844, Train: 35.18%, Valid: 34.72%, Test: 35.01%
Epoch: 75, Loss: 1.4721, Train: 35.82%, Valid: 35.04%, Test: 35.51%
Epoch: 100, Loss: 1.4596, Train: 36.42%, Valid: 35.68%, Test: 35.96%
Epoch: 125, Loss: 1.4503, Train: 36.84%, Valid: 35.70%, Test: 36.02%
Epoch: 150, Loss: 1.4393, Train: 37.70%, Valid: 35.95%, Test: 36.20%
Epoch: 175, Loss: 1.4315, Train: 38.16%, Valid: 36.10%, Test: 36.43%
Epoch: 200, Loss: 1.4209, Train: 37.69%, Valid: 35.50%, Test: 35.92%
Epoch: 225, Loss: 1.4116, Train: 39.06%, Valid: 36.20%, Test: 36.39%
Epoch: 250, Loss: 1.4146, Train: 39.24%, Valid: 35.81%, Test: 36.12%
Epoch: 275, Loss: 1.3948, Train: 39.93%, Valid: 35.65%, Test: 35.98%
Epoch: 300, Loss: 1.3878, Train: 40.15%, Valid: 35.36%, Test: 35.65%
Epoch: 325, Loss: 1.3810, Train: 40.73%, Valid: 35.06%, Test: 35.24%
Epoch: 350, Loss: 1.3836, Train: 40.27%, Valid: 36.23%, Test: 36.40%
Epoch: 375, Loss: 1.3889, Train: 37.18%, Valid: 31.39%, Test: 31.97%
Epoch: 400, Loss: 1.3855, Train: 40.54%, Valid: 35.75%, Test: 36.22%
Epoch: 425, Loss: 1.3681, Train: 41.49%, Valid: 35.11%, Test: 35.58%
Epoch: 450, Loss: 1.3664, Train: 41.66%, Valid: 35.00%, Test: 35.32%
Epoch: 475, Loss: 1.3520, Train: 42.18%, Valid: 34.57%, Test: 34.96%
Epoch: 500, Loss: 1.3527, Train: 41.94%, Valid: 34.87%, Test: 35.21%
Epoch: 525, Loss: 1.3527, Train: 42.00%, Valid: 34.78%, Test: 35.00%
Epoch: 550, Loss: 1.3367, Train: 43.02%, Valid: 35.05%, Test: 35.51%
Epoch: 575, Loss: 1.3543, Train: 43.00%, Valid: 34.56%, Test: 34.84%
Epoch: 600, Loss: 1.3321, Train: 43.09%, Valid: 33.82%, Test: 34.28%
Epoch: 625, Loss: 1.3318, Train: 43.41%, Valid: 35.11%, Test: 35.54%
Epoch: 650, Loss: 1.3278, Train: 43.66%, Valid: 35.06%, Test: 35.47%
Epoch: 675, Loss: 1.3247, Train: 43.58%, Valid: 34.77%, Test: 35.03%
Epoch: 700, Loss: 1.3720, Train: 43.78%, Valid: 34.78%, Test: 35.20%
Epoch: 725, Loss: 1.3259, Train: 43.14%, Valid: 33.70%, Test: 34.17%
Epoch: 750, Loss: 1.3295, Train: 43.25%, Valid: 32.72%, Test: 33.23%
Epoch: 775, Loss: 1.3137, Train: 44.61%, Valid: 33.76%, Test: 34.13%
Epoch: 800, Loss: 1.3166, Train: 44.44%, Valid: 34.79%, Test: 35.28%
Epoch: 825, Loss: 1.3184, Train: 44.85%, Valid: 34.11%, Test: 34.48%
Epoch: 850, Loss: 1.3041, Train: 44.92%, Valid: 34.22%, Test: 34.61%
Epoch: 875, Loss: 1.3020, Train: 44.52%, Valid: 33.89%, Test: 34.13%
Epoch: 900, Loss: 1.3098, Train: 42.68%, Valid: 32.87%, Test: 33.23%
Epoch: 925, Loss: 1.2982, Train: 45.33%, Valid: 34.25%, Test: 34.56%
Epoch: 950, Loss: 1.3007, Train: 45.36%, Valid: 33.31%, Test: 33.72%
Epoch: 975, Loss: 1.2943, Train: 45.70%, Valid: 34.01%, Test: 34.32%
Run 01:
Highest Train: 45.95
Highest Valid: 36.40
  Final Train: 38.41
   Final Test: 36.48
All runs:
Highest Train: 45.95 ± nan
Highest Valid: 36.40 ± nan
  Final Train: 38.41 ± nan
   Final Test: 36.48 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6102, Train: 28.72%, Valid: 28.53%, Test: 28.82%
Epoch: 25, Loss: 1.5040, Train: 34.19%, Valid: 34.08%, Test: 34.21%
Epoch: 50, Loss: 1.4833, Train: 35.29%, Valid: 34.88%, Test: 35.22%
Epoch: 75, Loss: 1.4546, Train: 36.41%, Valid: 35.87%, Test: 36.10%
Epoch: 100, Loss: 1.4565, Train: 37.12%, Valid: 36.34%, Test: 36.71%
Epoch: 125, Loss: 1.4256, Train: 38.39%, Valid: 37.41%, Test: 37.87%
Epoch: 150, Loss: 1.4375, Train: 37.23%, Valid: 36.57%, Test: 36.78%
Epoch: 175, Loss: 1.4456, Train: 37.44%, Valid: 36.25%, Test: 36.56%
Epoch: 200, Loss: 1.4041, Train: 39.67%, Valid: 37.98%, Test: 38.41%
Epoch: 225, Loss: 1.4003, Train: 39.98%, Valid: 37.85%, Test: 38.66%
Epoch: 250, Loss: 1.4282, Train: 38.36%, Valid: 36.83%, Test: 37.12%
Epoch: 275, Loss: 1.3800, Train: 40.67%, Valid: 38.02%, Test: 38.96%
Epoch: 300, Loss: 1.3695, Train: 41.27%, Valid: 38.54%, Test: 39.27%
Epoch: 325, Loss: 1.3546, Train: 42.22%, Valid: 39.05%, Test: 39.82%
Epoch: 350, Loss: 1.3502, Train: 42.59%, Valid: 39.15%, Test: 39.79%
Epoch: 375, Loss: 1.3395, Train: 42.59%, Valid: 39.39%, Test: 39.77%
Epoch: 400, Loss: 1.3417, Train: 42.64%, Valid: 39.49%, Test: 39.76%
Epoch: 425, Loss: 1.3282, Train: 43.38%, Valid: 39.53%, Test: 39.99%
Epoch: 450, Loss: 1.3315, Train: 42.88%, Valid: 39.16%, Test: 39.57%
Epoch: 475, Loss: 1.3212, Train: 43.72%, Valid: 39.49%, Test: 39.95%
Epoch: 500, Loss: 1.3197, Train: 43.69%, Valid: 39.18%, Test: 39.72%
Epoch: 525, Loss: 1.3375, Train: 42.90%, Valid: 39.24%, Test: 39.85%
Epoch: 550, Loss: 1.3077, Train: 44.05%, Valid: 39.39%, Test: 39.82%
Epoch: 575, Loss: 1.2904, Train: 45.13%, Valid: 39.95%, Test: 40.44%
Epoch: 600, Loss: 1.2911, Train: 44.72%, Valid: 39.47%, Test: 40.16%
Epoch: 625, Loss: 1.2869, Train: 44.45%, Valid: 39.11%, Test: 39.60%
Epoch: 650, Loss: 1.2758, Train: 45.65%, Valid: 40.30%, Test: 40.81%
Epoch: 675, Loss: 1.2864, Train: 45.33%, Valid: 39.76%, Test: 40.33%
Epoch: 700, Loss: 1.2738, Train: 45.93%, Valid: 39.94%, Test: 40.38%
Epoch: 725, Loss: 1.2720, Train: 45.82%, Valid: 39.62%, Test: 40.09%
Epoch: 750, Loss: 1.3006, Train: 43.47%, Valid: 39.48%, Test: 39.82%
Epoch: 775, Loss: 1.2664, Train: 46.27%, Valid: 40.18%, Test: 40.73%
Epoch: 800, Loss: 1.2617, Train: 46.35%, Valid: 39.76%, Test: 40.29%
Epoch: 825, Loss: 1.2793, Train: 44.78%, Valid: 38.83%, Test: 39.58%
Epoch: 850, Loss: 1.2552, Train: 46.51%, Valid: 40.06%, Test: 40.59%
Epoch: 875, Loss: 1.3371, Train: 43.57%, Valid: 37.27%, Test: 38.04%
Epoch: 900, Loss: 1.2533, Train: 46.52%, Valid: 40.07%, Test: 40.70%
Epoch: 925, Loss: 1.2795, Train: 45.80%, Valid: 39.25%, Test: 39.86%
Epoch: 950, Loss: 1.2385, Train: 47.17%, Valid: 39.93%, Test: 40.60%
Epoch: 975, Loss: 1.2674, Train: 46.11%, Valid: 39.09%, Test: 39.78%
Run 01:
Highest Train: 47.36
Highest Valid: 40.47
  Final Train: 44.38
   Final Test: 40.73
All runs:
Highest Train: 47.36 ± nan
Highest Valid: 40.47 ± nan
  Final Train: 44.38 ± nan
   Final Test: 40.73 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6069, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4874, Train: 35.11%, Valid: 34.41%, Test: 34.99%
Epoch: 50, Loss: 1.4679, Train: 36.10%, Valid: 35.22%, Test: 35.49%
Epoch: 75, Loss: 1.4508, Train: 36.80%, Valid: 35.86%, Test: 36.00%
Epoch: 100, Loss: 1.4360, Train: 37.64%, Valid: 36.03%, Test: 36.21%
Epoch: 125, Loss: 1.4249, Train: 38.16%, Valid: 35.80%, Test: 36.19%
Epoch: 150, Loss: 1.4222, Train: 38.39%, Valid: 36.30%, Test: 36.48%
Epoch: 175, Loss: 1.4073, Train: 39.17%, Valid: 35.82%, Test: 36.32%
Epoch: 200, Loss: 1.4016, Train: 39.71%, Valid: 35.80%, Test: 36.14%
Epoch: 225, Loss: 1.3915, Train: 40.01%, Valid: 35.94%, Test: 36.32%
Epoch: 250, Loss: 1.3936, Train: 39.97%, Valid: 34.64%, Test: 35.02%
Epoch: 275, Loss: 1.3890, Train: 40.58%, Valid: 35.60%, Test: 35.90%
Epoch: 300, Loss: 1.3739, Train: 41.11%, Valid: 35.01%, Test: 35.25%
Epoch: 325, Loss: 1.3603, Train: 41.46%, Valid: 34.79%, Test: 35.05%
Epoch: 350, Loss: 1.3628, Train: 41.81%, Valid: 34.66%, Test: 34.87%
Epoch: 375, Loss: 1.3519, Train: 42.57%, Valid: 35.08%, Test: 35.34%
Epoch: 400, Loss: 1.3478, Train: 42.29%, Valid: 33.84%, Test: 34.26%
Epoch: 425, Loss: 1.3452, Train: 42.56%, Valid: 33.97%, Test: 34.26%
Epoch: 450, Loss: 1.3354, Train: 43.09%, Valid: 35.23%, Test: 35.48%
Epoch: 475, Loss: 1.3439, Train: 41.84%, Valid: 33.32%, Test: 33.59%
Epoch: 500, Loss: 1.3298, Train: 43.01%, Valid: 33.87%, Test: 33.91%
Epoch: 525, Loss: 1.3220, Train: 43.53%, Valid: 35.14%, Test: 35.21%
Epoch: 550, Loss: 1.3127, Train: 44.36%, Valid: 34.15%, Test: 34.38%
Epoch: 575, Loss: 1.3175, Train: 44.03%, Valid: 34.97%, Test: 34.93%
Epoch: 600, Loss: 1.3314, Train: 43.73%, Valid: 33.50%, Test: 33.38%
Epoch: 625, Loss: 1.3031, Train: 44.79%, Valid: 33.78%, Test: 33.81%
Epoch: 650, Loss: 1.3039, Train: 45.09%, Valid: 33.37%, Test: 33.55%
Epoch: 675, Loss: 1.3172, Train: 44.43%, Valid: 33.80%, Test: 34.01%
Epoch: 700, Loss: 1.3721, Train: 44.23%, Valid: 32.91%, Test: 33.09%
Epoch: 725, Loss: 1.3234, Train: 43.46%, Valid: 34.92%, Test: 34.88%
Epoch: 750, Loss: 1.3008, Train: 44.87%, Valid: 34.50%, Test: 34.51%
Epoch: 775, Loss: 1.3296, Train: 43.14%, Valid: 34.30%, Test: 34.29%
Epoch: 800, Loss: 1.2971, Train: 44.91%, Valid: 34.73%, Test: 34.91%
Epoch: 825, Loss: 1.2850, Train: 45.71%, Valid: 34.22%, Test: 34.49%
Epoch: 850, Loss: 1.2838, Train: 45.54%, Valid: 34.47%, Test: 34.50%
Epoch: 875, Loss: 1.2784, Train: 45.96%, Valid: 33.38%, Test: 33.85%
Epoch: 900, Loss: 1.2831, Train: 45.87%, Valid: 34.02%, Test: 34.40%
Epoch: 925, Loss: 1.2976, Train: 45.40%, Valid: 33.51%, Test: 33.96%
Epoch: 950, Loss: 1.2741, Train: 46.09%, Valid: 33.23%, Test: 33.42%
Epoch: 975, Loss: 1.2847, Train: 45.70%, Valid: 33.19%, Test: 33.63%
Run 01:
Highest Train: 46.65
Highest Valid: 36.34
  Final Train: 38.09
   Final Test: 36.58
All runs:
Highest Train: 46.65 ± nan
Highest Valid: 36.34 ± nan
  Final Train: 38.09 ± nan
   Final Test: 36.58 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6083, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4889, Train: 35.00%, Valid: 34.60%, Test: 35.03%
Epoch: 50, Loss: 1.4709, Train: 35.93%, Valid: 35.30%, Test: 35.54%
Epoch: 75, Loss: 1.4554, Train: 36.73%, Valid: 35.81%, Test: 36.03%
Epoch: 100, Loss: 1.4461, Train: 36.71%, Valid: 35.16%, Test: 35.62%
Epoch: 125, Loss: 1.4319, Train: 37.95%, Valid: 36.20%, Test: 36.58%
Epoch: 150, Loss: 1.4268, Train: 38.36%, Valid: 35.85%, Test: 36.64%
Epoch: 175, Loss: 1.4162, Train: 38.84%, Valid: 36.11%, Test: 36.71%
Epoch: 200, Loss: 1.4098, Train: 38.87%, Valid: 35.29%, Test: 36.02%
Epoch: 225, Loss: 1.4093, Train: 39.66%, Valid: 35.93%, Test: 36.59%
Epoch: 250, Loss: 1.4072, Train: 39.83%, Valid: 35.43%, Test: 36.11%
Epoch: 275, Loss: 1.3827, Train: 40.41%, Valid: 35.92%, Test: 36.46%
Epoch: 300, Loss: 1.3907, Train: 40.37%, Valid: 35.57%, Test: 36.12%
Epoch: 325, Loss: 1.3717, Train: 41.31%, Valid: 35.45%, Test: 35.82%
Epoch: 350, Loss: 1.3935, Train: 40.34%, Valid: 35.91%, Test: 36.19%
Epoch: 375, Loss: 1.3684, Train: 41.49%, Valid: 35.49%, Test: 35.95%
Epoch: 400, Loss: 1.3676, Train: 41.30%, Valid: 34.65%, Test: 35.14%
Epoch: 425, Loss: 1.3529, Train: 42.34%, Valid: 35.41%, Test: 35.62%
Epoch: 450, Loss: 1.3499, Train: 42.49%, Valid: 34.28%, Test: 34.58%
Epoch: 475, Loss: 1.3489, Train: 42.21%, Valid: 35.10%, Test: 35.01%
Epoch: 500, Loss: 1.3348, Train: 42.93%, Valid: 35.24%, Test: 35.36%
Epoch: 525, Loss: 1.3412, Train: 42.88%, Valid: 34.60%, Test: 35.05%
Epoch: 550, Loss: 1.3324, Train: 42.15%, Valid: 35.27%, Test: 35.51%
Epoch: 575, Loss: 1.3222, Train: 44.02%, Valid: 35.21%, Test: 35.23%
Epoch: 600, Loss: 1.3164, Train: 44.18%, Valid: 34.14%, Test: 34.05%
Epoch: 625, Loss: 1.3119, Train: 44.77%, Valid: 35.20%, Test: 35.16%
Epoch: 650, Loss: 1.3117, Train: 43.65%, Valid: 34.83%, Test: 34.99%
Epoch: 675, Loss: 1.3126, Train: 44.71%, Valid: 34.46%, Test: 34.51%
Epoch: 700, Loss: 1.3127, Train: 44.38%, Valid: 33.56%, Test: 33.85%
Epoch: 725, Loss: 1.3105, Train: 44.31%, Valid: 34.97%, Test: 35.27%
Epoch: 750, Loss: 1.3437, Train: 44.52%, Valid: 33.70%, Test: 33.90%
Epoch: 775, Loss: 1.3000, Train: 45.30%, Valid: 34.44%, Test: 34.27%
Epoch: 800, Loss: 1.3136, Train: 44.07%, Valid: 35.34%, Test: 35.44%
Epoch: 825, Loss: 1.2988, Train: 45.48%, Valid: 34.81%, Test: 34.64%
Epoch: 850, Loss: 1.3915, Train: 42.34%, Valid: 32.72%, Test: 32.95%
Epoch: 875, Loss: 1.2927, Train: 45.43%, Valid: 34.89%, Test: 34.92%
Epoch: 900, Loss: 1.2861, Train: 45.82%, Valid: 34.56%, Test: 34.52%
Epoch: 925, Loss: 1.3480, Train: 45.06%, Valid: 33.05%, Test: 33.05%
Epoch: 950, Loss: 1.2875, Train: 45.34%, Valid: 34.24%, Test: 34.30%
Epoch: 975, Loss: 1.2865, Train: 44.89%, Valid: 34.66%, Test: 34.89%
Run 01:
Highest Train: 46.60
Highest Valid: 36.39
  Final Train: 37.57
   Final Test: 36.66
All runs:
Highest Train: 46.60 ± nan
Highest Valid: 36.39 ± nan
  Final Train: 37.57 ± nan
   Final Test: 36.66 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6127, Train: 29.11%, Valid: 28.72%, Test: 29.40%
Epoch: 25, Loss: 1.4906, Train: 34.77%, Valid: 34.45%, Test: 34.92%
Epoch: 50, Loss: 1.4656, Train: 36.03%, Valid: 35.39%, Test: 35.85%
Epoch: 75, Loss: 1.4393, Train: 37.92%, Valid: 37.43%, Test: 37.64%
Epoch: 100, Loss: 1.4196, Train: 38.57%, Valid: 37.80%, Test: 38.11%
Epoch: 125, Loss: 1.3934, Train: 39.90%, Valid: 39.20%, Test: 39.49%
Epoch: 150, Loss: 1.3958, Train: 39.97%, Valid: 38.86%, Test: 39.08%
Epoch: 175, Loss: 1.3650, Train: 40.98%, Valid: 39.95%, Test: 39.95%
Epoch: 200, Loss: 1.3566, Train: 41.66%, Valid: 40.43%, Test: 40.47%
Epoch: 225, Loss: 1.3579, Train: 41.59%, Valid: 40.07%, Test: 40.27%
Epoch: 250, Loss: 1.3870, Train: 41.78%, Valid: 39.87%, Test: 40.09%
Epoch: 275, Loss: 1.3351, Train: 42.70%, Valid: 41.03%, Test: 41.26%
Epoch: 300, Loss: 1.3209, Train: 43.56%, Valid: 41.38%, Test: 41.64%
Epoch: 325, Loss: 1.3128, Train: 44.02%, Valid: 41.65%, Test: 41.87%
Epoch: 350, Loss: 1.3045, Train: 44.30%, Valid: 41.46%, Test: 41.97%
Epoch: 375, Loss: 1.3375, Train: 43.05%, Valid: 40.84%, Test: 41.23%
Epoch: 400, Loss: 1.2961, Train: 44.59%, Valid: 41.66%, Test: 42.05%
Epoch: 425, Loss: 1.2876, Train: 45.10%, Valid: 41.70%, Test: 41.96%
Epoch: 450, Loss: 1.3135, Train: 44.46%, Valid: 41.41%, Test: 41.83%
Epoch: 475, Loss: 1.2751, Train: 45.35%, Valid: 42.00%, Test: 42.38%
Epoch: 500, Loss: 1.2636, Train: 45.81%, Valid: 42.22%, Test: 42.48%
Epoch: 525, Loss: 1.2625, Train: 46.15%, Valid: 42.42%, Test: 42.88%
Epoch: 550, Loss: 1.2636, Train: 43.83%, Valid: 41.67%, Test: 41.95%
Epoch: 575, Loss: 1.2608, Train: 46.02%, Valid: 42.70%, Test: 43.05%
Epoch: 600, Loss: 1.3155, Train: 43.72%, Valid: 40.39%, Test: 40.72%
Epoch: 625, Loss: 1.2541, Train: 46.14%, Valid: 43.34%, Test: 43.36%
Epoch: 650, Loss: 1.2335, Train: 46.92%, Valid: 43.62%, Test: 43.90%
Epoch: 675, Loss: 1.2224, Train: 47.05%, Valid: 43.43%, Test: 43.51%
Epoch: 700, Loss: 1.2219, Train: 46.53%, Valid: 42.81%, Test: 42.96%
Epoch: 725, Loss: 1.2372, Train: 46.81%, Valid: 43.19%, Test: 43.41%
Epoch: 750, Loss: 1.2157, Train: 47.63%, Valid: 43.70%, Test: 43.71%
Epoch: 775, Loss: 1.2021, Train: 48.31%, Valid: 44.18%, Test: 44.31%
Epoch: 800, Loss: 1.2835, Train: 44.56%, Valid: 41.87%, Test: 42.07%
Epoch: 825, Loss: 1.2313, Train: 46.80%, Valid: 43.82%, Test: 44.05%
Epoch: 850, Loss: 1.2231, Train: 47.06%, Valid: 43.84%, Test: 44.09%
Epoch: 875, Loss: 1.2315, Train: 47.07%, Valid: 44.20%, Test: 44.52%
Epoch: 900, Loss: 1.2092, Train: 47.44%, Valid: 44.12%, Test: 44.48%
Epoch: 925, Loss: 1.2378, Train: 46.25%, Valid: 43.62%, Test: 43.86%
Epoch: 950, Loss: 1.2005, Train: 48.05%, Valid: 44.65%, Test: 45.02%
Epoch: 975, Loss: 1.2036, Train: 47.91%, Valid: 44.34%, Test: 44.68%
Run 01:
Highest Train: 48.68
Highest Valid: 45.00
  Final Train: 48.38
   Final Test: 45.16
All runs:
Highest Train: 48.68 ± nan
Highest Valid: 45.00 ± nan
  Final Train: 48.38 ± nan
   Final Test: 45.16 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6129, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4837, Train: 35.11%, Valid: 34.54%, Test: 35.10%
Epoch: 50, Loss: 1.4642, Train: 36.00%, Valid: 35.26%, Test: 35.78%
Epoch: 75, Loss: 1.4464, Train: 36.82%, Valid: 35.59%, Test: 36.22%
Epoch: 100, Loss: 1.4345, Train: 37.44%, Valid: 35.45%, Test: 36.22%
Epoch: 125, Loss: 1.4233, Train: 38.23%, Valid: 36.19%, Test: 36.52%
Epoch: 150, Loss: 1.4152, Train: 38.57%, Valid: 36.17%, Test: 36.45%
Epoch: 175, Loss: 1.4097, Train: 39.26%, Valid: 35.93%, Test: 36.40%
Epoch: 200, Loss: 1.4055, Train: 39.51%, Valid: 35.48%, Test: 36.06%
Epoch: 225, Loss: 1.4010, Train: 39.53%, Valid: 35.84%, Test: 36.20%
Epoch: 250, Loss: 1.3851, Train: 40.48%, Valid: 35.78%, Test: 36.32%
Epoch: 275, Loss: 1.3796, Train: 41.00%, Valid: 35.41%, Test: 35.77%
Epoch: 300, Loss: 1.3762, Train: 41.06%, Valid: 35.71%, Test: 35.99%
Epoch: 325, Loss: 1.3624, Train: 41.62%, Valid: 34.97%, Test: 35.52%
Epoch: 350, Loss: 1.3599, Train: 42.08%, Valid: 35.21%, Test: 35.69%
Epoch: 375, Loss: 1.4347, Train: 41.94%, Valid: 34.59%, Test: 34.71%
Epoch: 400, Loss: 1.3472, Train: 42.69%, Valid: 35.04%, Test: 35.36%
Epoch: 425, Loss: 1.3727, Train: 41.11%, Valid: 35.57%, Test: 35.76%
Epoch: 450, Loss: 1.3384, Train: 43.05%, Valid: 34.61%, Test: 35.21%
Epoch: 475, Loss: 1.3332, Train: 43.50%, Valid: 34.48%, Test: 35.22%
Epoch: 500, Loss: 1.3263, Train: 43.73%, Valid: 34.76%, Test: 35.02%
Epoch: 525, Loss: 1.3271, Train: 44.14%, Valid: 33.85%, Test: 34.28%
Epoch: 550, Loss: 1.3140, Train: 44.07%, Valid: 34.73%, Test: 35.24%
Epoch: 575, Loss: 1.3152, Train: 44.37%, Valid: 34.34%, Test: 34.55%
Epoch: 600, Loss: 1.3013, Train: 44.87%, Valid: 34.34%, Test: 34.71%
Epoch: 625, Loss: 1.2985, Train: 44.94%, Valid: 34.23%, Test: 34.40%
Epoch: 650, Loss: 1.3080, Train: 44.89%, Valid: 34.59%, Test: 35.16%
Epoch: 675, Loss: 1.3102, Train: 45.25%, Valid: 33.73%, Test: 33.89%
Epoch: 700, Loss: 1.2976, Train: 45.15%, Valid: 33.06%, Test: 33.30%
Epoch: 725, Loss: 1.3469, Train: 41.66%, Valid: 31.45%, Test: 31.98%
Epoch: 750, Loss: 1.2913, Train: 45.36%, Valid: 33.80%, Test: 34.15%
Epoch: 775, Loss: 1.2872, Train: 44.46%, Valid: 32.05%, Test: 31.89%
Epoch: 800, Loss: 1.2806, Train: 46.05%, Valid: 33.81%, Test: 33.94%
Epoch: 825, Loss: 1.3011, Train: 45.10%, Valid: 32.43%, Test: 32.49%
Epoch: 850, Loss: 1.2771, Train: 46.33%, Valid: 33.78%, Test: 34.06%
Epoch: 875, Loss: 1.2755, Train: 46.35%, Valid: 33.99%, Test: 34.00%
Epoch: 900, Loss: 1.2775, Train: 45.76%, Valid: 33.78%, Test: 33.95%
Epoch: 925, Loss: 1.2707, Train: 45.58%, Valid: 31.25%, Test: 31.23%
Epoch: 950, Loss: 1.2748, Train: 46.46%, Valid: 32.84%, Test: 32.76%
Epoch: 975, Loss: 1.2642, Train: 46.61%, Valid: 33.73%, Test: 33.82%
Run 01:
Highest Train: 46.84
Highest Valid: 36.25
  Final Train: 38.53
   Final Test: 36.60
All runs:
Highest Train: 46.84 ± nan
Highest Valid: 36.25 ± nan
  Final Train: 38.53 ± nan
   Final Test: 36.60 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6120, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4858, Train: 35.05%, Valid: 34.57%, Test: 35.04%
Epoch: 50, Loss: 1.4685, Train: 36.05%, Valid: 35.36%, Test: 35.56%
Epoch: 75, Loss: 1.4512, Train: 36.99%, Valid: 35.92%, Test: 36.19%
Epoch: 100, Loss: 1.4326, Train: 37.72%, Valid: 36.49%, Test: 36.80%
Epoch: 125, Loss: 1.4034, Train: 39.36%, Valid: 37.38%, Test: 37.74%
Epoch: 150, Loss: 1.3783, Train: 40.60%, Valid: 38.23%, Test: 38.62%
Epoch: 175, Loss: 1.3422, Train: 41.97%, Valid: 39.38%, Test: 39.55%
Epoch: 200, Loss: 1.3262, Train: 42.83%, Valid: 39.19%, Test: 39.64%
Epoch: 225, Loss: 1.3067, Train: 43.61%, Valid: 39.61%, Test: 40.07%
Epoch: 250, Loss: 1.3001, Train: 43.96%, Valid: 39.85%, Test: 39.91%
Epoch: 275, Loss: 1.2991, Train: 44.65%, Valid: 39.75%, Test: 40.11%
Epoch: 300, Loss: 1.2617, Train: 46.25%, Valid: 41.16%, Test: 41.30%
Epoch: 325, Loss: 1.2468, Train: 46.59%, Valid: 40.71%, Test: 40.63%
Epoch: 350, Loss: 1.3086, Train: 43.63%, Valid: 40.83%, Test: 41.06%
Epoch: 375, Loss: 1.2627, Train: 45.68%, Valid: 41.95%, Test: 42.12%
Epoch: 400, Loss: 1.2498, Train: 46.84%, Valid: 42.44%, Test: 42.58%
Epoch: 425, Loss: 1.2431, Train: 47.32%, Valid: 42.66%, Test: 42.64%
Epoch: 450, Loss: 1.2038, Train: 48.57%, Valid: 43.02%, Test: 43.18%
Epoch: 475, Loss: 1.1910, Train: 48.95%, Valid: 42.99%, Test: 42.75%
Epoch: 500, Loss: 1.1899, Train: 48.90%, Valid: 42.87%, Test: 42.87%
Epoch: 525, Loss: 1.1764, Train: 49.81%, Valid: 43.36%, Test: 43.40%
Epoch: 550, Loss: 1.1803, Train: 47.98%, Valid: 41.68%, Test: 41.87%
Epoch: 575, Loss: 1.1532, Train: 51.01%, Valid: 43.97%, Test: 43.67%
Epoch: 600, Loss: 1.1586, Train: 51.20%, Valid: 43.95%, Test: 43.79%
Epoch: 625, Loss: 1.1502, Train: 51.32%, Valid: 44.33%, Test: 44.18%
Epoch: 650, Loss: 1.1592, Train: 50.57%, Valid: 43.52%, Test: 43.48%
Epoch: 675, Loss: 1.1256, Train: 52.08%, Valid: 44.39%, Test: 44.07%
Epoch: 700, Loss: 1.1373, Train: 51.43%, Valid: 44.19%, Test: 44.04%
Epoch: 725, Loss: 1.1120, Train: 52.85%, Valid: 44.43%, Test: 44.45%
Epoch: 750, Loss: 1.1512, Train: 51.02%, Valid: 44.54%, Test: 44.58%
Epoch: 775, Loss: 1.1123, Train: 53.22%, Valid: 44.90%, Test: 44.81%
Epoch: 800, Loss: 1.1415, Train: 52.25%, Valid: 44.04%, Test: 44.04%
Epoch: 825, Loss: 1.1022, Train: 53.46%, Valid: 45.17%, Test: 45.03%
Epoch: 850, Loss: 1.2027, Train: 48.75%, Valid: 44.31%, Test: 43.88%
Epoch: 875, Loss: 1.1361, Train: 51.66%, Valid: 45.22%, Test: 45.26%
Epoch: 900, Loss: 1.1149, Train: 52.83%, Valid: 45.43%, Test: 45.54%
Epoch: 925, Loss: 1.1030, Train: 53.39%, Valid: 45.37%, Test: 45.58%
Epoch: 950, Loss: 1.1221, Train: 52.42%, Valid: 45.35%, Test: 45.48%
Epoch: 975, Loss: 1.0962, Train: 53.47%, Valid: 45.50%, Test: 45.75%
Run 01:
Highest Train: 53.72
Highest Valid: 45.72
  Final Train: 52.67
   Final Test: 45.86
All runs:
Highest Train: 53.72 ± nan
Highest Valid: 45.72 ± nan
  Final Train: 52.67 ± nan
   Final Test: 45.86 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6009, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4812, Train: 35.32%, Valid: 34.72%, Test: 35.23%
Epoch: 50, Loss: 1.4322, Train: 37.33%, Valid: 36.54%, Test: 36.81%
Epoch: 75, Loss: 1.3935, Train: 39.52%, Valid: 38.30%, Test: 38.81%
Epoch: 100, Loss: 1.3761, Train: 40.49%, Valid: 39.32%, Test: 39.42%
Epoch: 125, Loss: 1.3551, Train: 41.49%, Valid: 40.03%, Test: 40.47%
Epoch: 150, Loss: 1.3315, Train: 42.57%, Valid: 41.08%, Test: 41.46%
Epoch: 175, Loss: 1.3146, Train: 43.23%, Valid: 41.58%, Test: 42.03%
Epoch: 200, Loss: 1.2866, Train: 44.62%, Valid: 42.61%, Test: 42.81%
Epoch: 225, Loss: 1.2832, Train: 44.05%, Valid: 42.33%, Test: 42.79%
Epoch: 250, Loss: 1.2726, Train: 45.17%, Valid: 43.13%, Test: 43.24%
Epoch: 275, Loss: 1.2452, Train: 46.35%, Valid: 43.99%, Test: 44.24%
Epoch: 300, Loss: 1.2389, Train: 46.52%, Valid: 44.07%, Test: 44.20%
Epoch: 325, Loss: 1.2462, Train: 46.16%, Valid: 44.05%, Test: 43.85%
Epoch: 350, Loss: 1.2167, Train: 47.53%, Valid: 44.56%, Test: 44.73%
Epoch: 375, Loss: 1.3207, Train: 45.63%, Valid: 43.64%, Test: 43.83%
Epoch: 400, Loss: 1.2145, Train: 47.60%, Valid: 45.02%, Test: 45.12%
Epoch: 425, Loss: 1.2113, Train: 47.69%, Valid: 45.07%, Test: 45.05%
Epoch: 450, Loss: 1.2117, Train: 47.03%, Valid: 44.25%, Test: 44.46%
Epoch: 475, Loss: 1.2716, Train: 45.63%, Valid: 42.40%, Test: 42.74%
Epoch: 500, Loss: 1.1994, Train: 48.29%, Valid: 45.42%, Test: 45.45%
Epoch: 525, Loss: 1.1988, Train: 48.37%, Valid: 45.27%, Test: 45.48%
Epoch: 550, Loss: 1.1872, Train: 48.56%, Valid: 44.77%, Test: 45.23%
Epoch: 575, Loss: 1.1968, Train: 48.27%, Valid: 44.52%, Test: 44.71%
Epoch: 600, Loss: 1.1658, Train: 49.93%, Valid: 45.80%, Test: 46.00%
Epoch: 625, Loss: 1.1743, Train: 49.48%, Valid: 45.92%, Test: 46.12%
Epoch: 650, Loss: 1.1645, Train: 49.72%, Valid: 45.79%, Test: 45.75%
Epoch: 675, Loss: 1.1545, Train: 50.16%, Valid: 46.28%, Test: 46.45%
Epoch: 700, Loss: 1.1481, Train: 50.46%, Valid: 46.07%, Test: 46.33%
Epoch: 725, Loss: 1.1676, Train: 49.52%, Valid: 45.61%, Test: 45.93%
Epoch: 750, Loss: 1.1544, Train: 50.26%, Valid: 46.07%, Test: 46.23%
Epoch: 775, Loss: 1.1912, Train: 49.32%, Valid: 45.06%, Test: 44.99%
Epoch: 800, Loss: 1.1552, Train: 50.82%, Valid: 46.18%, Test: 46.26%
Epoch: 825, Loss: 1.1497, Train: 50.01%, Valid: 45.94%, Test: 46.04%
Epoch: 850, Loss: 1.1364, Train: 51.09%, Valid: 46.39%, Test: 46.58%
Epoch: 875, Loss: 1.2873, Train: 46.84%, Valid: 43.72%, Test: 43.86%
Epoch: 900, Loss: 1.1655, Train: 49.86%, Valid: 46.09%, Test: 46.39%
Epoch: 925, Loss: 1.1738, Train: 50.23%, Valid: 46.31%, Test: 46.53%
Epoch: 950, Loss: 1.1363, Train: 50.68%, Valid: 46.31%, Test: 46.19%
Epoch: 975, Loss: 1.1514, Train: 51.16%, Valid: 46.58%, Test: 46.66%
Run 01:
Highest Train: 51.85
Highest Valid: 47.11
  Final Train: 51.47
   Final Test: 47.03
All runs:
Highest Train: 51.85 ± nan
Highest Valid: 47.11 ± nan
  Final Train: 51.47 ± nan
   Final Test: 47.03 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6109, Train: 30.58%, Valid: 30.29%, Test: 30.81%
Epoch: 25, Loss: 1.5030, Train: 34.19%, Valid: 34.01%, Test: 34.34%
Epoch: 50, Loss: 1.4830, Train: 35.24%, Valid: 34.72%, Test: 35.13%
Epoch: 75, Loss: 1.4722, Train: 35.84%, Valid: 35.14%, Test: 35.50%
Epoch: 100, Loss: 1.4609, Train: 36.35%, Valid: 35.61%, Test: 35.87%
Epoch: 125, Loss: 1.4522, Train: 36.91%, Valid: 35.96%, Test: 36.26%
Epoch: 150, Loss: 1.4360, Train: 38.11%, Valid: 36.21%, Test: 36.67%
Epoch: 175, Loss: 1.4224, Train: 38.37%, Valid: 36.61%, Test: 36.94%
Epoch: 200, Loss: 1.4167, Train: 39.22%, Valid: 36.62%, Test: 36.96%
Epoch: 225, Loss: 1.4055, Train: 39.70%, Valid: 36.65%, Test: 37.12%
Epoch: 250, Loss: 1.3880, Train: 40.36%, Valid: 36.78%, Test: 37.56%
Epoch: 275, Loss: 1.4327, Train: 38.89%, Valid: 34.83%, Test: 35.64%
Epoch: 300, Loss: 1.3814, Train: 41.07%, Valid: 36.78%, Test: 37.41%
Epoch: 325, Loss: 1.3591, Train: 41.66%, Valid: 36.92%, Test: 37.51%
Epoch: 350, Loss: 1.3566, Train: 42.29%, Valid: 37.30%, Test: 37.76%
Epoch: 375, Loss: 1.3833, Train: 41.20%, Valid: 36.22%, Test: 36.93%
Epoch: 400, Loss: 1.3380, Train: 43.28%, Valid: 37.62%, Test: 38.03%
Epoch: 425, Loss: 1.3217, Train: 44.35%, Valid: 38.03%, Test: 38.58%
Epoch: 450, Loss: 1.3045, Train: 45.08%, Valid: 37.78%, Test: 38.36%
Epoch: 475, Loss: 1.3083, Train: 45.37%, Valid: 38.57%, Test: 39.06%
Epoch: 500, Loss: 1.2918, Train: 46.03%, Valid: 38.58%, Test: 39.12%
Epoch: 525, Loss: 1.2913, Train: 46.71%, Valid: 38.95%, Test: 39.37%
Epoch: 550, Loss: 1.2892, Train: 44.29%, Valid: 37.50%, Test: 38.17%
Epoch: 575, Loss: 1.2708, Train: 46.49%, Valid: 38.44%, Test: 38.84%
Epoch: 600, Loss: 1.2557, Train: 46.23%, Valid: 37.91%, Test: 38.45%
Epoch: 625, Loss: 1.2594, Train: 46.93%, Valid: 37.87%, Test: 38.56%
Epoch: 650, Loss: 1.2752, Train: 46.18%, Valid: 37.67%, Test: 37.96%
Epoch: 675, Loss: 1.2653, Train: 47.23%, Valid: 37.52%, Test: 37.98%
Epoch: 700, Loss: 1.2547, Train: 48.62%, Valid: 38.36%, Test: 38.86%
Epoch: 725, Loss: 1.2310, Train: 49.04%, Valid: 38.47%, Test: 38.82%
Epoch: 750, Loss: 1.2749, Train: 46.65%, Valid: 37.79%, Test: 37.92%
Epoch: 775, Loss: 1.2381, Train: 48.92%, Valid: 39.10%, Test: 39.36%
Epoch: 800, Loss: 1.2255, Train: 49.32%, Valid: 38.88%, Test: 39.40%
Epoch: 825, Loss: 1.2477, Train: 47.53%, Valid: 37.22%, Test: 37.82%
Epoch: 850, Loss: 1.2378, Train: 48.89%, Valid: 38.77%, Test: 39.15%
Epoch: 875, Loss: 1.2068, Train: 50.15%, Valid: 38.62%, Test: 39.12%
Epoch: 900, Loss: 1.2006, Train: 50.67%, Valid: 38.67%, Test: 39.30%
Epoch: 925, Loss: 1.2071, Train: 50.36%, Valid: 39.35%, Test: 39.54%
Epoch: 950, Loss: 1.2009, Train: 50.44%, Valid: 38.83%, Test: 38.95%
Epoch: 975, Loss: 1.2067, Train: 49.93%, Valid: 38.87%, Test: 39.29%
Run 01:
Highest Train: 51.16
Highest Valid: 39.53
  Final Train: 50.20
   Final Test: 39.57
All runs:
Highest Train: 51.16 ± nan
Highest Valid: 39.53 ± nan
  Final Train: 50.20 ± nan
   Final Test: 39.57 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6159, Train: 24.49%, Valid: 24.12%, Test: 24.23%
Epoch: 25, Loss: 1.5313, Train: 28.73%, Valid: 28.55%, Test: 28.84%
Epoch: 50, Loss: 1.4807, Train: 34.43%, Valid: 34.13%, Test: 34.45%
Epoch: 75, Loss: 1.4648, Train: 35.29%, Valid: 34.90%, Test: 35.19%
Epoch: 100, Loss: 1.4541, Train: 35.80%, Valid: 35.41%, Test: 35.63%
Epoch: 125, Loss: 1.4166, Train: 39.35%, Valid: 38.88%, Test: 39.26%
Epoch: 150, Loss: 1.3996, Train: 39.53%, Valid: 39.08%, Test: 39.34%
Epoch: 175, Loss: 1.3682, Train: 40.26%, Valid: 39.75%, Test: 40.04%
Epoch: 200, Loss: 1.3471, Train: 40.80%, Valid: 40.23%, Test: 40.56%
Epoch: 225, Loss: 1.3339, Train: 41.93%, Valid: 41.20%, Test: 41.53%
Epoch: 250, Loss: 1.3056, Train: 43.37%, Valid: 42.74%, Test: 43.11%
Epoch: 275, Loss: 1.3239, Train: 42.65%, Valid: 41.94%, Test: 42.24%
Epoch: 300, Loss: 1.2908, Train: 43.87%, Valid: 43.31%, Test: 43.45%
Epoch: 325, Loss: 1.2825, Train: 44.74%, Valid: 43.83%, Test: 44.06%
Epoch: 350, Loss: 1.2822, Train: 43.76%, Valid: 42.83%, Test: 43.20%
Epoch: 375, Loss: 1.2443, Train: 46.37%, Valid: 45.33%, Test: 45.59%
Epoch: 400, Loss: 1.2402, Train: 46.30%, Valid: 45.51%, Test: 45.41%
Epoch: 425, Loss: 1.2269, Train: 47.32%, Valid: 46.25%, Test: 46.16%
Epoch: 450, Loss: 1.2220, Train: 47.46%, Valid: 46.38%, Test: 46.28%
Epoch: 475, Loss: 1.2305, Train: 46.87%, Valid: 45.76%, Test: 45.73%
Epoch: 500, Loss: 1.2425, Train: 46.59%, Valid: 45.32%, Test: 45.54%
Epoch: 525, Loss: 1.2110, Train: 47.66%, Valid: 46.44%, Test: 46.55%
Epoch: 550, Loss: 1.2103, Train: 47.74%, Valid: 46.61%, Test: 46.73%
Epoch: 575, Loss: 1.2073, Train: 47.37%, Valid: 46.21%, Test: 46.22%
Epoch: 600, Loss: 1.1978, Train: 48.40%, Valid: 46.99%, Test: 46.90%
Epoch: 625, Loss: 1.1958, Train: 48.41%, Valid: 46.89%, Test: 46.92%
Epoch: 650, Loss: 1.1981, Train: 48.20%, Valid: 46.86%, Test: 46.69%
Epoch: 675, Loss: 1.2039, Train: 48.35%, Valid: 46.61%, Test: 46.53%
Epoch: 700, Loss: 1.2038, Train: 47.67%, Valid: 46.16%, Test: 46.04%
Epoch: 725, Loss: 1.1910, Train: 48.59%, Valid: 46.85%, Test: 46.82%
Epoch: 750, Loss: 1.1967, Train: 48.70%, Valid: 47.04%, Test: 46.93%
Epoch: 775, Loss: 1.1848, Train: 49.01%, Valid: 47.29%, Test: 47.41%
Epoch: 800, Loss: 1.1839, Train: 48.90%, Valid: 47.13%, Test: 47.06%
Epoch: 825, Loss: 1.1826, Train: 49.08%, Valid: 47.20%, Test: 47.48%
Epoch: 850, Loss: 1.2021, Train: 48.85%, Valid: 47.09%, Test: 47.24%
Epoch: 875, Loss: 1.1762, Train: 49.30%, Valid: 47.29%, Test: 47.44%
Epoch: 900, Loss: 1.1866, Train: 49.00%, Valid: 47.15%, Test: 47.26%
Epoch: 925, Loss: 1.1888, Train: 49.33%, Valid: 47.19%, Test: 47.15%
Epoch: 950, Loss: 1.1819, Train: 49.59%, Valid: 47.42%, Test: 47.51%
Epoch: 975, Loss: 1.1788, Train: 49.58%, Valid: 47.06%, Test: 47.32%
Run 01:
Highest Train: 49.97
Highest Valid: 47.75
  Final Train: 49.71
   Final Test: 47.72
All runs:
Highest Train: 49.97 ± nan
Highest Valid: 47.75 ± nan
  Final Train: 49.71 ± nan
   Final Test: 47.72 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6044, Train: 28.32%, Valid: 28.23%, Test: 28.78%
Epoch: 25, Loss: 1.4722, Train: 36.46%, Valid: 36.13%, Test: 36.34%
Epoch: 50, Loss: 1.4747, Train: 32.58%, Valid: 32.32%, Test: 33.03%
Epoch: 75, Loss: 1.4632, Train: 36.48%, Valid: 35.87%, Test: 36.35%
Epoch: 100, Loss: 1.4534, Train: 36.98%, Valid: 36.58%, Test: 36.95%
Epoch: 125, Loss: 1.4523, Train: 32.89%, Valid: 32.68%, Test: 33.18%
Epoch: 150, Loss: 1.4682, Train: 32.70%, Valid: 32.40%, Test: 33.35%
Epoch: 175, Loss: 1.4321, Train: 35.74%, Valid: 35.31%, Test: 36.31%
Epoch: 200, Loss: 1.4060, Train: 38.33%, Valid: 37.86%, Test: 38.57%
Epoch: 225, Loss: 1.4316, Train: 38.23%, Valid: 37.78%, Test: 38.19%
Epoch: 250, Loss: 1.3982, Train: 39.71%, Valid: 39.29%, Test: 39.96%
Epoch: 275, Loss: 1.3831, Train: 40.42%, Valid: 40.12%, Test: 40.57%
Epoch: 300, Loss: 1.3933, Train: 39.33%, Valid: 38.80%, Test: 39.52%
Epoch: 325, Loss: 1.3588, Train: 41.19%, Valid: 40.81%, Test: 41.19%
Epoch: 350, Loss: 1.3810, Train: 40.71%, Valid: 40.28%, Test: 40.85%
Epoch: 375, Loss: 1.3496, Train: 41.58%, Valid: 41.35%, Test: 41.55%
Epoch: 400, Loss: 1.3733, Train: 40.75%, Valid: 40.47%, Test: 40.73%
Epoch: 425, Loss: 1.3738, Train: 40.48%, Valid: 40.43%, Test: 40.68%
Epoch: 450, Loss: 1.3454, Train: 41.74%, Valid: 41.49%, Test: 41.89%
Epoch: 475, Loss: 1.3487, Train: 41.80%, Valid: 41.47%, Test: 41.87%
Epoch: 500, Loss: 1.4394, Train: 41.27%, Valid: 41.16%, Test: 41.56%
Epoch: 525, Loss: 1.3352, Train: 42.17%, Valid: 41.96%, Test: 42.23%
Epoch: 550, Loss: 1.3270, Train: 42.74%, Valid: 42.55%, Test: 42.80%
Epoch: 575, Loss: 1.3134, Train: 43.19%, Valid: 43.02%, Test: 43.18%
Epoch: 600, Loss: 1.3211, Train: 42.52%, Valid: 42.33%, Test: 42.64%
Epoch: 625, Loss: 1.3160, Train: 43.53%, Valid: 43.29%, Test: 43.43%
Epoch: 650, Loss: 1.3154, Train: 43.05%, Valid: 42.89%, Test: 42.97%
Epoch: 675, Loss: 1.3019, Train: 43.07%, Valid: 42.84%, Test: 43.16%
Epoch: 700, Loss: 1.3116, Train: 43.30%, Valid: 43.17%, Test: 43.34%
Epoch: 725, Loss: 1.3131, Train: 43.65%, Valid: 43.47%, Test: 43.73%
Epoch: 750, Loss: 1.2951, Train: 44.02%, Valid: 43.71%, Test: 43.78%
Epoch: 775, Loss: 1.3080, Train: 44.22%, Valid: 44.05%, Test: 43.98%
Epoch: 800, Loss: 1.2922, Train: 44.32%, Valid: 43.93%, Test: 44.14%
Epoch: 825, Loss: 1.2995, Train: 44.18%, Valid: 44.02%, Test: 44.07%
Epoch: 850, Loss: 1.3500, Train: 41.59%, Valid: 40.96%, Test: 41.23%
Epoch: 875, Loss: 1.3303, Train: 42.43%, Valid: 42.17%, Test: 42.38%
Epoch: 900, Loss: 1.3008, Train: 43.93%, Valid: 43.72%, Test: 43.89%
Epoch: 925, Loss: 1.3294, Train: 42.75%, Valid: 42.33%, Test: 42.41%
Epoch: 950, Loss: 1.2985, Train: 43.97%, Valid: 43.78%, Test: 43.68%
Epoch: 975, Loss: 1.2958, Train: 43.68%, Valid: 43.47%, Test: 43.66%
Run 01:
Highest Train: 44.52
Highest Valid: 44.39
  Final Train: 44.52
   Final Test: 44.34
All runs:
Highest Train: 44.52 ± nan
Highest Valid: 44.39 ± nan
  Final Train: 44.52 ± nan
   Final Test: 44.34 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6083, Train: 28.73%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4885, Train: 35.04%, Valid: 34.58%, Test: 35.05%
Epoch: 50, Loss: 1.4703, Train: 35.95%, Valid: 35.20%, Test: 35.63%
Epoch: 75, Loss: 1.4523, Train: 36.88%, Valid: 36.02%, Test: 36.38%
Epoch: 100, Loss: 1.4378, Train: 38.14%, Valid: 36.76%, Test: 37.05%
Epoch: 125, Loss: 1.4183, Train: 38.48%, Valid: 36.92%, Test: 37.40%
Epoch: 150, Loss: 1.3856, Train: 40.29%, Valid: 38.11%, Test: 38.74%
Epoch: 175, Loss: 1.3668, Train: 41.25%, Valid: 38.85%, Test: 39.30%
Epoch: 200, Loss: 1.3923, Train: 39.92%, Valid: 38.72%, Test: 39.19%
Epoch: 225, Loss: 1.3563, Train: 41.67%, Valid: 39.60%, Test: 39.85%
Epoch: 250, Loss: 1.3437, Train: 42.03%, Valid: 39.65%, Test: 40.09%
Epoch: 275, Loss: 1.3248, Train: 43.80%, Valid: 40.57%, Test: 41.09%
Epoch: 300, Loss: 1.3074, Train: 44.27%, Valid: 41.19%, Test: 41.53%
Epoch: 325, Loss: 1.2901, Train: 45.58%, Valid: 41.77%, Test: 42.30%
Epoch: 350, Loss: 1.2767, Train: 45.75%, Valid: 41.52%, Test: 42.20%
Epoch: 375, Loss: 1.2623, Train: 46.22%, Valid: 41.75%, Test: 42.44%
Epoch: 400, Loss: 1.2478, Train: 46.87%, Valid: 41.94%, Test: 42.64%
Epoch: 425, Loss: 1.2272, Train: 48.14%, Valid: 42.39%, Test: 42.90%
Epoch: 450, Loss: 1.2256, Train: 47.81%, Valid: 41.76%, Test: 42.69%
Epoch: 475, Loss: 1.3841, Train: 39.12%, Valid: 35.88%, Test: 35.79%
Epoch: 500, Loss: 1.2328, Train: 48.04%, Valid: 43.38%, Test: 43.65%
Epoch: 525, Loss: 1.2542, Train: 47.39%, Valid: 41.95%, Test: 42.52%
Epoch: 550, Loss: 1.1868, Train: 49.96%, Valid: 43.97%, Test: 44.46%
Epoch: 575, Loss: 1.1854, Train: 49.48%, Valid: 43.46%, Test: 43.86%
Epoch: 600, Loss: 1.1861, Train: 50.11%, Valid: 43.51%, Test: 43.79%
Epoch: 625, Loss: 1.1656, Train: 50.44%, Valid: 43.98%, Test: 44.21%
Epoch: 650, Loss: 1.1934, Train: 49.91%, Valid: 43.32%, Test: 43.82%
Epoch: 675, Loss: 1.1539, Train: 51.18%, Valid: 44.40%, Test: 44.64%
Epoch: 700, Loss: 1.1904, Train: 49.84%, Valid: 43.24%, Test: 43.64%
Epoch: 725, Loss: 1.1657, Train: 50.87%, Valid: 43.68%, Test: 43.94%
Epoch: 750, Loss: 1.1305, Train: 52.37%, Valid: 45.00%, Test: 45.37%
Epoch: 775, Loss: 1.1346, Train: 52.15%, Valid: 43.90%, Test: 44.35%
Epoch: 800, Loss: 1.1215, Train: 52.73%, Valid: 44.79%, Test: 45.20%
Epoch: 825, Loss: 1.1123, Train: 53.11%, Valid: 44.52%, Test: 44.81%
Epoch: 850, Loss: 1.1061, Train: 53.65%, Valid: 44.81%, Test: 45.12%
Epoch: 875, Loss: 1.1262, Train: 51.16%, Valid: 43.37%, Test: 43.24%
Epoch: 900, Loss: 1.1002, Train: 53.71%, Valid: 44.87%, Test: 44.80%
Epoch: 925, Loss: 1.1074, Train: 53.39%, Valid: 45.14%, Test: 45.17%
Epoch: 950, Loss: 1.1280, Train: 52.93%, Valid: 44.54%, Test: 44.84%
Epoch: 975, Loss: 1.0986, Train: 53.59%, Valid: 44.38%, Test: 44.50%
Run 01:
Highest Train: 54.47
Highest Valid: 45.66
  Final Train: 54.38
   Final Test: 45.75
All runs:
Highest Train: 54.47 ± nan
Highest Valid: 45.66 ± nan
  Final Train: 54.38 ± nan
   Final Test: 45.75 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6113, Train: 28.14%, Valid: 27.99%, Test: 28.20%
Epoch: 25, Loss: 1.4848, Train: 35.05%, Valid: 34.66%, Test: 35.13%
Epoch: 50, Loss: 1.4571, Train: 35.91%, Valid: 35.54%, Test: 35.88%
Epoch: 75, Loss: 1.4196, Train: 38.16%, Valid: 37.59%, Test: 37.72%
Epoch: 100, Loss: 1.3817, Train: 40.95%, Valid: 40.13%, Test: 40.44%
Epoch: 125, Loss: 1.3420, Train: 42.32%, Valid: 41.66%, Test: 41.75%
Epoch: 150, Loss: 1.3110, Train: 43.48%, Valid: 42.66%, Test: 42.50%
Epoch: 175, Loss: 1.3154, Train: 43.91%, Valid: 42.92%, Test: 42.96%
Epoch: 200, Loss: 1.2708, Train: 45.23%, Valid: 44.19%, Test: 44.45%
Epoch: 225, Loss: 1.2419, Train: 46.52%, Valid: 45.29%, Test: 45.45%
Epoch: 250, Loss: 1.2364, Train: 46.48%, Valid: 45.43%, Test: 45.32%
Epoch: 275, Loss: 1.3262, Train: 43.14%, Valid: 41.88%, Test: 42.20%
Epoch: 300, Loss: 1.2277, Train: 46.97%, Valid: 45.74%, Test: 45.70%
Epoch: 325, Loss: 1.2206, Train: 47.47%, Valid: 46.04%, Test: 46.03%
Epoch: 350, Loss: 1.2282, Train: 47.49%, Valid: 46.15%, Test: 45.88%
Epoch: 375, Loss: 1.2012, Train: 48.71%, Valid: 47.11%, Test: 46.95%
Epoch: 400, Loss: 1.1939, Train: 48.89%, Valid: 46.87%, Test: 46.84%
Epoch: 425, Loss: 1.1895, Train: 48.99%, Valid: 47.01%, Test: 46.88%
Epoch: 450, Loss: 1.1685, Train: 49.66%, Valid: 47.43%, Test: 47.53%
Epoch: 475, Loss: 1.2061, Train: 49.28%, Valid: 46.87%, Test: 46.86%
Epoch: 500, Loss: 1.1526, Train: 50.50%, Valid: 48.07%, Test: 48.19%
Epoch: 525, Loss: 1.1506, Train: 50.47%, Valid: 48.02%, Test: 47.95%
Epoch: 550, Loss: 1.1458, Train: 50.75%, Valid: 48.20%, Test: 48.25%
Epoch: 575, Loss: 1.1424, Train: 50.73%, Valid: 47.92%, Test: 48.03%
Epoch: 600, Loss: 1.2254, Train: 49.60%, Valid: 47.09%, Test: 47.11%
Epoch: 625, Loss: 1.1407, Train: 50.97%, Valid: 48.35%, Test: 48.49%
Epoch: 650, Loss: 1.1374, Train: 51.28%, Valid: 48.36%, Test: 48.53%
Epoch: 675, Loss: 1.1427, Train: 51.08%, Valid: 48.14%, Test: 48.31%
Epoch: 700, Loss: 1.1743, Train: 50.45%, Valid: 47.79%, Test: 47.92%
Epoch: 725, Loss: 1.1266, Train: 51.56%, Valid: 48.59%, Test: 48.50%
Epoch: 750, Loss: 1.1215, Train: 52.14%, Valid: 48.75%, Test: 49.09%
Epoch: 775, Loss: 1.1157, Train: 51.98%, Valid: 48.69%, Test: 48.98%
Epoch: 800, Loss: 1.1280, Train: 51.45%, Valid: 48.22%, Test: 48.52%
Epoch: 825, Loss: 1.1148, Train: 52.36%, Valid: 48.93%, Test: 49.36%
Epoch: 850, Loss: 1.1349, Train: 52.03%, Valid: 48.42%, Test: 48.82%
Epoch: 875, Loss: 1.0977, Train: 52.84%, Valid: 49.06%, Test: 49.46%
Epoch: 900, Loss: 1.1158, Train: 52.15%, Valid: 48.81%, Test: 48.87%
Epoch: 925, Loss: 1.0961, Train: 52.63%, Valid: 48.77%, Test: 49.10%
Epoch: 950, Loss: 1.1047, Train: 52.95%, Valid: 48.74%, Test: 49.28%
Epoch: 975, Loss: 1.1058, Train: 53.04%, Valid: 48.73%, Test: 49.35%
Run 01:
Highest Train: 53.26
Highest Valid: 49.36
  Final Train: 52.94
   Final Test: 49.35
All runs:
Highest Train: 53.26 ± nan
Highest Valid: 49.36 ± nan
  Final Train: 52.94 ± nan
   Final Test: 49.35 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6218, Train: 26.11%, Valid: 26.00%, Test: 26.48%
Epoch: 25, Loss: 1.4810, Train: 35.46%, Valid: 35.20%, Test: 35.84%
Epoch: 50, Loss: 1.4421, Train: 36.84%, Valid: 36.43%, Test: 36.98%
Epoch: 75, Loss: 1.4231, Train: 38.31%, Valid: 38.01%, Test: 38.55%
Epoch: 100, Loss: 1.3916, Train: 39.29%, Valid: 39.01%, Test: 39.49%
Epoch: 125, Loss: 1.3644, Train: 40.26%, Valid: 40.09%, Test: 40.59%
Epoch: 150, Loss: 1.3616, Train: 42.11%, Valid: 41.73%, Test: 41.98%
Epoch: 175, Loss: 1.3136, Train: 43.65%, Valid: 43.19%, Test: 43.39%
Epoch: 200, Loss: 1.3037, Train: 42.81%, Valid: 42.53%, Test: 42.80%
Epoch: 225, Loss: 1.3208, Train: 44.74%, Valid: 44.25%, Test: 44.54%
Epoch: 250, Loss: 1.3306, Train: 40.98%, Valid: 40.57%, Test: 40.89%
Epoch: 275, Loss: 1.2864, Train: 44.84%, Valid: 44.52%, Test: 44.42%
Epoch: 300, Loss: 1.2798, Train: 45.29%, Valid: 44.97%, Test: 44.79%
Epoch: 325, Loss: 1.2659, Train: 43.90%, Valid: 43.78%, Test: 43.68%
Epoch: 350, Loss: 1.2560, Train: 46.09%, Valid: 45.68%, Test: 45.63%
Epoch: 375, Loss: 1.2344, Train: 46.99%, Valid: 46.42%, Test: 46.47%
Epoch: 400, Loss: 1.2406, Train: 46.68%, Valid: 46.34%, Test: 46.12%
Epoch: 425, Loss: 1.2550, Train: 46.95%, Valid: 46.41%, Test: 46.33%
Epoch: 450, Loss: 1.2236, Train: 47.45%, Valid: 46.89%, Test: 46.66%
Epoch: 475, Loss: 1.2202, Train: 47.68%, Valid: 47.01%, Test: 46.84%
Epoch: 500, Loss: 1.2144, Train: 47.78%, Valid: 46.92%, Test: 46.94%
Epoch: 525, Loss: 1.2165, Train: 47.74%, Valid: 47.15%, Test: 46.89%
Epoch: 550, Loss: 1.2153, Train: 48.10%, Valid: 47.30%, Test: 47.22%
Epoch: 575, Loss: 1.2513, Train: 47.67%, Valid: 46.83%, Test: 46.81%
Epoch: 600, Loss: 1.2035, Train: 48.27%, Valid: 47.42%, Test: 47.40%
Epoch: 625, Loss: 1.2006, Train: 48.40%, Valid: 47.51%, Test: 47.37%
Epoch: 650, Loss: 1.2200, Train: 48.35%, Valid: 47.39%, Test: 47.44%
Epoch: 675, Loss: 1.1913, Train: 48.87%, Valid: 47.80%, Test: 47.80%
Epoch: 700, Loss: 1.1909, Train: 48.78%, Valid: 47.81%, Test: 47.75%
Epoch: 725, Loss: 1.1797, Train: 49.25%, Valid: 48.14%, Test: 48.17%
Epoch: 750, Loss: 1.2582, Train: 46.10%, Valid: 45.35%, Test: 45.56%
Epoch: 775, Loss: 1.2156, Train: 47.64%, Valid: 47.08%, Test: 46.76%
Epoch: 800, Loss: 1.1968, Train: 48.54%, Valid: 47.68%, Test: 47.52%
Epoch: 825, Loss: 1.2359, Train: 47.48%, Valid: 46.71%, Test: 46.53%
Epoch: 850, Loss: 1.1924, Train: 48.73%, Valid: 47.77%, Test: 47.78%
Epoch: 875, Loss: 1.1972, Train: 48.86%, Valid: 47.96%, Test: 47.87%
Epoch: 900, Loss: 1.1871, Train: 45.92%, Valid: 44.76%, Test: 44.86%
Epoch: 925, Loss: 1.1875, Train: 49.01%, Valid: 47.96%, Test: 47.90%
Epoch: 950, Loss: 1.1926, Train: 49.37%, Valid: 48.12%, Test: 48.33%
Epoch: 975, Loss: 1.1798, Train: 49.54%, Valid: 48.44%, Test: 48.46%
Run 01:
Highest Train: 49.60
Highest Valid: 48.44
  Final Train: 49.54
   Final Test: 48.46
All runs:
Highest Train: 49.60 ± nan
Highest Valid: 48.44 ± nan
  Final Train: 49.54 ± nan
   Final Test: 48.46 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6091, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4840, Train: 35.22%, Valid: 34.67%, Test: 35.12%
Epoch: 50, Loss: 1.4639, Train: 36.28%, Valid: 35.57%, Test: 35.81%
Epoch: 75, Loss: 1.4405, Train: 37.82%, Valid: 36.70%, Test: 36.86%
Epoch: 100, Loss: 1.4091, Train: 39.18%, Valid: 37.84%, Test: 38.10%
Epoch: 125, Loss: 1.3876, Train: 40.69%, Valid: 38.88%, Test: 39.16%
Epoch: 150, Loss: 1.3759, Train: 40.83%, Valid: 38.73%, Test: 39.02%
Epoch: 175, Loss: 1.3353, Train: 43.16%, Valid: 40.43%, Test: 40.85%
Epoch: 200, Loss: 1.3416, Train: 42.87%, Valid: 40.21%, Test: 40.45%
Epoch: 225, Loss: 1.3139, Train: 44.22%, Valid: 41.16%, Test: 41.33%
Epoch: 250, Loss: 1.3412, Train: 43.06%, Valid: 39.74%, Test: 39.97%
Epoch: 275, Loss: 1.3000, Train: 44.76%, Valid: 41.84%, Test: 41.99%
Epoch: 300, Loss: 1.2851, Train: 45.17%, Valid: 41.94%, Test: 42.47%
Epoch: 325, Loss: 1.2707, Train: 45.26%, Valid: 41.26%, Test: 41.71%
Epoch: 350, Loss: 1.2935, Train: 45.28%, Valid: 42.34%, Test: 42.26%
Epoch: 375, Loss: 1.2548, Train: 46.96%, Valid: 42.74%, Test: 43.21%
Epoch: 400, Loss: 1.2493, Train: 47.01%, Valid: 42.44%, Test: 43.08%
Epoch: 425, Loss: 1.2790, Train: 45.01%, Valid: 40.94%, Test: 41.42%
Epoch: 450, Loss: 1.2225, Train: 48.47%, Valid: 43.61%, Test: 44.29%
Epoch: 475, Loss: 1.2104, Train: 48.95%, Valid: 43.29%, Test: 43.88%
Epoch: 500, Loss: 1.1976, Train: 49.33%, Valid: 43.63%, Test: 44.34%
Epoch: 525, Loss: 1.2392, Train: 47.83%, Valid: 42.53%, Test: 43.27%
Epoch: 550, Loss: 1.1842, Train: 49.77%, Valid: 43.46%, Test: 43.88%
Epoch: 575, Loss: 1.1848, Train: 49.90%, Valid: 43.32%, Test: 44.02%
Epoch: 600, Loss: 1.1644, Train: 50.83%, Valid: 44.11%, Test: 44.76%
Epoch: 625, Loss: 1.1698, Train: 50.82%, Valid: 44.56%, Test: 44.75%
Epoch: 650, Loss: 1.1602, Train: 51.57%, Valid: 43.97%, Test: 44.65%
Epoch: 675, Loss: 1.1610, Train: 51.57%, Valid: 44.25%, Test: 44.78%
Epoch: 700, Loss: 1.1514, Train: 51.10%, Valid: 43.60%, Test: 44.04%
Epoch: 725, Loss: 1.1292, Train: 52.45%, Valid: 44.55%, Test: 45.13%
Epoch: 750, Loss: 1.1765, Train: 50.97%, Valid: 44.32%, Test: 44.59%
Epoch: 775, Loss: 1.1249, Train: 52.68%, Valid: 44.81%, Test: 45.39%
Epoch: 800, Loss: 1.1356, Train: 52.51%, Valid: 45.08%, Test: 45.39%
Epoch: 825, Loss: 1.1337, Train: 52.37%, Valid: 44.71%, Test: 45.22%
Epoch: 850, Loss: 1.1139, Train: 53.29%, Valid: 44.99%, Test: 45.21%
Epoch: 875, Loss: 1.1053, Train: 53.02%, Valid: 44.84%, Test: 45.30%
Epoch: 900, Loss: 1.1076, Train: 53.59%, Valid: 45.23%, Test: 45.65%
Epoch: 925, Loss: 1.1509, Train: 52.10%, Valid: 44.28%, Test: 45.02%
Epoch: 950, Loss: 1.0943, Train: 54.10%, Valid: 44.91%, Test: 45.40%
Epoch: 975, Loss: 1.0975, Train: 53.31%, Valid: 44.24%, Test: 44.65%
Run 01:
Highest Train: 54.58
Highest Valid: 45.32
  Final Train: 53.82
   Final Test: 45.73
All runs:
Highest Train: 54.58 ± nan
Highest Valid: 45.32 ± nan
  Final Train: 53.82 ± nan
   Final Test: 45.73 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6368, Train: 23.88%, Valid: 23.93%, Test: 24.45%
Epoch: 25, Loss: 1.4767, Train: 35.25%, Valid: 34.83%, Test: 35.38%
Epoch: 50, Loss: 1.4267, Train: 37.36%, Valid: 36.69%, Test: 37.06%
Epoch: 75, Loss: 1.3884, Train: 39.67%, Valid: 38.87%, Test: 39.27%
Epoch: 100, Loss: 1.3572, Train: 41.21%, Valid: 40.42%, Test: 40.66%
Epoch: 125, Loss: 1.3266, Train: 41.81%, Valid: 40.72%, Test: 41.06%
Epoch: 150, Loss: 1.3114, Train: 43.82%, Valid: 42.65%, Test: 43.23%
Epoch: 175, Loss: 1.2740, Train: 44.98%, Valid: 43.73%, Test: 44.34%
Epoch: 200, Loss: 1.2440, Train: 45.95%, Valid: 44.62%, Test: 44.88%
Epoch: 225, Loss: 1.2280, Train: 46.67%, Valid: 44.97%, Test: 45.39%
Epoch: 250, Loss: 1.2199, Train: 47.27%, Valid: 45.57%, Test: 45.82%
Epoch: 275, Loss: 1.2109, Train: 48.12%, Valid: 46.09%, Test: 46.25%
Epoch: 300, Loss: 1.2267, Train: 47.55%, Valid: 45.91%, Test: 46.08%
Epoch: 325, Loss: 1.1763, Train: 49.09%, Valid: 46.86%, Test: 47.19%
Epoch: 350, Loss: 1.1771, Train: 49.24%, Valid: 47.20%, Test: 46.97%
Epoch: 375, Loss: 1.1576, Train: 49.97%, Valid: 47.54%, Test: 47.60%
Epoch: 400, Loss: 1.1523, Train: 49.74%, Valid: 47.39%, Test: 47.44%
Epoch: 425, Loss: 1.1488, Train: 50.61%, Valid: 47.91%, Test: 47.76%
Epoch: 450, Loss: 1.1441, Train: 50.58%, Valid: 47.98%, Test: 47.66%
Epoch: 475, Loss: 1.1416, Train: 51.11%, Valid: 48.21%, Test: 48.32%
Epoch: 500, Loss: 1.1489, Train: 50.97%, Valid: 48.00%, Test: 47.99%
Epoch: 525, Loss: 1.1188, Train: 51.86%, Valid: 48.81%, Test: 48.59%
Epoch: 550, Loss: 1.1323, Train: 51.52%, Valid: 48.54%, Test: 48.32%
Epoch: 575, Loss: 1.1077, Train: 52.45%, Valid: 49.09%, Test: 48.93%
Epoch: 600, Loss: 1.1259, Train: 51.80%, Valid: 48.48%, Test: 48.50%
Epoch: 625, Loss: 1.1024, Train: 52.49%, Valid: 48.93%, Test: 48.89%
Epoch: 650, Loss: 1.1098, Train: 52.57%, Valid: 49.10%, Test: 48.88%
Epoch: 675, Loss: 1.1340, Train: 50.92%, Valid: 47.37%, Test: 47.06%
Epoch: 700, Loss: 1.0961, Train: 53.02%, Valid: 49.10%, Test: 49.07%
Epoch: 725, Loss: 1.0862, Train: 53.05%, Valid: 48.99%, Test: 48.87%
Epoch: 750, Loss: 1.0918, Train: 53.44%, Valid: 49.39%, Test: 49.39%
Epoch: 775, Loss: 1.0830, Train: 53.70%, Valid: 49.45%, Test: 49.30%
Epoch: 800, Loss: 1.1324, Train: 51.90%, Valid: 48.24%, Test: 48.34%
Epoch: 825, Loss: 1.0847, Train: 53.37%, Valid: 49.26%, Test: 49.30%
Epoch: 850, Loss: 1.1018, Train: 53.08%, Valid: 49.08%, Test: 49.01%
Epoch: 875, Loss: 1.0713, Train: 54.06%, Valid: 49.53%, Test: 49.55%
Epoch: 900, Loss: 1.0973, Train: 53.18%, Valid: 48.84%, Test: 48.90%
Epoch: 925, Loss: 1.0651, Train: 54.37%, Valid: 49.51%, Test: 49.48%
Epoch: 950, Loss: 1.0816, Train: 53.99%, Valid: 49.53%, Test: 49.48%
Epoch: 975, Loss: 1.0679, Train: 54.01%, Valid: 49.46%, Test: 49.37%
Run 01:
Highest Train: 54.61
Highest Valid: 49.87
  Final Train: 54.46
   Final Test: 49.77
All runs:
Highest Train: 54.61 ± nan
Highest Valid: 49.87 ± nan
  Final Train: 54.46 ± nan
   Final Test: 49.77 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.5862, Train: 18.55%, Valid: 18.58%, Test: 18.20%
Epoch: 25, Loss: 1.4560, Train: 34.78%, Valid: 34.27%, Test: 35.10%
Epoch: 50, Loss: 1.4239, Train: 37.34%, Valid: 36.84%, Test: 37.43%
Epoch: 75, Loss: 1.4395, Train: 38.16%, Valid: 37.89%, Test: 38.27%
Epoch: 100, Loss: 1.4192, Train: 38.47%, Valid: 38.19%, Test: 38.45%
Epoch: 125, Loss: 1.3880, Train: 39.94%, Valid: 39.74%, Test: 40.33%
Epoch: 150, Loss: 1.3801, Train: 39.31%, Valid: 39.14%, Test: 39.51%
Epoch: 175, Loss: 1.3644, Train: 41.36%, Valid: 40.90%, Test: 41.14%
Epoch: 200, Loss: 1.4008, Train: 37.50%, Valid: 37.05%, Test: 37.45%
Epoch: 225, Loss: 1.3560, Train: 41.12%, Valid: 40.82%, Test: 41.09%
Epoch: 250, Loss: 1.3775, Train: 41.05%, Valid: 40.42%, Test: 40.96%
Epoch: 275, Loss: 1.3461, Train: 41.29%, Valid: 40.86%, Test: 40.93%
Epoch: 300, Loss: 1.3394, Train: 41.85%, Valid: 41.32%, Test: 41.83%
Epoch: 325, Loss: 1.3127, Train: 42.75%, Valid: 42.23%, Test: 42.71%
Epoch: 350, Loss: 1.3063, Train: 43.55%, Valid: 42.90%, Test: 43.40%
Epoch: 375, Loss: 1.2945, Train: 44.00%, Valid: 43.20%, Test: 43.69%
Epoch: 400, Loss: 1.3073, Train: 43.97%, Valid: 43.15%, Test: 43.79%
Epoch: 425, Loss: 1.4029, Train: 43.37%, Valid: 42.91%, Test: 43.15%
Epoch: 450, Loss: 1.3026, Train: 43.87%, Valid: 43.14%, Test: 43.61%
Epoch: 475, Loss: 1.2795, Train: 44.37%, Valid: 43.75%, Test: 44.12%
Epoch: 500, Loss: 1.2996, Train: 43.95%, Valid: 43.21%, Test: 43.74%
Epoch: 525, Loss: 1.2740, Train: 44.69%, Valid: 43.91%, Test: 44.28%
Epoch: 550, Loss: 1.3240, Train: 41.24%, Valid: 40.59%, Test: 41.25%
Epoch: 575, Loss: 1.2897, Train: 44.47%, Valid: 43.81%, Test: 44.35%
Epoch: 600, Loss: 1.2816, Train: 44.76%, Valid: 43.92%, Test: 44.67%
Epoch: 625, Loss: 1.2561, Train: 45.60%, Valid: 44.81%, Test: 45.23%
Epoch: 650, Loss: 1.2751, Train: 45.04%, Valid: 44.22%, Test: 44.83%
Epoch: 675, Loss: 1.2487, Train: 45.46%, Valid: 44.61%, Test: 45.08%
Epoch: 700, Loss: 1.2498, Train: 46.02%, Valid: 45.20%, Test: 45.57%
Epoch: 725, Loss: 1.2969, Train: 34.03%, Valid: 33.61%, Test: 33.82%
Epoch: 750, Loss: 1.2921, Train: 44.12%, Valid: 43.36%, Test: 43.71%
Epoch: 775, Loss: 1.2612, Train: 45.18%, Valid: 44.39%, Test: 44.63%
Epoch: 800, Loss: 1.2559, Train: 45.72%, Valid: 44.80%, Test: 45.06%
Epoch: 825, Loss: 1.2475, Train: 45.73%, Valid: 44.92%, Test: 45.36%
Epoch: 850, Loss: 1.2355, Train: 46.39%, Valid: 45.31%, Test: 45.72%
Epoch: 875, Loss: 1.2942, Train: 44.06%, Valid: 43.23%, Test: 43.93%
Epoch: 900, Loss: 1.2529, Train: 45.75%, Valid: 44.89%, Test: 45.35%
Epoch: 925, Loss: 1.2342, Train: 46.26%, Valid: 45.33%, Test: 45.81%
Epoch: 950, Loss: 1.2376, Train: 46.15%, Valid: 45.16%, Test: 45.68%
Epoch: 975, Loss: 1.2502, Train: 46.34%, Valid: 45.31%, Test: 45.90%
Run 01:
Highest Train: 46.88
Highest Valid: 45.85
  Final Train: 46.77
   Final Test: 46.35
All runs:
Highest Train: 46.88 ± nan
Highest Valid: 45.85 ± nan
  Final Train: 46.77 ± nan
   Final Test: 46.35 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6072, Train: 28.34%, Valid: 27.93%, Test: 28.44%
Epoch: 25, Loss: 1.4998, Train: 34.51%, Valid: 34.43%, Test: 34.78%
Epoch: 50, Loss: 1.4558, Train: 37.03%, Valid: 36.71%, Test: 36.72%
Epoch: 75, Loss: 1.4308, Train: 38.37%, Valid: 37.84%, Test: 38.18%
Epoch: 100, Loss: 1.4043, Train: 39.91%, Valid: 39.25%, Test: 39.45%
Epoch: 125, Loss: 1.3847, Train: 40.86%, Valid: 40.20%, Test: 40.28%
Epoch: 150, Loss: 1.3403, Train: 43.17%, Valid: 42.33%, Test: 42.27%
Epoch: 175, Loss: 1.3097, Train: 44.74%, Valid: 43.10%, Test: 43.32%
Epoch: 200, Loss: 1.2892, Train: 45.26%, Valid: 43.65%, Test: 43.71%
Epoch: 225, Loss: 1.3062, Train: 44.50%, Valid: 42.75%, Test: 43.05%
Epoch: 250, Loss: 1.2723, Train: 45.16%, Valid: 43.40%, Test: 43.39%
Epoch: 275, Loss: 1.2484, Train: 47.72%, Valid: 45.01%, Test: 45.17%
Epoch: 300, Loss: 1.2230, Train: 48.14%, Valid: 45.28%, Test: 45.34%
Epoch: 325, Loss: 1.2281, Train: 47.91%, Valid: 45.23%, Test: 45.03%
Epoch: 350, Loss: 1.2194, Train: 48.26%, Valid: 45.09%, Test: 45.05%
Epoch: 375, Loss: 1.1928, Train: 49.10%, Valid: 45.74%, Test: 45.37%
Epoch: 400, Loss: 1.1874, Train: 49.77%, Valid: 46.03%, Test: 46.04%
Epoch: 425, Loss: 1.1876, Train: 49.86%, Valid: 45.78%, Test: 45.86%
Epoch: 450, Loss: 1.1617, Train: 50.38%, Valid: 45.98%, Test: 46.07%
Epoch: 475, Loss: 1.1556, Train: 51.31%, Valid: 46.34%, Test: 46.31%
Epoch: 500, Loss: 1.1497, Train: 51.30%, Valid: 46.47%, Test: 46.38%
Epoch: 525, Loss: 1.1729, Train: 50.22%, Valid: 45.11%, Test: 45.25%
Epoch: 550, Loss: 1.1261, Train: 52.38%, Valid: 46.89%, Test: 46.75%
Epoch: 575, Loss: 1.1253, Train: 52.14%, Valid: 46.38%, Test: 46.57%
Epoch: 600, Loss: 1.1417, Train: 51.97%, Valid: 46.35%, Test: 46.47%
Epoch: 625, Loss: 1.1273, Train: 52.49%, Valid: 46.75%, Test: 46.96%
Epoch: 650, Loss: 1.1061, Train: 53.28%, Valid: 46.93%, Test: 47.08%
Epoch: 675, Loss: 1.1303, Train: 52.67%, Valid: 46.23%, Test: 46.30%
Epoch: 700, Loss: 1.0860, Train: 53.85%, Valid: 47.00%, Test: 47.19%
Epoch: 725, Loss: 1.1174, Train: 53.32%, Valid: 46.95%, Test: 46.97%
Epoch: 750, Loss: 1.1184, Train: 52.90%, Valid: 46.01%, Test: 46.13%
Epoch: 775, Loss: 1.0770, Train: 54.14%, Valid: 46.78%, Test: 46.93%
Epoch: 800, Loss: 1.0799, Train: 54.46%, Valid: 47.10%, Test: 47.28%
Epoch: 825, Loss: 1.0773, Train: 54.09%, Valid: 46.70%, Test: 47.10%
Epoch: 850, Loss: 1.1088, Train: 52.53%, Valid: 45.08%, Test: 45.30%
Epoch: 875, Loss: 1.0645, Train: 54.57%, Valid: 47.14%, Test: 47.21%
Epoch: 900, Loss: 1.0831, Train: 54.46%, Valid: 47.10%, Test: 47.26%
Epoch: 925, Loss: 1.0623, Train: 55.10%, Valid: 47.10%, Test: 47.16%
Epoch: 950, Loss: 1.0951, Train: 54.25%, Valid: 46.48%, Test: 46.49%
Epoch: 975, Loss: 1.0470, Train: 55.43%, Valid: 47.06%, Test: 47.30%
Run 01:
Highest Train: 55.43
Highest Valid: 47.30
  Final Train: 54.76
   Final Test: 47.28
All runs:
Highest Train: 55.43 ± nan
Highest Valid: 47.30 ± nan
  Final Train: 54.76 ± nan
   Final Test: 47.28 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6208, Train: 26.87%, Valid: 26.50%, Test: 26.83%
Epoch: 25, Loss: 1.4552, Train: 33.06%, Valid: 32.66%, Test: 33.67%
Epoch: 50, Loss: 1.4703, Train: 33.34%, Valid: 32.98%, Test: 33.58%
Epoch: 75, Loss: 1.4177, Train: 35.75%, Valid: 35.39%, Test: 35.94%
Epoch: 100, Loss: 1.4014, Train: 39.55%, Valid: 39.08%, Test: 39.57%
Epoch: 125, Loss: 1.3793, Train: 40.80%, Valid: 40.29%, Test: 40.59%
Epoch: 150, Loss: 1.3643, Train: 41.64%, Valid: 41.11%, Test: 41.55%
Epoch: 175, Loss: 1.3967, Train: 39.87%, Valid: 39.51%, Test: 39.87%
Epoch: 200, Loss: 1.3363, Train: 43.09%, Valid: 42.63%, Test: 42.80%
Epoch: 225, Loss: 1.3358, Train: 43.32%, Valid: 43.08%, Test: 43.16%
Epoch: 250, Loss: 1.3045, Train: 44.49%, Valid: 43.91%, Test: 44.24%
Epoch: 275, Loss: 1.2955, Train: 44.99%, Valid: 44.33%, Test: 44.95%
Epoch: 300, Loss: 1.2949, Train: 45.21%, Valid: 44.59%, Test: 44.97%
Epoch: 325, Loss: 1.2836, Train: 45.83%, Valid: 44.99%, Test: 45.69%
Epoch: 350, Loss: 1.3332, Train: 42.02%, Valid: 41.26%, Test: 41.93%
Epoch: 375, Loss: 1.2739, Train: 46.07%, Valid: 45.33%, Test: 45.72%
Epoch: 400, Loss: 1.2574, Train: 46.50%, Valid: 45.62%, Test: 46.09%
Epoch: 425, Loss: 1.2467, Train: 47.29%, Valid: 46.36%, Test: 46.80%
Epoch: 450, Loss: 1.2314, Train: 47.73%, Valid: 46.90%, Test: 47.38%
Epoch: 475, Loss: 1.2481, Train: 47.47%, Valid: 46.52%, Test: 46.91%
Epoch: 500, Loss: 1.2471, Train: 47.29%, Valid: 46.29%, Test: 46.93%
Epoch: 525, Loss: 1.2248, Train: 47.88%, Valid: 46.90%, Test: 47.29%
Epoch: 550, Loss: 1.2086, Train: 48.74%, Valid: 47.51%, Test: 48.11%
Epoch: 575, Loss: 1.2151, Train: 48.54%, Valid: 47.31%, Test: 47.97%
Epoch: 600, Loss: 1.2278, Train: 47.93%, Valid: 46.58%, Test: 47.05%
Epoch: 625, Loss: 1.1980, Train: 49.07%, Valid: 47.56%, Test: 48.22%
Epoch: 650, Loss: 1.1921, Train: 49.39%, Valid: 47.89%, Test: 48.42%
Epoch: 675, Loss: 1.1936, Train: 49.43%, Valid: 47.78%, Test: 48.64%
Epoch: 700, Loss: 1.1867, Train: 49.37%, Valid: 47.86%, Test: 48.52%
Epoch: 725, Loss: 1.1825, Train: 49.44%, Valid: 47.61%, Test: 48.32%
Epoch: 750, Loss: 1.1868, Train: 49.70%, Valid: 48.32%, Test: 48.77%
Epoch: 775, Loss: 1.2008, Train: 49.24%, Valid: 47.57%, Test: 48.19%
Epoch: 800, Loss: 1.1748, Train: 49.99%, Valid: 48.41%, Test: 48.84%
Epoch: 825, Loss: 1.2477, Train: 46.73%, Valid: 45.26%, Test: 45.72%
Epoch: 850, Loss: 1.1923, Train: 49.37%, Valid: 47.92%, Test: 48.27%
Epoch: 875, Loss: 1.1717, Train: 49.03%, Valid: 47.31%, Test: 47.85%
Epoch: 900, Loss: 1.1742, Train: 50.09%, Valid: 48.39%, Test: 48.76%
Epoch: 925, Loss: 1.2083, Train: 48.35%, Valid: 46.59%, Test: 47.11%
Epoch: 950, Loss: 1.1532, Train: 50.70%, Valid: 48.71%, Test: 49.23%
Epoch: 975, Loss: 1.1699, Train: 50.17%, Valid: 48.39%, Test: 48.92%
Run 01:
Highest Train: 51.14
Highest Valid: 48.97
  Final Train: 50.99
   Final Test: 49.38
All runs:
Highest Train: 51.14 ± nan
Highest Valid: 48.97 ± nan
  Final Train: 50.99 ± nan
   Final Test: 49.38 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.7114, Train: 30.35%, Valid: 30.11%, Test: 30.19%
Epoch: 25, Loss: 1.4650, Train: 31.18%, Valid: 30.75%, Test: 31.62%
Epoch: 50, Loss: 1.4369, Train: 32.47%, Valid: 32.19%, Test: 33.04%
Epoch: 75, Loss: 1.4336, Train: 32.96%, Valid: 32.59%, Test: 33.72%
Epoch: 100, Loss: 1.4090, Train: 33.81%, Valid: 33.50%, Test: 34.41%
Epoch: 125, Loss: 1.4304, Train: 34.14%, Valid: 33.85%, Test: 34.83%
Epoch: 150, Loss: 1.3983, Train: 34.44%, Valid: 34.10%, Test: 34.93%
Epoch: 175, Loss: 1.3674, Train: 41.68%, Valid: 41.56%, Test: 41.81%
Epoch: 200, Loss: 1.3429, Train: 42.78%, Valid: 42.40%, Test: 42.85%
Epoch: 225, Loss: 1.3654, Train: 42.01%, Valid: 41.79%, Test: 42.06%
Epoch: 250, Loss: 1.3229, Train: 43.09%, Valid: 42.87%, Test: 43.12%
Epoch: 275, Loss: 1.3554, Train: 42.11%, Valid: 41.86%, Test: 41.95%
Epoch: 300, Loss: 1.3158, Train: 43.54%, Valid: 43.05%, Test: 43.34%
Epoch: 325, Loss: 1.2959, Train: 44.27%, Valid: 43.82%, Test: 44.03%
Epoch: 350, Loss: 1.3871, Train: 43.76%, Valid: 43.50%, Test: 43.41%
Epoch: 375, Loss: 1.3008, Train: 44.20%, Valid: 43.74%, Test: 43.94%
Epoch: 400, Loss: 1.2775, Train: 45.09%, Valid: 44.56%, Test: 44.79%
Epoch: 425, Loss: 1.2716, Train: 45.55%, Valid: 44.91%, Test: 45.00%
Epoch: 450, Loss: 1.2750, Train: 45.65%, Valid: 45.04%, Test: 45.11%
Epoch: 475, Loss: 1.2963, Train: 44.38%, Valid: 44.39%, Test: 44.33%
Epoch: 500, Loss: 1.2645, Train: 45.92%, Valid: 45.31%, Test: 45.39%
Epoch: 525, Loss: 1.2759, Train: 45.40%, Valid: 44.81%, Test: 44.97%
Epoch: 550, Loss: 1.2485, Train: 46.29%, Valid: 45.73%, Test: 45.77%
Epoch: 575, Loss: 1.2616, Train: 45.79%, Valid: 45.19%, Test: 45.31%
Epoch: 600, Loss: 1.2528, Train: 45.54%, Valid: 45.17%, Test: 45.31%
Epoch: 625, Loss: 1.2523, Train: 46.18%, Valid: 45.52%, Test: 45.79%
Epoch: 650, Loss: 1.2409, Train: 46.88%, Valid: 46.13%, Test: 46.13%
Epoch: 675, Loss: 1.2501, Train: 46.61%, Valid: 45.92%, Test: 46.01%
Epoch: 700, Loss: 1.2385, Train: 46.61%, Valid: 45.95%, Test: 46.03%
Epoch: 725, Loss: 1.2491, Train: 47.04%, Valid: 46.31%, Test: 46.27%
Epoch: 750, Loss: 1.2377, Train: 46.91%, Valid: 46.19%, Test: 46.24%
Epoch: 775, Loss: 1.2421, Train: 46.98%, Valid: 46.03%, Test: 46.36%
Epoch: 800, Loss: 1.2331, Train: 47.69%, Valid: 46.63%, Test: 46.64%
Epoch: 825, Loss: 1.2265, Train: 47.19%, Valid: 46.43%, Test: 46.39%
Epoch: 850, Loss: 1.2856, Train: 45.57%, Valid: 44.77%, Test: 45.01%
Epoch: 875, Loss: 1.2427, Train: 46.24%, Valid: 45.50%, Test: 45.76%
Epoch: 900, Loss: 1.2331, Train: 47.46%, Valid: 46.60%, Test: 46.69%
Epoch: 925, Loss: 1.2217, Train: 47.80%, Valid: 46.94%, Test: 46.91%
Epoch: 950, Loss: 1.2068, Train: 47.99%, Valid: 46.85%, Test: 46.96%
Epoch: 975, Loss: 1.2795, Train: 45.49%, Valid: 44.82%, Test: 44.98%
Run 01:
Highest Train: 48.09
Highest Valid: 47.04
  Final Train: 48.09
   Final Test: 47.04
All runs:
Highest Train: 48.09 ± nan
Highest Valid: 47.04 ± nan
  Final Train: 48.09 ± nan
   Final Test: 47.04 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6046, Train: 28.72%, Valid: 28.53%, Test: 28.83%
Epoch: 25, Loss: 1.4681, Train: 35.81%, Valid: 35.44%, Test: 35.70%
Epoch: 50, Loss: 1.4240, Train: 38.84%, Valid: 38.20%, Test: 38.57%
Epoch: 75, Loss: 1.3887, Train: 40.73%, Valid: 40.04%, Test: 40.20%
Epoch: 100, Loss: 1.3640, Train: 41.40%, Valid: 40.65%, Test: 40.49%
Epoch: 125, Loss: 1.3307, Train: 43.13%, Valid: 41.95%, Test: 42.01%
Epoch: 150, Loss: 1.3071, Train: 44.12%, Valid: 42.81%, Test: 42.96%
Epoch: 175, Loss: 1.2855, Train: 44.90%, Valid: 43.45%, Test: 43.35%
Epoch: 200, Loss: 1.2649, Train: 46.07%, Valid: 44.10%, Test: 43.85%
Epoch: 225, Loss: 1.2425, Train: 46.97%, Valid: 44.48%, Test: 44.42%
Epoch: 250, Loss: 1.2478, Train: 47.00%, Valid: 44.50%, Test: 44.33%
Epoch: 275, Loss: 1.2255, Train: 48.07%, Valid: 44.79%, Test: 44.78%
Epoch: 300, Loss: 1.2125, Train: 48.68%, Valid: 45.12%, Test: 45.08%
Epoch: 325, Loss: 1.1953, Train: 48.98%, Valid: 44.78%, Test: 45.07%
Epoch: 350, Loss: 1.1854, Train: 49.60%, Valid: 45.27%, Test: 45.26%
Epoch: 375, Loss: 1.1863, Train: 49.95%, Valid: 45.27%, Test: 45.21%
Epoch: 400, Loss: 1.1825, Train: 50.15%, Valid: 45.40%, Test: 45.40%
Epoch: 425, Loss: 1.1682, Train: 50.42%, Valid: 45.48%, Test: 45.64%
Epoch: 450, Loss: 1.1670, Train: 50.09%, Valid: 45.28%, Test: 45.34%
Epoch: 475, Loss: 1.1727, Train: 50.87%, Valid: 45.51%, Test: 45.69%
Epoch: 500, Loss: 1.1460, Train: 51.20%, Valid: 45.71%, Test: 46.11%
Epoch: 525, Loss: 1.1411, Train: 51.70%, Valid: 45.84%, Test: 45.96%
Epoch: 550, Loss: 1.1267, Train: 52.41%, Valid: 46.22%, Test: 46.46%
Epoch: 575, Loss: 1.1101, Train: 52.53%, Valid: 46.01%, Test: 46.37%
Epoch: 600, Loss: 1.1055, Train: 52.51%, Valid: 45.83%, Test: 46.07%
Epoch: 625, Loss: 1.0993, Train: 53.31%, Valid: 46.52%, Test: 46.81%
Epoch: 650, Loss: 1.1072, Train: 52.85%, Valid: 46.19%, Test: 46.32%
Epoch: 675, Loss: 1.0920, Train: 53.74%, Valid: 46.57%, Test: 46.46%
Epoch: 700, Loss: 1.1017, Train: 53.29%, Valid: 46.24%, Test: 46.52%
Epoch: 725, Loss: 1.1088, Train: 53.36%, Valid: 46.83%, Test: 46.85%
Epoch: 750, Loss: 1.0853, Train: 54.10%, Valid: 46.54%, Test: 46.62%
Epoch: 775, Loss: 1.1028, Train: 53.73%, Valid: 46.64%, Test: 46.93%
Epoch: 800, Loss: 1.0609, Train: 54.86%, Valid: 47.20%, Test: 47.05%
Epoch: 825, Loss: 1.0681, Train: 54.24%, Valid: 46.54%, Test: 46.20%
Epoch: 850, Loss: 1.1079, Train: 51.30%, Valid: 44.71%, Test: 44.40%
Epoch: 875, Loss: 1.0706, Train: 54.76%, Valid: 47.20%, Test: 47.39%
Epoch: 900, Loss: 1.0659, Train: 54.86%, Valid: 47.13%, Test: 47.17%
Epoch: 925, Loss: 1.0520, Train: 55.28%, Valid: 47.30%, Test: 47.29%
Epoch: 950, Loss: 1.0285, Train: 56.24%, Valid: 47.74%, Test: 47.55%
Epoch: 975, Loss: 1.0417, Train: 55.79%, Valid: 47.94%, Test: 47.72%
Run 01:
Highest Train: 56.70
Highest Valid: 48.05
  Final Train: 56.08
   Final Test: 47.96
All runs:
Highest Train: 56.70 ± nan
Highest Valid: 48.05 ± nan
  Final Train: 56.08 ± nan
   Final Test: 47.96 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6509, Train: 27.03%, Valid: 26.88%, Test: 27.14%
Epoch: 25, Loss: 1.4530, Train: 32.68%, Valid: 32.35%, Test: 32.81%
Epoch: 50, Loss: 1.4305, Train: 37.45%, Valid: 37.28%, Test: 37.80%
Epoch: 75, Loss: 1.3875, Train: 39.98%, Valid: 39.60%, Test: 39.98%
Epoch: 100, Loss: 1.3666, Train: 40.53%, Valid: 40.13%, Test: 40.37%
Epoch: 125, Loss: 1.3680, Train: 40.66%, Valid: 40.10%, Test: 40.54%
Epoch: 150, Loss: 1.3539, Train: 41.32%, Valid: 40.85%, Test: 41.08%
Epoch: 175, Loss: 1.3363, Train: 41.96%, Valid: 41.51%, Test: 41.85%
Epoch: 200, Loss: 1.3315, Train: 42.56%, Valid: 42.13%, Test: 42.60%
Epoch: 225, Loss: 1.3315, Train: 42.40%, Valid: 41.88%, Test: 42.25%
Epoch: 250, Loss: 1.3231, Train: 42.74%, Valid: 42.19%, Test: 42.54%
Epoch: 275, Loss: 1.3154, Train: 43.54%, Valid: 42.95%, Test: 43.29%
Epoch: 300, Loss: 1.3467, Train: 41.06%, Valid: 40.61%, Test: 40.92%
Epoch: 325, Loss: 1.3144, Train: 43.68%, Valid: 43.06%, Test: 43.38%
Epoch: 350, Loss: 1.3100, Train: 43.70%, Valid: 43.03%, Test: 43.37%
Epoch: 375, Loss: 1.3321, Train: 43.67%, Valid: 43.24%, Test: 43.58%
Epoch: 400, Loss: 1.2980, Train: 44.53%, Valid: 44.09%, Test: 44.12%
Epoch: 425, Loss: 1.3095, Train: 42.81%, Valid: 42.25%, Test: 42.37%
Epoch: 450, Loss: 1.2874, Train: 45.12%, Valid: 44.60%, Test: 44.71%
Epoch: 475, Loss: 1.3118, Train: 43.93%, Valid: 43.44%, Test: 43.94%
Epoch: 500, Loss: 1.2806, Train: 45.60%, Valid: 45.11%, Test: 45.08%
Epoch: 525, Loss: 1.2830, Train: 45.51%, Valid: 44.87%, Test: 45.03%
Epoch: 550, Loss: 1.3064, Train: 44.61%, Valid: 44.35%, Test: 44.48%
Epoch: 575, Loss: 1.2657, Train: 45.92%, Valid: 45.36%, Test: 45.56%
Epoch: 600, Loss: 1.2959, Train: 45.22%, Valid: 44.61%, Test: 44.50%
Epoch: 625, Loss: 1.2641, Train: 45.95%, Valid: 45.47%, Test: 45.37%
Epoch: 650, Loss: 1.2592, Train: 45.99%, Valid: 45.52%, Test: 45.53%
Epoch: 675, Loss: 1.2816, Train: 44.37%, Valid: 43.71%, Test: 43.73%
Epoch: 700, Loss: 1.2572, Train: 46.30%, Valid: 45.77%, Test: 45.84%
Epoch: 725, Loss: 1.2475, Train: 46.55%, Valid: 45.95%, Test: 46.06%
Epoch: 750, Loss: 1.2478, Train: 46.35%, Valid: 45.68%, Test: 45.70%
Epoch: 775, Loss: 1.2399, Train: 46.14%, Valid: 45.50%, Test: 45.52%
Epoch: 800, Loss: 1.2378, Train: 46.91%, Valid: 46.17%, Test: 46.17%
Epoch: 825, Loss: 1.2462, Train: 47.35%, Valid: 46.45%, Test: 46.49%
Epoch: 850, Loss: 1.2492, Train: 46.68%, Valid: 45.76%, Test: 45.69%
Epoch: 875, Loss: 1.2237, Train: 47.44%, Valid: 46.46%, Test: 46.55%
Epoch: 900, Loss: 1.2198, Train: 47.75%, Valid: 46.56%, Test: 47.02%
Epoch: 925, Loss: 1.2401, Train: 47.62%, Valid: 46.48%, Test: 46.81%
Epoch: 950, Loss: 1.2435, Train: 47.58%, Valid: 46.34%, Test: 46.45%
Epoch: 975, Loss: 1.2097, Train: 48.31%, Valid: 47.20%, Test: 47.40%
Run 01:
Highest Train: 48.49
Highest Valid: 47.43
  Final Train: 48.47
   Final Test: 47.47
All runs:
Highest Train: 48.49 ± nan
Highest Valid: 47.43 ± nan
  Final Train: 48.47 ± nan
   Final Test: 47.47 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 2.1314, Train: 18.93%, Valid: 19.19%, Test: 18.79%
Epoch: 25, Loss: 1.4637, Train: 32.48%, Valid: 32.17%, Test: 33.20%
Epoch: 50, Loss: 1.4221, Train: 38.29%, Valid: 37.72%, Test: 38.39%
Epoch: 75, Loss: 1.4767, Train: 31.15%, Valid: 30.94%, Test: 31.74%
Epoch: 100, Loss: 1.4361, Train: 35.95%, Valid: 35.66%, Test: 35.95%
Epoch: 125, Loss: 1.4213, Train: 33.72%, Valid: 33.40%, Test: 34.09%
Epoch: 150, Loss: 1.4176, Train: 37.30%, Valid: 36.90%, Test: 37.56%
Epoch: 175, Loss: 1.4023, Train: 37.46%, Valid: 37.05%, Test: 37.57%
Epoch: 200, Loss: 1.3956, Train: 38.86%, Valid: 38.59%, Test: 38.89%
Epoch: 225, Loss: 1.3695, Train: 40.86%, Valid: 40.64%, Test: 40.58%
Epoch: 250, Loss: 1.3750, Train: 40.91%, Valid: 40.57%, Test: 40.76%
Epoch: 275, Loss: 1.3488, Train: 42.36%, Valid: 41.87%, Test: 42.10%
Epoch: 300, Loss: 1.3411, Train: 42.70%, Valid: 42.39%, Test: 42.66%
Epoch: 325, Loss: 1.3348, Train: 42.72%, Valid: 42.45%, Test: 42.71%
Epoch: 350, Loss: 1.3394, Train: 42.80%, Valid: 42.52%, Test: 42.69%
Epoch: 375, Loss: 1.3408, Train: 42.17%, Valid: 41.73%, Test: 42.27%
Epoch: 400, Loss: 1.3142, Train: 44.06%, Valid: 43.44%, Test: 43.64%
Epoch: 425, Loss: 1.3283, Train: 42.64%, Valid: 42.35%, Test: 42.51%
Epoch: 450, Loss: 1.3079, Train: 44.00%, Valid: 43.56%, Test: 43.75%
Epoch: 475, Loss: 1.3054, Train: 43.38%, Valid: 43.14%, Test: 43.23%
Epoch: 500, Loss: 1.3391, Train: 41.78%, Valid: 41.30%, Test: 41.60%
Epoch: 525, Loss: 1.3047, Train: 44.25%, Valid: 43.68%, Test: 43.88%
Epoch: 550, Loss: 1.3103, Train: 44.54%, Valid: 43.97%, Test: 44.21%
Epoch: 575, Loss: 1.2925, Train: 44.92%, Valid: 44.36%, Test: 44.73%
Epoch: 600, Loss: 1.3161, Train: 44.10%, Valid: 43.46%, Test: 43.64%
Epoch: 625, Loss: 1.2926, Train: 44.96%, Valid: 44.30%, Test: 44.56%
Epoch: 650, Loss: 1.2823, Train: 45.05%, Valid: 44.55%, Test: 44.78%
Epoch: 675, Loss: 1.3003, Train: 44.35%, Valid: 43.92%, Test: 44.16%
Epoch: 700, Loss: 1.2805, Train: 45.26%, Valid: 44.66%, Test: 45.22%
Epoch: 725, Loss: 1.3199, Train: 44.98%, Valid: 44.23%, Test: 44.45%
Epoch: 750, Loss: 1.2956, Train: 44.51%, Valid: 44.08%, Test: 44.64%
Epoch: 775, Loss: 1.2774, Train: 45.41%, Valid: 44.77%, Test: 45.28%
Epoch: 800, Loss: 1.2853, Train: 45.05%, Valid: 44.53%, Test: 44.79%
Epoch: 825, Loss: 1.2711, Train: 45.90%, Valid: 45.27%, Test: 45.36%
Epoch: 850, Loss: 1.2827, Train: 45.86%, Valid: 45.17%, Test: 45.48%
Epoch: 875, Loss: 1.2635, Train: 45.79%, Valid: 45.35%, Test: 45.67%
Epoch: 900, Loss: 1.2884, Train: 45.33%, Valid: 44.55%, Test: 44.89%
Epoch: 925, Loss: 1.2654, Train: 46.13%, Valid: 45.27%, Test: 45.79%
Epoch: 950, Loss: 1.2576, Train: 46.40%, Valid: 45.62%, Test: 45.98%
Epoch: 975, Loss: 1.2708, Train: 45.67%, Valid: 45.08%, Test: 45.51%
Run 01:
Highest Train: 46.57
Highest Valid: 45.74
  Final Train: 46.57
   Final Test: 45.97
All runs:
Highest Train: 46.57 ± nan
Highest Valid: 45.74 ± nan
  Final Train: 46.57 ± nan
   Final Test: 45.97 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.5909, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4638, Train: 35.92%, Valid: 35.31%, Test: 35.80%
Epoch: 50, Loss: 1.4251, Train: 38.13%, Valid: 37.15%, Test: 37.46%
Epoch: 75, Loss: 1.3875, Train: 38.79%, Valid: 38.07%, Test: 38.24%
Epoch: 100, Loss: 1.3651, Train: 41.52%, Valid: 40.69%, Test: 40.65%
Epoch: 125, Loss: 1.3264, Train: 42.85%, Valid: 41.97%, Test: 42.02%
Epoch: 150, Loss: 1.2957, Train: 43.45%, Valid: 42.13%, Test: 42.16%
Epoch: 175, Loss: 1.2874, Train: 44.56%, Valid: 42.80%, Test: 43.19%
Epoch: 200, Loss: 1.2629, Train: 45.69%, Valid: 43.81%, Test: 43.96%
Epoch: 225, Loss: 1.2492, Train: 45.84%, Valid: 43.96%, Test: 44.36%
Epoch: 250, Loss: 1.2561, Train: 46.20%, Valid: 43.93%, Test: 44.18%
Epoch: 275, Loss: 1.2236, Train: 47.29%, Valid: 44.87%, Test: 45.36%
Epoch: 300, Loss: 1.2715, Train: 45.87%, Valid: 43.97%, Test: 44.07%
Epoch: 325, Loss: 1.1995, Train: 48.29%, Valid: 45.24%, Test: 45.56%
Epoch: 350, Loss: 1.1859, Train: 48.54%, Valid: 45.53%, Test: 45.79%
Epoch: 375, Loss: 1.1989, Train: 49.12%, Valid: 45.74%, Test: 45.91%
Epoch: 400, Loss: 1.2121, Train: 48.41%, Valid: 45.04%, Test: 45.29%
Epoch: 425, Loss: 1.1513, Train: 50.61%, Valid: 46.57%, Test: 46.67%
Epoch: 450, Loss: 1.1670, Train: 49.83%, Valid: 45.75%, Test: 45.93%
Epoch: 475, Loss: 1.1503, Train: 50.04%, Valid: 45.52%, Test: 45.63%
Epoch: 500, Loss: 1.1456, Train: 51.08%, Valid: 46.50%, Test: 46.70%
Epoch: 525, Loss: 1.1393, Train: 51.24%, Valid: 46.74%, Test: 46.55%
Epoch: 550, Loss: 1.1374, Train: 51.97%, Valid: 46.96%, Test: 47.00%
Epoch: 575, Loss: 1.1289, Train: 51.48%, Valid: 46.54%, Test: 46.84%
Epoch: 600, Loss: 1.1249, Train: 51.97%, Valid: 46.68%, Test: 46.70%
Epoch: 625, Loss: 1.1030, Train: 52.72%, Valid: 47.07%, Test: 47.42%
Epoch: 650, Loss: 1.0990, Train: 52.97%, Valid: 47.30%, Test: 47.31%
Epoch: 675, Loss: 1.1217, Train: 50.15%, Valid: 45.14%, Test: 45.38%
Epoch: 700, Loss: 1.0858, Train: 53.45%, Valid: 47.43%, Test: 47.56%
Epoch: 725, Loss: 1.1556, Train: 50.43%, Valid: 45.67%, Test: 46.00%
Epoch: 750, Loss: 1.0847, Train: 53.44%, Valid: 47.61%, Test: 47.75%
Epoch: 775, Loss: 1.0695, Train: 54.17%, Valid: 47.74%, Test: 47.76%
Epoch: 800, Loss: 1.0825, Train: 54.02%, Valid: 47.74%, Test: 47.83%
Epoch: 825, Loss: 1.0660, Train: 54.23%, Valid: 47.41%, Test: 47.32%
Epoch: 850, Loss: 1.0648, Train: 54.26%, Valid: 47.47%, Test: 47.50%
Epoch: 875, Loss: 1.0941, Train: 49.80%, Valid: 43.78%, Test: 43.97%
Epoch: 900, Loss: 1.0553, Train: 54.57%, Valid: 47.56%, Test: 47.84%
Epoch: 925, Loss: 1.1026, Train: 51.10%, Valid: 45.18%, Test: 45.29%
Epoch: 950, Loss: 1.0538, Train: 55.28%, Valid: 47.96%, Test: 48.09%
Epoch: 975, Loss: 1.0361, Train: 55.38%, Valid: 48.07%, Test: 48.11%
Run 01:
Highest Train: 55.78
Highest Valid: 48.21
  Final Train: 55.78
   Final Test: 48.36
All runs:
Highest Train: 55.78 ± nan
Highest Valid: 48.21 ± nan
  Final Train: 55.78 ± nan
   Final Test: 48.36 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6067, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4492, Train: 35.61%, Valid: 35.13%, Test: 35.33%
Epoch: 50, Loss: 1.4231, Train: 38.05%, Valid: 37.60%, Test: 37.88%
Epoch: 75, Loss: 1.3994, Train: 38.63%, Valid: 38.38%, Test: 38.58%
Epoch: 100, Loss: 1.3966, Train: 39.44%, Valid: 38.85%, Test: 38.98%
Epoch: 125, Loss: 1.3819, Train: 39.89%, Valid: 39.28%, Test: 39.76%
Epoch: 150, Loss: 1.3859, Train: 39.13%, Valid: 38.58%, Test: 38.72%
Epoch: 175, Loss: 1.3631, Train: 40.67%, Valid: 39.96%, Test: 40.19%
Epoch: 200, Loss: 1.3556, Train: 40.75%, Valid: 40.04%, Test: 40.45%
Epoch: 225, Loss: 1.3539, Train: 40.69%, Valid: 40.14%, Test: 40.13%
Epoch: 250, Loss: 1.3592, Train: 40.28%, Valid: 39.68%, Test: 39.77%
Epoch: 275, Loss: 1.3450, Train: 41.44%, Valid: 40.81%, Test: 41.05%
Epoch: 300, Loss: 1.3679, Train: 41.37%, Valid: 40.81%, Test: 41.11%
Epoch: 325, Loss: 1.3314, Train: 41.51%, Valid: 40.81%, Test: 41.04%
Epoch: 350, Loss: 1.3377, Train: 42.42%, Valid: 41.92%, Test: 42.05%
Epoch: 375, Loss: 1.3278, Train: 42.38%, Valid: 41.73%, Test: 41.98%
Epoch: 400, Loss: 1.3193, Train: 42.78%, Valid: 42.14%, Test: 42.39%
Epoch: 425, Loss: 1.3207, Train: 42.61%, Valid: 42.08%, Test: 42.11%
Epoch: 450, Loss: 1.3289, Train: 42.36%, Valid: 41.75%, Test: 41.90%
Epoch: 475, Loss: 1.3455, Train: 42.00%, Valid: 41.28%, Test: 41.49%
Epoch: 500, Loss: 1.3142, Train: 42.92%, Valid: 42.39%, Test: 42.28%
Epoch: 525, Loss: 1.3130, Train: 43.18%, Valid: 42.53%, Test: 42.57%
Epoch: 550, Loss: 1.3051, Train: 43.03%, Valid: 42.23%, Test: 42.29%
Epoch: 575, Loss: 1.2995, Train: 43.51%, Valid: 42.71%, Test: 42.86%
Epoch: 600, Loss: 1.2999, Train: 43.37%, Valid: 42.70%, Test: 42.61%
Epoch: 625, Loss: 1.3080, Train: 42.97%, Valid: 42.35%, Test: 42.46%
Epoch: 650, Loss: 1.2908, Train: 43.97%, Valid: 43.18%, Test: 43.27%
Epoch: 675, Loss: 1.2957, Train: 44.06%, Valid: 43.39%, Test: 43.41%
Epoch: 700, Loss: 1.2954, Train: 44.14%, Valid: 43.37%, Test: 43.57%
Epoch: 725, Loss: 1.2817, Train: 44.22%, Valid: 43.54%, Test: 43.40%
Epoch: 750, Loss: 1.2933, Train: 44.63%, Valid: 43.65%, Test: 43.84%
Epoch: 775, Loss: 1.2916, Train: 43.66%, Valid: 42.76%, Test: 42.83%
Epoch: 800, Loss: 1.2761, Train: 44.53%, Valid: 43.69%, Test: 43.80%
Epoch: 825, Loss: 1.2845, Train: 44.26%, Valid: 43.27%, Test: 43.41%
Epoch: 850, Loss: 1.2804, Train: 43.52%, Valid: 42.83%, Test: 42.68%
Epoch: 875, Loss: 1.2823, Train: 44.30%, Valid: 43.34%, Test: 43.49%
Epoch: 900, Loss: 1.2708, Train: 45.13%, Valid: 44.02%, Test: 44.25%
Epoch: 925, Loss: 1.2603, Train: 45.73%, Valid: 44.70%, Test: 44.79%
Epoch: 950, Loss: 1.2741, Train: 44.73%, Valid: 43.78%, Test: 43.98%
Epoch: 975, Loss: 1.3128, Train: 44.32%, Valid: 43.19%, Test: 43.42%
Run 01:
Highest Train: 45.84
Highest Valid: 44.80
  Final Train: 45.84
   Final Test: 44.87
All runs:
Highest Train: 45.84 ± nan
Highest Valid: 44.80 ± nan
  Final Train: 45.84 ± nan
   Final Test: 44.87 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.5675, Train: 20.44%, Valid: 20.57%, Test: 20.14%
Epoch: 25, Loss: 1.4235, Train: 37.70%, Valid: 37.20%, Test: 37.98%
Epoch: 50, Loss: 1.3871, Train: 40.16%, Valid: 39.91%, Test: 40.20%
Epoch: 75, Loss: 1.4303, Train: 36.90%, Valid: 36.55%, Test: 37.33%
Epoch: 100, Loss: 1.3691, Train: 40.82%, Valid: 40.47%, Test: 40.78%
Epoch: 125, Loss: 1.3599, Train: 41.43%, Valid: 41.12%, Test: 41.44%
Epoch: 150, Loss: 1.3645, Train: 41.55%, Valid: 41.09%, Test: 41.51%
Epoch: 175, Loss: 1.3513, Train: 41.57%, Valid: 41.21%, Test: 41.58%
Epoch: 200, Loss: 1.3517, Train: 41.28%, Valid: 40.89%, Test: 41.27%
Epoch: 225, Loss: 1.3394, Train: 42.33%, Valid: 42.01%, Test: 42.28%
Epoch: 250, Loss: 1.4130, Train: 37.07%, Valid: 36.52%, Test: 37.03%
Epoch: 275, Loss: 1.3728, Train: 41.19%, Valid: 40.72%, Test: 41.22%
Epoch: 300, Loss: 1.3728, Train: 41.30%, Valid: 41.02%, Test: 41.22%
Epoch: 325, Loss: 1.3525, Train: 41.36%, Valid: 41.17%, Test: 41.57%
Epoch: 350, Loss: 1.3434, Train: 40.63%, Valid: 40.45%, Test: 40.87%
Epoch: 375, Loss: 1.3476, Train: 41.77%, Valid: 41.47%, Test: 41.82%
Epoch: 400, Loss: 1.3360, Train: 42.37%, Valid: 42.12%, Test: 42.33%
Epoch: 425, Loss: 1.3628, Train: 41.35%, Valid: 41.25%, Test: 41.42%
Epoch: 450, Loss: 1.3367, Train: 42.25%, Valid: 41.85%, Test: 42.28%
Epoch: 475, Loss: 1.3296, Train: 42.52%, Valid: 42.21%, Test: 42.48%
Epoch: 500, Loss: 1.3325, Train: 42.12%, Valid: 41.82%, Test: 42.15%
Epoch: 525, Loss: 1.3286, Train: 42.42%, Valid: 42.02%, Test: 42.44%
Epoch: 550, Loss: 1.3348, Train: 42.80%, Valid: 42.46%, Test: 42.65%
Epoch: 575, Loss: 1.3981, Train: 40.55%, Valid: 40.12%, Test: 40.14%
Epoch: 600, Loss: 1.3586, Train: 41.33%, Valid: 41.05%, Test: 41.39%
Epoch: 625, Loss: 1.3407, Train: 42.16%, Valid: 41.88%, Test: 42.11%
Epoch: 650, Loss: 1.3368, Train: 42.64%, Valid: 42.32%, Test: 42.51%
Epoch: 675, Loss: 1.3346, Train: 42.64%, Valid: 42.23%, Test: 42.44%
Epoch: 700, Loss: 1.3268, Train: 42.86%, Valid: 42.51%, Test: 42.89%
Epoch: 725, Loss: 1.3237, Train: 42.96%, Valid: 42.69%, Test: 42.93%
Epoch: 750, Loss: 1.3260, Train: 42.91%, Valid: 42.60%, Test: 42.88%
Epoch: 775, Loss: 1.3203, Train: 43.24%, Valid: 42.82%, Test: 43.08%
Epoch: 800, Loss: 1.3306, Train: 42.84%, Valid: 42.42%, Test: 42.81%
Epoch: 825, Loss: 1.3205, Train: 43.38%, Valid: 42.84%, Test: 43.22%
Epoch: 850, Loss: 1.3180, Train: 43.12%, Valid: 42.60%, Test: 42.97%
Epoch: 875, Loss: 1.3172, Train: 43.53%, Valid: 43.04%, Test: 43.34%
Epoch: 900, Loss: 1.3158, Train: 43.48%, Valid: 43.01%, Test: 43.40%
Epoch: 925, Loss: 1.3140, Train: 43.41%, Valid: 42.96%, Test: 43.19%
Epoch: 950, Loss: 1.3129, Train: 43.42%, Valid: 42.83%, Test: 43.14%
Epoch: 975, Loss: 1.3155, Train: 43.93%, Valid: 43.44%, Test: 43.74%
Run 01:
Highest Train: 43.93
Highest Valid: 43.48
  Final Train: 43.87
   Final Test: 43.79
All runs:
Highest Train: 43.93 ± nan
Highest Valid: 43.48 ± nan
  Final Train: 43.87 ± nan
   Final Test: 43.79 ± nan
Saving results to results/arxiv-year.csv
20211117-02:05 ---> 20211117-02:31 Totl:1544 seconds
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 10.8715, Train: 12.00%, Valid: 11.90%, Test: 12.01%
Epoch: 25, Loss: 2834731368448.0000, Train: 16.16%, Valid: 16.24%, Test: 16.05%
Epoch: 50, Loss: 233736.6562, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 75, Loss: 7999140.5000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 100, Loss: 178993.4844, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 125, Loss: 18921632.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 150, Loss: 412502.6875, Train: 83.81%, Valid: 83.74%, Test: 83.90%
Epoch: 175, Loss: 9084922.0000, Train: 83.81%, Valid: 83.75%, Test: 83.91%
Epoch: 200, Loss: 1329008384.0000, Train: 83.37%, Valid: 83.45%, Test: 83.45%
Epoch: 225, Loss: 20771.5879, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 250, Loss: 1937.9828, Train: 83.81%, Valid: 83.75%, Test: 83.91%
Epoch: 275, Loss: 5605222400.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 300, Loss: 4470.8213, Train: 83.81%, Valid: 83.75%, Test: 83.91%
Epoch: 325, Loss: 1646563.2500, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 350, Loss: 4007020.7500, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 375, Loss: 5854302208.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 400, Loss: 30089762.0000, Train: 16.18%, Valid: 16.24%, Test: 16.08%
Epoch: 425, Loss: 144400.5156, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 450, Loss: 30795.0703, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 475, Loss: 188624176.0000, Train: 83.81%, Valid: 83.74%, Test: 83.91%
Epoch: 500, Loss: 912720512.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 525, Loss: 83872152.0000, Train: 83.80%, Valid: 83.74%, Test: 83.90%
Epoch: 550, Loss: 7864770048.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 575, Loss: 6391437.5000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 600, Loss: 1666512384.0000, Train: 83.81%, Valid: 83.75%, Test: 83.91%
Epoch: 625, Loss: 35411.2422, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 650, Loss: 8900388864.0000, Train: 83.81%, Valid: 83.74%, Test: 83.91%
Epoch: 675, Loss: 9130496.0000, Train: 83.81%, Valid: 83.74%, Test: 83.91%
Epoch: 700, Loss: 72748144.0000, Train: 83.81%, Valid: 83.75%, Test: 83.91%
Epoch: 725, Loss: 3406284.7500, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 750, Loss: 6273.0933, Train: 83.75%, Valid: 83.69%, Test: 83.85%
Epoch: 775, Loss: 6511202.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 800, Loss: 1074496.7500, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 825, Loss: 10538409.0000, Train: 83.81%, Valid: 83.75%, Test: 83.91%
Epoch: 850, Loss: 222532.9375, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 875, Loss: 59708076032.0000, Train: 83.81%, Valid: 83.75%, Test: 83.91%
Epoch: 900, Loss: 180869.1250, Train: 83.81%, Valid: 83.75%, Test: 83.91%
Epoch: 925, Loss: 342252256.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 950, Loss: 77475632.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Epoch: 975, Loss: 46474600.0000, Train: 16.19%, Valid: 16.25%, Test: 16.09%
Run 01:
Highest Train: 87.53
Highest Valid: 87.60
  Final Train: 87.53
   Final Test: 87.48
All runs:
Highest Train: 87.53 ± nan
Highest Valid: 87.60 ± nan
  Final Train: 87.53 ± nan
   Final Test: 87.48 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 2.1259, Train: 17.02%, Valid: 17.12%, Test: 16.84%
Epoch: 25, Loss: 360876909527040.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 38593748992.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 5256391950336.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 56989539368960.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 15432992768.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 884604076032.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 776943239168.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 15644215296.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 774278651838464.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 3838197104640.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 614621161455616.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 11279354822656.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 27785953280.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 318602543104.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 72146709643264.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 3756648448.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 23106560000.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 1973482160128.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 200810336.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 500, Loss: 2854105120768.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 525, Loss: 88069464064.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 550, Loss: 5280475643904.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 575, Loss: 356381425664.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 600, Loss: 870370089369600.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 625, Loss: 71558097797120.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 650, Loss: 26909767680.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 675, Loss: 333025657225216.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 700, Loss: 357387927552.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 725, Loss: 2042529579008.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 750, Loss: 940506944.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 775, Loss: 7244749471744.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 800, Loss: 28434712576.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 825, Loss: 136913520.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 850, Loss: 665262555136.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 875, Loss: 3713625489408.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 900, Loss: 12615027712.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 925, Loss: 418997600.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 950, Loss: 119163535360.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 975, Loss: 13098553442304.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 85.60
Highest Valid: 85.48
  Final Train: 85.60
   Final Test: 85.71
All runs:
Highest Train: 85.60 ± nan
Highest Valid: 85.48 ± nan
  Final Train: 85.60 ± nan
   Final Test: 85.71 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.5103, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 25, Loss: 1.2460, Train: 84.33%, Valid: 84.13%, Test: 84.46%
Epoch: 50, Loss: 52810422943744.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 469597683712.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 829024448.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 206562312192.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 49828192256.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 325870583808.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 550322560.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 981561638912.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 5471941632.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 6768966534933197619200.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 4432505965878104420364224299008.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: nan, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 12314870350454413072903775977472.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 246319564201510158381589534343168.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 3791539540947526105080883314688.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 500, Loss: 14635914836826390761893181521920.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 525, Loss: 82928413648721123820384420888576.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 550, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 575, Loss: inf, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 600, Loss: 18935634808529663542966028861440.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 625, Loss: 529703806037778767203977396224.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 650, Loss: 15684690626339211165938506268672.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 675, Loss: 73406981631061134722589523968.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 700, Loss: 73681122447841294629805433552896.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 725, Loss: 597738032657654125018500051238912.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 750, Loss: 27531136071615904643260530819072.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 775, Loss: 237337844988979992469593300926464.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 800, Loss: 22842263766383581510343065600.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 825, Loss: 7248325104592122162427277082624.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 850, Loss: 2902260777421629740025905152.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 875, Loss: 8828248091458210440736145408.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 900, Loss: 14940475891784445445989384323072.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 925, Loss: 14278103017365950891909521080320.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 950, Loss: 275714179634957919332134104858624.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 975, Loss: 93057181021714763727408669392896.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 85.75
Highest Valid: 85.62
  Final Train: 85.75
   Final Test: 85.76
All runs:
Highest Train: 85.75 ± nan
Highest Valid: 85.62 ± nan
  Final Train: 85.75 ± nan
   Final Test: 85.76 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.5851, Train: 87.12%, Valid: 87.01%, Test: 87.12%
Epoch: 25, Loss: 31600945152.0000, Train: 49.95%, Valid: 49.94%, Test: 49.95%
Epoch: 50, Loss: 19421984718848.0000, Train: 49.99%, Valid: 49.98%, Test: 49.99%
Epoch: 75, Loss: 15587079.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 8.5401, Train: 84.48%, Valid: 84.26%, Test: 84.58%
Epoch: 125, Loss: 5.5004, Train: 84.39%, Valid: 84.17%, Test: 84.52%
Epoch: 150, Loss: 5.2964, Train: 84.45%, Valid: 84.26%, Test: 84.58%
Epoch: 175, Loss: 5.2948, Train: 84.52%, Valid: 84.29%, Test: 84.61%
Epoch: 200, Loss: 5.2966, Train: 84.44%, Valid: 84.26%, Test: 84.58%
Epoch: 225, Loss: 5.2679, Train: 84.56%, Valid: 84.35%, Test: 84.67%
Epoch: 250, Loss: 5.2884, Train: 84.47%, Valid: 84.29%, Test: 84.60%
Epoch: 275, Loss: 5.2857, Train: 84.56%, Valid: 84.34%, Test: 84.68%
Epoch: 300, Loss: 5.2721, Train: 84.52%, Valid: 84.30%, Test: 84.61%
Epoch: 325, Loss: 5.3030, Train: 84.53%, Valid: 84.35%, Test: 84.62%
Epoch: 350, Loss: 5.2834, Train: 84.43%, Valid: 84.23%, Test: 84.57%
Epoch: 375, Loss: 5.2203, Train: 84.55%, Valid: 84.33%, Test: 84.69%
Epoch: 400, Loss: 5.2781, Train: 84.49%, Valid: 84.31%, Test: 84.63%
Epoch: 425, Loss: 5.2873, Train: 84.47%, Valid: 84.25%, Test: 84.57%
Epoch: 450, Loss: 5.2838, Train: 84.49%, Valid: 84.30%, Test: 84.61%
Epoch: 475, Loss: 5.2491, Train: 84.49%, Valid: 84.26%, Test: 84.62%
Epoch: 500, Loss: 5.2813, Train: 84.53%, Valid: 84.34%, Test: 84.63%
Epoch: 525, Loss: 5.2386, Train: 84.42%, Valid: 84.25%, Test: 84.54%
Epoch: 550, Loss: 5.2976, Train: 84.44%, Valid: 84.21%, Test: 84.51%
Epoch: 575, Loss: 5.2310, Train: 84.55%, Valid: 84.31%, Test: 84.67%
Epoch: 600, Loss: 5.2389, Train: 84.51%, Valid: 84.26%, Test: 84.57%
Epoch: 625, Loss: 5.2954, Train: 84.61%, Valid: 84.40%, Test: 84.70%
Epoch: 650, Loss: 5.3096, Train: 84.44%, Valid: 84.25%, Test: 84.58%
Epoch: 675, Loss: 5.2914, Train: 84.49%, Valid: 84.28%, Test: 84.65%
Epoch: 700, Loss: 5.2939, Train: 84.49%, Valid: 84.25%, Test: 84.58%
Epoch: 725, Loss: 5.2774, Train: 84.52%, Valid: 84.31%, Test: 84.63%
Epoch: 750, Loss: 5.2689, Train: 84.46%, Valid: 84.27%, Test: 84.58%
Epoch: 775, Loss: 5.2587, Train: 84.41%, Valid: 84.21%, Test: 84.58%
Epoch: 800, Loss: 5.2438, Train: 84.37%, Valid: 84.18%, Test: 84.47%
Epoch: 825, Loss: 5.3123, Train: 84.46%, Valid: 84.28%, Test: 84.56%
Epoch: 850, Loss: 5.2634, Train: 84.49%, Valid: 84.32%, Test: 84.62%
Epoch: 875, Loss: 5.2921, Train: 84.37%, Valid: 84.20%, Test: 84.52%
Epoch: 900, Loss: 5.2726, Train: 84.33%, Valid: 84.18%, Test: 84.45%
Epoch: 925, Loss: 5.3164, Train: 84.54%, Valid: 84.30%, Test: 84.63%
Epoch: 950, Loss: 5.2500, Train: 84.49%, Valid: 84.28%, Test: 84.61%
Epoch: 975, Loss: 5.2648, Train: 84.41%, Valid: 84.21%, Test: 84.55%
Run 01:
Highest Train: 87.12
Highest Valid: 87.01
  Final Train: 87.12
   Final Test: 87.12
All runs:
Highest Train: 87.12 ± nan
Highest Valid: 87.01 ± nan
  Final Train: 87.12 ± nan
   Final Test: 87.12 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 15.6334, Train: 84.64%, Valid: 84.54%, Test: 84.71%
Epoch: 25, Loss: 174.9337, Train: 16.46%, Valid: 16.55%, Test: 16.26%
Epoch: 50, Loss: 2564.4478, Train: 83.73%, Valid: 83.63%, Test: 83.95%
Epoch: 75, Loss: 1364918016.0000, Train: 16.41%, Valid: 16.50%, Test: 16.20%
Epoch: 100, Loss: 3520894.0000, Train: 15.66%, Valid: 15.74%, Test: 15.52%
Epoch: 125, Loss: 69814.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 447634.2812, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 25437.7148, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 1204.1696, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 8763.8809, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 188.0183, Train: 16.01%, Valid: 16.08%, Test: 15.76%
Epoch: 275, Loss: 3743.7402, Train: 84.73%, Valid: 84.51%, Test: 84.75%
Epoch: 300, Loss: 44291.6016, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 96539.9922, Train: 16.12%, Valid: 16.18%, Test: 15.87%
Epoch: 350, Loss: 927.1679, Train: 16.13%, Valid: 16.19%, Test: 15.88%
Epoch: 375, Loss: 174.9864, Train: 16.11%, Valid: 16.17%, Test: 15.86%
Epoch: 400, Loss: 167.0415, Train: 84.85%, Valid: 84.62%, Test: 84.94%
Epoch: 425, Loss: 942.6904, Train: 16.02%, Valid: 16.10%, Test: 15.76%
Epoch: 450, Loss: 143.7041, Train: 85.91%, Valid: 85.82%, Test: 85.89%
Epoch: 475, Loss: 29203.7676, Train: 16.06%, Valid: 16.12%, Test: 15.81%
Epoch: 500, Loss: 261.0262, Train: 84.71%, Valid: 84.50%, Test: 84.77%
Epoch: 525, Loss: 151.7362, Train: 16.13%, Valid: 16.19%, Test: 15.88%
Epoch: 550, Loss: 29.4644, Train: 85.90%, Valid: 85.82%, Test: 85.88%
Epoch: 575, Loss: 9.6112, Train: 16.13%, Valid: 16.19%, Test: 15.88%
Epoch: 600, Loss: 173.4862, Train: 16.03%, Valid: 16.11%, Test: 15.78%
Epoch: 625, Loss: 145.3985, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 650, Loss: 8887.8555, Train: 16.13%, Valid: 16.19%, Test: 15.88%
Epoch: 675, Loss: 201.8847, Train: 16.13%, Valid: 16.19%, Test: 15.88%
Epoch: 700, Loss: 1707.7991, Train: 16.13%, Valid: 16.19%, Test: 15.88%
Epoch: 725, Loss: 1115.3206, Train: 84.05%, Valid: 83.94%, Test: 84.28%
Epoch: 750, Loss: 32459.8633, Train: 84.70%, Valid: 84.48%, Test: 84.74%
Epoch: 775, Loss: 1178.3271, Train: 16.13%, Valid: 16.19%, Test: 15.88%
Epoch: 800, Loss: 5750.0063, Train: 85.90%, Valid: 85.82%, Test: 85.88%
Epoch: 825, Loss: 192.6834, Train: 84.65%, Valid: 84.54%, Test: 84.65%
Epoch: 850, Loss: 660197.3750, Train: 84.79%, Valid: 84.67%, Test: 84.81%
Epoch: 875, Loss: 418.1140, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 900, Loss: 27560.0391, Train: 16.11%, Valid: 16.17%, Test: 15.86%
Epoch: 925, Loss: 8095.2251, Train: 15.54%, Valid: 15.64%, Test: 15.41%
Epoch: 950, Loss: 189.4934, Train: 14.30%, Valid: 14.35%, Test: 14.10%
Epoch: 975, Loss: 70.4933, Train: 85.89%, Valid: 85.80%, Test: 85.86%
Run 01:
Highest Train: 86.67
Highest Valid: 86.58
  Final Train: 86.67
   Final Test: 86.65
All runs:
Highest Train: 86.67 ± nan
Highest Valid: 86.58 ± nan
  Final Train: 86.67 ± nan
   Final Test: 86.65 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 16.1554, Train: 86.22%, Valid: 86.22%, Test: 86.29%
Epoch: 25, Loss: 494420.0312, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 23843934.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 2921034240.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 832077430784.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 1.7755, Train: 15.16%, Valid: 15.29%, Test: 14.99%
Epoch: 150, Loss: 4.4657, Train: 86.50%, Valid: 86.53%, Test: 86.52%
Epoch: 175, Loss: 5.3315, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 200, Loss: 5.2954, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 225, Loss: 5.3750, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 250, Loss: 5.2890, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 275, Loss: 5.0943, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 300, Loss: 5.3272, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 325, Loss: 5.1986, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 350, Loss: 5.3972, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 375, Loss: 5.3874, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 400, Loss: 5.4253, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 425, Loss: 5.4023, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 450, Loss: 5.3842, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 475, Loss: 5.2245, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 500, Loss: 5.2038, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 525, Loss: 5.5163, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 550, Loss: 5.6131, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 575, Loss: 5.1294, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 600, Loss: 5.1440, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 625, Loss: 5.6434, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 650, Loss: 5.6087, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 675, Loss: 6.0486, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 700, Loss: 5.1084, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 725, Loss: 5.2428, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 750, Loss: 5.4436, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 775, Loss: 5.2767, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 800, Loss: 5.6947, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 825, Loss: 5.3510, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 850, Loss: 5.3687, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 875, Loss: 5.3399, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 900, Loss: 5.2904, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 925, Loss: 5.5675, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Epoch: 950, Loss: 5.5702, Train: 86.49%, Valid: 86.52%, Test: 86.52%
Epoch: 975, Loss: 5.6211, Train: 86.50%, Valid: 86.52%, Test: 86.52%
Run 01:
Highest Train: 86.51
Highest Valid: 86.54
  Final Train: 86.51
   Final Test: 86.54
All runs:
Highest Train: 86.51 ± nan
Highest Valid: 86.54 ± nan
  Final Train: 86.51 ± nan
   Final Test: 86.54 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.4816, Train: 14.29%, Valid: 14.27%, Test: 14.27%
Epoch: 25, Loss: 19.9577, Train: 85.35%, Valid: 85.37%, Test: 85.47%
Epoch: 50, Loss: 3.1578, Train: 85.28%, Valid: 85.30%, Test: 85.42%
Epoch: 75, Loss: 3.2392, Train: 85.33%, Valid: 85.33%, Test: 85.44%
Epoch: 100, Loss: 3.2440, Train: 85.29%, Valid: 85.30%, Test: 85.41%
Epoch: 125, Loss: 3.2535, Train: 85.32%, Valid: 85.34%, Test: 85.44%
Epoch: 150, Loss: 3.2646, Train: 85.29%, Valid: 85.30%, Test: 85.40%
Epoch: 175, Loss: 3.2459, Train: 85.31%, Valid: 85.30%, Test: 85.45%
Epoch: 200, Loss: 3.2361, Train: 85.31%, Valid: 85.32%, Test: 85.42%
Epoch: 225, Loss: 3.2448, Train: 85.31%, Valid: 85.33%, Test: 85.42%
Epoch: 250, Loss: 3.2489, Train: 85.31%, Valid: 85.33%, Test: 85.43%
Epoch: 275, Loss: 3.2353, Train: 85.38%, Valid: 85.38%, Test: 85.47%
Epoch: 300, Loss: 3.2367, Train: 85.29%, Valid: 85.30%, Test: 85.40%
Epoch: 325, Loss: 3.2317, Train: 85.38%, Valid: 85.35%, Test: 85.50%
Epoch: 350, Loss: 3.2274, Train: 85.32%, Valid: 85.28%, Test: 85.39%
Epoch: 375, Loss: 3.2332, Train: 85.28%, Valid: 85.30%, Test: 85.40%
Epoch: 400, Loss: 3.2218, Train: 85.31%, Valid: 85.30%, Test: 85.42%
Epoch: 425, Loss: 3.2208, Train: 85.35%, Valid: 85.36%, Test: 85.46%
Epoch: 450, Loss: 3.2196, Train: 85.31%, Valid: 85.32%, Test: 85.42%
Epoch: 475, Loss: 3.2275, Train: 85.37%, Valid: 85.37%, Test: 85.47%
Epoch: 500, Loss: 3.2137, Train: 85.29%, Valid: 85.31%, Test: 85.41%
Epoch: 525, Loss: 3.2222, Train: 85.28%, Valid: 85.31%, Test: 85.41%
Epoch: 550, Loss: 3.2082, Train: 85.39%, Valid: 85.37%, Test: 85.47%
Epoch: 575, Loss: 3.2086, Train: 85.28%, Valid: 85.29%, Test: 85.40%
Epoch: 600, Loss: 3.2125, Train: 85.32%, Valid: 85.36%, Test: 85.44%
Epoch: 625, Loss: 3.1962, Train: 85.33%, Valid: 85.34%, Test: 85.44%
Epoch: 650, Loss: 3.2019, Train: 85.30%, Valid: 85.32%, Test: 85.42%
Epoch: 675, Loss: 3.2081, Train: 85.35%, Valid: 85.36%, Test: 85.46%
Epoch: 700, Loss: 3.2046, Train: 85.28%, Valid: 85.30%, Test: 85.40%
Epoch: 725, Loss: 3.1925, Train: 85.35%, Valid: 85.37%, Test: 85.46%
Epoch: 750, Loss: 3.1910, Train: 85.30%, Valid: 85.31%, Test: 85.41%
Epoch: 775, Loss: 3.2026, Train: 85.27%, Valid: 85.28%, Test: 85.38%
Epoch: 800, Loss: 3.1945, Train: 85.28%, Valid: 85.30%, Test: 85.40%
Epoch: 825, Loss: 3.2059, Train: 85.28%, Valid: 85.29%, Test: 85.39%
Epoch: 850, Loss: 3.1850, Train: 85.27%, Valid: 85.30%, Test: 85.39%
Epoch: 875, Loss: 3.1821, Train: 85.27%, Valid: 85.28%, Test: 85.37%
Epoch: 900, Loss: 3.1809, Train: 85.27%, Valid: 85.28%, Test: 85.38%
Epoch: 925, Loss: 3.1909, Train: 85.28%, Valid: 85.28%, Test: 85.39%
Epoch: 950, Loss: 3.1798, Train: 85.27%, Valid: 85.28%, Test: 85.38%
Epoch: 975, Loss: 3.1920, Train: 85.31%, Valid: 85.35%, Test: 85.42%
Run 01:
Highest Train: 85.43
Highest Valid: 85.46
  Final Train: 85.43
   Final Test: 85.53
All runs:
Highest Train: 85.43 ± nan
Highest Valid: 85.46 ± nan
  Final Train: 85.43 ± nan
   Final Test: 85.53 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 22.7335, Train: 86.04%, Valid: 85.94%, Test: 86.02%
Epoch: 25, Loss: 3.6380, Train: 85.90%, Valid: 85.75%, Test: 85.95%
Epoch: 50, Loss: 18.3622, Train: 85.86%, Valid: 85.72%, Test: 85.82%
Epoch: 75, Loss: 4.6460, Train: 85.99%, Valid: 85.84%, Test: 85.94%
Epoch: 100, Loss: 2.5592, Train: 86.54%, Valid: 86.49%, Test: 86.72%
Epoch: 125, Loss: 0.4729, Train: 85.23%, Valid: 85.07%, Test: 85.37%
Epoch: 150, Loss: 0.4033, Train: 86.38%, Valid: 86.22%, Test: 86.41%
Epoch: 175, Loss: 0.3778, Train: 85.37%, Valid: 85.25%, Test: 85.53%
Epoch: 200, Loss: 0.3653, Train: 85.36%, Valid: 85.27%, Test: 85.52%
Epoch: 225, Loss: 0.3569, Train: 85.60%, Valid: 85.47%, Test: 85.73%
Epoch: 250, Loss: 0.3498, Train: 85.72%, Valid: 85.57%, Test: 85.86%
Epoch: 275, Loss: 2.4648, Train: 86.12%, Valid: 86.01%, Test: 86.11%
Epoch: 300, Loss: 1.5430, Train: 87.07%, Valid: 87.05%, Test: 87.14%
Epoch: 325, Loss: 1.5790, Train: 86.40%, Valid: 86.34%, Test: 86.44%
Epoch: 350, Loss: 0.6323, Train: 86.56%, Valid: 86.49%, Test: 86.54%
Epoch: 375, Loss: 0.3860, Train: 85.88%, Valid: 85.67%, Test: 85.97%
Epoch: 400, Loss: 0.3627, Train: 86.09%, Valid: 85.90%, Test: 86.18%
Epoch: 425, Loss: 0.3485, Train: 85.89%, Valid: 85.69%, Test: 85.99%
Epoch: 450, Loss: 0.4683, Train: 86.59%, Valid: 86.54%, Test: 86.72%
Epoch: 475, Loss: 0.3415, Train: 86.05%, Valid: 85.88%, Test: 86.18%
Epoch: 500, Loss: 0.3347, Train: 85.94%, Valid: 85.75%, Test: 86.06%
Epoch: 525, Loss: 0.3285, Train: 86.13%, Valid: 85.95%, Test: 86.25%
Epoch: 550, Loss: 0.3265, Train: 86.15%, Valid: 85.97%, Test: 86.28%
Epoch: 575, Loss: 3.5306, Train: 85.84%, Valid: 85.71%, Test: 85.92%
Epoch: 600, Loss: 8.0965, Train: 85.78%, Valid: 85.64%, Test: 85.87%
Epoch: 625, Loss: 6.3699, Train: 86.06%, Valid: 85.93%, Test: 86.05%
Epoch: 650, Loss: 4.5029, Train: 86.17%, Valid: 86.04%, Test: 86.18%
Epoch: 675, Loss: 0.6407, Train: 50.66%, Valid: 50.29%, Test: 50.15%
Epoch: 700, Loss: 0.5218, Train: 85.33%, Valid: 85.19%, Test: 85.44%
Epoch: 725, Loss: 0.4684, Train: 85.76%, Valid: 85.64%, Test: 85.88%
Epoch: 750, Loss: 0.4365, Train: 85.88%, Valid: 85.72%, Test: 86.00%
Epoch: 775, Loss: 0.4007, Train: 86.06%, Valid: 85.91%, Test: 86.16%
Epoch: 800, Loss: 0.3817, Train: 86.13%, Valid: 85.96%, Test: 86.21%
Epoch: 825, Loss: 0.3684, Train: 86.12%, Valid: 85.95%, Test: 86.20%
Epoch: 850, Loss: 0.3585, Train: 86.13%, Valid: 85.96%, Test: 86.22%
Epoch: 875, Loss: 0.3491, Train: 86.14%, Valid: 85.96%, Test: 86.23%
Epoch: 900, Loss: 0.3415, Train: 86.16%, Valid: 85.99%, Test: 86.26%
Epoch: 925, Loss: 0.7602, Train: 85.97%, Valid: 85.84%, Test: 86.07%
Epoch: 950, Loss: 4.1311, Train: 85.83%, Valid: 85.69%, Test: 85.95%
Epoch: 975, Loss: 4.3493, Train: 85.89%, Valid: 85.75%, Test: 85.98%
Run 01:
Highest Train: 87.28
Highest Valid: 87.28
  Final Train: 87.28
   Final Test: 87.32
All runs:
Highest Train: 87.28 ± nan
Highest Valid: 87.28 ± nan
  Final Train: 87.28 ± nan
   Final Test: 87.32 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 31.0594, Train: 85.43%, Valid: 85.28%, Test: 85.51%
Epoch: 25, Loss: 4.5858, Train: 85.60%, Valid: 85.38%, Test: 85.62%
Epoch: 50, Loss: 5.7096, Train: 86.07%, Valid: 85.86%, Test: 86.06%
Epoch: 75, Loss: 9.5200, Train: 15.05%, Valid: 15.28%, Test: 14.99%
Epoch: 100, Loss: 8.8501, Train: 15.18%, Valid: 15.44%, Test: 15.12%
Epoch: 125, Loss: 9.4270, Train: 87.05%, Valid: 87.17%, Test: 87.18%
Epoch: 150, Loss: 9.1276, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 175, Loss: 9.1655, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 200, Loss: 9.2657, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 225, Loss: 9.1249, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 250, Loss: 9.2208, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 275, Loss: 9.1724, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 300, Loss: 9.1952, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 325, Loss: 9.1019, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 350, Loss: 9.2706, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 375, Loss: 9.2082, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 400, Loss: 9.1817, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 425, Loss: 9.1270, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 450, Loss: 9.1823, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 475, Loss: 9.1874, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 500, Loss: 9.1407, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 525, Loss: 9.1471, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 550, Loss: 9.3655, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 575, Loss: 9.1231, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 600, Loss: 9.1283, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 625, Loss: 9.1407, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 650, Loss: 9.1548, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 675, Loss: 9.2778, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 700, Loss: 9.2000, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 725, Loss: 9.1263, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 750, Loss: 9.1860, Train: 87.05%, Valid: 87.17%, Test: 87.18%
Epoch: 775, Loss: 9.1750, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 800, Loss: 9.1516, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 825, Loss: 9.1293, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 850, Loss: 9.2098, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 875, Loss: 9.2474, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 900, Loss: 9.4375, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 925, Loss: 9.1086, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 950, Loss: 9.2161, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Epoch: 975, Loss: 9.2181, Train: 87.06%, Valid: 87.17%, Test: 87.18%
Run 01:
Highest Train: 87.06
Highest Valid: 87.17
  Final Train: 87.05
   Final Test: 87.18
All runs:
Highest Train: 87.06 ± nan
Highest Valid: 87.17 ± nan
  Final Train: 87.05 ± nan
   Final Test: 87.18 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.3680, Train: 87.77%, Valid: 87.82%, Test: 87.82%
Epoch: 25, Loss: 5949.0322, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 745940457619456.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 0.5595, Train: 86.37%, Valid: 86.38%, Test: 86.48%
Epoch: 100, Loss: 562471.3125, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 209455344.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 8244333.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 1034854.8125, Train: 15.54%, Valid: 15.64%, Test: 15.41%
Epoch: 200, Loss: 1956103424.0000, Train: 84.35%, Valid: 84.33%, Test: 84.53%
Epoch: 225, Loss: 5.8873, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 646336128.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 266814.9688, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 55736.7188, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 5656.4624, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 310345856.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 440242240.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 282270.6250, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 58379.2070, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 990462.1875, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 160908768.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 500, Loss: 35371.1250, Train: 15.72%, Valid: 15.74%, Test: 15.57%
Epoch: 525, Loss: 846870.4375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 550, Loss: 11076829184.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 575, Loss: 429043.9375, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 600, Loss: 5262.5532, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 625, Loss: 131575056.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 650, Loss: 2601053.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 675, Loss: 1016564.6875, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 700, Loss: 1418869.2500, Train: 84.23%, Valid: 84.23%, Test: 84.40%
Epoch: 725, Loss: 19713202.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 750, Loss: 9810286.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 775, Loss: 15127.9209, Train: 15.54%, Valid: 15.64%, Test: 15.41%
Epoch: 800, Loss: 37540700.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 825, Loss: 523383.0625, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 850, Loss: 2148.4121, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 875, Loss: 26967.4121, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 900, Loss: 130229.4453, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 925, Loss: 323103264.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 950, Loss: 134119.3594, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 975, Loss: 3437505792.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 87.77
Highest Valid: 87.82
  Final Train: 87.77
   Final Test: 87.82
All runs:
Highest Train: 87.77 ± nan
Highest Valid: 87.82 ± nan
  Final Train: 87.77 ± nan
   Final Test: 87.82 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.2766, Train: 87.19%, Valid: 87.09%, Test: 87.26%
Epoch: 25, Loss: 0.7418, Train: 85.41%, Valid: 85.32%, Test: 85.43%
Epoch: 50, Loss: 225828064.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 417189696.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 274936064.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 125, Loss: 207578.2188, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 258511232.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 6445001728.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 200, Loss: 27087.5703, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 748672064.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 44352960.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 71939488.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 30384294.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 21689858.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 350, Loss: 921633.7500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 22082.6875, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 400, Loss: 90601312.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 437.7694, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 450, Loss: 1825935.8750, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 2618541312.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 500, Loss: 4630707200.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 525, Loss: 19768913920.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 550, Loss: 407644224.0000, Train: 50.01%, Valid: 50.01%, Test: 50.02%
Epoch: 575, Loss: 11426451456.0000, Train: 85.06%, Valid: 84.99%, Test: 85.15%
Epoch: 600, Loss: 818050240.0000, Train: 50.03%, Valid: 50.04%, Test: 50.04%
Epoch: 625, Loss: 167659765760.0000, Train: 50.03%, Valid: 50.04%, Test: 50.03%
Epoch: 650, Loss: 37079609344.0000, Train: 50.02%, Valid: 50.02%, Test: 50.02%
Epoch: 675, Loss: 3819515648.0000, Train: 49.97%, Valid: 49.96%, Test: 49.96%
Epoch: 700, Loss: 13482877.0000, Train: 49.97%, Valid: 49.96%, Test: 49.96%
Epoch: 725, Loss: 656647.3125, Train: 49.97%, Valid: 49.95%, Test: 49.96%
Epoch: 750, Loss: 105009.5703, Train: 50.04%, Valid: 50.05%, Test: 50.05%
Epoch: 775, Loss: 52276.3242, Train: 50.03%, Valid: 50.04%, Test: 50.04%
Epoch: 800, Loss: 2102245.7500, Train: 49.97%, Valid: 49.95%, Test: 49.96%
Epoch: 825, Loss: 50666660.0000, Train: 49.96%, Valid: 49.94%, Test: 49.95%
Epoch: 850, Loss: 1133396.2500, Train: 49.96%, Valid: 49.95%, Test: 49.95%
Epoch: 875, Loss: 4197432.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 900, Loss: 2478303.2500, Train: 50.04%, Valid: 50.05%, Test: 50.05%
Epoch: 925, Loss: 3127462912.0000, Train: 50.03%, Valid: 50.04%, Test: 50.04%
Epoch: 950, Loss: 511836.9062, Train: 49.97%, Valid: 49.96%, Test: 49.96%
Epoch: 975, Loss: 180640.3125, Train: 49.96%, Valid: 49.95%, Test: 49.95%
Run 01:
Highest Train: 87.19
Highest Valid: 87.09
  Final Train: 87.19
   Final Test: 87.26
All runs:
Highest Train: 87.19 ± nan
Highest Valid: 87.09 ± nan
  Final Train: 87.19 ± nan
   Final Test: 87.26 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 2.8557, Train: 14.24%, Valid: 14.29%, Test: 14.17%
Epoch: 25, Loss: 2420.4197, Train: 49.95%, Valid: 49.95%, Test: 49.95%
Epoch: 50, Loss: 27827.2695, Train: 85.89%, Valid: 85.79%, Test: 85.95%
Epoch: 75, Loss: 79.9095, Train: 86.90%, Valid: 86.87%, Test: 86.94%
Epoch: 100, Loss: 85.3940, Train: 13.03%, Valid: 13.22%, Test: 13.04%
Epoch: 125, Loss: 1.1179, Train: 86.56%, Valid: 86.56%, Test: 86.59%
Epoch: 150, Loss: 201.5911, Train: 15.07%, Valid: 15.29%, Test: 15.01%
Epoch: 175, Loss: 95.0476, Train: 14.82%, Valid: 14.90%, Test: 14.78%
Epoch: 200, Loss: 56.6954, Train: 13.41%, Valid: 13.56%, Test: 13.41%
Epoch: 225, Loss: 1.3046, Train: 13.47%, Valid: 13.61%, Test: 13.43%
Epoch: 250, Loss: 71.7717, Train: 13.95%, Valid: 14.05%, Test: 13.90%
Epoch: 275, Loss: 708.2984, Train: 16.17%, Valid: 16.32%, Test: 16.08%
Epoch: 300, Loss: 135.8699, Train: 16.15%, Valid: 16.31%, Test: 16.07%
Epoch: 325, Loss: 103.3663, Train: 13.54%, Valid: 13.71%, Test: 13.54%
Epoch: 350, Loss: 1.7099, Train: 84.24%, Valid: 84.18%, Test: 84.39%
Epoch: 375, Loss: 70.3575, Train: 13.62%, Valid: 13.74%, Test: 13.59%
Epoch: 400, Loss: 40.7002, Train: 14.63%, Valid: 14.80%, Test: 14.57%
Epoch: 425, Loss: 89.6910, Train: 16.40%, Valid: 16.55%, Test: 16.34%
Epoch: 450, Loss: 38.3516, Train: 16.20%, Valid: 16.35%, Test: 16.09%
Epoch: 475, Loss: 804.9766, Train: 13.54%, Valid: 13.67%, Test: 13.52%
Epoch: 500, Loss: 1018.3774, Train: 13.50%, Valid: 13.64%, Test: 13.47%
Epoch: 525, Loss: 100.1867, Train: 85.52%, Valid: 85.53%, Test: 85.57%
Epoch: 550, Loss: 11.0273, Train: 13.53%, Valid: 13.64%, Test: 13.48%
Epoch: 575, Loss: 3719.2700, Train: 16.22%, Valid: 16.38%, Test: 16.13%
Epoch: 600, Loss: 0.7368, Train: 14.03%, Valid: 14.20%, Test: 14.02%
Epoch: 625, Loss: 28.2472, Train: 84.74%, Valid: 84.80%, Test: 84.82%
Epoch: 650, Loss: 24.8894, Train: 16.44%, Valid: 16.58%, Test: 16.37%
Epoch: 675, Loss: 57.3503, Train: 15.59%, Valid: 15.74%, Test: 15.50%
Epoch: 700, Loss: 12.1316, Train: 16.40%, Valid: 16.55%, Test: 16.32%
Epoch: 725, Loss: 205.3206, Train: 16.48%, Valid: 16.61%, Test: 16.42%
Epoch: 750, Loss: 76.8924, Train: 16.21%, Valid: 16.37%, Test: 16.12%
Epoch: 775, Loss: 81.7148, Train: 84.56%, Valid: 84.61%, Test: 84.61%
Epoch: 800, Loss: 28.4052, Train: 13.56%, Valid: 13.69%, Test: 13.52%
Epoch: 825, Loss: 197.0183, Train: 13.44%, Valid: 13.59%, Test: 13.42%
Epoch: 850, Loss: 1.1856, Train: 13.49%, Valid: 13.61%, Test: 13.45%
Epoch: 875, Loss: 83.6672, Train: 13.21%, Valid: 13.34%, Test: 13.19%
Epoch: 900, Loss: 4885.2656, Train: 85.57%, Valid: 85.58%, Test: 85.62%
Epoch: 925, Loss: 183.7369, Train: 13.50%, Valid: 13.64%, Test: 13.47%
Epoch: 950, Loss: 71.8923, Train: 16.47%, Valid: 16.60%, Test: 16.41%
Epoch: 975, Loss: 5379.3911, Train: 16.28%, Valid: 16.43%, Test: 16.20%
Run 01:
Highest Train: 86.90
Highest Valid: 86.87
  Final Train: 86.90
   Final Test: 86.94
All runs:
Highest Train: 86.90 ± nan
Highest Valid: 86.87 ± nan
  Final Train: 86.90 ± nan
   Final Test: 86.94 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.3728, Train: 86.85%, Valid: 86.83%, Test: 86.98%
Epoch: 25, Loss: 331.1170, Train: 84.63%, Valid: 84.46%, Test: 84.74%
Epoch: 50, Loss: 55.7898, Train: 84.42%, Valid: 84.22%, Test: 84.53%
Epoch: 75, Loss: 24.2629, Train: 85.73%, Valid: 85.56%, Test: 85.73%
Epoch: 100, Loss: 20.9478, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 125, Loss: 20.0006, Train: 85.74%, Valid: 85.58%, Test: 85.74%
Epoch: 150, Loss: 20.2982, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 175, Loss: 19.1800, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 200, Loss: 18.7097, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 225, Loss: 21.1230, Train: 85.74%, Valid: 85.58%, Test: 85.74%
Epoch: 250, Loss: 20.0743, Train: 85.74%, Valid: 85.58%, Test: 85.74%
Epoch: 275, Loss: 19.3398, Train: 85.75%, Valid: 85.58%, Test: 85.74%
Epoch: 300, Loss: 20.0766, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 325, Loss: 19.9234, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 350, Loss: 19.7561, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 375, Loss: 19.4696, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 400, Loss: 20.1791, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 425, Loss: 19.5227, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 450, Loss: 21.4490, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 475, Loss: 19.2555, Train: 85.75%, Valid: 85.58%, Test: 85.74%
Epoch: 500, Loss: 20.4899, Train: 85.74%, Valid: 85.58%, Test: 85.74%
Epoch: 525, Loss: 19.9401, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 550, Loss: 22.4167, Train: 85.74%, Valid: 85.58%, Test: 85.74%
Epoch: 575, Loss: 19.9915, Train: 85.75%, Valid: 85.58%, Test: 85.74%
Epoch: 600, Loss: 23.0795, Train: 85.75%, Valid: 85.58%, Test: 85.74%
Epoch: 625, Loss: 19.3548, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 650, Loss: 19.9123, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 675, Loss: 18.9390, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 700, Loss: 20.1321, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 725, Loss: 19.4443, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 750, Loss: 20.0185, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 775, Loss: 18.2852, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 800, Loss: 19.0785, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 825, Loss: 18.8487, Train: 85.75%, Valid: 85.58%, Test: 85.74%
Epoch: 850, Loss: 21.1334, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 875, Loss: 20.3874, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 900, Loss: 18.8442, Train: 85.75%, Valid: 85.58%, Test: 85.75%
Epoch: 925, Loss: 20.9137, Train: 85.74%, Valid: 85.58%, Test: 85.74%
Epoch: 950, Loss: 19.4629, Train: 85.74%, Valid: 85.58%, Test: 85.74%
Epoch: 975, Loss: 18.8380, Train: 85.74%, Valid: 85.58%, Test: 85.74%
Run 01:
Highest Train: 87.19
Highest Valid: 87.26
  Final Train: 87.19
   Final Test: 87.27
All runs:
Highest Train: 87.19 ± nan
Highest Valid: 87.26 ± nan
  Final Train: 87.19 ± nan
   Final Test: 87.27 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.4099, Train: 86.62%, Valid: 86.65%, Test: 86.67%
Epoch: 25, Loss: 2.1088, Train: 85.92%, Valid: 85.80%, Test: 85.99%
Epoch: 50, Loss: 2.0528, Train: 85.88%, Valid: 85.76%, Test: 85.90%
Epoch: 75, Loss: 2.0712, Train: 86.14%, Valid: 86.05%, Test: 86.15%
Epoch: 100, Loss: 1.9745, Train: 86.14%, Valid: 86.05%, Test: 86.15%
Epoch: 125, Loss: 1.9034, Train: 85.80%, Valid: 85.69%, Test: 85.89%
Epoch: 150, Loss: 1.5188, Train: 85.78%, Valid: 85.67%, Test: 85.87%
Epoch: 175, Loss: 0.4411, Train: 84.16%, Valid: 84.04%, Test: 84.26%
Epoch: 200, Loss: 0.3862, Train: 84.65%, Valid: 84.54%, Test: 84.74%
Epoch: 225, Loss: 0.3809, Train: 84.83%, Valid: 84.72%, Test: 84.92%
Epoch: 250, Loss: 0.3764, Train: 85.17%, Valid: 85.05%, Test: 85.25%
Epoch: 275, Loss: 0.3724, Train: 85.26%, Valid: 85.14%, Test: 85.38%
Epoch: 300, Loss: 0.3687, Train: 85.33%, Valid: 85.20%, Test: 85.43%
Epoch: 325, Loss: 0.3654, Train: 85.80%, Valid: 85.62%, Test: 85.89%
Epoch: 350, Loss: 0.3624, Train: 85.78%, Valid: 85.59%, Test: 85.88%
Epoch: 375, Loss: 0.3594, Train: 85.48%, Valid: 85.34%, Test: 85.64%
Epoch: 400, Loss: 0.3562, Train: 85.10%, Valid: 85.05%, Test: 85.31%
Epoch: 425, Loss: 0.3529, Train: 85.33%, Valid: 85.25%, Test: 85.52%
Epoch: 450, Loss: 0.3502, Train: 86.80%, Valid: 86.69%, Test: 86.92%
Epoch: 475, Loss: 0.3484, Train: 85.94%, Valid: 85.86%, Test: 86.08%
Epoch: 500, Loss: 0.3473, Train: 86.44%, Valid: 86.44%, Test: 86.61%
Epoch: 525, Loss: 0.3524, Train: 85.84%, Valid: 85.71%, Test: 85.95%
Epoch: 550, Loss: 0.3477, Train: 87.21%, Valid: 87.12%, Test: 87.29%
Epoch: 575, Loss: 0.3457, Train: 86.92%, Valid: 86.81%, Test: 87.04%
Epoch: 600, Loss: 0.3443, Train: 86.49%, Valid: 86.41%, Test: 86.65%
Epoch: 625, Loss: 0.3427, Train: 85.82%, Valid: 85.70%, Test: 85.95%
Epoch: 650, Loss: 0.3415, Train: 85.51%, Valid: 85.39%, Test: 85.67%
Epoch: 675, Loss: 0.4179, Train: 85.67%, Valid: 85.55%, Test: 85.77%
Epoch: 700, Loss: 0.3459, Train: 87.18%, Valid: 87.04%, Test: 87.25%
Epoch: 725, Loss: 0.3431, Train: 87.01%, Valid: 86.91%, Test: 87.11%
Epoch: 750, Loss: 0.3416, Train: 86.40%, Valid: 86.31%, Test: 86.54%
Epoch: 775, Loss: 0.3405, Train: 86.39%, Valid: 86.31%, Test: 86.55%
Epoch: 800, Loss: 0.3395, Train: 86.26%, Valid: 86.19%, Test: 86.41%
Epoch: 825, Loss: 0.3388, Train: 86.01%, Valid: 85.89%, Test: 86.10%
Epoch: 850, Loss: 0.3379, Train: 85.99%, Valid: 85.85%, Test: 86.07%
Epoch: 875, Loss: 0.3375, Train: 85.98%, Valid: 85.82%, Test: 86.04%
Epoch: 900, Loss: 0.3367, Train: 86.07%, Valid: 85.93%, Test: 86.13%
Epoch: 925, Loss: 0.3361, Train: 85.98%, Valid: 85.83%, Test: 86.04%
Epoch: 950, Loss: 0.3354, Train: 86.10%, Valid: 85.98%, Test: 86.16%
Epoch: 975, Loss: 0.3811, Train: 85.79%, Valid: 85.60%, Test: 85.92%
Run 01:
Highest Train: 87.30
Highest Valid: 87.17
  Final Train: 87.25
   Final Test: 87.34
All runs:
Highest Train: 87.30 ± nan
Highest Valid: 87.17 ± nan
  Final Train: 87.25 ± nan
   Final Test: 87.34 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 34.6476, Train: 14.84%, Valid: 14.84%, Test: 14.75%
Epoch: 25, Loss: 3347345.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 50, Loss: 2822772621312.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 75, Loss: 7938692.5000, Train: 49.97%, Valid: 49.96%, Test: 49.97%
Epoch: 100, Loss: 836822.4375, Train: 15.83%, Valid: 15.86%, Test: 15.67%
Epoch: 125, Loss: 15276.8564, Train: 16.27%, Valid: 16.43%, Test: 16.18%
Epoch: 150, Loss: 56277.2891, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 175, Loss: 4512.7881, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 200, Loss: 40813.3945, Train: 15.44%, Valid: 15.58%, Test: 15.29%
Epoch: 225, Loss: 3085.4231, Train: 15.83%, Valid: 15.86%, Test: 15.68%
Epoch: 250, Loss: 828.6887, Train: 16.26%, Valid: 16.41%, Test: 16.17%
Epoch: 275, Loss: 618.2885, Train: 15.81%, Valid: 15.85%, Test: 15.66%
Epoch: 300, Loss: 172.8674, Train: 50.21%, Valid: 50.18%, Test: 50.21%
Epoch: 325, Loss: 25557.2441, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 350, Loss: 453.9204, Train: 84.39%, Valid: 84.23%, Test: 84.47%
Epoch: 375, Loss: 344.3859, Train: 15.43%, Valid: 15.57%, Test: 15.28%
Epoch: 400, Loss: 316.1798, Train: 84.39%, Valid: 84.29%, Test: 84.55%
Epoch: 425, Loss: 457.1096, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 450, Loss: 384.9874, Train: 83.62%, Valid: 83.48%, Test: 83.67%
Epoch: 475, Loss: 9738.5967, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 500, Loss: 35885.7461, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 525, Loss: 4913.1851, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 550, Loss: 21559.1504, Train: 50.21%, Valid: 50.18%, Test: 50.21%
Epoch: 575, Loss: 284393.7188, Train: 15.80%, Valid: 15.89%, Test: 15.68%
Epoch: 600, Loss: 407707.7500, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 625, Loss: 343228.9062, Train: 84.28%, Valid: 84.21%, Test: 84.45%
Epoch: 650, Loss: 44097.5625, Train: 49.79%, Valid: 49.82%, Test: 49.79%
Epoch: 675, Loss: 965.6550, Train: 15.68%, Valid: 15.74%, Test: 15.52%
Epoch: 700, Loss: 659440.0000, Train: 50.20%, Valid: 50.18%, Test: 50.21%
Epoch: 725, Loss: 775.9296, Train: 15.85%, Valid: 15.90%, Test: 15.70%
Epoch: 750, Loss: 8698.4492, Train: 15.59%, Valid: 15.68%, Test: 15.43%
Epoch: 775, Loss: 756309.7500, Train: 15.61%, Valid: 15.69%, Test: 15.44%
Epoch: 800, Loss: 3792.8835, Train: 85.72%, Valid: 85.69%, Test: 85.84%
Epoch: 825, Loss: 4549.4263, Train: 15.82%, Valid: 15.87%, Test: 15.67%
Epoch: 850, Loss: 5041.8477, Train: 15.91%, Valid: 15.93%, Test: 15.78%
Epoch: 875, Loss: 911662.8750, Train: 15.41%, Valid: 15.53%, Test: 15.25%
Epoch: 900, Loss: 18469994.0000, Train: 49.80%, Valid: 49.82%, Test: 49.79%
Epoch: 925, Loss: 317068.2188, Train: 15.65%, Valid: 15.82%, Test: 15.54%
Epoch: 950, Loss: 296356.9688, Train: 85.63%, Valid: 85.54%, Test: 85.65%
Epoch: 975, Loss: 376442.3438, Train: 84.43%, Valid: 84.35%, Test: 84.60%
Run 01:
Highest Train: 87.02
Highest Valid: 86.86
  Final Train: 86.83
   Final Test: 86.88
All runs:
Highest Train: 87.02 ± nan
Highest Valid: 86.86 ± nan
  Final Train: 86.83 ± nan
   Final Test: 86.88 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.4276, Train: 84.28%, Valid: 84.14%, Test: 84.39%
Epoch: 25, Loss: 2.9274, Train: 86.23%, Valid: 86.34%, Test: 86.28%
Epoch: 50, Loss: 2.8392, Train: 85.77%, Valid: 85.63%, Test: 85.80%
Epoch: 75, Loss: 2.7001, Train: 85.92%, Valid: 85.79%, Test: 85.96%
Epoch: 100, Loss: 2.4545, Train: 85.76%, Valid: 85.64%, Test: 85.80%
Epoch: 125, Loss: 0.9627, Train: 85.02%, Valid: 84.94%, Test: 85.06%
Epoch: 150, Loss: 0.4635, Train: 85.36%, Valid: 85.38%, Test: 85.49%
Epoch: 175, Loss: 0.3858, Train: 85.65%, Valid: 85.68%, Test: 85.77%
Epoch: 200, Loss: 1.1031, Train: 87.30%, Valid: 87.16%, Test: 87.30%
Epoch: 225, Loss: 0.5006, Train: 86.41%, Valid: 86.43%, Test: 86.50%
Epoch: 250, Loss: 0.8912, Train: 87.12%, Valid: 86.92%, Test: 87.14%
Epoch: 275, Loss: 0.4493, Train: 87.44%, Valid: 87.34%, Test: 87.54%
Epoch: 300, Loss: 0.3695, Train: 85.71%, Valid: 85.74%, Test: 85.83%
Epoch: 325, Loss: 0.3593, Train: 85.55%, Valid: 85.50%, Test: 85.68%
Epoch: 350, Loss: 0.3496, Train: 85.90%, Valid: 85.92%, Test: 86.03%
Epoch: 375, Loss: 0.3414, Train: 85.90%, Valid: 85.91%, Test: 86.02%
Epoch: 400, Loss: 0.6001, Train: 86.77%, Valid: 86.74%, Test: 86.80%
Epoch: 425, Loss: 2.5079, Train: 86.74%, Valid: 86.76%, Test: 86.79%
Epoch: 450, Loss: 0.6611, Train: 85.97%, Valid: 85.95%, Test: 86.08%
Epoch: 475, Loss: 0.8340, Train: 85.91%, Valid: 85.77%, Test: 85.91%
Epoch: 500, Loss: 2.7997, Train: 85.76%, Valid: 85.62%, Test: 85.79%
Epoch: 525, Loss: 2.8122, Train: 84.51%, Valid: 84.35%, Test: 84.66%
Epoch: 550, Loss: 1464.3903, Train: 17.05%, Valid: 17.18%, Test: 16.93%
Epoch: 575, Loss: 940.6800, Train: 17.48%, Valid: 17.59%, Test: 17.38%
Epoch: 600, Loss: 8.0542, Train: 86.19%, Valid: 86.19%, Test: 86.19%
Epoch: 625, Loss: 9.3420, Train: 86.18%, Valid: 86.16%, Test: 86.18%
Epoch: 650, Loss: 8.7322, Train: 86.13%, Valid: 86.15%, Test: 86.16%
Epoch: 675, Loss: 8.1762, Train: 85.98%, Valid: 85.97%, Test: 86.02%
Epoch: 700, Loss: 7.6363, Train: 85.78%, Valid: 85.80%, Test: 85.88%
Epoch: 725, Loss: 7.1225, Train: 85.42%, Valid: 85.46%, Test: 85.53%
Epoch: 750, Loss: 6.6182, Train: 85.37%, Valid: 85.37%, Test: 85.46%
Epoch: 775, Loss: 6.0924, Train: 85.36%, Valid: 85.39%, Test: 85.48%
Epoch: 800, Loss: 5.5210, Train: 85.36%, Valid: 85.38%, Test: 85.47%
Epoch: 825, Loss: 4.8821, Train: 85.39%, Valid: 85.40%, Test: 85.47%
Epoch: 850, Loss: 4.1480, Train: 85.37%, Valid: 85.39%, Test: 85.48%
Epoch: 875, Loss: 3.2708, Train: 85.40%, Valid: 85.41%, Test: 85.48%
Epoch: 900, Loss: 2.1921, Train: 85.15%, Valid: 85.13%, Test: 85.27%
Epoch: 925, Loss: 0.8409, Train: 85.28%, Valid: 85.25%, Test: 85.40%
Epoch: 950, Loss: 0.6217, Train: 85.43%, Valid: 85.40%, Test: 85.54%
Epoch: 975, Loss: 0.5291, Train: 85.85%, Valid: 85.85%, Test: 85.95%
Run 01:
Highest Train: 88.26
Highest Valid: 88.37
  Final Train: 88.26
   Final Test: 88.40
All runs:
Highest Train: 88.26 ± nan
Highest Valid: 88.37 ± nan
  Final Train: 88.26 ± nan
   Final Test: 88.40 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 36.5286, Train: 85.81%, Valid: 85.71%, Test: 85.84%
Epoch: 25, Loss: 3.0497, Train: 85.75%, Valid: 85.65%, Test: 85.85%
Epoch: 50, Loss: 3.1128, Train: 85.84%, Valid: 85.73%, Test: 85.94%
Epoch: 75, Loss: 2.7138, Train: 85.81%, Valid: 85.71%, Test: 85.90%
Epoch: 100, Loss: 0.5349, Train: 85.65%, Valid: 85.52%, Test: 85.75%
Epoch: 125, Loss: 0.6279, Train: 85.95%, Valid: 85.99%, Test: 85.99%
Epoch: 150, Loss: 1.1451, Train: 85.49%, Valid: 85.55%, Test: 85.56%
Epoch: 175, Loss: 0.9857, Train: 85.27%, Valid: 85.30%, Test: 85.34%
Epoch: 200, Loss: 1.4763, Train: 85.41%, Valid: 85.41%, Test: 85.46%
Epoch: 225, Loss: 1.2448, Train: 85.44%, Valid: 85.47%, Test: 85.49%
Epoch: 250, Loss: 0.7335, Train: 85.67%, Valid: 85.71%, Test: 85.75%
Epoch: 275, Loss: 0.3611, Train: 85.86%, Valid: 85.70%, Test: 86.02%
Epoch: 300, Loss: 3.4509, Train: 85.73%, Valid: 85.62%, Test: 85.85%
Epoch: 325, Loss: 4.3449, Train: 86.43%, Valid: 86.43%, Test: 86.49%
Epoch: 350, Loss: 2.3471, Train: 86.34%, Valid: 86.29%, Test: 86.40%
Epoch: 375, Loss: 3.2420, Train: 86.02%, Valid: 85.98%, Test: 86.06%
Epoch: 400, Loss: 2.8283, Train: 86.03%, Valid: 85.98%, Test: 86.05%
Epoch: 425, Loss: 1.4774, Train: 86.11%, Valid: 86.09%, Test: 86.20%
Epoch: 450, Loss: 0.4830, Train: 85.52%, Valid: 85.38%, Test: 85.65%
Epoch: 475, Loss: 0.4264, Train: 85.80%, Valid: 85.67%, Test: 85.94%
Epoch: 500, Loss: 0.3897, Train: 86.07%, Valid: 85.93%, Test: 86.19%
Epoch: 525, Loss: 0.3636, Train: 85.92%, Valid: 85.71%, Test: 86.04%
Epoch: 550, Loss: 0.3740, Train: 86.25%, Valid: 86.05%, Test: 86.33%
Epoch: 575, Loss: 1.8256, Train: 86.80%, Valid: 86.80%, Test: 86.80%
Epoch: 600, Loss: 1.3173, Train: 87.16%, Valid: 87.12%, Test: 87.17%
Epoch: 625, Loss: 0.6315, Train: 87.23%, Valid: 87.20%, Test: 87.23%
Epoch: 650, Loss: 0.3665, Train: 86.09%, Valid: 85.91%, Test: 86.18%
Epoch: 675, Loss: 0.3443, Train: 86.17%, Valid: 85.99%, Test: 86.25%
Epoch: 700, Loss: 0.3350, Train: 86.05%, Valid: 85.86%, Test: 86.14%
Epoch: 725, Loss: 0.3923, Train: 87.21%, Valid: 87.06%, Test: 87.24%
Epoch: 750, Loss: 0.3696, Train: 86.65%, Valid: 86.59%, Test: 86.74%
Epoch: 775, Loss: 0.3423, Train: 86.13%, Valid: 85.90%, Test: 86.23%
Epoch: 800, Loss: 0.3305, Train: 86.17%, Valid: 85.95%, Test: 86.27%
Epoch: 825, Loss: 2.8593, Train: 85.90%, Valid: 85.79%, Test: 86.05%
Epoch: 850, Loss: 399.3766, Train: 86.90%, Valid: 86.76%, Test: 86.93%
Epoch: 875, Loss: 2521.5430, Train: 16.88%, Valid: 17.03%, Test: 16.78%
Epoch: 900, Loss: 2821.3074, Train: 16.84%, Valid: 16.98%, Test: 16.73%
Epoch: 925, Loss: 659.4353, Train: 15.62%, Valid: 15.73%, Test: 15.50%
Epoch: 950, Loss: 5216.4575, Train: 16.36%, Valid: 16.49%, Test: 16.17%
Epoch: 975, Loss: 5065.7480, Train: 16.18%, Valid: 16.35%, Test: 16.00%
Run 01:
Highest Train: 87.80
Highest Valid: 87.74
  Final Train: 87.78
   Final Test: 87.80
All runs:
Highest Train: 87.80 ± nan
Highest Valid: 87.74 ± nan
  Final Train: 87.78 ± nan
   Final Test: 87.80 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.1731, Train: 85.82%, Valid: 85.70%, Test: 85.88%
Epoch: 25, Loss: 3.6112, Train: 86.16%, Valid: 86.01%, Test: 86.20%
Epoch: 50, Loss: 3.6339, Train: 86.25%, Valid: 86.08%, Test: 86.35%
Epoch: 75, Loss: 2.4760, Train: 85.61%, Valid: 85.44%, Test: 85.69%
Epoch: 100, Loss: 0.4953, Train: 85.02%, Valid: 84.86%, Test: 85.08%
Epoch: 125, Loss: 0.4267, Train: 84.47%, Valid: 84.46%, Test: 84.69%
Epoch: 150, Loss: 0.3835, Train: 84.47%, Valid: 84.50%, Test: 84.69%
Epoch: 175, Loss: 0.5069, Train: 85.68%, Valid: 85.51%, Test: 85.73%
Epoch: 200, Loss: 0.3694, Train: 85.27%, Valid: 85.18%, Test: 85.40%
Epoch: 225, Loss: 0.3439, Train: 86.28%, Valid: 86.13%, Test: 86.36%
Epoch: 250, Loss: 0.6104, Train: 85.61%, Valid: 85.42%, Test: 85.64%
Epoch: 275, Loss: 3.1947, Train: 85.76%, Valid: 85.57%, Test: 85.77%
Epoch: 300, Loss: 2.4313, Train: 85.71%, Valid: 85.49%, Test: 85.73%
Epoch: 325, Loss: 0.5246, Train: 85.69%, Valid: 85.46%, Test: 85.70%
Epoch: 350, Loss: 0.3961, Train: 85.15%, Valid: 84.93%, Test: 85.24%
Epoch: 375, Loss: 0.3897, Train: 85.68%, Valid: 85.45%, Test: 85.74%
Epoch: 400, Loss: 0.3516, Train: 85.75%, Valid: 85.51%, Test: 85.82%
Epoch: 425, Loss: 0.3372, Train: 85.73%, Valid: 85.48%, Test: 85.80%
Epoch: 450, Loss: 1.5756, Train: 87.16%, Valid: 87.22%, Test: 87.25%
Epoch: 475, Loss: 1.5464, Train: 86.31%, Valid: 86.13%, Test: 86.33%
Epoch: 500, Loss: 1.3783, Train: 86.23%, Valid: 86.08%, Test: 86.26%
Epoch: 525, Loss: 1.3693, Train: 85.75%, Valid: 85.56%, Test: 85.75%
Epoch: 550, Loss: 0.4015, Train: 85.85%, Valid: 85.66%, Test: 85.91%
Epoch: 575, Loss: 1.5490, Train: 86.03%, Valid: 86.01%, Test: 86.26%
Epoch: 600, Loss: 4.7431, Train: 86.52%, Valid: 86.50%, Test: 86.72%
Epoch: 625, Loss: 0.7974, Train: 86.90%, Valid: 86.90%, Test: 87.04%
Epoch: 650, Loss: 5.7259, Train: 86.27%, Valid: 86.23%, Test: 86.48%
Epoch: 675, Loss: 4.6528, Train: 86.59%, Valid: 86.57%, Test: 86.80%
Epoch: 700, Loss: 3.2496, Train: 86.84%, Valid: 86.83%, Test: 86.98%
Epoch: 725, Loss: 1.9132, Train: 86.48%, Valid: 86.45%, Test: 86.60%
Epoch: 750, Loss: 1.0854, Train: 86.11%, Valid: 86.09%, Test: 86.24%
Epoch: 775, Loss: 0.4135, Train: 86.43%, Valid: 86.37%, Test: 86.55%
Epoch: 800, Loss: 2.0823, Train: 86.63%, Valid: 86.51%, Test: 86.58%
Epoch: 825, Loss: 1.6696, Train: 86.89%, Valid: 86.78%, Test: 86.82%
Epoch: 850, Loss: 0.5843, Train: 85.44%, Valid: 85.45%, Test: 85.60%
Epoch: 875, Loss: 0.5352, Train: 84.55%, Valid: 84.52%, Test: 84.77%
Epoch: 900, Loss: 0.3738, Train: 85.84%, Valid: 85.72%, Test: 86.01%
Epoch: 925, Loss: 0.3427, Train: 86.44%, Valid: 86.38%, Test: 86.58%
Epoch: 950, Loss: 2.6628, Train: 86.22%, Valid: 86.02%, Test: 86.26%
Epoch: 975, Loss: 1.7340, Train: 86.35%, Valid: 86.15%, Test: 86.34%
Run 01:
Highest Train: 88.05
Highest Valid: 87.92
  Final Train: 88.05
   Final Test: 87.95
All runs:
Highest Train: 88.05 ± nan
Highest Valid: 87.92 ± nan
  Final Train: 88.05 ± nan
   Final Test: 87.95 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.4773, Train: 85.18%, Valid: 85.15%, Test: 85.31%
Epoch: 25, Loss: 0.6697, Train: 88.32%, Valid: 88.37%, Test: 88.33%
Epoch: 50, Loss: 1.6536, Train: 88.03%, Valid: 88.05%, Test: 88.00%
Epoch: 75, Loss: 3535096.5000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 4.8215, Train: 87.93%, Valid: 87.97%, Test: 87.91%
Epoch: 125, Loss: 9451307.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 150, Loss: 116741608.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 175, Loss: 589807.3125, Train: 86.77%, Valid: 86.77%, Test: 86.74%
Epoch: 200, Loss: 1050685.1250, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 225, Loss: 1805.2346, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 250, Loss: 26499724.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 275, Loss: 9800098.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 300, Loss: 3466180.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 487978.6250, Train: 86.70%, Valid: 86.71%, Test: 86.68%
Epoch: 350, Loss: 7143486.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 375, Loss: 1642.5066, Train: 16.44%, Valid: 16.63%, Test: 16.32%
Epoch: 400, Loss: 409.3468, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 346031.3125, Train: 85.29%, Valid: 85.28%, Test: 85.37%
Epoch: 450, Loss: 86479.2422, Train: 86.77%, Valid: 86.77%, Test: 86.74%
Epoch: 475, Loss: 71115.5312, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 500, Loss: 1798.4225, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 525, Loss: 147956.0469, Train: 86.76%, Valid: 86.76%, Test: 86.73%
Epoch: 550, Loss: 18786054.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 575, Loss: 2484.0928, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 600, Loss: 36100.9297, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 625, Loss: 142671952.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 650, Loss: 5354.8071, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 675, Loss: 135741.8438, Train: 86.68%, Valid: 86.68%, Test: 86.65%
Epoch: 700, Loss: 1302054.2500, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 725, Loss: 37557080.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 750, Loss: 12039.4238, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 775, Loss: 60527.4844, Train: 85.40%, Valid: 85.37%, Test: 85.48%
Epoch: 800, Loss: 3247.2583, Train: 86.77%, Valid: 86.77%, Test: 86.75%
Epoch: 825, Loss: 24486.6797, Train: 86.77%, Valid: 86.77%, Test: 86.74%
Epoch: 850, Loss: 21092.6621, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 875, Loss: 22045.0527, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 900, Loss: 6.5065, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 925, Loss: 34524.0039, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 950, Loss: 61441.2695, Train: 85.33%, Valid: 85.31%, Test: 85.41%
Epoch: 975, Loss: 874.6653, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Run 01:
Highest Train: 88.32
Highest Valid: 88.37
  Final Train: 88.32
   Final Test: 88.33
All runs:
Highest Train: 88.32 ± nan
Highest Valid: 88.37 ± nan
  Final Train: 88.32 ± nan
   Final Test: 88.33 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 3.5793, Train: 86.76%, Valid: 86.73%, Test: 86.79%
Epoch: 25, Loss: 4.1440, Train: 85.96%, Valid: 85.85%, Test: 86.05%
Epoch: 50, Loss: 1.8298, Train: 86.03%, Valid: 85.92%, Test: 86.11%
Epoch: 75, Loss: 1.9662, Train: 86.16%, Valid: 86.04%, Test: 86.24%
Epoch: 100, Loss: 3.1322, Train: 85.91%, Valid: 85.79%, Test: 85.99%
Epoch: 125, Loss: 3.1412, Train: 85.91%, Valid: 85.79%, Test: 86.00%
Epoch: 150, Loss: 2.9015, Train: 85.93%, Valid: 85.81%, Test: 86.01%
Epoch: 175, Loss: 2.6055, Train: 85.91%, Valid: 85.79%, Test: 86.00%
Epoch: 200, Loss: 2.0751, Train: 85.92%, Valid: 85.80%, Test: 86.01%
Epoch: 225, Loss: 1.4567, Train: 85.92%, Valid: 85.80%, Test: 86.01%
Epoch: 250, Loss: 0.6733, Train: 85.57%, Valid: 85.48%, Test: 85.67%
Epoch: 275, Loss: 0.3898, Train: 85.23%, Valid: 85.22%, Test: 85.33%
Epoch: 300, Loss: 0.3802, Train: 85.07%, Valid: 85.08%, Test: 85.16%
Epoch: 325, Loss: 0.3786, Train: 85.07%, Valid: 85.07%, Test: 85.17%
Epoch: 350, Loss: 0.3777, Train: 85.04%, Valid: 85.04%, Test: 85.15%
Epoch: 375, Loss: 0.3771, Train: 85.03%, Valid: 85.03%, Test: 85.14%
Epoch: 400, Loss: 0.3765, Train: 85.00%, Valid: 85.00%, Test: 85.11%
Epoch: 425, Loss: 0.3760, Train: 84.96%, Valid: 84.96%, Test: 85.08%
Epoch: 450, Loss: 0.3754, Train: 84.91%, Valid: 84.91%, Test: 85.02%
Epoch: 475, Loss: 0.3749, Train: 84.82%, Valid: 84.84%, Test: 84.93%
Epoch: 500, Loss: 0.3743, Train: 84.83%, Valid: 84.85%, Test: 84.95%
Epoch: 525, Loss: 0.3737, Train: 84.86%, Valid: 84.88%, Test: 84.97%
Epoch: 550, Loss: 0.3732, Train: 84.87%, Valid: 84.90%, Test: 84.99%
Epoch: 575, Loss: 0.3726, Train: 84.99%, Valid: 84.98%, Test: 85.10%
Epoch: 600, Loss: 0.3720, Train: 85.00%, Valid: 85.00%, Test: 85.12%
Epoch: 625, Loss: 0.3714, Train: 85.03%, Valid: 85.03%, Test: 85.15%
Epoch: 650, Loss: 0.3707, Train: 85.07%, Valid: 85.07%, Test: 85.19%
Epoch: 675, Loss: 0.3701, Train: 85.14%, Valid: 85.13%, Test: 85.26%
Epoch: 700, Loss: 0.3687, Train: 85.28%, Valid: 85.29%, Test: 85.43%
Epoch: 725, Loss: 0.3671, Train: 85.35%, Valid: 85.36%, Test: 85.52%
Epoch: 750, Loss: 0.3656, Train: 85.24%, Valid: 85.18%, Test: 85.42%
Epoch: 775, Loss: 0.3642, Train: 85.49%, Valid: 85.41%, Test: 85.66%
Epoch: 800, Loss: 0.3630, Train: 85.51%, Valid: 85.42%, Test: 85.68%
Epoch: 825, Loss: 0.3619, Train: 85.53%, Valid: 85.44%, Test: 85.70%
Epoch: 850, Loss: 0.3608, Train: 85.54%, Valid: 85.45%, Test: 85.70%
Epoch: 875, Loss: 0.3599, Train: 85.53%, Valid: 85.44%, Test: 85.69%
Epoch: 900, Loss: 0.3590, Train: 85.49%, Valid: 85.41%, Test: 85.66%
Epoch: 925, Loss: 0.3581, Train: 85.48%, Valid: 85.40%, Test: 85.64%
Epoch: 950, Loss: 0.3573, Train: 85.48%, Valid: 85.38%, Test: 85.63%
Epoch: 975, Loss: 0.3566, Train: 85.50%, Valid: 85.39%, Test: 85.63%
Run 01:
Highest Train: 86.98
Highest Valid: 86.94
  Final Train: 86.98
   Final Test: 87.08
All runs:
Highest Train: 86.98 ± nan
Highest Valid: 86.94 ± nan
  Final Train: 86.98 ± nan
   Final Test: 87.08 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 11.3845, Train: 14.66%, Valid: 14.78%, Test: 14.60%
Epoch: 25, Loss: 0.9347, Train: 84.32%, Valid: 84.34%, Test: 84.41%
Epoch: 50, Loss: 0.6425, Train: 85.07%, Valid: 84.94%, Test: 85.13%
Epoch: 75, Loss: 0.6110, Train: 85.54%, Valid: 85.34%, Test: 85.58%
Epoch: 100, Loss: 0.5282, Train: 85.74%, Valid: 85.57%, Test: 85.78%
Epoch: 125, Loss: 0.3708, Train: 84.46%, Valid: 84.42%, Test: 84.66%
Epoch: 150, Loss: 0.3652, Train: 86.72%, Valid: 86.70%, Test: 86.80%
Epoch: 175, Loss: 0.3620, Train: 86.98%, Valid: 87.02%, Test: 87.03%
Epoch: 200, Loss: 0.3594, Train: 86.99%, Valid: 87.03%, Test: 87.04%
Epoch: 225, Loss: 0.3562, Train: 87.12%, Valid: 87.17%, Test: 87.15%
Epoch: 250, Loss: 0.3525, Train: 87.13%, Valid: 87.16%, Test: 87.15%
Epoch: 275, Loss: 0.3483, Train: 87.12%, Valid: 87.14%, Test: 87.14%
Epoch: 300, Loss: 0.3441, Train: 86.94%, Valid: 86.96%, Test: 86.95%
Epoch: 325, Loss: 0.3400, Train: 85.21%, Valid: 85.18%, Test: 85.19%
Epoch: 350, Loss: 0.3366, Train: 86.56%, Valid: 86.52%, Test: 86.53%
Epoch: 375, Loss: 0.3338, Train: 86.81%, Valid: 86.79%, Test: 86.80%
Epoch: 400, Loss: 0.3341, Train: 85.38%, Valid: 85.21%, Test: 85.43%
Epoch: 425, Loss: 0.3371, Train: 85.75%, Valid: 85.72%, Test: 85.91%
Epoch: 450, Loss: 0.3353, Train: 85.51%, Valid: 85.30%, Test: 85.59%
Epoch: 475, Loss: 0.3298, Train: 86.74%, Valid: 86.73%, Test: 86.82%
Epoch: 500, Loss: 0.3289, Train: 87.06%, Valid: 86.94%, Test: 87.17%
Epoch: 525, Loss: 0.3399, Train: 87.54%, Valid: 87.35%, Test: 87.60%
Epoch: 550, Loss: 0.3393, Train: 86.97%, Valid: 86.93%, Test: 87.07%
Epoch: 575, Loss: 0.3815, Train: 85.28%, Valid: 85.12%, Test: 85.41%
Epoch: 600, Loss: 0.3427, Train: 86.99%, Valid: 87.01%, Test: 87.06%
Epoch: 625, Loss: 0.3387, Train: 86.61%, Valid: 86.53%, Test: 86.70%
Epoch: 650, Loss: 0.3361, Train: 85.73%, Valid: 85.56%, Test: 85.83%
Epoch: 675, Loss: 0.3339, Train: 86.93%, Valid: 86.84%, Test: 87.07%
Epoch: 700, Loss: 0.3319, Train: 87.05%, Valid: 86.97%, Test: 87.19%
Epoch: 725, Loss: 0.3301, Train: 87.05%, Valid: 86.96%, Test: 87.18%
Epoch: 750, Loss: 0.3287, Train: 86.94%, Valid: 86.85%, Test: 87.03%
Epoch: 775, Loss: 0.3275, Train: 86.96%, Valid: 86.88%, Test: 87.05%
Epoch: 800, Loss: 0.3278, Train: 87.01%, Valid: 86.97%, Test: 87.10%
Epoch: 825, Loss: 0.3569, Train: 87.17%, Valid: 87.08%, Test: 87.25%
Epoch: 850, Loss: 0.4104, Train: 87.58%, Valid: 87.48%, Test: 87.62%
Epoch: 875, Loss: 0.3392, Train: 87.01%, Valid: 87.00%, Test: 87.09%
Epoch: 900, Loss: 0.3323, Train: 87.46%, Valid: 87.33%, Test: 87.57%
Epoch: 925, Loss: 0.3300, Train: 87.24%, Valid: 87.14%, Test: 87.38%
Epoch: 950, Loss: 0.3286, Train: 87.26%, Valid: 87.16%, Test: 87.40%
Epoch: 975, Loss: 0.3276, Train: 87.22%, Valid: 87.13%, Test: 87.35%
Run 01:
Highest Train: 88.04
Highest Valid: 87.87
  Final Train: 88.04
   Final Test: 88.10
All runs:
Highest Train: 88.04 ± nan
Highest Valid: 87.87 ± nan
  Final Train: 88.04 ± nan
   Final Test: 88.10 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.5057, Train: 87.26%, Valid: 87.32%, Test: 87.33%
Epoch: 25, Loss: 3.0631, Train: 85.68%, Valid: 85.72%, Test: 85.75%
Epoch: 50, Loss: 32.6603, Train: 86.51%, Valid: 86.52%, Test: 86.54%
Epoch: 75, Loss: 6.3110, Train: 86.29%, Valid: 86.35%, Test: 86.31%
Epoch: 100, Loss: 6.7212, Train: 85.70%, Valid: 85.55%, Test: 85.70%
Epoch: 125, Loss: 6.7015, Train: 86.56%, Valid: 86.62%, Test: 86.58%
Epoch: 150, Loss: 6.5731, Train: 86.28%, Valid: 86.34%, Test: 86.34%
Epoch: 175, Loss: 6.5558, Train: 85.98%, Valid: 86.05%, Test: 86.06%
Epoch: 200, Loss: 6.6014, Train: 86.02%, Valid: 86.08%, Test: 86.10%
Epoch: 225, Loss: 6.5693, Train: 86.00%, Valid: 86.06%, Test: 86.08%
Epoch: 250, Loss: 6.5974, Train: 86.03%, Valid: 86.08%, Test: 86.10%
Epoch: 275, Loss: 6.5278, Train: 86.04%, Valid: 86.10%, Test: 86.12%
Epoch: 300, Loss: 6.5639, Train: 86.04%, Valid: 86.10%, Test: 86.12%
Epoch: 325, Loss: 6.5708, Train: 85.89%, Valid: 85.96%, Test: 85.95%
Epoch: 350, Loss: 6.5828, Train: 85.97%, Valid: 86.03%, Test: 86.05%
Epoch: 375, Loss: 6.6367, Train: 86.02%, Valid: 86.08%, Test: 86.10%
Epoch: 400, Loss: 6.6150, Train: 86.05%, Valid: 86.11%, Test: 86.13%
Epoch: 425, Loss: 6.5713, Train: 86.00%, Valid: 86.06%, Test: 86.07%
Epoch: 450, Loss: 6.5721, Train: 86.03%, Valid: 86.08%, Test: 86.11%
Epoch: 475, Loss: 6.5340, Train: 86.04%, Valid: 86.10%, Test: 86.13%
Epoch: 500, Loss: 6.7050, Train: 86.07%, Valid: 86.14%, Test: 86.15%
Epoch: 525, Loss: 6.5556, Train: 86.03%, Valid: 86.09%, Test: 86.11%
Epoch: 550, Loss: 6.4838, Train: 85.95%, Valid: 86.02%, Test: 86.04%
Epoch: 575, Loss: 7.1147, Train: 86.57%, Valid: 86.61%, Test: 86.62%
Epoch: 600, Loss: 1009.4238, Train: 17.65%, Valid: 17.58%, Test: 17.49%
Epoch: 625, Loss: 1392.3973, Train: 17.54%, Valid: 17.49%, Test: 17.42%
Epoch: 650, Loss: 1481.3422, Train: 17.44%, Valid: 17.37%, Test: 17.30%
Epoch: 675, Loss: 1378.8928, Train: 17.55%, Valid: 17.52%, Test: 17.43%
Epoch: 700, Loss: 1466.1278, Train: 17.39%, Valid: 17.33%, Test: 17.25%
Epoch: 725, Loss: 1418.3379, Train: 17.53%, Valid: 17.48%, Test: 17.43%
Epoch: 750, Loss: 1382.1611, Train: 17.53%, Valid: 17.47%, Test: 17.42%
Epoch: 775, Loss: 1462.9451, Train: 17.56%, Valid: 17.51%, Test: 17.44%
Epoch: 800, Loss: 1434.3193, Train: 17.41%, Valid: 17.35%, Test: 17.27%
Epoch: 825, Loss: 1401.1427, Train: 17.41%, Valid: 17.35%, Test: 17.27%
Epoch: 850, Loss: 1400.1676, Train: 17.57%, Valid: 17.50%, Test: 17.43%
Epoch: 875, Loss: 1535.1149, Train: 17.43%, Valid: 17.37%, Test: 17.28%
Epoch: 900, Loss: 1392.0525, Train: 17.45%, Valid: 17.38%, Test: 17.31%
Epoch: 925, Loss: 1366.9397, Train: 17.44%, Valid: 17.39%, Test: 17.31%
Epoch: 950, Loss: 1450.7882, Train: 17.38%, Valid: 17.35%, Test: 17.25%
Epoch: 975, Loss: 1396.8771, Train: 17.55%, Valid: 17.50%, Test: 17.42%
Run 01:
Highest Train: 87.26
Highest Valid: 87.32
  Final Train: 87.26
   Final Test: 87.33
All runs:
Highest Train: 87.26 ± nan
Highest Valid: 87.32 ± nan
  Final Train: 87.26 ± nan
   Final Test: 87.33 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.4221, Train: 85.82%, Valid: 85.75%, Test: 85.87%
Epoch: 25, Loss: 1.5263, Train: 86.65%, Valid: 86.55%, Test: 86.76%
Epoch: 50, Loss: 1.6016, Train: 86.06%, Valid: 85.97%, Test: 86.14%
Epoch: 75, Loss: 0.9599, Train: 86.27%, Valid: 86.21%, Test: 86.39%
Epoch: 100, Loss: 0.7542, Train: 86.25%, Valid: 86.13%, Test: 86.34%
Epoch: 125, Loss: 0.3644, Train: 87.31%, Valid: 87.18%, Test: 87.41%
Epoch: 150, Loss: 0.3528, Train: 87.26%, Valid: 87.12%, Test: 87.36%
Epoch: 175, Loss: 0.3419, Train: 87.45%, Valid: 87.28%, Test: 87.53%
Epoch: 200, Loss: 0.7116, Train: 85.75%, Valid: 85.66%, Test: 85.89%
Epoch: 225, Loss: 2.6492, Train: 86.44%, Valid: 86.34%, Test: 86.45%
Epoch: 250, Loss: 1.4933, Train: 86.72%, Valid: 86.67%, Test: 86.70%
Epoch: 275, Loss: 2.6660, Train: 87.12%, Valid: 87.09%, Test: 87.13%
Epoch: 300, Loss: 1.3091, Train: 87.48%, Valid: 87.43%, Test: 87.44%
Epoch: 325, Loss: 0.5814, Train: 86.83%, Valid: 86.81%, Test: 86.82%
Epoch: 350, Loss: 0.3686, Train: 87.26%, Valid: 87.12%, Test: 87.37%
Epoch: 375, Loss: 0.5788, Train: 85.83%, Valid: 85.85%, Test: 85.94%
Epoch: 400, Loss: 2.6620, Train: 86.04%, Valid: 86.08%, Test: 86.10%
Epoch: 425, Loss: 1.8613, Train: 85.97%, Valid: 85.93%, Test: 85.97%
Epoch: 450, Loss: 0.4216, Train: 85.86%, Valid: 85.83%, Test: 85.97%
Epoch: 475, Loss: 0.4168, Train: 85.73%, Valid: 85.60%, Test: 85.83%
Epoch: 500, Loss: 0.3581, Train: 86.02%, Valid: 85.85%, Test: 86.13%
Epoch: 525, Loss: 2.1348, Train: 86.91%, Valid: 86.97%, Test: 86.94%
Epoch: 550, Loss: 3.0176, Train: 87.09%, Valid: 87.07%, Test: 87.05%
Epoch: 575, Loss: 1.2999, Train: 86.50%, Valid: 86.51%, Test: 86.55%
Epoch: 600, Loss: 0.9080, Train: 87.18%, Valid: 87.26%, Test: 87.24%
Epoch: 625, Loss: 0.4137, Train: 85.78%, Valid: 85.74%, Test: 85.96%
Epoch: 650, Loss: 0.7175, Train: 85.86%, Valid: 85.85%, Test: 85.92%
Epoch: 675, Loss: 3.2440, Train: 85.55%, Valid: 85.57%, Test: 85.63%
Epoch: 700, Loss: 2.6835, Train: 85.63%, Valid: 85.64%, Test: 85.70%
Epoch: 725, Loss: 1.1985, Train: 85.55%, Valid: 85.58%, Test: 85.64%
Epoch: 750, Loss: 0.4065, Train: 86.60%, Valid: 86.58%, Test: 86.83%
Epoch: 775, Loss: 0.3665, Train: 85.87%, Valid: 85.77%, Test: 86.05%
Epoch: 800, Loss: 0.3480, Train: 85.57%, Valid: 85.39%, Test: 85.71%
Epoch: 825, Loss: 0.4870, Train: 86.99%, Valid: 86.86%, Test: 87.08%
Epoch: 850, Loss: 0.4359, Train: 85.90%, Valid: 85.87%, Test: 85.96%
Epoch: 875, Loss: 1.5432, Train: 86.30%, Valid: 86.32%, Test: 86.37%
Epoch: 900, Loss: 0.3700, Train: 86.07%, Valid: 85.93%, Test: 86.18%
Epoch: 925, Loss: 0.4862, Train: 86.31%, Valid: 86.05%, Test: 86.42%
Epoch: 950, Loss: 2.9666, Train: 85.48%, Valid: 85.36%, Test: 85.61%
Epoch: 975, Loss: 4.1648, Train: 86.39%, Valid: 86.34%, Test: 86.40%
Run 01:
Highest Train: 87.63
Highest Valid: 87.57
  Final Train: 87.47
   Final Test: 87.58
All runs:
Highest Train: 87.63 ± nan
Highest Valid: 87.57 ± nan
  Final Train: 87.47 ± nan
   Final Test: 87.58 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 13.9684, Train: 85.97%, Valid: 85.85%, Test: 86.10%
Epoch: 25, Loss: 2.0674, Train: 85.99%, Valid: 85.86%, Test: 86.07%
Epoch: 50, Loss: 1.9425, Train: 86.07%, Valid: 85.92%, Test: 86.14%
Epoch: 75, Loss: 1.2480, Train: 86.20%, Valid: 86.05%, Test: 86.19%
Epoch: 100, Loss: 0.8130, Train: 86.56%, Valid: 86.58%, Test: 86.60%
Epoch: 125, Loss: 0.5329, Train: 86.10%, Valid: 85.93%, Test: 86.09%
Epoch: 150, Loss: 0.3600, Train: 85.87%, Valid: 85.74%, Test: 85.95%
Epoch: 175, Loss: 0.3442, Train: 85.74%, Valid: 85.58%, Test: 85.85%
Epoch: 200, Loss: 0.3566, Train: 86.89%, Valid: 86.84%, Test: 87.05%
Epoch: 225, Loss: 0.3319, Train: 86.80%, Valid: 86.77%, Test: 87.02%
Epoch: 250, Loss: 0.3483, Train: 87.36%, Valid: 87.18%, Test: 87.52%
Epoch: 275, Loss: 0.8095, Train: 85.77%, Valid: 85.63%, Test: 85.85%
Epoch: 300, Loss: 0.3538, Train: 86.98%, Valid: 86.93%, Test: 87.15%
Epoch: 325, Loss: 0.3473, Train: 86.52%, Valid: 86.45%, Test: 86.67%
Epoch: 350, Loss: 0.3323, Train: 86.69%, Valid: 86.60%, Test: 86.81%
Epoch: 375, Loss: 0.3285, Train: 87.50%, Valid: 87.39%, Test: 87.66%
Epoch: 400, Loss: 0.4993, Train: 87.42%, Valid: 87.36%, Test: 87.49%
Epoch: 425, Loss: 0.3451, Train: 85.82%, Valid: 85.64%, Test: 85.91%
Epoch: 450, Loss: 0.3319, Train: 86.34%, Valid: 86.15%, Test: 86.48%
Epoch: 475, Loss: 0.3272, Train: 86.14%, Valid: 85.93%, Test: 86.21%
Epoch: 500, Loss: 0.7306, Train: 87.05%, Valid: 87.09%, Test: 87.17%
Epoch: 525, Loss: 0.5053, Train: 85.72%, Valid: 85.54%, Test: 85.79%
Epoch: 550, Loss: 0.3450, Train: 87.41%, Valid: 87.40%, Test: 87.50%
Epoch: 575, Loss: 0.3361, Train: 87.02%, Valid: 86.95%, Test: 87.15%
Epoch: 600, Loss: 0.3325, Train: 87.23%, Valid: 87.15%, Test: 87.39%
Epoch: 625, Loss: 0.3325, Train: 87.22%, Valid: 87.14%, Test: 87.37%
Epoch: 650, Loss: 0.3310, Train: 87.39%, Valid: 87.29%, Test: 87.54%
Epoch: 675, Loss: 0.3286, Train: 87.49%, Valid: 87.38%, Test: 87.64%
Epoch: 700, Loss: 0.3264, Train: 86.27%, Valid: 86.13%, Test: 86.39%
Epoch: 725, Loss: 0.3252, Train: 86.96%, Valid: 86.87%, Test: 87.05%
Epoch: 750, Loss: 0.3246, Train: 87.10%, Valid: 87.05%, Test: 87.12%
Epoch: 775, Loss: 0.3242, Train: 85.76%, Valid: 85.65%, Test: 85.81%
Epoch: 800, Loss: 0.3254, Train: 86.11%, Valid: 86.00%, Test: 86.15%
Epoch: 825, Loss: 0.6267, Train: 87.09%, Valid: 87.03%, Test: 87.16%
Epoch: 850, Loss: 1.6227, Train: 86.94%, Valid: 86.95%, Test: 87.02%
Epoch: 875, Loss: 0.8969, Train: 86.95%, Valid: 86.94%, Test: 87.01%
Epoch: 900, Loss: 0.4676, Train: 87.59%, Valid: 87.54%, Test: 87.66%
Epoch: 925, Loss: 0.3502, Train: 86.67%, Valid: 86.52%, Test: 86.74%
Epoch: 950, Loss: 0.3406, Train: 86.06%, Valid: 85.89%, Test: 86.21%
Epoch: 975, Loss: 0.3310, Train: 87.09%, Valid: 86.96%, Test: 87.20%
Run 01:
Highest Train: 88.21
Highest Valid: 88.08
  Final Train: 88.21
   Final Test: 88.21
All runs:
Highest Train: 88.21 ± nan
Highest Valid: 88.08 ± nan
  Final Train: 88.21 ± nan
   Final Test: 88.21 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 5.2163, Train: 84.68%, Valid: 84.49%, Test: 84.65%
Epoch: 25, Loss: 3.4146, Train: 86.72%, Valid: 86.67%, Test: 86.75%
Epoch: 50, Loss: 4.3598, Train: 86.14%, Valid: 86.21%, Test: 86.19%
Epoch: 75, Loss: 3.4823, Train: 85.40%, Valid: 85.48%, Test: 85.46%
Epoch: 100, Loss: 0.8332, Train: 83.59%, Valid: 83.69%, Test: 83.63%
Epoch: 125, Loss: 0.5071, Train: 84.71%, Valid: 84.79%, Test: 84.83%
Epoch: 150, Loss: 0.3734, Train: 85.71%, Valid: 85.72%, Test: 85.83%
Epoch: 175, Loss: 1.0780, Train: 85.72%, Valid: 85.57%, Test: 85.79%
Epoch: 200, Loss: 0.6360, Train: 87.42%, Valid: 87.32%, Test: 87.46%
Epoch: 225, Loss: 0.3695, Train: 85.58%, Valid: 85.54%, Test: 85.66%
Epoch: 250, Loss: 0.3391, Train: 85.50%, Valid: 85.51%, Test: 85.56%
Epoch: 275, Loss: 0.3294, Train: 85.59%, Valid: 85.55%, Test: 85.67%
Epoch: 300, Loss: 2.8063, Train: 85.50%, Valid: 85.54%, Test: 85.65%
Epoch: 325, Loss: 2.9047, Train: 85.71%, Valid: 85.75%, Test: 85.79%
Epoch: 350, Loss: 0.9664, Train: 85.69%, Valid: 85.72%, Test: 85.76%
Epoch: 375, Loss: 1.7502, Train: 85.37%, Valid: 85.38%, Test: 85.49%
Epoch: 400, Loss: 0.4422, Train: 85.55%, Valid: 85.54%, Test: 85.65%
Epoch: 425, Loss: 0.4163, Train: 85.91%, Valid: 85.92%, Test: 86.01%
Epoch: 450, Loss: 0.3710, Train: 85.99%, Valid: 85.99%, Test: 86.08%
Epoch: 475, Loss: 0.3450, Train: 85.84%, Valid: 85.84%, Test: 85.96%
Epoch: 500, Loss: 1.7034, Train: 86.33%, Valid: 86.19%, Test: 86.38%
Epoch: 525, Loss: 1.0453, Train: 86.90%, Valid: 86.77%, Test: 86.89%
Epoch: 550, Loss: 0.3942, Train: 85.23%, Valid: 84.97%, Test: 85.26%
Epoch: 575, Loss: 0.3440, Train: 85.50%, Valid: 85.25%, Test: 85.54%
Epoch: 600, Loss: 0.3325, Train: 86.49%, Valid: 86.48%, Test: 86.56%
Epoch: 625, Loss: 0.3272, Train: 84.50%, Valid: 84.41%, Test: 84.54%
Epoch: 650, Loss: 2.9971, Train: 86.69%, Valid: 86.69%, Test: 86.72%
Epoch: 675, Loss: 4.0735, Train: 85.75%, Valid: 85.61%, Test: 85.78%
Epoch: 700, Loss: 3.4252, Train: 85.73%, Valid: 85.59%, Test: 85.78%
Epoch: 725, Loss: 2.0785, Train: 85.71%, Valid: 85.58%, Test: 85.75%
Epoch: 750, Loss: 0.7773, Train: 85.42%, Valid: 85.43%, Test: 85.53%
Epoch: 775, Loss: 0.5576, Train: 85.88%, Valid: 85.84%, Test: 85.98%
Epoch: 800, Loss: 0.3942, Train: 85.92%, Valid: 85.89%, Test: 86.00%
Epoch: 825, Loss: 0.6068, Train: 84.78%, Valid: 84.75%, Test: 84.86%
Epoch: 850, Loss: 0.3906, Train: 85.75%, Valid: 85.70%, Test: 85.85%
Epoch: 875, Loss: 0.3466, Train: 85.94%, Valid: 85.91%, Test: 85.99%
Epoch: 900, Loss: 0.3321, Train: 86.22%, Valid: 86.17%, Test: 86.25%
Epoch: 925, Loss: 0.3668, Train: 86.07%, Valid: 86.05%, Test: 86.16%
Epoch: 950, Loss: 0.3381, Train: 85.94%, Valid: 85.90%, Test: 85.99%
Epoch: 975, Loss: 0.3286, Train: 86.03%, Valid: 86.02%, Test: 86.06%
Run 01:
Highest Train: 88.45
Highest Valid: 88.47
  Final Train: 88.45
   Final Test: 88.54
All runs:
Highest Train: 88.45 ± nan
Highest Valid: 88.47 ± nan
  Final Train: 88.45 ± nan
   Final Test: 88.54 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.5121, Train: 85.85%, Valid: 85.82%, Test: 85.97%
Epoch: 25, Loss: 2.4584, Train: 85.23%, Valid: 85.10%, Test: 85.38%
Epoch: 50, Loss: 1.6763, Train: 86.75%, Valid: 86.72%, Test: 86.73%
Epoch: 75, Loss: 0.5599, Train: 85.70%, Valid: 85.72%, Test: 85.71%
Epoch: 100, Loss: 0.3690, Train: 86.08%, Valid: 86.08%, Test: 86.26%
Epoch: 125, Loss: 0.3450, Train: 85.71%, Valid: 85.67%, Test: 85.78%
Epoch: 150, Loss: 0.6609, Train: 85.95%, Valid: 85.82%, Test: 86.02%
Epoch: 175, Loss: 0.3789, Train: 85.93%, Valid: 85.86%, Test: 85.96%
Epoch: 200, Loss: 0.3493, Train: 86.29%, Valid: 86.23%, Test: 86.33%
Epoch: 225, Loss: 0.3411, Train: 86.83%, Valid: 86.81%, Test: 86.88%
Epoch: 250, Loss: 0.3339, Train: 87.27%, Valid: 87.26%, Test: 87.30%
Epoch: 275, Loss: 0.3298, Train: 87.41%, Valid: 87.40%, Test: 87.45%
Epoch: 300, Loss: 0.3267, Train: 87.61%, Valid: 87.57%, Test: 87.62%
Epoch: 325, Loss: 0.3377, Train: 87.19%, Valid: 87.11%, Test: 87.17%
Epoch: 350, Loss: 3.7886, Train: 86.01%, Valid: 85.91%, Test: 86.10%
Epoch: 375, Loss: 1.9130, Train: 85.67%, Valid: 85.58%, Test: 85.81%
Epoch: 400, Loss: 0.4797, Train: 85.90%, Valid: 85.89%, Test: 86.07%
Epoch: 425, Loss: 0.3969, Train: 86.54%, Valid: 86.47%, Test: 86.72%
Epoch: 450, Loss: 0.3542, Train: 86.52%, Valid: 86.47%, Test: 86.68%
Epoch: 475, Loss: 0.3331, Train: 86.81%, Valid: 86.88%, Test: 86.87%
Epoch: 500, Loss: 0.3411, Train: 86.57%, Valid: 86.46%, Test: 86.66%
Epoch: 525, Loss: 0.3305, Train: 87.22%, Valid: 87.10%, Test: 87.27%
Epoch: 550, Loss: 0.5028, Train: 86.48%, Valid: 86.42%, Test: 86.50%
Epoch: 575, Loss: 2.2700, Train: 86.47%, Valid: 86.37%, Test: 86.53%
Epoch: 600, Loss: 2.0800, Train: 86.24%, Valid: 86.12%, Test: 86.32%
Epoch: 625, Loss: 1.3375, Train: 87.14%, Valid: 87.11%, Test: 87.10%
Epoch: 650, Loss: 1.8521, Train: 87.02%, Valid: 87.03%, Test: 87.00%
Epoch: 675, Loss: 1.3924, Train: 86.96%, Valid: 86.97%, Test: 86.95%
Epoch: 700, Loss: 0.6047, Train: 86.92%, Valid: 86.93%, Test: 86.96%
Epoch: 725, Loss: 0.5686, Train: 87.08%, Valid: 87.08%, Test: 87.08%
Epoch: 750, Loss: 0.3660, Train: 86.89%, Valid: 86.80%, Test: 86.95%
Epoch: 775, Loss: 0.3445, Train: 87.33%, Valid: 87.23%, Test: 87.41%
Epoch: 800, Loss: 2.8356, Train: 86.26%, Valid: 86.13%, Test: 86.35%
Epoch: 825, Loss: 1.9220, Train: 85.54%, Valid: 85.35%, Test: 85.66%
Epoch: 850, Loss: 1.0849, Train: 85.56%, Valid: 85.38%, Test: 85.68%
Epoch: 875, Loss: 0.4213, Train: 86.25%, Valid: 86.16%, Test: 86.30%
Epoch: 900, Loss: 0.3547, Train: 85.68%, Valid: 85.59%, Test: 85.72%
Epoch: 925, Loss: 3.3955, Train: 86.05%, Valid: 86.15%, Test: 86.08%
Epoch: 950, Loss: 9.4135, Train: 85.77%, Valid: 85.66%, Test: 85.85%
Epoch: 975, Loss: 8.1521, Train: 85.84%, Valid: 85.74%, Test: 85.93%
Run 01:
Highest Train: 87.78
Highest Valid: 87.73
  Final Train: 87.78
   Final Test: 87.78
All runs:
Highest Train: 87.78 ± nan
Highest Valid: 87.73 ± nan
  Final Train: 87.78 ± nan
   Final Test: 87.78 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 5.4345, Train: 81.57%, Valid: 81.63%, Test: 81.86%
Epoch: 25, Loss: 2.4822, Train: 85.94%, Valid: 85.80%, Test: 86.01%
Epoch: 50, Loss: 0.6706, Train: 85.30%, Valid: 85.17%, Test: 85.37%
Epoch: 75, Loss: 0.4534, Train: 85.17%, Valid: 85.02%, Test: 85.23%
Epoch: 100, Loss: 0.3827, Train: 85.63%, Valid: 85.46%, Test: 85.69%
Epoch: 125, Loss: 0.3679, Train: 85.94%, Valid: 85.73%, Test: 86.01%
Epoch: 150, Loss: 0.3547, Train: 86.56%, Valid: 86.41%, Test: 86.71%
Epoch: 175, Loss: 0.3438, Train: 86.84%, Valid: 86.72%, Test: 86.97%
Epoch: 200, Loss: 4.5158, Train: 86.50%, Valid: 86.48%, Test: 86.58%
Epoch: 225, Loss: 4.3461, Train: 85.57%, Valid: 85.40%, Test: 85.63%
Epoch: 250, Loss: 1.9367, Train: 85.60%, Valid: 85.55%, Test: 85.62%
Epoch: 275, Loss: 0.4896, Train: 85.84%, Valid: 85.85%, Test: 85.90%
Epoch: 300, Loss: 0.3862, Train: 85.15%, Valid: 85.00%, Test: 85.22%
Epoch: 325, Loss: 0.3582, Train: 85.34%, Valid: 85.18%, Test: 85.53%
Epoch: 350, Loss: 0.3550, Train: 85.53%, Valid: 85.43%, Test: 85.68%
Epoch: 375, Loss: 0.3399, Train: 86.00%, Valid: 85.84%, Test: 86.09%
Epoch: 400, Loss: 0.3319, Train: 87.14%, Valid: 87.04%, Test: 87.26%
Epoch: 425, Loss: 4.3454, Train: 85.61%, Valid: 85.42%, Test: 85.65%
Epoch: 450, Loss: 4.0115, Train: 86.86%, Valid: 86.89%, Test: 86.91%
Epoch: 475, Loss: 1.3082, Train: 86.08%, Valid: 85.95%, Test: 86.20%
Epoch: 500, Loss: 0.4039, Train: 86.05%, Valid: 85.84%, Test: 86.04%
Epoch: 525, Loss: 0.3701, Train: 87.08%, Valid: 87.07%, Test: 87.14%
Epoch: 550, Loss: 0.3477, Train: 87.27%, Valid: 87.26%, Test: 87.29%
Epoch: 575, Loss: 0.3588, Train: 86.34%, Valid: 86.23%, Test: 86.38%
Epoch: 600, Loss: 0.9389, Train: 86.61%, Valid: 86.62%, Test: 86.65%
Epoch: 625, Loss: 2.8598, Train: 85.28%, Valid: 85.16%, Test: 85.39%
Epoch: 650, Loss: 3.3547, Train: 85.55%, Valid: 85.37%, Test: 85.57%
Epoch: 675, Loss: 5.7160, Train: 85.41%, Valid: 85.24%, Test: 85.49%
Epoch: 700, Loss: 3.6986, Train: 85.51%, Valid: 85.43%, Test: 85.59%
Epoch: 725, Loss: 2.6572, Train: 85.05%, Valid: 84.92%, Test: 85.13%
Epoch: 750, Loss: 1.4364, Train: 86.54%, Valid: 86.41%, Test: 86.57%
Epoch: 775, Loss: 0.5236, Train: 86.09%, Valid: 85.93%, Test: 86.04%
Epoch: 800, Loss: 0.3938, Train: 86.71%, Valid: 86.65%, Test: 86.75%
Epoch: 825, Loss: 0.3565, Train: 86.93%, Valid: 86.92%, Test: 87.01%
Epoch: 850, Loss: 4.2708, Train: 86.15%, Valid: 86.08%, Test: 86.28%
Epoch: 875, Loss: 5.8847, Train: 86.89%, Valid: 86.89%, Test: 86.96%
Epoch: 900, Loss: 8.0933, Train: 85.58%, Valid: 85.42%, Test: 85.68%
Epoch: 925, Loss: 6.2175, Train: 86.48%, Valid: 86.33%, Test: 86.57%
Epoch: 950, Loss: 1.7685, Train: 86.74%, Valid: 86.53%, Test: 86.78%
Epoch: 975, Loss: 8.9127, Train: 87.54%, Valid: 87.39%, Test: 87.52%
Run 01:
Highest Train: 87.87
Highest Valid: 87.73
  Final Train: 87.87
   Final Test: 87.97
All runs:
Highest Train: 87.87 ± nan
Highest Valid: 87.73 ± nan
  Final Train: 87.87 ± nan
   Final Test: 87.97 ± nan
Saving results to results/genius.csv
20211117-02:31 ---> 20211117-03:43 Totl:4338 seconds
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6941, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.6932, Train: 50.42%, Valid: 50.50%, Test: 50.52%
Epoch: 50, Loss: 0.6864, Train: 56.11%, Valid: 56.12%, Test: 56.15%
Epoch: 75, Loss: 0.6668, Train: 59.78%, Valid: 59.68%, Test: 59.74%
Epoch: 100, Loss: 0.6446, Train: 61.23%, Valid: 61.11%, Test: 61.12%
Epoch: 125, Loss: 0.6415, Train: 61.47%, Valid: 61.42%, Test: 61.37%
Epoch: 150, Loss: 0.6409, Train: 61.53%, Valid: 61.49%, Test: 61.46%
Epoch: 175, Loss: 0.6406, Train: 61.53%, Valid: 61.50%, Test: 61.45%
Epoch: 200, Loss: 0.6403, Train: 61.55%, Valid: 61.53%, Test: 61.45%
Epoch: 225, Loss: 0.6402, Train: 61.54%, Valid: 61.55%, Test: 61.45%
Epoch: 250, Loss: 0.6395, Train: 61.54%, Valid: 61.53%, Test: 61.41%
Epoch: 275, Loss: 0.6391, Train: 61.55%, Valid: 61.57%, Test: 61.44%
Epoch: 300, Loss: 0.6388, Train: 61.65%, Valid: 61.62%, Test: 61.51%
Epoch: 325, Loss: 0.6381, Train: 61.67%, Valid: 61.69%, Test: 61.57%
Epoch: 350, Loss: 0.6377, Train: 61.76%, Valid: 61.78%, Test: 61.67%
Epoch: 375, Loss: 0.6373, Train: 61.83%, Valid: 61.85%, Test: 61.78%
Epoch: 400, Loss: 0.6377, Train: 61.83%, Valid: 61.82%, Test: 61.62%
Epoch: 425, Loss: 0.6356, Train: 62.02%, Valid: 62.06%, Test: 61.90%
Epoch: 450, Loss: 0.6351, Train: 62.08%, Valid: 62.08%, Test: 61.90%
Epoch: 475, Loss: 0.6348, Train: 62.10%, Valid: 62.14%, Test: 62.01%
Epoch: 500, Loss: 0.6346, Train: 62.14%, Valid: 62.14%, Test: 61.91%
Epoch: 525, Loss: 0.6342, Train: 62.16%, Valid: 62.18%, Test: 62.03%
Epoch: 550, Loss: 0.6344, Train: 62.19%, Valid: 62.17%, Test: 61.94%
Epoch: 575, Loss: 0.6338, Train: 62.20%, Valid: 62.23%, Test: 62.07%
Epoch: 600, Loss: 0.6338, Train: 62.21%, Valid: 62.17%, Test: 61.94%
Epoch: 625, Loss: 0.6337, Train: 62.26%, Valid: 62.27%, Test: 62.04%
Epoch: 650, Loss: 0.6334, Train: 62.26%, Valid: 62.27%, Test: 62.14%
Epoch: 675, Loss: 0.6335, Train: 62.20%, Valid: 62.21%, Test: 62.13%
Epoch: 700, Loss: 0.6334, Train: 62.29%, Valid: 62.31%, Test: 62.18%
Epoch: 725, Loss: 0.6331, Train: 62.31%, Valid: 62.32%, Test: 62.20%
Epoch: 750, Loss: 0.6401, Train: 62.17%, Valid: 62.18%, Test: 62.08%
Epoch: 775, Loss: 0.6330, Train: 62.33%, Valid: 62.29%, Test: 62.11%
Epoch: 800, Loss: 0.6328, Train: 62.41%, Valid: 62.38%, Test: 62.21%
Epoch: 825, Loss: 0.6326, Train: 62.43%, Valid: 62.42%, Test: 62.24%
Epoch: 850, Loss: 0.6335, Train: 62.32%, Valid: 62.32%, Test: 62.20%
Epoch: 875, Loss: 0.6323, Train: 62.42%, Valid: 62.42%, Test: 62.26%
Epoch: 900, Loss: 0.6327, Train: 62.30%, Valid: 62.28%, Test: 62.16%
Epoch: 925, Loss: 0.6320, Train: 62.50%, Valid: 62.47%, Test: 62.27%
Epoch: 950, Loss: 0.6353, Train: 62.00%, Valid: 61.95%, Test: 61.84%
Epoch: 975, Loss: 0.6317, Train: 62.47%, Valid: 62.42%, Test: 62.29%
Run 01:
Highest Train: 62.56
Highest Valid: 62.53
  Final Train: 62.56
   Final Test: 62.30
All runs:
Highest Train: 62.56 ± nan
Highest Valid: 62.53 ± nan
  Final Train: 62.56 ± nan
   Final Test: 62.30 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7055, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.6925, Train: 51.94%, Valid: 51.94%, Test: 51.81%
Epoch: 50, Loss: 0.6839, Train: 57.28%, Valid: 57.16%, Test: 57.22%
Epoch: 75, Loss: 0.6661, Train: 59.69%, Valid: 59.63%, Test: 59.64%
Epoch: 100, Loss: 0.6460, Train: 61.22%, Valid: 61.19%, Test: 61.14%
Epoch: 125, Loss: 0.6418, Train: 61.47%, Valid: 61.42%, Test: 61.40%
Epoch: 150, Loss: 0.6410, Train: 61.53%, Valid: 61.51%, Test: 61.47%
Epoch: 175, Loss: 0.6407, Train: 61.52%, Valid: 61.54%, Test: 61.47%
Epoch: 200, Loss: 0.6404, Train: 61.56%, Valid: 61.53%, Test: 61.47%
Epoch: 225, Loss: 0.6398, Train: 61.59%, Valid: 61.58%, Test: 61.50%
Epoch: 250, Loss: 0.6394, Train: 61.64%, Valid: 61.62%, Test: 61.55%
Epoch: 275, Loss: 0.6387, Train: 61.71%, Valid: 61.74%, Test: 61.65%
Epoch: 300, Loss: 0.6382, Train: 61.80%, Valid: 61.82%, Test: 61.74%
Epoch: 325, Loss: 0.6369, Train: 61.89%, Valid: 61.91%, Test: 61.84%
Epoch: 350, Loss: 0.6373, Train: 61.88%, Valid: 61.91%, Test: 61.77%
Epoch: 375, Loss: 0.6354, Train: 62.06%, Valid: 62.05%, Test: 61.97%
Epoch: 400, Loss: 0.6351, Train: 61.93%, Valid: 61.98%, Test: 61.83%
Epoch: 425, Loss: 0.6347, Train: 62.19%, Valid: 62.17%, Test: 62.07%
Epoch: 450, Loss: 0.6340, Train: 62.26%, Valid: 62.22%, Test: 62.17%
Epoch: 475, Loss: 0.6338, Train: 62.23%, Valid: 62.28%, Test: 62.16%
Epoch: 500, Loss: 0.6335, Train: 62.30%, Valid: 62.32%, Test: 62.19%
Epoch: 525, Loss: 0.6338, Train: 62.37%, Valid: 62.34%, Test: 62.22%
Epoch: 550, Loss: 0.6334, Train: 62.38%, Valid: 62.36%, Test: 62.20%
Epoch: 575, Loss: 0.6338, Train: 62.32%, Valid: 62.27%, Test: 62.10%
Epoch: 600, Loss: 0.6333, Train: 62.31%, Valid: 62.33%, Test: 62.18%
Epoch: 625, Loss: 0.6339, Train: 62.27%, Valid: 62.19%, Test: 62.07%
Epoch: 650, Loss: 0.6326, Train: 62.40%, Valid: 62.42%, Test: 62.27%
Epoch: 675, Loss: 0.6345, Train: 62.11%, Valid: 62.13%, Test: 61.94%
Epoch: 700, Loss: 0.6323, Train: 62.43%, Valid: 62.43%, Test: 62.27%
Epoch: 725, Loss: 0.6322, Train: 62.46%, Valid: 62.45%, Test: 62.28%
Epoch: 750, Loss: 0.6323, Train: 62.42%, Valid: 62.41%, Test: 62.28%
Epoch: 775, Loss: 0.6329, Train: 62.46%, Valid: 62.45%, Test: 62.27%
Epoch: 800, Loss: 0.6322, Train: 62.44%, Valid: 62.46%, Test: 62.27%
Epoch: 825, Loss: 0.6333, Train: 62.19%, Valid: 62.17%, Test: 62.02%
Epoch: 850, Loss: 0.6323, Train: 62.48%, Valid: 62.46%, Test: 62.31%
Epoch: 875, Loss: 0.6316, Train: 62.53%, Valid: 62.49%, Test: 62.29%
Epoch: 900, Loss: 0.6327, Train: 62.52%, Valid: 62.35%, Test: 62.20%
Epoch: 925, Loss: 0.6317, Train: 62.52%, Valid: 62.35%, Test: 62.20%
Epoch: 950, Loss: 0.6313, Train: 62.45%, Valid: 62.40%, Test: 62.27%
Epoch: 975, Loss: 0.6313, Train: 62.58%, Valid: 62.45%, Test: 62.27%
Run 01:
Highest Train: 62.61
Highest Valid: 62.57
  Final Train: 62.60
   Final Test: 62.36
All runs:
Highest Train: 62.61 ± nan
Highest Valid: 62.57 ± nan
  Final Train: 62.60 ± nan
   Final Test: 62.36 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6957, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.6937, Train: 50.46%, Valid: 50.51%, Test: 50.56%
Epoch: 50, Loss: 0.6790, Train: 57.71%, Valid: 57.62%, Test: 57.68%
Epoch: 75, Loss: 0.6526, Train: 60.91%, Valid: 60.87%, Test: 60.82%
Epoch: 100, Loss: 0.6429, Train: 61.35%, Valid: 61.26%, Test: 61.23%
Epoch: 125, Loss: 0.6414, Train: 61.45%, Valid: 61.38%, Test: 61.39%
Epoch: 150, Loss: 0.6410, Train: 61.52%, Valid: 61.48%, Test: 61.47%
Epoch: 175, Loss: 0.6409, Train: 61.52%, Valid: 61.52%, Test: 61.47%
Epoch: 200, Loss: 0.6406, Train: 61.54%, Valid: 61.53%, Test: 61.49%
Epoch: 225, Loss: 0.6405, Train: 61.54%, Valid: 61.51%, Test: 61.41%
Epoch: 250, Loss: 0.6402, Train: 61.56%, Valid: 61.55%, Test: 61.45%
Epoch: 275, Loss: 0.6402, Train: 61.53%, Valid: 61.52%, Test: 61.39%
Epoch: 300, Loss: 0.6399, Train: 61.57%, Valid: 61.55%, Test: 61.52%
Epoch: 325, Loss: 0.6396, Train: 61.58%, Valid: 61.58%, Test: 61.52%
Epoch: 350, Loss: 0.6393, Train: 61.57%, Valid: 61.56%, Test: 61.46%
Epoch: 375, Loss: 0.6389, Train: 61.61%, Valid: 61.60%, Test: 61.51%
Epoch: 400, Loss: 0.6387, Train: 61.69%, Valid: 61.69%, Test: 61.62%
Epoch: 425, Loss: 0.6379, Train: 61.73%, Valid: 61.72%, Test: 61.67%
Epoch: 450, Loss: 0.6383, Train: 61.74%, Valid: 61.73%, Test: 61.66%
Epoch: 475, Loss: 0.6370, Train: 61.85%, Valid: 61.84%, Test: 61.79%
Epoch: 500, Loss: 0.6366, Train: 61.91%, Valid: 61.93%, Test: 61.85%
Epoch: 525, Loss: 0.6364, Train: 61.99%, Valid: 62.01%, Test: 61.96%
Epoch: 550, Loss: 0.6362, Train: 61.98%, Valid: 62.04%, Test: 61.97%
Epoch: 575, Loss: 0.6382, Train: 61.66%, Valid: 61.73%, Test: 61.63%
Epoch: 600, Loss: 0.6353, Train: 62.10%, Valid: 62.11%, Test: 62.06%
Epoch: 625, Loss: 0.6351, Train: 62.14%, Valid: 62.13%, Test: 62.05%
Epoch: 650, Loss: 0.6369, Train: 62.13%, Valid: 62.07%, Test: 61.95%
Epoch: 675, Loss: 0.6347, Train: 62.24%, Valid: 62.26%, Test: 62.20%
Epoch: 700, Loss: 0.6342, Train: 62.27%, Valid: 62.22%, Test: 62.16%
Epoch: 725, Loss: 0.6352, Train: 62.05%, Valid: 62.09%, Test: 61.96%
Epoch: 750, Loss: 0.6336, Train: 62.31%, Valid: 62.27%, Test: 62.22%
Epoch: 775, Loss: 0.6344, Train: 62.24%, Valid: 62.26%, Test: 62.14%
Epoch: 800, Loss: 0.6335, Train: 62.32%, Valid: 62.24%, Test: 62.10%
Epoch: 825, Loss: 0.6338, Train: 62.35%, Valid: 62.26%, Test: 62.13%
Epoch: 850, Loss: 0.6357, Train: 62.05%, Valid: 62.05%, Test: 61.90%
Epoch: 875, Loss: 0.6325, Train: 62.46%, Valid: 62.35%, Test: 62.19%
Epoch: 900, Loss: 0.6335, Train: 62.30%, Valid: 62.30%, Test: 62.20%
Epoch: 925, Loss: 0.6318, Train: 62.51%, Valid: 62.46%, Test: 62.37%
Epoch: 950, Loss: 0.6327, Train: 62.38%, Valid: 62.24%, Test: 62.16%
Epoch: 975, Loss: 0.6345, Train: 62.28%, Valid: 62.23%, Test: 62.16%
Run 01:
Highest Train: 62.64
Highest Valid: 62.58
  Final Train: 62.63
   Final Test: 62.42
All runs:
Highest Train: 62.64 ± nan
Highest Valid: 62.58 ± nan
  Final Train: 62.63 ± nan
   Final Test: 62.42 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7224, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.6873, Train: 55.10%, Valid: 55.04%, Test: 55.14%
Epoch: 50, Loss: 0.6839, Train: 54.59%, Valid: 54.57%, Test: 54.59%
Epoch: 75, Loss: 0.6764, Train: 58.79%, Valid: 58.67%, Test: 58.70%
Epoch: 100, Loss: 0.6683, Train: 59.45%, Valid: 59.32%, Test: 59.39%
Epoch: 125, Loss: 0.6586, Train: 60.31%, Valid: 60.27%, Test: 60.31%
Epoch: 150, Loss: 0.6504, Train: 60.88%, Valid: 60.87%, Test: 60.90%
Epoch: 175, Loss: 0.6449, Train: 61.32%, Valid: 61.22%, Test: 61.26%
Epoch: 200, Loss: 0.6421, Train: 61.48%, Valid: 61.43%, Test: 61.41%
Epoch: 225, Loss: 0.6409, Train: 61.53%, Valid: 61.53%, Test: 61.47%
Epoch: 250, Loss: 0.6405, Train: 61.55%, Valid: 61.56%, Test: 61.47%
Epoch: 275, Loss: 0.6402, Train: 61.57%, Valid: 61.60%, Test: 61.50%
Epoch: 300, Loss: 0.6400, Train: 61.58%, Valid: 61.62%, Test: 61.52%
Epoch: 325, Loss: 0.6398, Train: 61.59%, Valid: 61.64%, Test: 61.53%
Epoch: 350, Loss: 0.6396, Train: 61.60%, Valid: 61.66%, Test: 61.54%
Epoch: 375, Loss: 0.6394, Train: 61.62%, Valid: 61.68%, Test: 61.54%
Epoch: 400, Loss: 0.6392, Train: 61.65%, Valid: 61.69%, Test: 61.57%
Epoch: 425, Loss: 0.6390, Train: 61.69%, Valid: 61.74%, Test: 61.61%
Epoch: 450, Loss: 0.6388, Train: 61.70%, Valid: 61.74%, Test: 61.62%
Epoch: 475, Loss: 0.6385, Train: 61.73%, Valid: 61.76%, Test: 61.65%
Epoch: 500, Loss: 0.6383, Train: 61.75%, Valid: 61.78%, Test: 61.66%
Epoch: 525, Loss: 0.6380, Train: 61.76%, Valid: 61.82%, Test: 61.69%
Epoch: 550, Loss: 0.6377, Train: 61.79%, Valid: 61.84%, Test: 61.72%
Epoch: 575, Loss: 0.6374, Train: 61.85%, Valid: 61.86%, Test: 61.77%
Epoch: 600, Loss: 0.6371, Train: 61.89%, Valid: 61.91%, Test: 61.83%
Epoch: 625, Loss: 0.6368, Train: 61.93%, Valid: 61.95%, Test: 61.85%
Epoch: 650, Loss: 0.6365, Train: 61.98%, Valid: 62.02%, Test: 61.92%
Epoch: 675, Loss: 0.6361, Train: 62.04%, Valid: 62.06%, Test: 61.98%
Epoch: 700, Loss: 0.6358, Train: 62.11%, Valid: 62.12%, Test: 62.04%
Epoch: 725, Loss: 0.6356, Train: 62.17%, Valid: 62.16%, Test: 62.04%
Epoch: 750, Loss: 0.6352, Train: 62.14%, Valid: 62.15%, Test: 62.08%
Epoch: 775, Loss: 0.6348, Train: 62.21%, Valid: 62.22%, Test: 62.09%
Epoch: 800, Loss: 0.6346, Train: 62.25%, Valid: 62.25%, Test: 62.11%
Epoch: 825, Loss: 0.6344, Train: 62.28%, Valid: 62.29%, Test: 62.11%
Epoch: 850, Loss: 0.6347, Train: 62.25%, Valid: 62.20%, Test: 62.15%
Epoch: 875, Loss: 0.6350, Train: 62.12%, Valid: 62.10%, Test: 62.04%
Epoch: 900, Loss: 0.6338, Train: 62.32%, Valid: 62.30%, Test: 62.18%
Epoch: 925, Loss: 0.6348, Train: 62.10%, Valid: 62.10%, Test: 62.00%
Epoch: 950, Loss: 0.6338, Train: 62.37%, Valid: 62.31%, Test: 62.22%
Epoch: 975, Loss: 0.6338, Train: 62.24%, Valid: 62.23%, Test: 62.14%
Run 01:
Highest Train: 62.41
Highest Valid: 62.40
  Final Train: 62.41
   Final Test: 62.27
All runs:
Highest Train: 62.41 ± nan
Highest Valid: 62.40 ± nan
  Final Train: 62.41 ± nan
   Final Test: 62.27 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6932, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.6902, Train: 54.93%, Valid: 54.85%, Test: 54.82%
Epoch: 50, Loss: 0.6891, Train: 52.54%, Valid: 52.49%, Test: 52.49%
Epoch: 75, Loss: 0.6860, Train: 55.73%, Valid: 55.72%, Test: 55.70%
Epoch: 100, Loss: 0.6811, Train: 57.65%, Valid: 57.48%, Test: 57.55%
Epoch: 125, Loss: 0.6743, Train: 58.75%, Valid: 58.64%, Test: 58.66%
Epoch: 150, Loss: 0.6653, Train: 59.78%, Valid: 59.63%, Test: 59.75%
Epoch: 175, Loss: 0.6528, Train: 60.85%, Valid: 60.83%, Test: 60.80%
Epoch: 200, Loss: 0.6424, Train: 61.46%, Valid: 61.41%, Test: 61.39%
Epoch: 225, Loss: 0.6410, Train: 61.54%, Valid: 61.52%, Test: 61.49%
Epoch: 250, Loss: 0.6406, Train: 61.59%, Valid: 61.61%, Test: 61.52%
Epoch: 275, Loss: 0.6404, Train: 61.61%, Valid: 61.61%, Test: 61.51%
Epoch: 300, Loss: 0.6402, Train: 61.60%, Valid: 61.62%, Test: 61.53%
Epoch: 325, Loss: 0.6400, Train: 61.62%, Valid: 61.64%, Test: 61.56%
Epoch: 350, Loss: 0.6399, Train: 61.62%, Valid: 61.65%, Test: 61.54%
Epoch: 375, Loss: 0.6397, Train: 61.64%, Valid: 61.67%, Test: 61.57%
Epoch: 400, Loss: 0.6394, Train: 61.68%, Valid: 61.68%, Test: 61.61%
Epoch: 425, Loss: 0.6386, Train: 61.76%, Valid: 61.75%, Test: 61.71%
Epoch: 450, Loss: 0.6382, Train: 61.81%, Valid: 61.81%, Test: 61.72%
Epoch: 475, Loss: 0.6379, Train: 61.86%, Valid: 61.83%, Test: 61.76%
Epoch: 500, Loss: 0.6377, Train: 61.87%, Valid: 61.88%, Test: 61.77%
Epoch: 525, Loss: 0.6374, Train: 61.92%, Valid: 61.94%, Test: 61.79%
Epoch: 550, Loss: 0.6369, Train: 61.90%, Valid: 61.92%, Test: 61.80%
Epoch: 575, Loss: 0.6363, Train: 61.97%, Valid: 62.01%, Test: 61.90%
Epoch: 600, Loss: 0.6359, Train: 62.07%, Valid: 62.07%, Test: 61.95%
Epoch: 625, Loss: 0.6355, Train: 62.11%, Valid: 62.10%, Test: 61.96%
Epoch: 650, Loss: 0.6352, Train: 62.11%, Valid: 62.11%, Test: 61.97%
Epoch: 675, Loss: 0.6350, Train: 62.12%, Valid: 62.13%, Test: 62.01%
Epoch: 700, Loss: 0.6348, Train: 62.22%, Valid: 62.19%, Test: 62.04%
Epoch: 725, Loss: 0.6346, Train: 62.23%, Valid: 62.21%, Test: 62.04%
Epoch: 750, Loss: 0.6348, Train: 62.23%, Valid: 62.15%, Test: 62.04%
Epoch: 775, Loss: 0.6349, Train: 62.23%, Valid: 62.15%, Test: 62.02%
Epoch: 800, Loss: 0.6341, Train: 62.22%, Valid: 62.23%, Test: 62.11%
Epoch: 825, Loss: 0.6345, Train: 62.18%, Valid: 62.17%, Test: 62.07%
Epoch: 850, Loss: 0.6336, Train: 62.34%, Valid: 62.24%, Test: 62.14%
Epoch: 875, Loss: 0.6334, Train: 62.33%, Valid: 62.31%, Test: 62.22%
Epoch: 900, Loss: 0.6330, Train: 62.35%, Valid: 62.36%, Test: 62.27%
Epoch: 925, Loss: 0.6336, Train: 62.27%, Valid: 62.19%, Test: 62.06%
Epoch: 950, Loss: 0.6327, Train: 62.37%, Valid: 62.35%, Test: 62.25%
Epoch: 975, Loss: 0.6326, Train: 62.40%, Valid: 62.37%, Test: 62.26%
Run 01:
Highest Train: 62.50
Highest Valid: 62.45
  Final Train: 62.50
   Final Test: 62.29
All runs:
Highest Train: 62.50 ± nan
Highest Valid: 62.45 ± nan
  Final Train: 62.50 ± nan
   Final Test: 62.29 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.8066, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.7111, Train: 48.60%, Valid: 48.43%, Test: 48.66%
Epoch: 50, Loss: 0.6900, Train: 53.80%, Valid: 53.94%, Test: 53.78%
Epoch: 75, Loss: 0.6837, Train: 56.49%, Valid: 56.46%, Test: 56.33%
Epoch: 100, Loss: 0.6757, Train: 59.82%, Valid: 59.78%, Test: 59.78%
Epoch: 125, Loss: 0.6655, Train: 60.11%, Valid: 60.05%, Test: 60.05%
Epoch: 150, Loss: 0.6543, Train: 60.83%, Valid: 60.74%, Test: 60.80%
Epoch: 175, Loss: 0.6428, Train: 61.41%, Valid: 61.41%, Test: 61.41%
Epoch: 200, Loss: 0.6407, Train: 61.58%, Valid: 61.55%, Test: 61.53%
Epoch: 225, Loss: 0.6404, Train: 61.62%, Valid: 61.64%, Test: 61.56%
Epoch: 250, Loss: 0.6400, Train: 61.64%, Valid: 61.66%, Test: 61.58%
Epoch: 275, Loss: 0.6397, Train: 61.66%, Valid: 61.70%, Test: 61.59%
Epoch: 300, Loss: 0.6393, Train: 61.68%, Valid: 61.72%, Test: 61.62%
Epoch: 325, Loss: 0.6388, Train: 61.73%, Valid: 61.78%, Test: 61.66%
Epoch: 350, Loss: 0.6383, Train: 61.79%, Valid: 61.81%, Test: 61.69%
Epoch: 375, Loss: 0.6374, Train: 61.86%, Valid: 61.92%, Test: 61.78%
Epoch: 400, Loss: 0.6376, Train: 61.93%, Valid: 61.91%, Test: 61.82%
Epoch: 425, Loss: 0.6364, Train: 62.01%, Valid: 61.98%, Test: 61.89%
Epoch: 450, Loss: 0.6361, Train: 62.04%, Valid: 62.04%, Test: 61.90%
Epoch: 475, Loss: 0.6358, Train: 62.03%, Valid: 62.04%, Test: 61.87%
Epoch: 500, Loss: 0.6352, Train: 62.13%, Valid: 62.12%, Test: 61.98%
Epoch: 525, Loss: 0.6350, Train: 62.15%, Valid: 62.16%, Test: 62.01%
Epoch: 550, Loss: 0.6355, Train: 62.10%, Valid: 62.08%, Test: 61.95%
Epoch: 575, Loss: 0.6344, Train: 62.24%, Valid: 62.22%, Test: 62.06%
Epoch: 600, Loss: 0.6347, Train: 62.14%, Valid: 62.15%, Test: 61.97%
Epoch: 625, Loss: 0.6340, Train: 62.28%, Valid: 62.26%, Test: 62.07%
Epoch: 650, Loss: 0.6338, Train: 62.30%, Valid: 62.31%, Test: 62.10%
Epoch: 675, Loss: 0.6337, Train: 62.32%, Valid: 62.32%, Test: 62.11%
Epoch: 700, Loss: 0.6336, Train: 62.35%, Valid: 62.35%, Test: 62.13%
Epoch: 725, Loss: 0.6334, Train: 62.39%, Valid: 62.36%, Test: 62.16%
Epoch: 750, Loss: 0.6338, Train: 62.33%, Valid: 62.28%, Test: 62.12%
Epoch: 775, Loss: 0.6330, Train: 62.44%, Valid: 62.40%, Test: 62.21%
Epoch: 800, Loss: 0.6337, Train: 62.37%, Valid: 62.36%, Test: 62.17%
Epoch: 825, Loss: 0.6329, Train: 62.40%, Valid: 62.37%, Test: 62.19%
Epoch: 850, Loss: 0.6327, Train: 62.43%, Valid: 62.39%, Test: 62.22%
Epoch: 875, Loss: 0.6325, Train: 62.48%, Valid: 62.42%, Test: 62.25%
Epoch: 900, Loss: 0.6325, Train: 62.46%, Valid: 62.43%, Test: 62.23%
Epoch: 925, Loss: 0.6323, Train: 62.46%, Valid: 62.42%, Test: 62.23%
Epoch: 950, Loss: 0.6321, Train: 62.51%, Valid: 62.46%, Test: 62.25%
Epoch: 975, Loss: 0.6321, Train: 62.54%, Valid: 62.43%, Test: 62.29%
Run 01:
Highest Train: 62.55
Highest Valid: 62.49
  Final Train: 62.53
   Final Test: 62.27
All runs:
Highest Train: 62.55 ± nan
Highest Valid: 62.49 ± nan
  Final Train: 62.53 ± nan
   Final Test: 62.27 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7338, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.7147, Train: 51.28%, Valid: 51.34%, Test: 51.38%
Epoch: 50, Loss: 0.6846, Train: 52.59%, Valid: 52.54%, Test: 52.44%
Epoch: 75, Loss: 0.6796, Train: 58.63%, Valid: 58.56%, Test: 58.49%
Epoch: 100, Loss: 0.6728, Train: 58.71%, Valid: 58.60%, Test: 58.63%
Epoch: 125, Loss: 0.6642, Train: 60.07%, Valid: 59.99%, Test: 60.01%
Epoch: 150, Loss: 0.6553, Train: 60.70%, Valid: 60.67%, Test: 60.69%
Epoch: 175, Loss: 0.6488, Train: 61.10%, Valid: 61.06%, Test: 61.06%
Epoch: 200, Loss: 0.6448, Train: 61.36%, Valid: 61.28%, Test: 61.29%
Epoch: 225, Loss: 0.6425, Train: 61.47%, Valid: 61.44%, Test: 61.41%
Epoch: 250, Loss: 0.6412, Train: 61.54%, Valid: 61.54%, Test: 61.50%
Epoch: 275, Loss: 0.6406, Train: 61.57%, Valid: 61.59%, Test: 61.53%
Epoch: 300, Loss: 0.6402, Train: 61.57%, Valid: 61.59%, Test: 61.51%
Epoch: 325, Loss: 0.6400, Train: 61.59%, Valid: 61.61%, Test: 61.52%
Epoch: 350, Loss: 0.6397, Train: 61.60%, Valid: 61.64%, Test: 61.54%
Epoch: 375, Loss: 0.6395, Train: 61.62%, Valid: 61.66%, Test: 61.56%
Epoch: 400, Loss: 0.6393, Train: 61.64%, Valid: 61.68%, Test: 61.57%
Epoch: 425, Loss: 0.6391, Train: 61.65%, Valid: 61.71%, Test: 61.58%
Epoch: 450, Loss: 0.6389, Train: 61.70%, Valid: 61.75%, Test: 61.62%
Epoch: 475, Loss: 0.6387, Train: 61.72%, Valid: 61.76%, Test: 61.64%
Epoch: 500, Loss: 0.6384, Train: 61.75%, Valid: 61.77%, Test: 61.67%
Epoch: 525, Loss: 0.6382, Train: 61.77%, Valid: 61.80%, Test: 61.66%
Epoch: 550, Loss: 0.6380, Train: 61.78%, Valid: 61.81%, Test: 61.69%
Epoch: 575, Loss: 0.6378, Train: 61.83%, Valid: 61.83%, Test: 61.73%
Epoch: 600, Loss: 0.6375, Train: 61.85%, Valid: 61.84%, Test: 61.76%
Epoch: 625, Loss: 0.6373, Train: 61.89%, Valid: 61.87%, Test: 61.77%
Epoch: 650, Loss: 0.6371, Train: 61.92%, Valid: 61.90%, Test: 61.78%
Epoch: 675, Loss: 0.6368, Train: 61.95%, Valid: 61.91%, Test: 61.80%
Epoch: 700, Loss: 0.6365, Train: 61.98%, Valid: 61.95%, Test: 61.86%
Epoch: 725, Loss: 0.6362, Train: 62.01%, Valid: 61.99%, Test: 61.86%
Epoch: 750, Loss: 0.6360, Train: 62.04%, Valid: 62.01%, Test: 61.88%
Epoch: 775, Loss: 0.6357, Train: 62.05%, Valid: 62.03%, Test: 61.90%
Epoch: 800, Loss: 0.6355, Train: 62.08%, Valid: 62.05%, Test: 61.91%
Epoch: 825, Loss: 0.6353, Train: 62.10%, Valid: 62.08%, Test: 61.91%
Epoch: 850, Loss: 0.6351, Train: 62.13%, Valid: 62.12%, Test: 61.92%
Epoch: 875, Loss: 0.6349, Train: 62.14%, Valid: 62.14%, Test: 61.97%
Epoch: 900, Loss: 0.6347, Train: 62.16%, Valid: 62.16%, Test: 61.99%
Epoch: 925, Loss: 0.6345, Train: 62.18%, Valid: 62.18%, Test: 62.00%
Epoch: 950, Loss: 0.6343, Train: 62.20%, Valid: 62.19%, Test: 62.02%
Epoch: 975, Loss: 0.6343, Train: 62.19%, Valid: 62.17%, Test: 62.03%
Run 01:
Highest Train: 62.27
Highest Valid: 62.27
  Final Train: 62.25
   Final Test: 62.11
All runs:
Highest Train: 62.27 ± nan
Highest Valid: 62.27 ± nan
  Final Train: 62.25 ± nan
   Final Test: 62.11 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.4079, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7341, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 50, Loss: 0.6861, Train: 53.28%, Valid: 53.26%, Test: 53.13%
Epoch: 75, Loss: 0.6798, Train: 57.69%, Valid: 57.65%, Test: 57.59%
Epoch: 100, Loss: 0.6740, Train: 59.10%, Valid: 59.02%, Test: 59.05%
Epoch: 125, Loss: 0.6665, Train: 59.87%, Valid: 59.76%, Test: 59.85%
Epoch: 150, Loss: 0.6581, Train: 60.61%, Valid: 60.56%, Test: 60.56%
Epoch: 175, Loss: 0.6511, Train: 61.00%, Valid: 60.96%, Test: 60.96%
Epoch: 200, Loss: 0.6464, Train: 61.29%, Valid: 61.22%, Test: 61.23%
Epoch: 225, Loss: 0.6435, Train: 61.44%, Valid: 61.36%, Test: 61.35%
Epoch: 250, Loss: 0.6417, Train: 61.52%, Valid: 61.48%, Test: 61.45%
Epoch: 275, Loss: 0.6408, Train: 61.55%, Valid: 61.55%, Test: 61.49%
Epoch: 300, Loss: 0.6402, Train: 61.58%, Valid: 61.59%, Test: 61.49%
Epoch: 325, Loss: 0.6399, Train: 61.61%, Valid: 61.64%, Test: 61.53%
Epoch: 350, Loss: 0.6397, Train: 61.62%, Valid: 61.66%, Test: 61.55%
Epoch: 375, Loss: 0.6395, Train: 61.63%, Valid: 61.68%, Test: 61.57%
Epoch: 400, Loss: 0.6393, Train: 61.65%, Valid: 61.68%, Test: 61.58%
Epoch: 425, Loss: 0.6391, Train: 61.68%, Valid: 61.70%, Test: 61.58%
Epoch: 450, Loss: 0.6389, Train: 61.69%, Valid: 61.71%, Test: 61.58%
Epoch: 475, Loss: 0.6387, Train: 61.72%, Valid: 61.72%, Test: 61.58%
Epoch: 500, Loss: 0.6385, Train: 61.75%, Valid: 61.75%, Test: 61.62%
Epoch: 525, Loss: 0.6383, Train: 61.76%, Valid: 61.77%, Test: 61.65%
Epoch: 550, Loss: 0.6380, Train: 61.79%, Valid: 61.81%, Test: 61.68%
Epoch: 575, Loss: 0.6378, Train: 61.82%, Valid: 61.84%, Test: 61.72%
Epoch: 600, Loss: 0.6376, Train: 61.84%, Valid: 61.89%, Test: 61.74%
Epoch: 625, Loss: 0.6374, Train: 61.86%, Valid: 61.91%, Test: 61.77%
Epoch: 650, Loss: 0.6371, Train: 61.90%, Valid: 61.93%, Test: 61.79%
Epoch: 675, Loss: 0.6369, Train: 61.95%, Valid: 61.98%, Test: 61.84%
Epoch: 700, Loss: 0.6367, Train: 61.97%, Valid: 61.99%, Test: 61.86%
Epoch: 725, Loss: 0.6364, Train: 62.00%, Valid: 62.02%, Test: 61.88%
Epoch: 750, Loss: 0.6362, Train: 62.02%, Valid: 62.03%, Test: 61.90%
Epoch: 775, Loss: 0.6359, Train: 62.04%, Valid: 62.05%, Test: 61.92%
Epoch: 800, Loss: 0.6357, Train: 62.08%, Valid: 62.10%, Test: 61.96%
Epoch: 825, Loss: 0.6354, Train: 62.14%, Valid: 62.18%, Test: 61.99%
Epoch: 850, Loss: 0.6351, Train: 62.17%, Valid: 62.22%, Test: 62.03%
Epoch: 875, Loss: 0.6348, Train: 62.19%, Valid: 62.23%, Test: 62.07%
Epoch: 900, Loss: 0.6345, Train: 62.21%, Valid: 62.22%, Test: 62.09%
Epoch: 925, Loss: 0.6341, Train: 62.26%, Valid: 62.25%, Test: 62.12%
Epoch: 950, Loss: 0.6335, Train: 62.33%, Valid: 62.34%, Test: 62.18%
Epoch: 975, Loss: 0.6328, Train: 62.46%, Valid: 62.46%, Test: 62.30%
Run 01:
Highest Train: 62.52
Highest Valid: 62.51
  Final Train: 62.52
   Final Test: 62.35
All runs:
Highest Train: 62.52 ± nan
Highest Valid: 62.51 ± nan
  Final Train: 62.52 ± nan
   Final Test: 62.35 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 2.2173, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.7505, Train: 51.99%, Valid: 51.88%, Test: 52.01%
Epoch: 50, Loss: 0.6858, Train: 54.26%, Valid: 54.24%, Test: 54.06%
Epoch: 75, Loss: 0.6779, Train: 58.03%, Valid: 57.98%, Test: 57.86%
Epoch: 100, Loss: 0.6695, Train: 59.66%, Valid: 59.66%, Test: 59.55%
Epoch: 125, Loss: 0.6605, Train: 60.29%, Valid: 60.27%, Test: 60.19%
Epoch: 150, Loss: 0.6520, Train: 60.97%, Valid: 60.98%, Test: 60.91%
Epoch: 175, Loss: 0.6455, Train: 61.35%, Valid: 61.32%, Test: 61.31%
Epoch: 200, Loss: 0.6418, Train: 61.56%, Valid: 61.53%, Test: 61.50%
Epoch: 225, Loss: 0.6404, Train: 61.60%, Valid: 61.63%, Test: 61.56%
Epoch: 250, Loss: 0.6399, Train: 61.63%, Valid: 61.66%, Test: 61.57%
Epoch: 275, Loss: 0.6395, Train: 61.65%, Valid: 61.72%, Test: 61.60%
Epoch: 300, Loss: 0.6392, Train: 61.67%, Valid: 61.74%, Test: 61.63%
Epoch: 325, Loss: 0.6389, Train: 61.69%, Valid: 61.78%, Test: 61.65%
Epoch: 350, Loss: 0.6385, Train: 61.75%, Valid: 61.80%, Test: 61.71%
Epoch: 375, Loss: 0.6377, Train: 61.86%, Valid: 61.90%, Test: 61.80%
Epoch: 400, Loss: 0.6370, Train: 61.92%, Valid: 61.96%, Test: 61.87%
Epoch: 425, Loss: 0.6363, Train: 62.06%, Valid: 62.08%, Test: 61.98%
Epoch: 450, Loss: 0.6357, Train: 62.12%, Valid: 62.15%, Test: 62.04%
Epoch: 475, Loss: 0.6348, Train: 62.22%, Valid: 62.26%, Test: 62.14%
Epoch: 500, Loss: 0.6342, Train: 62.35%, Valid: 62.40%, Test: 62.25%
Epoch: 525, Loss: 0.6336, Train: 62.41%, Valid: 62.46%, Test: 62.30%
Epoch: 550, Loss: 0.6326, Train: 62.58%, Valid: 62.59%, Test: 62.49%
Epoch: 575, Loss: 0.6315, Train: 62.59%, Valid: 62.59%, Test: 62.45%
Epoch: 600, Loss: 0.6293, Train: 63.12%, Valid: 63.11%, Test: 63.01%
Epoch: 625, Loss: 0.6307, Train: 62.72%, Valid: 62.74%, Test: 62.65%
Epoch: 650, Loss: 0.6453, Train: 60.87%, Valid: 60.95%, Test: 60.86%
Epoch: 675, Loss: 0.6286, Train: 63.30%, Valid: 63.30%, Test: 63.19%
Epoch: 700, Loss: 0.6283, Train: 63.28%, Valid: 63.32%, Test: 63.22%
Epoch: 725, Loss: 0.6290, Train: 63.61%, Valid: 63.65%, Test: 63.57%
Epoch: 750, Loss: 0.6232, Train: 63.32%, Valid: 63.34%, Test: 63.22%
Epoch: 775, Loss: 0.6181, Train: 64.61%, Valid: 64.58%, Test: 64.51%
Epoch: 800, Loss: 0.6117, Train: 65.13%, Valid: 65.07%, Test: 65.06%
Epoch: 825, Loss: 0.6187, Train: 64.69%, Valid: 64.64%, Test: 64.53%
Epoch: 850, Loss: 0.6153, Train: 65.18%, Valid: 65.17%, Test: 65.07%
Epoch: 875, Loss: 0.6126, Train: 65.58%, Valid: 65.56%, Test: 65.53%
Epoch: 900, Loss: 0.6076, Train: 65.31%, Valid: 65.21%, Test: 65.29%
Epoch: 925, Loss: 0.6033, Train: 68.05%, Valid: 68.08%, Test: 67.98%
Epoch: 950, Loss: 0.6537, Train: 63.54%, Valid: 63.40%, Test: 63.49%
Epoch: 975, Loss: 0.6427, Train: 63.99%, Valid: 64.17%, Test: 64.10%
Run 01:
Highest Train: 69.54
Highest Valid: 69.63
  Final Train: 69.54
   Final Test: 69.48
All runs:
Highest Train: 69.54 ± nan
Highest Valid: 69.63 ± nan
  Final Train: 69.54 ± nan
   Final Test: 69.48 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7049, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.6908, Train: 52.05%, Valid: 52.06%, Test: 51.92%
Epoch: 50, Loss: 0.6840, Train: 57.95%, Valid: 57.95%, Test: 57.71%
Epoch: 75, Loss: 0.6649, Train: 59.87%, Valid: 59.79%, Test: 59.79%
Epoch: 100, Loss: 0.6442, Train: 61.28%, Valid: 61.21%, Test: 61.21%
Epoch: 125, Loss: 0.6414, Train: 61.48%, Valid: 61.44%, Test: 61.44%
Epoch: 150, Loss: 0.6409, Train: 61.51%, Valid: 61.48%, Test: 61.44%
Epoch: 175, Loss: 0.6408, Train: 61.50%, Valid: 61.47%, Test: 61.37%
Epoch: 200, Loss: 0.6403, Train: 61.55%, Valid: 61.56%, Test: 61.48%
Epoch: 225, Loss: 0.6398, Train: 61.56%, Valid: 61.56%, Test: 61.42%
Epoch: 250, Loss: 0.6388, Train: 61.75%, Valid: 61.79%, Test: 61.69%
Epoch: 275, Loss: 0.6378, Train: 61.78%, Valid: 61.80%, Test: 61.67%
Epoch: 300, Loss: 0.6372, Train: 61.88%, Valid: 61.89%, Test: 61.77%
Epoch: 325, Loss: 0.6364, Train: 61.99%, Valid: 62.01%, Test: 61.90%
Epoch: 350, Loss: 0.6358, Train: 62.04%, Valid: 62.07%, Test: 61.93%
Epoch: 375, Loss: 0.6353, Train: 62.03%, Valid: 62.06%, Test: 61.92%
Epoch: 400, Loss: 0.6350, Train: 62.09%, Valid: 62.07%, Test: 61.97%
Epoch: 425, Loss: 0.6358, Train: 62.06%, Valid: 62.04%, Test: 61.92%
Epoch: 450, Loss: 0.6343, Train: 62.14%, Valid: 62.14%, Test: 62.03%
Epoch: 475, Loss: 0.6342, Train: 62.18%, Valid: 62.14%, Test: 62.07%
Epoch: 500, Loss: 0.6343, Train: 62.22%, Valid: 62.19%, Test: 62.00%
Epoch: 525, Loss: 0.6344, Train: 62.17%, Valid: 62.14%, Test: 62.04%
Epoch: 550, Loss: 0.6336, Train: 62.27%, Valid: 62.22%, Test: 62.08%
Epoch: 575, Loss: 0.6337, Train: 62.32%, Valid: 62.26%, Test: 62.09%
Epoch: 600, Loss: 0.6337, Train: 62.30%, Valid: 62.28%, Test: 62.19%
Epoch: 625, Loss: 0.6340, Train: 62.25%, Valid: 62.21%, Test: 62.08%
Epoch: 650, Loss: 0.6335, Train: 62.29%, Valid: 62.28%, Test: 62.16%
Epoch: 675, Loss: 0.6332, Train: 62.34%, Valid: 62.28%, Test: 62.17%
Epoch: 700, Loss: 0.6331, Train: 62.35%, Valid: 62.32%, Test: 62.21%
Epoch: 725, Loss: 0.6338, Train: 62.46%, Valid: 62.37%, Test: 62.26%
Epoch: 750, Loss: 0.6324, Train: 62.47%, Valid: 62.39%, Test: 62.31%
Epoch: 775, Loss: 0.6339, Train: 62.29%, Valid: 62.30%, Test: 62.12%
Epoch: 800, Loss: 0.6320, Train: 62.49%, Valid: 62.41%, Test: 62.33%
Epoch: 825, Loss: 0.6320, Train: 62.52%, Valid: 62.38%, Test: 62.30%
Epoch: 850, Loss: 0.6319, Train: 62.44%, Valid: 62.39%, Test: 62.27%
Epoch: 875, Loss: 0.6315, Train: 62.57%, Valid: 62.49%, Test: 62.38%
Epoch: 900, Loss: 0.6317, Train: 62.49%, Valid: 62.34%, Test: 62.25%
Epoch: 925, Loss: 0.6312, Train: 62.50%, Valid: 62.44%, Test: 62.35%
Epoch: 950, Loss: 0.6311, Train: 62.62%, Valid: 62.50%, Test: 62.41%
Epoch: 975, Loss: 0.6314, Train: 62.61%, Valid: 62.48%, Test: 62.39%
Run 01:
Highest Train: 62.63
Highest Valid: 62.58
  Final Train: 62.63
   Final Test: 62.40
All runs:
Highest Train: 62.63 ± nan
Highest Valid: 62.58 ± nan
  Final Train: 62.63 ± nan
   Final Test: 62.40 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6963, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.6902, Train: 51.96%, Valid: 52.18%, Test: 51.86%
Epoch: 50, Loss: 0.6839, Train: 56.48%, Valid: 56.43%, Test: 56.41%
Epoch: 75, Loss: 0.6686, Train: 59.69%, Valid: 59.63%, Test: 59.66%
Epoch: 100, Loss: 0.6482, Train: 61.11%, Valid: 61.09%, Test: 61.04%
Epoch: 125, Loss: 0.6418, Train: 61.47%, Valid: 61.43%, Test: 61.38%
Epoch: 150, Loss: 0.6407, Train: 61.53%, Valid: 61.51%, Test: 61.49%
Epoch: 175, Loss: 0.6402, Train: 61.56%, Valid: 61.55%, Test: 61.49%
Epoch: 200, Loss: 0.6397, Train: 61.56%, Valid: 61.58%, Test: 61.47%
Epoch: 225, Loss: 0.6391, Train: 61.61%, Valid: 61.60%, Test: 61.54%
Epoch: 250, Loss: 0.6387, Train: 61.65%, Valid: 61.64%, Test: 61.60%
Epoch: 275, Loss: 0.6380, Train: 61.70%, Valid: 61.69%, Test: 61.64%
Epoch: 300, Loss: 0.6374, Train: 61.82%, Valid: 61.83%, Test: 61.78%
Epoch: 325, Loss: 0.6368, Train: 61.86%, Valid: 61.84%, Test: 61.81%
Epoch: 350, Loss: 0.6366, Train: 61.93%, Valid: 61.90%, Test: 61.84%
Epoch: 375, Loss: 0.6364, Train: 61.92%, Valid: 61.95%, Test: 61.82%
Epoch: 400, Loss: 0.6361, Train: 61.93%, Valid: 61.92%, Test: 61.81%
Epoch: 425, Loss: 0.6355, Train: 62.04%, Valid: 62.01%, Test: 61.95%
Epoch: 450, Loss: 0.6355, Train: 62.02%, Valid: 62.02%, Test: 61.93%
Epoch: 475, Loss: 0.6369, Train: 61.88%, Valid: 61.88%, Test: 61.78%
Epoch: 500, Loss: 0.6348, Train: 62.15%, Valid: 62.16%, Test: 62.03%
Epoch: 525, Loss: 0.6346, Train: 62.19%, Valid: 62.20%, Test: 62.11%
Epoch: 550, Loss: 0.6342, Train: 62.24%, Valid: 62.22%, Test: 62.12%
Epoch: 575, Loss: 0.6340, Train: 62.32%, Valid: 62.31%, Test: 62.11%
Epoch: 600, Loss: 0.6338, Train: 62.31%, Valid: 62.31%, Test: 62.09%
Epoch: 625, Loss: 0.6332, Train: 62.36%, Valid: 62.34%, Test: 62.22%
Epoch: 650, Loss: 0.6334, Train: 62.21%, Valid: 62.23%, Test: 62.10%
Epoch: 675, Loss: 0.6327, Train: 62.39%, Valid: 62.38%, Test: 62.24%
Epoch: 700, Loss: 0.6324, Train: 62.43%, Valid: 62.42%, Test: 62.31%
Epoch: 725, Loss: 0.6327, Train: 62.38%, Valid: 62.38%, Test: 62.24%
Epoch: 750, Loss: 0.6326, Train: 62.54%, Valid: 62.53%, Test: 62.35%
Epoch: 775, Loss: 0.6317, Train: 62.55%, Valid: 62.53%, Test: 62.35%
Epoch: 800, Loss: 0.6315, Train: 62.59%, Valid: 62.56%, Test: 62.36%
Epoch: 825, Loss: 0.6314, Train: 62.51%, Valid: 62.48%, Test: 62.39%
Epoch: 850, Loss: 0.6322, Train: 62.62%, Valid: 62.60%, Test: 62.40%
Epoch: 875, Loss: 0.6318, Train: 62.56%, Valid: 62.52%, Test: 62.31%
Epoch: 900, Loss: 0.6307, Train: 62.71%, Valid: 62.64%, Test: 62.48%
Epoch: 925, Loss: 0.6317, Train: 62.55%, Valid: 62.50%, Test: 62.42%
Epoch: 950, Loss: 0.6301, Train: 62.74%, Valid: 62.70%, Test: 62.60%
Epoch: 975, Loss: 0.6305, Train: 62.83%, Valid: 62.81%, Test: 62.60%
Run 01:
Highest Train: 62.88
Highest Valid: 62.84
  Final Train: 62.88
   Final Test: 62.64
All runs:
Highest Train: 62.88 ± nan
Highest Valid: 62.84 ± nan
  Final Train: 62.88 ± nan
   Final Test: 62.64 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.0919, Train: 50.13%, Valid: 49.98%, Test: 50.02%
Epoch: 25, Loss: 0.7426, Train: 50.97%, Valid: 50.65%, Test: 50.91%
Epoch: 50, Loss: 0.6907, Train: 56.45%, Valid: 56.24%, Test: 56.31%
Epoch: 75, Loss: 0.6763, Train: 58.64%, Valid: 58.73%, Test: 58.63%
Epoch: 100, Loss: 0.6668, Train: 59.81%, Valid: 59.80%, Test: 59.82%
Epoch: 125, Loss: 0.6580, Train: 60.57%, Valid: 60.58%, Test: 60.62%
Epoch: 150, Loss: 0.6507, Train: 61.06%, Valid: 61.04%, Test: 61.10%
Epoch: 175, Loss: 0.6454, Train: 61.43%, Valid: 61.39%, Test: 61.40%
Epoch: 200, Loss: 0.6419, Train: 61.77%, Valid: 61.77%, Test: 61.74%
Epoch: 225, Loss: 0.6397, Train: 62.00%, Valid: 61.99%, Test: 61.97%
Epoch: 250, Loss: 0.6382, Train: 62.16%, Valid: 62.13%, Test: 62.13%
Epoch: 275, Loss: 0.6370, Train: 62.28%, Valid: 62.24%, Test: 62.25%
Epoch: 300, Loss: 0.6361, Train: 62.40%, Valid: 62.37%, Test: 62.35%
Epoch: 325, Loss: 0.6410, Train: 61.33%, Valid: 61.28%, Test: 61.16%
Epoch: 350, Loss: 0.6351, Train: 62.62%, Valid: 62.56%, Test: 62.49%
Epoch: 375, Loss: 0.6340, Train: 62.74%, Valid: 62.73%, Test: 62.69%
Epoch: 400, Loss: 0.6325, Train: 62.95%, Valid: 62.94%, Test: 62.90%
Epoch: 425, Loss: 0.6304, Train: 63.33%, Valid: 63.31%, Test: 63.27%
Epoch: 450, Loss: 0.6300, Train: 63.22%, Valid: 63.25%, Test: 63.17%
Epoch: 475, Loss: 0.6250, Train: 64.15%, Valid: 64.15%, Test: 64.13%
Epoch: 500, Loss: 0.6353, Train: 63.66%, Valid: 63.58%, Test: 63.58%
Epoch: 525, Loss: 0.6249, Train: 64.35%, Valid: 64.37%, Test: 64.26%
Epoch: 550, Loss: 0.6251, Train: 63.99%, Valid: 63.96%, Test: 63.93%
Epoch: 575, Loss: 0.6237, Train: 64.25%, Valid: 64.23%, Test: 64.22%
Epoch: 600, Loss: 0.6251, Train: 63.78%, Valid: 63.76%, Test: 63.66%
Epoch: 625, Loss: 0.6233, Train: 64.60%, Valid: 64.63%, Test: 64.51%
Epoch: 650, Loss: 0.6200, Train: 64.84%, Valid: 64.85%, Test: 64.76%
Epoch: 675, Loss: 0.6184, Train: 64.99%, Valid: 65.02%, Test: 64.94%
Epoch: 700, Loss: 0.6291, Train: 63.43%, Valid: 63.37%, Test: 63.35%
Epoch: 725, Loss: 0.6157, Train: 65.61%, Valid: 65.57%, Test: 65.53%
Epoch: 750, Loss: 0.6268, Train: 63.91%, Valid: 63.88%, Test: 63.86%
Epoch: 775, Loss: 0.6166, Train: 65.42%, Valid: 65.38%, Test: 65.32%
Epoch: 800, Loss: 0.6163, Train: 65.47%, Valid: 65.48%, Test: 65.43%
Epoch: 825, Loss: 0.6149, Train: 65.30%, Valid: 65.26%, Test: 65.17%
Epoch: 850, Loss: 0.6138, Train: 65.34%, Valid: 65.30%, Test: 65.21%
Epoch: 875, Loss: 0.6129, Train: 64.75%, Valid: 64.70%, Test: 64.65%
Epoch: 900, Loss: 0.6126, Train: 65.52%, Valid: 65.56%, Test: 65.42%
Epoch: 925, Loss: 0.6180, Train: 65.63%, Valid: 65.64%, Test: 65.53%
Epoch: 950, Loss: 0.6374, Train: 63.87%, Valid: 63.88%, Test: 63.88%
Epoch: 975, Loss: 0.6341, Train: 65.18%, Valid: 65.20%, Test: 65.13%
Run 01:
Highest Train: 66.18
Highest Valid: 66.16
  Final Train: 66.18
   Final Test: 66.07
All runs:
Highest Train: 66.18 ± nan
Highest Valid: 66.16 ± nan
  Final Train: 66.18 ± nan
   Final Test: 66.07 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7127, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.7187, Train: 49.45%, Valid: 49.51%, Test: 49.56%
Epoch: 50, Loss: 0.6874, Train: 52.93%, Valid: 52.96%, Test: 53.03%
Epoch: 75, Loss: 0.6806, Train: 57.46%, Valid: 57.42%, Test: 57.39%
Epoch: 100, Loss: 0.6735, Train: 59.18%, Valid: 59.07%, Test: 59.17%
Epoch: 125, Loss: 0.6644, Train: 60.12%, Valid: 60.02%, Test: 60.09%
Epoch: 150, Loss: 0.6548, Train: 60.78%, Valid: 60.76%, Test: 60.78%
Epoch: 175, Loss: 0.6475, Train: 61.13%, Valid: 61.10%, Test: 61.09%
Epoch: 200, Loss: 0.6420, Train: 61.49%, Valid: 61.48%, Test: 61.46%
Epoch: 225, Loss: 0.6406, Train: 61.56%, Valid: 61.57%, Test: 61.48%
Epoch: 250, Loss: 0.6403, Train: 61.58%, Valid: 61.59%, Test: 61.49%
Epoch: 275, Loss: 0.6400, Train: 61.61%, Valid: 61.64%, Test: 61.53%
Epoch: 300, Loss: 0.6397, Train: 61.65%, Valid: 61.70%, Test: 61.58%
Epoch: 325, Loss: 0.6393, Train: 61.68%, Valid: 61.73%, Test: 61.63%
Epoch: 350, Loss: 0.6386, Train: 61.74%, Valid: 61.80%, Test: 61.71%
Epoch: 375, Loss: 0.6377, Train: 61.86%, Valid: 61.86%, Test: 61.75%
Epoch: 400, Loss: 0.6377, Train: 61.86%, Valid: 61.89%, Test: 61.82%
Epoch: 425, Loss: 0.6363, Train: 62.01%, Valid: 62.00%, Test: 61.92%
Epoch: 450, Loss: 0.6357, Train: 62.06%, Valid: 62.04%, Test: 61.95%
Epoch: 475, Loss: 0.6355, Train: 62.07%, Valid: 62.07%, Test: 62.01%
Epoch: 500, Loss: 0.6353, Train: 62.10%, Valid: 62.13%, Test: 62.03%
Epoch: 525, Loss: 0.6351, Train: 62.13%, Valid: 62.19%, Test: 62.08%
Epoch: 550, Loss: 0.6345, Train: 62.18%, Valid: 62.23%, Test: 62.13%
Epoch: 575, Loss: 0.6349, Train: 62.16%, Valid: 62.18%, Test: 62.09%
Epoch: 600, Loss: 0.6344, Train: 62.20%, Valid: 62.24%, Test: 62.12%
Epoch: 625, Loss: 0.6342, Train: 62.27%, Valid: 62.29%, Test: 62.14%
Epoch: 650, Loss: 0.6342, Train: 62.22%, Valid: 62.25%, Test: 62.14%
Epoch: 675, Loss: 0.6337, Train: 62.33%, Valid: 62.33%, Test: 62.20%
Epoch: 700, Loss: 0.6336, Train: 62.34%, Valid: 62.34%, Test: 62.19%
Epoch: 725, Loss: 0.6335, Train: 62.28%, Valid: 62.31%, Test: 62.19%
Epoch: 750, Loss: 0.6334, Train: 62.33%, Valid: 62.29%, Test: 62.21%
Epoch: 775, Loss: 0.6333, Train: 62.35%, Valid: 62.35%, Test: 62.22%
Epoch: 800, Loss: 0.6348, Train: 62.02%, Valid: 62.03%, Test: 61.88%
Epoch: 825, Loss: 0.6330, Train: 62.37%, Valid: 62.40%, Test: 62.28%
Epoch: 850, Loss: 0.6329, Train: 62.42%, Valid: 62.41%, Test: 62.27%
Epoch: 875, Loss: 0.6339, Train: 62.34%, Valid: 62.30%, Test: 62.19%
Epoch: 900, Loss: 0.6331, Train: 62.43%, Valid: 62.40%, Test: 62.25%
Epoch: 925, Loss: 0.6326, Train: 62.40%, Valid: 62.38%, Test: 62.30%
Epoch: 950, Loss: 0.6324, Train: 62.43%, Valid: 62.42%, Test: 62.33%
Epoch: 975, Loss: 0.6323, Train: 62.46%, Valid: 62.42%, Test: 62.26%
Run 01:
Highest Train: 62.50
Highest Valid: 62.48
  Final Train: 62.49
   Final Test: 62.32
All runs:
Highest Train: 62.50 ± nan
Highest Valid: 62.48 ± nan
  Final Train: 62.49 ± nan
   Final Test: 62.32 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7320, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7185, Train: 52.10%, Valid: 52.11%, Test: 51.96%
Epoch: 50, Loss: 0.6842, Train: 56.26%, Valid: 56.24%, Test: 56.01%
Epoch: 75, Loss: 0.6777, Train: 58.86%, Valid: 58.76%, Test: 58.80%
Epoch: 100, Loss: 0.6692, Train: 60.11%, Valid: 60.07%, Test: 60.09%
Epoch: 125, Loss: 0.6594, Train: 60.68%, Valid: 60.67%, Test: 60.66%
Epoch: 150, Loss: 0.6508, Train: 61.09%, Valid: 61.05%, Test: 61.04%
Epoch: 175, Loss: 0.6447, Train: 61.42%, Valid: 61.34%, Test: 61.35%
Epoch: 200, Loss: 0.6407, Train: 61.61%, Valid: 61.65%, Test: 61.61%
Epoch: 225, Loss: 0.6397, Train: 61.68%, Valid: 61.70%, Test: 61.63%
Epoch: 250, Loss: 0.6393, Train: 61.67%, Valid: 61.72%, Test: 61.64%
Epoch: 275, Loss: 0.6390, Train: 61.71%, Valid: 61.76%, Test: 61.67%
Epoch: 300, Loss: 0.6386, Train: 61.74%, Valid: 61.79%, Test: 61.69%
Epoch: 325, Loss: 0.6381, Train: 61.80%, Valid: 61.85%, Test: 61.76%
Epoch: 350, Loss: 0.6377, Train: 61.85%, Valid: 61.91%, Test: 61.79%
Epoch: 375, Loss: 0.6372, Train: 61.91%, Valid: 61.94%, Test: 61.85%
Epoch: 400, Loss: 0.6368, Train: 61.92%, Valid: 61.96%, Test: 61.89%
Epoch: 425, Loss: 0.6361, Train: 62.05%, Valid: 62.11%, Test: 61.98%
Epoch: 450, Loss: 0.6361, Train: 62.02%, Valid: 62.06%, Test: 61.97%
Epoch: 475, Loss: 0.6348, Train: 62.26%, Valid: 62.28%, Test: 62.17%
Epoch: 500, Loss: 0.6344, Train: 62.23%, Valid: 62.24%, Test: 62.21%
Epoch: 525, Loss: 0.6344, Train: 62.44%, Valid: 62.43%, Test: 62.32%
Epoch: 550, Loss: 0.6326, Train: 62.63%, Valid: 62.66%, Test: 62.55%
Epoch: 575, Loss: 0.6322, Train: 62.68%, Valid: 62.64%, Test: 62.60%
Epoch: 600, Loss: 0.6310, Train: 62.83%, Valid: 62.84%, Test: 62.73%
Epoch: 625, Loss: 0.6297, Train: 63.03%, Valid: 63.00%, Test: 62.91%
Epoch: 650, Loss: 0.6647, Train: 62.52%, Valid: 62.45%, Test: 62.34%
Epoch: 675, Loss: 0.6302, Train: 63.03%, Valid: 62.97%, Test: 62.92%
Epoch: 700, Loss: 0.6245, Train: 64.08%, Valid: 64.01%, Test: 63.97%
Epoch: 725, Loss: 0.6275, Train: 63.37%, Valid: 63.40%, Test: 63.31%
Epoch: 750, Loss: 0.6391, Train: 61.31%, Valid: 61.17%, Test: 61.19%
Epoch: 775, Loss: 0.6198, Train: 65.48%, Valid: 65.48%, Test: 65.35%
Epoch: 800, Loss: 0.6080, Train: 66.26%, Valid: 66.26%, Test: 66.22%
Epoch: 825, Loss: 0.6367, Train: 60.55%, Valid: 60.46%, Test: 60.47%
Epoch: 850, Loss: 0.6244, Train: 65.35%, Valid: 65.20%, Test: 65.20%
Epoch: 875, Loss: 0.6246, Train: 64.15%, Valid: 64.15%, Test: 64.08%
Epoch: 900, Loss: 0.6536, Train: 61.25%, Valid: 61.20%, Test: 61.25%
Epoch: 925, Loss: 0.6279, Train: 63.48%, Valid: 63.32%, Test: 63.36%
Epoch: 950, Loss: 0.6147, Train: 66.87%, Valid: 66.84%, Test: 66.85%
Epoch: 975, Loss: 0.6214, Train: 64.23%, Valid: 64.33%, Test: 64.13%
Run 01:
Highest Train: 68.87
Highest Valid: 68.88
  Final Train: 68.87
   Final Test: 68.78
All runs:
Highest Train: 68.87 ± nan
Highest Valid: 68.88 ± nan
  Final Train: 68.87 ± nan
   Final Test: 68.78 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.5, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.1458, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7565, Train: 49.61%, Valid: 49.89%, Test: 49.67%
Epoch: 50, Loss: 0.6837, Train: 56.56%, Valid: 56.39%, Test: 56.51%
Epoch: 75, Loss: 0.6739, Train: 59.23%, Valid: 59.11%, Test: 59.19%
Epoch: 100, Loss: 0.6624, Train: 60.51%, Valid: 60.41%, Test: 60.53%
Epoch: 125, Loss: 0.6499, Train: 61.40%, Valid: 61.38%, Test: 61.42%
Epoch: 150, Loss: 0.6415, Train: 61.87%, Valid: 61.73%, Test: 61.80%
Epoch: 175, Loss: 0.6386, Train: 62.03%, Valid: 61.96%, Test: 61.98%
Epoch: 200, Loss: 0.6379, Train: 62.10%, Valid: 62.07%, Test: 62.05%
Epoch: 225, Loss: 0.6376, Train: 62.11%, Valid: 62.12%, Test: 62.08%
Epoch: 250, Loss: 0.6373, Train: 62.14%, Valid: 62.16%, Test: 62.11%
Epoch: 275, Loss: 0.6371, Train: 62.17%, Valid: 62.18%, Test: 62.14%
Epoch: 300, Loss: 0.6368, Train: 62.23%, Valid: 62.24%, Test: 62.18%
Epoch: 325, Loss: 0.6366, Train: 62.23%, Valid: 62.27%, Test: 62.15%
Epoch: 350, Loss: 0.6361, Train: 62.33%, Valid: 62.33%, Test: 62.27%
Epoch: 375, Loss: 0.6356, Train: 62.41%, Valid: 62.42%, Test: 62.34%
Epoch: 400, Loss: 0.6346, Train: 62.64%, Valid: 62.66%, Test: 62.53%
Epoch: 425, Loss: 0.6356, Train: 60.23%, Valid: 60.31%, Test: 60.28%
Epoch: 450, Loss: 0.6358, Train: 62.15%, Valid: 62.13%, Test: 62.05%
Epoch: 475, Loss: 0.6317, Train: 63.16%, Valid: 63.15%, Test: 63.06%
Epoch: 500, Loss: 0.6439, Train: 58.41%, Valid: 58.35%, Test: 58.27%
Epoch: 525, Loss: 0.6365, Train: 62.24%, Valid: 62.20%, Test: 62.17%
Epoch: 550, Loss: 0.6332, Train: 62.79%, Valid: 62.79%, Test: 62.70%
Epoch: 575, Loss: 0.6249, Train: 64.24%, Valid: 64.29%, Test: 64.24%
Epoch: 600, Loss: 0.6327, Train: 63.08%, Valid: 63.05%, Test: 63.00%
Epoch: 625, Loss: 0.6361, Train: 62.87%, Valid: 62.77%, Test: 62.74%
Epoch: 650, Loss: 0.6301, Train: 63.16%, Valid: 63.19%, Test: 63.15%
Epoch: 675, Loss: 0.6692, Train: 61.12%, Valid: 61.27%, Test: 61.03%
Epoch: 700, Loss: 0.6371, Train: 62.31%, Valid: 62.35%, Test: 62.17%
Epoch: 725, Loss: 0.6232, Train: 64.89%, Valid: 64.85%, Test: 64.76%
Epoch: 750, Loss: 0.6256, Train: 63.74%, Valid: 63.72%, Test: 63.75%
Epoch: 775, Loss: 0.6168, Train: 65.00%, Valid: 64.99%, Test: 64.93%
Epoch: 800, Loss: 0.6079, Train: 67.04%, Valid: 67.06%, Test: 66.91%
Epoch: 825, Loss: 0.5975, Train: 68.49%, Valid: 68.46%, Test: 68.44%
Epoch: 850, Loss: 0.6077, Train: 66.92%, Valid: 66.97%, Test: 66.76%
Epoch: 875, Loss: 0.5855, Train: 69.14%, Valid: 69.16%, Test: 69.00%
Epoch: 900, Loss: 0.6251, Train: 62.65%, Valid: 62.84%, Test: 62.65%
Epoch: 925, Loss: 0.6065, Train: 66.04%, Valid: 65.91%, Test: 65.92%
Epoch: 950, Loss: 0.5824, Train: 71.93%, Valid: 71.93%, Test: 71.94%
Epoch: 975, Loss: 0.5642, Train: 68.45%, Valid: 68.42%, Test: 68.46%
Run 01:
Highest Train: 73.70
Highest Valid: 73.63
  Final Train: 73.70
   Final Test: 73.68
All runs:
Highest Train: 73.70 ± nan
Highest Valid: 73.63 ± nan
  Final Train: 73.70 ± nan
   Final Test: 73.68 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.1817, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.6873, Train: 51.80%, Valid: 51.81%, Test: 51.89%
Epoch: 50, Loss: 0.6886, Train: 51.68%, Valid: 51.64%, Test: 51.53%
Epoch: 75, Loss: 0.6837, Train: 56.48%, Valid: 56.46%, Test: 56.30%
Epoch: 100, Loss: 0.6781, Train: 58.25%, Valid: 58.06%, Test: 58.17%
Epoch: 125, Loss: 0.6710, Train: 59.05%, Valid: 58.90%, Test: 59.01%
Epoch: 150, Loss: 0.6593, Train: 60.46%, Valid: 60.43%, Test: 60.42%
Epoch: 175, Loss: 0.6433, Train: 61.43%, Valid: 61.42%, Test: 61.37%
Epoch: 200, Loss: 0.6408, Train: 61.58%, Valid: 61.58%, Test: 61.50%
Epoch: 225, Loss: 0.6404, Train: 61.62%, Valid: 61.64%, Test: 61.54%
Epoch: 250, Loss: 0.6402, Train: 61.63%, Valid: 61.67%, Test: 61.57%
Epoch: 275, Loss: 0.6397, Train: 61.69%, Valid: 61.70%, Test: 61.60%
Epoch: 300, Loss: 0.6390, Train: 61.73%, Valid: 61.76%, Test: 61.67%
Epoch: 325, Loss: 0.6387, Train: 61.79%, Valid: 61.76%, Test: 61.71%
Epoch: 350, Loss: 0.6383, Train: 61.83%, Valid: 61.82%, Test: 61.70%
Epoch: 375, Loss: 0.6380, Train: 61.85%, Valid: 61.84%, Test: 61.73%
Epoch: 400, Loss: 0.6378, Train: 61.91%, Valid: 61.92%, Test: 61.77%
Epoch: 425, Loss: 0.6373, Train: 61.95%, Valid: 61.96%, Test: 61.79%
Epoch: 450, Loss: 0.6370, Train: 61.98%, Valid: 61.96%, Test: 61.79%
Epoch: 475, Loss: 0.6365, Train: 62.04%, Valid: 61.98%, Test: 61.87%
Epoch: 500, Loss: 0.6367, Train: 62.07%, Valid: 62.02%, Test: 61.87%
Epoch: 525, Loss: 0.6359, Train: 62.08%, Valid: 62.06%, Test: 61.93%
Epoch: 550, Loss: 0.6357, Train: 62.10%, Valid: 62.08%, Test: 61.95%
Epoch: 575, Loss: 0.6355, Train: 62.16%, Valid: 62.12%, Test: 61.95%
Epoch: 600, Loss: 0.6355, Train: 62.16%, Valid: 62.16%, Test: 61.98%
Epoch: 625, Loss: 0.6350, Train: 62.21%, Valid: 62.19%, Test: 62.02%
Epoch: 650, Loss: 0.6346, Train: 62.23%, Valid: 62.19%, Test: 62.06%
Epoch: 675, Loss: 0.6343, Train: 62.30%, Valid: 62.29%, Test: 62.16%
Epoch: 700, Loss: 0.6336, Train: 62.38%, Valid: 62.30%, Test: 62.17%
Epoch: 725, Loss: 0.6326, Train: 62.27%, Valid: 62.24%, Test: 62.12%
Epoch: 750, Loss: 0.6347, Train: 62.35%, Valid: 62.29%, Test: 62.20%
Epoch: 775, Loss: 0.6334, Train: 62.40%, Valid: 62.36%, Test: 62.24%
Epoch: 800, Loss: 0.6329, Train: 62.50%, Valid: 62.47%, Test: 62.36%
Epoch: 825, Loss: 0.6314, Train: 62.84%, Valid: 62.76%, Test: 62.69%
Epoch: 850, Loss: 0.6410, Train: 56.61%, Valid: 56.61%, Test: 56.56%
Epoch: 875, Loss: 0.6452, Train: 61.19%, Valid: 61.16%, Test: 61.18%
Epoch: 900, Loss: 0.6371, Train: 62.02%, Valid: 61.93%, Test: 61.92%
Epoch: 925, Loss: 0.6347, Train: 62.28%, Valid: 62.24%, Test: 62.17%
Epoch: 950, Loss: 0.6330, Train: 62.47%, Valid: 62.46%, Test: 62.37%
Epoch: 975, Loss: 0.6316, Train: 62.62%, Valid: 62.57%, Test: 62.54%
Run 01:
Highest Train: 63.75
Highest Valid: 63.66
  Final Train: 63.75
   Final Test: 63.50
All runs:
Highest Train: 63.75 ± nan
Highest Valid: 63.66 ± nan
  Final Train: 63.75 ± nan
   Final Test: 63.50 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.0563, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7568, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 50, Loss: 0.6871, Train: 54.01%, Valid: 54.14%, Test: 54.06%
Epoch: 75, Loss: 0.6788, Train: 57.07%, Valid: 57.07%, Test: 57.04%
Epoch: 100, Loss: 0.6726, Train: 59.20%, Valid: 59.09%, Test: 59.17%
Epoch: 125, Loss: 0.6650, Train: 59.98%, Valid: 59.93%, Test: 59.96%
Epoch: 150, Loss: 0.6568, Train: 60.67%, Valid: 60.67%, Test: 60.66%
Epoch: 175, Loss: 0.6496, Train: 61.07%, Valid: 61.05%, Test: 61.06%
Epoch: 200, Loss: 0.6423, Train: 61.54%, Valid: 61.53%, Test: 61.47%
Epoch: 225, Loss: 0.6405, Train: 61.62%, Valid: 61.61%, Test: 61.57%
Epoch: 250, Loss: 0.6402, Train: 61.65%, Valid: 61.67%, Test: 61.59%
Epoch: 275, Loss: 0.6398, Train: 61.68%, Valid: 61.69%, Test: 61.62%
Epoch: 300, Loss: 0.6394, Train: 61.73%, Valid: 61.76%, Test: 61.65%
Epoch: 325, Loss: 0.6389, Train: 61.78%, Valid: 61.82%, Test: 61.71%
Epoch: 350, Loss: 0.6381, Train: 61.90%, Valid: 61.94%, Test: 61.82%
Epoch: 375, Loss: 0.6366, Train: 62.19%, Valid: 62.22%, Test: 62.12%
Epoch: 400, Loss: 0.6352, Train: 62.51%, Valid: 62.49%, Test: 62.43%
Epoch: 425, Loss: 0.6301, Train: 63.32%, Valid: 63.31%, Test: 63.26%
Epoch: 450, Loss: 0.6186, Train: 64.94%, Valid: 64.97%, Test: 64.83%
Epoch: 475, Loss: 0.6244, Train: 65.34%, Valid: 65.35%, Test: 65.22%
Epoch: 500, Loss: 0.5870, Train: 68.18%, Valid: 68.12%, Test: 68.12%
Epoch: 525, Loss: 0.6185, Train: 67.86%, Valid: 67.87%, Test: 67.75%
Epoch: 550, Loss: 0.5845, Train: 69.73%, Valid: 69.72%, Test: 69.61%
Epoch: 575, Loss: 0.5737, Train: 69.64%, Valid: 69.73%, Test: 69.60%
Epoch: 600, Loss: 0.5728, Train: 69.93%, Valid: 69.98%, Test: 69.86%
Epoch: 625, Loss: 0.6141, Train: 71.55%, Valid: 71.58%, Test: 71.58%
Epoch: 650, Loss: 0.5529, Train: 71.25%, Valid: 71.21%, Test: 71.22%
Epoch: 675, Loss: 0.5376, Train: 72.34%, Valid: 72.32%, Test: 72.33%
Epoch: 700, Loss: 0.5729, Train: 72.01%, Valid: 72.12%, Test: 72.02%
Epoch: 725, Loss: 0.5323, Train: 72.46%, Valid: 72.58%, Test: 72.45%
Epoch: 750, Loss: 0.5389, Train: 72.35%, Valid: 72.48%, Test: 72.34%
Epoch: 775, Loss: 0.5251, Train: 72.87%, Valid: 72.95%, Test: 72.87%
Epoch: 800, Loss: 0.5260, Train: 74.38%, Valid: 74.49%, Test: 74.46%
Epoch: 825, Loss: 0.5358, Train: 73.39%, Valid: 73.49%, Test: 73.41%
Epoch: 850, Loss: 0.5184, Train: 74.55%, Valid: 74.66%, Test: 74.62%
Epoch: 875, Loss: 0.5122, Train: 74.47%, Valid: 74.53%, Test: 74.59%
Epoch: 900, Loss: 0.5124, Train: 73.86%, Valid: 73.91%, Test: 73.88%
Epoch: 925, Loss: 0.5075, Train: 74.90%, Valid: 74.96%, Test: 74.97%
Epoch: 950, Loss: 0.5051, Train: 74.49%, Valid: 74.51%, Test: 74.56%
Epoch: 975, Loss: 0.5415, Train: 74.20%, Valid: 74.27%, Test: 74.27%
Run 01:
Highest Train: 75.03
Highest Valid: 75.06
  Final Train: 75.03
   Final Test: 75.06
All runs:
Highest Train: 75.03 ± nan
Highest Valid: 75.06 ± nan
  Final Train: 75.03 ± nan
   Final Test: 75.06 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.3140, Train: 49.22%, Valid: 48.98%, Test: 49.29%
Epoch: 25, Loss: 0.9148, Train: 51.89%, Valid: 51.71%, Test: 51.80%
Epoch: 50, Loss: 0.7015, Train: 53.91%, Valid: 53.96%, Test: 54.01%
Epoch: 75, Loss: 0.6860, Train: 60.00%, Valid: 59.87%, Test: 59.89%
Epoch: 100, Loss: 0.6828, Train: 61.85%, Valid: 61.81%, Test: 61.86%
Epoch: 125, Loss: 0.6799, Train: 61.81%, Valid: 61.76%, Test: 61.81%
Epoch: 150, Loss: 0.6744, Train: 63.31%, Valid: 63.25%, Test: 63.24%
Epoch: 175, Loss: 0.6748, Train: 61.45%, Valid: 61.29%, Test: 61.47%
Epoch: 200, Loss: 0.6670, Train: 62.57%, Valid: 62.63%, Test: 62.59%
Epoch: 225, Loss: 0.6730, Train: 61.20%, Valid: 61.11%, Test: 61.11%
Epoch: 250, Loss: 0.6578, Train: 58.34%, Valid: 58.20%, Test: 58.31%
Epoch: 275, Loss: 0.6940, Train: 61.41%, Valid: 61.28%, Test: 61.40%
Epoch: 300, Loss: 0.6710, Train: 61.21%, Valid: 61.23%, Test: 61.28%
Epoch: 325, Loss: 0.6548, Train: 65.34%, Valid: 65.41%, Test: 65.29%
Epoch: 350, Loss: 0.6633, Train: 60.49%, Valid: 60.47%, Test: 60.52%
Epoch: 375, Loss: 0.6462, Train: 65.72%, Valid: 65.74%, Test: 65.68%
Epoch: 400, Loss: 0.6894, Train: 62.82%, Valid: 62.79%, Test: 62.82%
Epoch: 425, Loss: 0.6452, Train: 63.58%, Valid: 63.59%, Test: 63.60%
Epoch: 450, Loss: 0.6387, Train: 67.94%, Valid: 67.98%, Test: 67.91%
Epoch: 475, Loss: 0.6194, Train: 67.91%, Valid: 67.90%, Test: 67.90%
Epoch: 500, Loss: 0.6161, Train: 68.04%, Valid: 68.06%, Test: 68.03%
Epoch: 525, Loss: 0.7052, Train: 68.24%, Valid: 68.14%, Test: 68.27%
Epoch: 550, Loss: 0.6134, Train: 68.53%, Valid: 68.49%, Test: 68.62%
Epoch: 575, Loss: 0.6062, Train: 66.65%, Valid: 66.52%, Test: 66.65%
Epoch: 600, Loss: 0.5895, Train: 70.62%, Valid: 70.55%, Test: 70.64%
Epoch: 625, Loss: 0.6319, Train: 64.68%, Valid: 64.74%, Test: 64.76%
Epoch: 650, Loss: 0.5920, Train: 70.49%, Valid: 70.53%, Test: 70.51%
Epoch: 675, Loss: 0.6041, Train: 72.11%, Valid: 72.08%, Test: 72.16%
Epoch: 700, Loss: 0.6093, Train: 74.26%, Valid: 74.17%, Test: 74.30%
Epoch: 725, Loss: 0.5621, Train: 70.57%, Valid: 70.54%, Test: 70.62%
Epoch: 750, Loss: 0.6273, Train: 74.14%, Valid: 74.18%, Test: 74.24%
Epoch: 775, Loss: 0.5360, Train: 74.06%, Valid: 74.05%, Test: 74.14%
Epoch: 800, Loss: 0.5451, Train: 74.39%, Valid: 74.32%, Test: 74.46%
Epoch: 825, Loss: 0.5302, Train: 73.53%, Valid: 73.57%, Test: 73.63%
Epoch: 850, Loss: 0.6006, Train: 72.23%, Valid: 72.31%, Test: 72.32%
Epoch: 875, Loss: 0.5210, Train: 76.03%, Valid: 75.99%, Test: 76.13%
Epoch: 900, Loss: 0.5274, Train: 75.49%, Valid: 75.53%, Test: 75.63%
Epoch: 925, Loss: 0.5046, Train: 76.38%, Valid: 76.43%, Test: 76.53%
Epoch: 950, Loss: 0.5040, Train: 75.24%, Valid: 75.34%, Test: 75.43%
Epoch: 975, Loss: 0.4892, Train: 76.98%, Valid: 76.88%, Test: 77.04%
Run 01:
Highest Train: 77.00
Highest Valid: 77.00
  Final Train: 77.00
   Final Test: 77.10
All runs:
Highest Train: 77.00 ± nan
Highest Valid: 77.00 ± nan
  Final Train: 77.00 ± nan
   Final Test: 77.10 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7002, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.6940, Train: 50.49%, Valid: 50.61%, Test: 50.63%
Epoch: 50, Loss: 0.6913, Train: 52.62%, Valid: 52.67%, Test: 52.63%
Epoch: 75, Loss: 0.6879, Train: 54.85%, Valid: 54.94%, Test: 54.84%
Epoch: 100, Loss: 0.6729, Train: 59.25%, Valid: 59.23%, Test: 59.15%
Epoch: 125, Loss: 0.6498, Train: 60.87%, Valid: 60.86%, Test: 60.80%
Epoch: 150, Loss: 0.6421, Train: 61.43%, Valid: 61.41%, Test: 61.34%
Epoch: 175, Loss: 0.6413, Train: 61.48%, Valid: 61.46%, Test: 61.41%
Epoch: 200, Loss: 0.6411, Train: 61.51%, Valid: 61.50%, Test: 61.42%
Epoch: 225, Loss: 0.6410, Train: 61.52%, Valid: 61.52%, Test: 61.41%
Epoch: 250, Loss: 0.6409, Train: 61.51%, Valid: 61.51%, Test: 61.40%
Epoch: 275, Loss: 0.6407, Train: 61.53%, Valid: 61.53%, Test: 61.44%
Epoch: 300, Loss: 0.6411, Train: 61.41%, Valid: 61.43%, Test: 61.29%
Epoch: 325, Loss: 0.6402, Train: 61.57%, Valid: 61.57%, Test: 61.47%
Epoch: 350, Loss: 0.6398, Train: 61.58%, Valid: 61.63%, Test: 61.51%
Epoch: 375, Loss: 0.6396, Train: 61.58%, Valid: 61.60%, Test: 61.50%
Epoch: 400, Loss: 0.6392, Train: 61.63%, Valid: 61.69%, Test: 61.54%
Epoch: 425, Loss: 0.6388, Train: 61.66%, Valid: 61.69%, Test: 61.62%
Epoch: 450, Loss: 0.6398, Train: 61.71%, Valid: 61.74%, Test: 61.62%
Epoch: 475, Loss: 0.6380, Train: 61.79%, Valid: 61.81%, Test: 61.70%
Epoch: 500, Loss: 0.6371, Train: 61.86%, Valid: 61.92%, Test: 61.81%
Epoch: 525, Loss: 0.6368, Train: 61.95%, Valid: 61.98%, Test: 61.84%
Epoch: 550, Loss: 0.6362, Train: 61.97%, Valid: 62.00%, Test: 61.91%
Epoch: 575, Loss: 0.6361, Train: 61.98%, Valid: 62.02%, Test: 61.92%
Epoch: 600, Loss: 0.6365, Train: 61.96%, Valid: 61.97%, Test: 61.73%
Epoch: 625, Loss: 0.6348, Train: 62.12%, Valid: 62.14%, Test: 62.01%
Epoch: 650, Loss: 0.6365, Train: 62.00%, Valid: 62.06%, Test: 61.93%
Epoch: 675, Loss: 0.6345, Train: 62.16%, Valid: 62.18%, Test: 62.06%
Epoch: 700, Loss: 0.6341, Train: 62.23%, Valid: 62.25%, Test: 62.12%
Epoch: 725, Loss: 0.6342, Train: 62.23%, Valid: 62.25%, Test: 62.05%
Epoch: 750, Loss: 0.6351, Train: 62.15%, Valid: 62.20%, Test: 62.08%
Epoch: 775, Loss: 0.6332, Train: 62.34%, Valid: 62.35%, Test: 62.20%
Epoch: 800, Loss: 0.6335, Train: 62.32%, Valid: 62.33%, Test: 62.09%
Epoch: 825, Loss: 0.6326, Train: 62.38%, Valid: 62.39%, Test: 62.25%
Epoch: 850, Loss: 0.6331, Train: 62.37%, Valid: 62.35%, Test: 62.13%
Epoch: 875, Loss: 0.6322, Train: 62.45%, Valid: 62.45%, Test: 62.33%
Epoch: 900, Loss: 0.6319, Train: 62.54%, Valid: 62.55%, Test: 62.33%
Epoch: 925, Loss: 0.6321, Train: 62.52%, Valid: 62.55%, Test: 62.37%
Epoch: 950, Loss: 0.6308, Train: 62.69%, Valid: 62.67%, Test: 62.55%
Epoch: 975, Loss: 0.6334, Train: 62.50%, Valid: 62.54%, Test: 62.35%
Run 01:
Highest Train: 62.86
Highest Valid: 62.83
  Final Train: 62.85
   Final Test: 62.62
All runs:
Highest Train: 62.86 ± nan
Highest Valid: 62.83 ± nan
  Final Train: 62.85 ± nan
   Final Test: 62.62 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.9223, Train: 51.11%, Valid: 51.05%, Test: 50.96%
Epoch: 25, Loss: 0.7171, Train: 50.22%, Valid: 50.47%, Test: 50.21%
Epoch: 50, Loss: 0.6741, Train: 58.63%, Valid: 58.84%, Test: 58.56%
Epoch: 75, Loss: 0.6427, Train: 66.09%, Valid: 66.10%, Test: 66.10%
Epoch: 100, Loss: 0.6306, Train: 67.92%, Valid: 67.85%, Test: 67.88%
Epoch: 125, Loss: 0.6346, Train: 62.71%, Valid: 62.90%, Test: 62.76%
Epoch: 150, Loss: 0.6231, Train: 67.99%, Valid: 68.01%, Test: 67.88%
Epoch: 175, Loss: 0.6424, Train: 60.80%, Valid: 60.90%, Test: 60.87%
Epoch: 200, Loss: 0.6252, Train: 65.44%, Valid: 65.40%, Test: 65.40%
Epoch: 225, Loss: 0.6066, Train: 69.28%, Valid: 69.30%, Test: 69.25%
Epoch: 250, Loss: 0.6077, Train: 68.48%, Valid: 68.48%, Test: 68.38%
Epoch: 275, Loss: 0.6120, Train: 66.24%, Valid: 66.38%, Test: 66.29%
Epoch: 300, Loss: 0.5981, Train: 69.45%, Valid: 69.51%, Test: 69.43%
Epoch: 325, Loss: 0.6078, Train: 66.24%, Valid: 66.41%, Test: 66.30%
Epoch: 350, Loss: 0.5762, Train: 72.03%, Valid: 72.11%, Test: 72.05%
Epoch: 375, Loss: 0.6083, Train: 65.09%, Valid: 64.99%, Test: 65.03%
Epoch: 400, Loss: 0.5798, Train: 71.35%, Valid: 71.36%, Test: 71.32%
Epoch: 425, Loss: 0.5878, Train: 70.08%, Valid: 70.13%, Test: 70.02%
Epoch: 450, Loss: 0.5911, Train: 71.48%, Valid: 71.60%, Test: 71.45%
Epoch: 475, Loss: 0.5668, Train: 71.19%, Valid: 71.27%, Test: 71.14%
Epoch: 500, Loss: 0.5826, Train: 71.64%, Valid: 71.75%, Test: 71.60%
Epoch: 525, Loss: 0.5699, Train: 71.82%, Valid: 71.91%, Test: 71.77%
Epoch: 550, Loss: 0.5685, Train: 71.50%, Valid: 71.53%, Test: 71.52%
Epoch: 575, Loss: 0.5610, Train: 70.20%, Valid: 70.18%, Test: 70.19%
Epoch: 600, Loss: 0.5529, Train: 70.93%, Valid: 71.08%, Test: 70.89%
Epoch: 625, Loss: 0.5783, Train: 71.59%, Valid: 71.67%, Test: 71.57%
Epoch: 650, Loss: 0.5528, Train: 71.57%, Valid: 71.66%, Test: 71.54%
Epoch: 675, Loss: 0.5477, Train: 72.11%, Valid: 72.18%, Test: 72.06%
Epoch: 700, Loss: 0.5751, Train: 71.71%, Valid: 71.74%, Test: 71.79%
Epoch: 725, Loss: 0.5490, Train: 71.92%, Valid: 71.94%, Test: 71.88%
Epoch: 750, Loss: 0.5745, Train: 72.65%, Valid: 72.67%, Test: 72.57%
Epoch: 775, Loss: 0.5481, Train: 72.01%, Valid: 72.09%, Test: 71.92%
Epoch: 800, Loss: 0.5687, Train: 71.10%, Valid: 71.14%, Test: 71.07%
Epoch: 825, Loss: 0.6018, Train: 70.96%, Valid: 71.11%, Test: 70.95%
Epoch: 850, Loss: 0.5860, Train: 71.76%, Valid: 71.87%, Test: 71.75%
Epoch: 875, Loss: 0.5491, Train: 72.12%, Valid: 72.21%, Test: 72.05%
Epoch: 900, Loss: 0.5440, Train: 71.80%, Valid: 71.88%, Test: 71.72%
Epoch: 925, Loss: 0.5626, Train: 72.05%, Valid: 72.17%, Test: 72.02%
Epoch: 950, Loss: 0.5436, Train: 72.08%, Valid: 72.19%, Test: 72.04%
Epoch: 975, Loss: 0.5418, Train: 71.72%, Valid: 71.82%, Test: 71.65%
Run 01:
Highest Train: 72.65
Highest Valid: 72.69
  Final Train: 72.65
   Final Test: 72.63
All runs:
Highest Train: 72.65 ± nan
Highest Valid: 72.69 ± nan
  Final Train: 72.65 ± nan
   Final Test: 72.63 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=1000, gamma=0.1, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 4.8939, Train: 49.57%, Valid: 49.68%, Test: 49.71%
Epoch: 25, Loss: 1.7761, Train: 50.79%, Valid: 50.91%, Test: 50.94%
Epoch: 50, Loss: 0.8926, Train: 50.72%, Valid: 50.80%, Test: 50.88%
Epoch: 75, Loss: 0.7304, Train: 51.71%, Valid: 51.82%, Test: 51.76%
Epoch: 100, Loss: 0.8660, Train: 54.63%, Valid: 54.70%, Test: 54.63%
Epoch: 125, Loss: 0.7064, Train: 53.68%, Valid: 53.74%, Test: 53.75%
Epoch: 150, Loss: 0.6809, Train: 57.38%, Valid: 57.38%, Test: 57.37%
Epoch: 175, Loss: 0.6756, Train: 58.45%, Valid: 58.43%, Test: 58.41%
Epoch: 200, Loss: 0.6724, Train: 59.64%, Valid: 59.56%, Test: 59.59%
Epoch: 225, Loss: 0.6691, Train: 60.38%, Valid: 60.33%, Test: 60.40%
Epoch: 250, Loss: 0.6658, Train: 60.92%, Valid: 60.90%, Test: 60.91%
Epoch: 275, Loss: 0.6623, Train: 61.54%, Valid: 61.52%, Test: 61.49%
Epoch: 300, Loss: 0.6587, Train: 62.14%, Valid: 62.07%, Test: 62.07%
Epoch: 325, Loss: 0.6546, Train: 62.77%, Valid: 62.73%, Test: 62.73%
Epoch: 350, Loss: 0.6488, Train: 63.65%, Valid: 63.57%, Test: 63.59%
Epoch: 375, Loss: 0.6276, Train: 67.52%, Valid: 67.58%, Test: 67.62%
Epoch: 400, Loss: 0.6542, Train: 69.89%, Valid: 69.93%, Test: 69.79%
Epoch: 425, Loss: 0.6009, Train: 71.17%, Valid: 71.17%, Test: 71.10%
Epoch: 450, Loss: 0.6062, Train: 69.39%, Valid: 69.48%, Test: 69.39%
Epoch: 475, Loss: 0.6246, Train: 67.15%, Valid: 67.30%, Test: 67.11%
Epoch: 500, Loss: 0.5952, Train: 71.73%, Valid: 71.71%, Test: 71.67%
Epoch: 525, Loss: 0.5937, Train: 71.74%, Valid: 71.73%, Test: 71.71%
Epoch: 550, Loss: 0.6222, Train: 69.61%, Valid: 69.80%, Test: 69.57%
Epoch: 575, Loss: 0.5862, Train: 71.86%, Valid: 71.91%, Test: 71.87%
Epoch: 600, Loss: 0.5872, Train: 70.32%, Valid: 70.46%, Test: 70.35%
Epoch: 625, Loss: 0.5678, Train: 72.08%, Valid: 72.09%, Test: 72.09%
Epoch: 650, Loss: 0.5710, Train: 72.37%, Valid: 72.37%, Test: 72.36%
Epoch: 675, Loss: 0.5482, Train: 72.85%, Valid: 72.84%, Test: 72.80%
Epoch: 700, Loss: 0.5648, Train: 72.95%, Valid: 72.94%, Test: 72.91%
Epoch: 725, Loss: 0.5508, Train: 73.01%, Valid: 73.04%, Test: 73.01%
Epoch: 750, Loss: 0.5460, Train: 72.91%, Valid: 72.87%, Test: 72.84%
Epoch: 775, Loss: 0.5667, Train: 72.98%, Valid: 73.02%, Test: 72.98%
