nohup: ignoring input
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6153, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4851, Train: 35.11%, Valid: 34.69%, Test: 35.04%
Epoch: 50, Loss: 1.4644, Train: 36.37%, Valid: 35.38%, Test: 35.62%
Epoch: 75, Loss: 1.4478, Train: 37.21%, Valid: 35.96%, Test: 36.11%
Epoch: 100, Loss: 1.4339, Train: 37.77%, Valid: 35.79%, Test: 36.17%
Epoch: 125, Loss: 1.4235, Train: 38.63%, Valid: 35.63%, Test: 36.00%
Epoch: 150, Loss: 1.4121, Train: 38.64%, Valid: 35.56%, Test: 36.21%
Epoch: 175, Loss: 1.4230, Train: 38.54%, Valid: 35.16%, Test: 35.12%
Epoch: 200, Loss: 1.3911, Train: 40.03%, Valid: 35.85%, Test: 36.37%
Epoch: 225, Loss: 1.3895, Train: 40.29%, Valid: 35.84%, Test: 36.24%
Epoch: 250, Loss: 1.3743, Train: 41.12%, Valid: 35.68%, Test: 35.90%
Epoch: 275, Loss: 1.3681, Train: 41.33%, Valid: 35.33%, Test: 35.80%
Epoch: 300, Loss: 1.3611, Train: 41.63%, Valid: 35.39%, Test: 35.74%
Epoch: 325, Loss: 1.3579, Train: 42.02%, Valid: 35.48%, Test: 35.86%
Epoch: 350, Loss: 1.3805, Train: 40.72%, Valid: 35.51%, Test: 36.06%
Epoch: 375, Loss: 1.3476, Train: 42.53%, Valid: 34.85%, Test: 35.26%
Epoch: 400, Loss: 1.3681, Train: 42.28%, Valid: 34.84%, Test: 35.26%
Epoch: 425, Loss: 1.3320, Train: 43.19%, Valid: 35.04%, Test: 35.25%
Epoch: 450, Loss: 1.3735, Train: 42.75%, Valid: 34.66%, Test: 35.00%
Epoch: 475, Loss: 1.3320, Train: 43.39%, Valid: 34.29%, Test: 34.72%
Run 01:
Highest Train: 44.16
Highest Valid: 36.25
  Final Train: 38.63
   Final Test: 36.56
All runs:
Highest Train: 44.16 ± nan
Highest Valid: 36.25 ± nan
  Final Train: 38.63 ± nan
   Final Test: 36.56 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6043, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4889, Train: 34.92%, Valid: 34.44%, Test: 34.96%
Epoch: 50, Loss: 1.4696, Train: 36.03%, Valid: 35.20%, Test: 35.72%
Epoch: 75, Loss: 1.4518, Train: 36.90%, Valid: 35.72%, Test: 36.20%
Epoch: 100, Loss: 1.4293, Train: 38.00%, Valid: 36.44%, Test: 36.82%
Epoch: 125, Loss: 1.4061, Train: 39.06%, Valid: 37.23%, Test: 37.46%
Epoch: 150, Loss: 1.4158, Train: 39.03%, Valid: 36.72%, Test: 37.07%
Epoch: 175, Loss: 1.3567, Train: 41.66%, Valid: 38.87%, Test: 39.63%
Epoch: 200, Loss: 1.3330, Train: 42.37%, Valid: 39.33%, Test: 39.86%
Epoch: 225, Loss: 1.3162, Train: 43.34%, Valid: 39.39%, Test: 40.16%
Epoch: 250, Loss: 1.3058, Train: 43.78%, Valid: 39.78%, Test: 40.30%
Epoch: 275, Loss: 1.2944, Train: 44.71%, Valid: 40.21%, Test: 40.45%
Epoch: 300, Loss: 1.2632, Train: 45.84%, Valid: 41.13%, Test: 41.37%
Epoch: 325, Loss: 1.4052, Train: 43.12%, Valid: 39.11%, Test: 39.25%
Epoch: 350, Loss: 1.2775, Train: 45.04%, Valid: 41.48%, Test: 41.94%
Epoch: 375, Loss: 1.2441, Train: 46.48%, Valid: 41.97%, Test: 42.20%
Epoch: 400, Loss: 1.2402, Train: 46.44%, Valid: 41.98%, Test: 42.12%
Epoch: 425, Loss: 1.2213, Train: 47.72%, Valid: 42.66%, Test: 42.67%
Epoch: 450, Loss: 1.2164, Train: 48.01%, Valid: 43.04%, Test: 42.90%
Epoch: 475, Loss: 1.2075, Train: 48.25%, Valid: 42.70%, Test: 42.59%
Run 01:
Highest Train: 49.11
Highest Valid: 43.67
  Final Train: 48.74
   Final Test: 43.50
All runs:
Highest Train: 49.11 ± nan
Highest Valid: 43.67 ± nan
  Final Train: 48.74 ± nan
   Final Test: 43.50 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6120, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4840, Train: 35.28%, Valid: 34.73%, Test: 35.15%
Epoch: 50, Loss: 1.4533, Train: 36.85%, Valid: 35.98%, Test: 36.43%
Epoch: 75, Loss: 1.3995, Train: 39.56%, Valid: 38.64%, Test: 38.85%
Epoch: 100, Loss: 1.3632, Train: 41.34%, Valid: 39.75%, Test: 40.21%
Epoch: 125, Loss: 1.3461, Train: 41.92%, Valid: 40.39%, Test: 40.82%
Epoch: 150, Loss: 1.3684, Train: 41.03%, Valid: 39.72%, Test: 40.30%
Epoch: 175, Loss: 1.3251, Train: 43.15%, Valid: 41.37%, Test: 41.98%
Epoch: 200, Loss: 1.3117, Train: 43.51%, Valid: 41.36%, Test: 41.94%
Epoch: 225, Loss: 1.2793, Train: 45.22%, Valid: 42.74%, Test: 43.44%
Epoch: 250, Loss: 1.2626, Train: 45.95%, Valid: 43.50%, Test: 43.98%
Epoch: 275, Loss: 1.2482, Train: 46.34%, Valid: 43.79%, Test: 44.10%
Epoch: 300, Loss: 1.2423, Train: 46.63%, Valid: 44.01%, Test: 44.46%
Epoch: 325, Loss: 1.3439, Train: 46.11%, Valid: 43.39%, Test: 43.97%
Epoch: 350, Loss: 1.2418, Train: 46.62%, Valid: 44.03%, Test: 44.63%
Epoch: 375, Loss: 1.2384, Train: 46.85%, Valid: 44.19%, Test: 44.43%
Epoch: 400, Loss: 1.2296, Train: 47.71%, Valid: 44.72%, Test: 44.95%
Epoch: 425, Loss: 1.2065, Train: 48.23%, Valid: 45.27%, Test: 45.43%
Epoch: 450, Loss: 1.2092, Train: 47.61%, Valid: 44.68%, Test: 44.97%
Epoch: 475, Loss: 1.1947, Train: 48.44%, Valid: 45.18%, Test: 45.40%
Run 01:
Highest Train: 49.06
Highest Valid: 45.49
  Final Train: 48.84
   Final Test: 45.47
All runs:
Highest Train: 49.06 ± nan
Highest Valid: 45.49 ± nan
  Final Train: 48.84 ± nan
   Final Test: 45.47 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6138, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4871, Train: 35.05%, Valid: 34.50%, Test: 35.07%
Epoch: 50, Loss: 1.4656, Train: 36.21%, Valid: 35.50%, Test: 35.79%
Epoch: 75, Loss: 1.4515, Train: 36.61%, Valid: 35.78%, Test: 36.09%
Epoch: 100, Loss: 1.4381, Train: 37.66%, Valid: 36.28%, Test: 36.45%
Epoch: 125, Loss: 1.4249, Train: 38.38%, Valid: 36.69%, Test: 36.94%
Epoch: 150, Loss: 1.4153, Train: 38.14%, Valid: 36.64%, Test: 36.93%
Epoch: 175, Loss: 1.3904, Train: 39.97%, Valid: 37.64%, Test: 38.04%
Epoch: 200, Loss: 1.3758, Train: 40.68%, Valid: 37.95%, Test: 38.19%
Epoch: 225, Loss: 1.3638, Train: 41.28%, Valid: 38.26%, Test: 38.42%
Epoch: 250, Loss: 1.3490, Train: 42.09%, Valid: 38.71%, Test: 38.85%
Epoch: 275, Loss: 1.3378, Train: 42.25%, Valid: 38.99%, Test: 39.24%
Epoch: 300, Loss: 1.3250, Train: 42.81%, Valid: 38.84%, Test: 38.89%
Epoch: 325, Loss: 1.3118, Train: 44.14%, Valid: 39.55%, Test: 39.79%
Epoch: 350, Loss: 1.3104, Train: 44.48%, Valid: 39.78%, Test: 39.94%
Epoch: 375, Loss: 1.2964, Train: 44.94%, Valid: 39.75%, Test: 39.94%
Epoch: 400, Loss: 1.2724, Train: 45.78%, Valid: 39.76%, Test: 40.04%
Epoch: 425, Loss: 1.2800, Train: 44.19%, Valid: 38.16%, Test: 38.28%
Epoch: 450, Loss: 1.2639, Train: 46.31%, Valid: 40.42%, Test: 40.52%
Epoch: 475, Loss: 1.2529, Train: 47.02%, Valid: 40.82%, Test: 40.82%
Run 01:
Highest Train: 47.49
Highest Valid: 41.00
  Final Train: 47.15
   Final Test: 41.29
All runs:
Highest Train: 47.49 ± nan
Highest Valid: 41.00 ± nan
  Final Train: 47.15 ± nan
   Final Test: 41.29 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6081, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4832, Train: 35.23%, Valid: 34.77%, Test: 35.16%
Epoch: 50, Loss: 1.4585, Train: 36.52%, Valid: 35.76%, Test: 36.00%
Epoch: 75, Loss: 1.4238, Train: 38.25%, Valid: 37.26%, Test: 37.32%
Epoch: 100, Loss: 1.3996, Train: 39.31%, Valid: 37.94%, Test: 38.17%
Epoch: 125, Loss: 1.3486, Train: 39.32%, Valid: 37.49%, Test: 37.79%
Epoch: 150, Loss: 1.3152, Train: 43.06%, Valid: 41.37%, Test: 41.52%
Epoch: 175, Loss: 1.2926, Train: 44.46%, Valid: 42.52%, Test: 42.63%
Epoch: 200, Loss: 1.2538, Train: 45.40%, Valid: 42.91%, Test: 43.34%
Epoch: 225, Loss: 1.2340, Train: 46.71%, Valid: 44.10%, Test: 44.34%
Epoch: 250, Loss: 1.2165, Train: 47.47%, Valid: 45.00%, Test: 44.83%
Epoch: 275, Loss: 1.1963, Train: 48.35%, Valid: 45.31%, Test: 45.58%
Epoch: 300, Loss: 1.1839, Train: 48.71%, Valid: 46.00%, Test: 45.75%
Epoch: 325, Loss: 1.1792, Train: 49.31%, Valid: 46.08%, Test: 46.16%
Epoch: 350, Loss: 1.1603, Train: 49.91%, Valid: 46.43%, Test: 46.42%
Epoch: 375, Loss: 1.1756, Train: 49.20%, Valid: 46.20%, Test: 46.13%
Epoch: 400, Loss: 1.1533, Train: 50.32%, Valid: 46.96%, Test: 46.48%
Epoch: 425, Loss: 1.1499, Train: 50.01%, Valid: 45.96%, Test: 45.84%
Epoch: 450, Loss: 1.1533, Train: 50.67%, Valid: 46.78%, Test: 46.41%
Epoch: 475, Loss: 1.1325, Train: 50.10%, Valid: 45.99%, Test: 45.83%
Run 01:
Highest Train: 51.69
Highest Valid: 47.69
  Final Train: 51.40
   Final Test: 47.41
All runs:
Highest Train: 51.69 ± nan
Highest Valid: 47.69 ± nan
  Final Train: 51.40 ± nan
   Final Test: 47.41 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6200, Train: 28.48%, Valid: 28.26%, Test: 28.57%
Epoch: 25, Loss: 1.4698, Train: 35.58%, Valid: 35.38%, Test: 35.63%
Epoch: 50, Loss: 1.4460, Train: 34.47%, Valid: 34.62%, Test: 34.78%
Epoch: 75, Loss: 1.4223, Train: 38.01%, Valid: 37.81%, Test: 38.17%
Epoch: 100, Loss: 1.4109, Train: 38.67%, Valid: 38.41%, Test: 38.67%
Epoch: 125, Loss: 1.3815, Train: 40.06%, Valid: 39.91%, Test: 40.17%
Epoch: 150, Loss: 1.3543, Train: 41.97%, Valid: 41.62%, Test: 41.90%
Epoch: 175, Loss: 1.3592, Train: 41.35%, Valid: 40.81%, Test: 41.15%
Epoch: 200, Loss: 1.3484, Train: 41.76%, Valid: 41.39%, Test: 41.60%
Epoch: 225, Loss: 1.3402, Train: 42.49%, Valid: 42.15%, Test: 42.30%
Epoch: 250, Loss: 1.3078, Train: 43.37%, Valid: 42.83%, Test: 43.16%
Epoch: 275, Loss: 1.3077, Train: 43.42%, Valid: 42.99%, Test: 43.19%
Epoch: 300, Loss: 1.3514, Train: 42.86%, Valid: 42.08%, Test: 42.39%
Epoch: 325, Loss: 1.3001, Train: 43.99%, Valid: 43.43%, Test: 43.40%
Epoch: 350, Loss: 1.3336, Train: 39.98%, Valid: 39.36%, Test: 39.92%
Epoch: 375, Loss: 1.2994, Train: 44.04%, Valid: 43.35%, Test: 43.48%
Epoch: 400, Loss: 1.2828, Train: 44.23%, Valid: 43.81%, Test: 43.84%
Epoch: 425, Loss: 1.3124, Train: 43.16%, Valid: 42.47%, Test: 42.84%
Epoch: 450, Loss: 1.2843, Train: 44.62%, Valid: 43.95%, Test: 44.20%
Epoch: 475, Loss: 1.3022, Train: 43.70%, Valid: 42.99%, Test: 43.21%
Run 01:
Highest Train: 44.88
Highest Valid: 44.28
  Final Train: 44.76
   Final Test: 44.28
All runs:
Highest Train: 44.88 ± nan
Highest Valid: 44.28 ± nan
  Final Train: 44.76 ± nan
   Final Test: 44.28 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6216, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4828, Train: 35.35%, Valid: 34.73%, Test: 35.07%
Epoch: 50, Loss: 1.4581, Train: 36.59%, Valid: 35.75%, Test: 36.04%
Epoch: 75, Loss: 1.4353, Train: 37.42%, Valid: 36.27%, Test: 36.80%
Epoch: 100, Loss: 1.4088, Train: 38.65%, Valid: 37.00%, Test: 37.53%
Epoch: 125, Loss: 1.3775, Train: 40.95%, Valid: 38.88%, Test: 39.25%
Epoch: 150, Loss: 1.3520, Train: 41.82%, Valid: 39.44%, Test: 39.54%
Epoch: 175, Loss: 1.3374, Train: 43.24%, Valid: 40.47%, Test: 40.67%
Epoch: 200, Loss: 1.3292, Train: 43.82%, Valid: 40.63%, Test: 40.89%
Epoch: 225, Loss: 1.2996, Train: 44.47%, Valid: 40.95%, Test: 41.39%
Epoch: 250, Loss: 1.3299, Train: 43.14%, Valid: 40.04%, Test: 40.33%
Epoch: 275, Loss: 1.2849, Train: 45.36%, Valid: 41.78%, Test: 42.13%
Epoch: 300, Loss: 1.2690, Train: 46.15%, Valid: 42.04%, Test: 42.37%
Epoch: 325, Loss: 1.2522, Train: 47.10%, Valid: 42.41%, Test: 42.96%
Epoch: 350, Loss: 1.2445, Train: 47.12%, Valid: 42.23%, Test: 42.83%
Epoch: 375, Loss: 1.2582, Train: 46.56%, Valid: 41.52%, Test: 41.92%
Epoch: 400, Loss: 1.2356, Train: 47.87%, Valid: 42.60%, Test: 43.09%
Epoch: 425, Loss: 1.2296, Train: 48.39%, Valid: 42.92%, Test: 43.37%
Epoch: 450, Loss: 1.2000, Train: 49.32%, Valid: 42.91%, Test: 43.35%
Epoch: 475, Loss: 1.2045, Train: 49.16%, Valid: 42.88%, Test: 43.32%
Run 01:
Highest Train: 50.54
Highest Valid: 43.99
  Final Train: 50.27
   Final Test: 44.18
All runs:
Highest Train: 50.54 ± nan
Highest Valid: 43.99 ± nan
  Final Train: 50.27 ± nan
   Final Test: 44.18 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6226, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4783, Train: 35.37%, Valid: 35.03%, Test: 35.53%
Epoch: 50, Loss: 1.4501, Train: 36.41%, Valid: 35.84%, Test: 36.36%
Epoch: 75, Loss: 1.4147, Train: 38.05%, Valid: 37.28%, Test: 37.61%
Epoch: 100, Loss: 1.3813, Train: 40.02%, Valid: 39.15%, Test: 39.33%
Epoch: 125, Loss: 1.3792, Train: 40.35%, Valid: 39.36%, Test: 39.54%
Epoch: 150, Loss: 1.3492, Train: 41.17%, Valid: 40.12%, Test: 40.50%
Epoch: 175, Loss: 1.3276, Train: 42.69%, Valid: 41.74%, Test: 41.90%
Epoch: 200, Loss: 1.3103, Train: 42.70%, Valid: 41.56%, Test: 41.88%
Epoch: 225, Loss: 1.3052, Train: 44.49%, Valid: 43.46%, Test: 43.54%
Epoch: 250, Loss: 1.2742, Train: 45.14%, Valid: 43.83%, Test: 44.16%
Epoch: 275, Loss: 1.2597, Train: 45.99%, Valid: 44.55%, Test: 44.78%
Epoch: 300, Loss: 1.2614, Train: 45.94%, Valid: 44.37%, Test: 44.67%
Epoch: 325, Loss: 1.2425, Train: 46.71%, Valid: 45.09%, Test: 45.21%
Epoch: 350, Loss: 1.2728, Train: 45.43%, Valid: 44.26%, Test: 44.54%
Epoch: 375, Loss: 1.2290, Train: 47.23%, Valid: 45.73%, Test: 46.00%
Epoch: 400, Loss: 1.2131, Train: 47.73%, Valid: 45.84%, Test: 46.34%
Epoch: 425, Loss: 1.2180, Train: 47.75%, Valid: 46.20%, Test: 46.26%
Epoch: 450, Loss: 1.2019, Train: 48.28%, Valid: 45.98%, Test: 46.51%
Epoch: 475, Loss: 1.1851, Train: 48.77%, Valid: 46.44%, Test: 46.83%
Run 01:
Highest Train: 49.30
Highest Valid: 47.00
  Final Train: 49.30
   Final Test: 47.15
All runs:
Highest Train: 49.30 ± nan
Highest Valid: 47.00 ± nan
  Final Train: 49.30 ± nan
   Final Test: 47.15 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6264, Train: 27.72%, Valid: 27.39%, Test: 27.84%
Epoch: 25, Loss: 1.4500, Train: 36.32%, Valid: 36.01%, Test: 37.01%
Epoch: 50, Loss: 1.4255, Train: 36.99%, Valid: 36.44%, Test: 36.96%
Epoch: 75, Loss: 1.3897, Train: 38.90%, Valid: 38.14%, Test: 38.79%
Epoch: 100, Loss: 1.3547, Train: 41.48%, Valid: 40.74%, Test: 41.17%
Epoch: 125, Loss: 1.3561, Train: 40.97%, Valid: 40.67%, Test: 40.72%
Epoch: 150, Loss: 1.3399, Train: 41.58%, Valid: 41.14%, Test: 41.34%
Epoch: 175, Loss: 1.3209, Train: 42.70%, Valid: 42.04%, Test: 42.30%
Epoch: 200, Loss: 1.3062, Train: 43.66%, Valid: 42.95%, Test: 43.46%
Epoch: 225, Loss: 1.2981, Train: 43.90%, Valid: 43.08%, Test: 43.56%
Epoch: 250, Loss: 1.2955, Train: 44.33%, Valid: 43.28%, Test: 43.85%
Epoch: 275, Loss: 1.2877, Train: 44.90%, Valid: 44.03%, Test: 44.47%
Epoch: 300, Loss: 1.2954, Train: 44.80%, Valid: 43.85%, Test: 44.53%
Epoch: 325, Loss: 1.2892, Train: 45.01%, Valid: 44.25%, Test: 44.51%
Epoch: 350, Loss: 2.1227, Train: 29.33%, Valid: 29.04%, Test: 29.35%
Epoch: 375, Loss: 1.3593, Train: 40.96%, Valid: 40.36%, Test: 40.81%
Epoch: 400, Loss: 1.3267, Train: 42.12%, Valid: 41.47%, Test: 41.74%
Epoch: 425, Loss: 1.3072, Train: 43.87%, Valid: 42.98%, Test: 43.39%
Epoch: 450, Loss: 1.3290, Train: 43.67%, Valid: 42.91%, Test: 43.18%
Epoch: 475, Loss: 1.2927, Train: 44.39%, Valid: 43.62%, Test: 44.09%
Run 01:
Highest Train: 45.27
Highest Valid: 44.49
  Final Train: 45.17
   Final Test: 44.65
All runs:
Highest Train: 45.27 ± nan
Highest Valid: 44.49 ± nan
  Final Train: 45.17 ± nan
   Final Test: 44.65 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6141, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4818, Train: 35.36%, Valid: 34.87%, Test: 35.32%
Epoch: 50, Loss: 1.4541, Train: 36.91%, Valid: 36.19%, Test: 36.31%
Epoch: 75, Loss: 1.4254, Train: 37.92%, Valid: 37.25%, Test: 37.50%
Epoch: 100, Loss: 1.3892, Train: 40.07%, Valid: 38.65%, Test: 38.95%
Epoch: 125, Loss: 1.3552, Train: 41.46%, Valid: 40.24%, Test: 40.56%
Epoch: 150, Loss: 1.3268, Train: 42.55%, Valid: 41.11%, Test: 41.29%
Epoch: 175, Loss: 1.3143, Train: 43.79%, Valid: 41.93%, Test: 42.19%
Epoch: 200, Loss: 1.2951, Train: 44.00%, Valid: 41.74%, Test: 42.10%
Epoch: 225, Loss: 1.2740, Train: 45.88%, Valid: 43.22%, Test: 43.40%
Epoch: 250, Loss: 1.2598, Train: 46.74%, Valid: 43.65%, Test: 43.98%
Epoch: 275, Loss: 1.2691, Train: 46.07%, Valid: 43.26%, Test: 43.52%
Epoch: 300, Loss: 1.2405, Train: 47.23%, Valid: 44.07%, Test: 44.12%
Epoch: 325, Loss: 1.2253, Train: 47.95%, Valid: 44.31%, Test: 44.48%
Epoch: 350, Loss: 1.2393, Train: 47.30%, Valid: 43.64%, Test: 43.98%
Epoch: 375, Loss: 1.1999, Train: 48.72%, Valid: 44.07%, Test: 44.37%
Epoch: 400, Loss: 1.1899, Train: 49.64%, Valid: 44.97%, Test: 45.35%
Epoch: 425, Loss: 1.1820, Train: 50.00%, Valid: 45.25%, Test: 45.48%
Epoch: 450, Loss: 1.2198, Train: 49.79%, Valid: 45.27%, Test: 45.44%
Epoch: 475, Loss: 1.1637, Train: 49.82%, Valid: 44.80%, Test: 45.26%
Run 01:
Highest Train: 51.62
Highest Valid: 46.11
  Final Train: 51.31
   Final Test: 46.13
All runs:
Highest Train: 51.62 ± nan
Highest Valid: 46.11 ± nan
  Final Train: 51.31 ± nan
   Final Test: 46.13 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.5682, Train: 28.71%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4576, Train: 35.60%, Valid: 35.12%, Test: 35.55%
Epoch: 50, Loss: 1.4228, Train: 37.85%, Valid: 37.12%, Test: 37.64%
Epoch: 75, Loss: 1.3806, Train: 40.07%, Valid: 39.36%, Test: 39.73%
Epoch: 100, Loss: 1.3596, Train: 40.95%, Valid: 39.99%, Test: 40.54%
Epoch: 125, Loss: 1.3474, Train: 41.11%, Valid: 40.52%, Test: 40.64%
Epoch: 150, Loss: 1.3390, Train: 42.32%, Valid: 41.44%, Test: 41.59%
Epoch: 175, Loss: 1.2976, Train: 44.46%, Valid: 43.59%, Test: 44.02%
Epoch: 200, Loss: 1.2902, Train: 45.00%, Valid: 44.22%, Test: 44.53%
Epoch: 225, Loss: 1.2940, Train: 45.00%, Valid: 44.02%, Test: 44.46%
Epoch: 250, Loss: 1.2693, Train: 46.07%, Valid: 45.18%, Test: 45.44%
Epoch: 275, Loss: 1.2821, Train: 45.81%, Valid: 45.06%, Test: 45.36%
Epoch: 300, Loss: 1.2497, Train: 46.50%, Valid: 45.32%, Test: 45.91%
Epoch: 325, Loss: 1.2597, Train: 46.84%, Valid: 45.82%, Test: 46.34%
Epoch: 350, Loss: 1.2411, Train: 47.32%, Valid: 46.06%, Test: 46.70%
Epoch: 375, Loss: 1.2373, Train: 47.27%, Valid: 46.01%, Test: 46.69%
Epoch: 400, Loss: 1.2232, Train: 47.29%, Valid: 46.00%, Test: 46.47%
Epoch: 425, Loss: 1.3503, Train: 45.24%, Valid: 44.20%, Test: 44.57%
Epoch: 450, Loss: 1.2374, Train: 47.26%, Valid: 46.10%, Test: 46.66%
Epoch: 475, Loss: 1.2191, Train: 48.28%, Valid: 46.80%, Test: 47.36%
Run 01:
Highest Train: 48.56
Highest Valid: 47.07
  Final Train: 48.19
   Final Test: 47.33
All runs:
Highest Train: 48.56 ± nan
Highest Valid: 47.07 ± nan
  Final Train: 48.19 ± nan
   Final Test: 47.33 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.7418, Train: 22.14%, Valid: 22.02%, Test: 21.65%
Epoch: 25, Loss: 1.4438, Train: 35.29%, Valid: 34.77%, Test: 35.37%
Epoch: 50, Loss: 1.4617, Train: 37.04%, Valid: 36.69%, Test: 37.07%
Epoch: 75, Loss: 1.4098, Train: 37.63%, Valid: 36.83%, Test: 37.29%
Epoch: 100, Loss: 1.3945, Train: 38.99%, Valid: 38.34%, Test: 38.66%
Epoch: 125, Loss: 1.3843, Train: 38.99%, Valid: 38.29%, Test: 38.40%
Epoch: 150, Loss: 1.3678, Train: 40.54%, Valid: 39.99%, Test: 40.55%
Epoch: 175, Loss: 1.3868, Train: 39.27%, Valid: 38.68%, Test: 39.02%
Epoch: 200, Loss: 1.3629, Train: 40.26%, Valid: 39.66%, Test: 40.11%
Epoch: 225, Loss: 1.3561, Train: 41.31%, Valid: 40.78%, Test: 41.17%
Epoch: 250, Loss: 1.3990, Train: 38.91%, Valid: 38.50%, Test: 38.88%
Epoch: 275, Loss: 1.3617, Train: 40.30%, Valid: 39.71%, Test: 39.96%
Epoch: 300, Loss: 1.3722, Train: 40.05%, Valid: 39.56%, Test: 39.72%
Epoch: 325, Loss: 1.3433, Train: 41.81%, Valid: 40.90%, Test: 41.45%
Epoch: 350, Loss: 1.3554, Train: 42.19%, Valid: 41.36%, Test: 41.90%
Epoch: 375, Loss: 1.3298, Train: 42.93%, Valid: 41.97%, Test: 42.68%
Epoch: 400, Loss: 1.3638, Train: 40.99%, Valid: 40.28%, Test: 40.82%
Epoch: 425, Loss: 1.3300, Train: 42.52%, Valid: 41.84%, Test: 42.34%
Epoch: 450, Loss: 1.3366, Train: 42.76%, Valid: 41.89%, Test: 42.48%
Epoch: 475, Loss: 1.3180, Train: 43.47%, Valid: 42.58%, Test: 43.18%
Run 01:
Highest Train: 43.50
Highest Valid: 42.60
  Final Train: 43.33
   Final Test: 43.22
All runs:
Highest Train: 43.50 ± nan
Highest Valid: 42.60 ± nan
  Final Train: 43.33 ± nan
   Final Test: 43.22 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6199, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4670, Train: 35.77%, Valid: 35.20%, Test: 35.74%
Epoch: 50, Loss: 1.4367, Train: 37.31%, Valid: 36.60%, Test: 36.87%
Epoch: 75, Loss: 1.4027, Train: 38.68%, Valid: 37.89%, Test: 38.18%
Epoch: 100, Loss: 1.3736, Train: 40.61%, Valid: 39.61%, Test: 39.82%
Epoch: 125, Loss: 1.3456, Train: 40.82%, Valid: 39.57%, Test: 39.81%
Epoch: 150, Loss: 1.3220, Train: 41.21%, Valid: 40.04%, Test: 40.37%
Epoch: 175, Loss: 1.2975, Train: 43.96%, Valid: 42.28%, Test: 42.71%
Epoch: 200, Loss: 1.2853, Train: 44.05%, Valid: 42.49%, Test: 42.58%
Epoch: 225, Loss: 1.2746, Train: 44.95%, Valid: 43.24%, Test: 43.81%
Epoch: 250, Loss: 1.2618, Train: 45.25%, Valid: 43.42%, Test: 43.69%
Epoch: 275, Loss: 1.2550, Train: 45.92%, Valid: 44.04%, Test: 44.31%
Epoch: 300, Loss: 1.2607, Train: 45.39%, Valid: 43.70%, Test: 43.77%
Epoch: 325, Loss: 1.2476, Train: 46.26%, Valid: 43.89%, Test: 44.04%
Epoch: 350, Loss: 1.3117, Train: 41.68%, Valid: 40.08%, Test: 40.19%
Epoch: 375, Loss: 1.2342, Train: 46.57%, Valid: 44.38%, Test: 44.75%
Epoch: 400, Loss: 1.2095, Train: 47.92%, Valid: 45.04%, Test: 45.63%
Epoch: 425, Loss: 1.2234, Train: 46.99%, Valid: 44.15%, Test: 44.60%
Epoch: 450, Loss: 1.1966, Train: 48.47%, Valid: 45.36%, Test: 45.85%
Epoch: 475, Loss: 1.2292, Train: 47.96%, Valid: 44.66%, Test: 45.05%
Run 01:
Highest Train: 49.13
Highest Valid: 45.80
  Final Train: 48.89
   Final Test: 46.09
All runs:
Highest Train: 49.13 ± nan
Highest Valid: 45.80 ± nan
  Final Train: 48.89 ± nan
   Final Test: 46.09 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6484, Train: 28.72%, Valid: 28.54%, Test: 28.82%
Epoch: 25, Loss: 1.4583, Train: 35.95%, Valid: 35.41%, Test: 35.85%
Epoch: 50, Loss: 1.4179, Train: 38.04%, Valid: 37.55%, Test: 37.93%
Epoch: 75, Loss: 1.4059, Train: 38.16%, Valid: 37.66%, Test: 37.93%
Epoch: 100, Loss: 1.3851, Train: 39.65%, Valid: 38.93%, Test: 39.21%
Epoch: 125, Loss: 1.3916, Train: 38.22%, Valid: 37.78%, Test: 38.04%
Epoch: 150, Loss: 1.3693, Train: 40.49%, Valid: 39.85%, Test: 40.13%
Epoch: 175, Loss: 1.3755, Train: 38.87%, Valid: 38.40%, Test: 38.59%
Epoch: 200, Loss: 1.3613, Train: 41.00%, Valid: 40.42%, Test: 40.62%
Epoch: 225, Loss: 1.3459, Train: 40.54%, Valid: 40.04%, Test: 40.19%
Epoch: 250, Loss: 1.3536, Train: 40.45%, Valid: 40.01%, Test: 40.06%
Epoch: 275, Loss: 1.3391, Train: 40.39%, Valid: 39.73%, Test: 40.01%
Epoch: 300, Loss: 1.3466, Train: 40.02%, Valid: 39.51%, Test: 39.66%
Epoch: 325, Loss: 1.3360, Train: 41.23%, Valid: 40.91%, Test: 40.93%
Epoch: 350, Loss: 1.3483, Train: 40.85%, Valid: 40.29%, Test: 40.58%
Epoch: 375, Loss: 1.3373, Train: 41.67%, Valid: 41.25%, Test: 41.25%
Epoch: 400, Loss: 1.3260, Train: 41.86%, Valid: 41.30%, Test: 41.42%
Epoch: 425, Loss: 1.3379, Train: 41.26%, Valid: 40.49%, Test: 40.98%
Epoch: 450, Loss: 1.3108, Train: 42.79%, Valid: 42.32%, Test: 42.33%
Epoch: 475, Loss: 1.3207, Train: 42.73%, Valid: 42.07%, Test: 42.38%
Run 01:
Highest Train: 43.09
Highest Valid: 42.73
  Final Train: 43.08
   Final Test: 42.72
All runs:
Highest Train: 43.09 ± nan
Highest Valid: 42.73 ± nan
  Final Train: 43.08 ± nan
   Final Test: 42.72 ± nan
Saving results to results/arxiv-year.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='arxiv-year', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 169343 | num classes 5 | num node feats 128
MODEL: MLPNORM(
  (fc1): Linear(in_features=128, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.7729, Train: 27.97%, Valid: 27.71%, Test: 28.05%
Epoch: 25, Loss: 1.4513, Train: 33.95%, Valid: 33.63%, Test: 33.92%
Epoch: 50, Loss: 1.4200, Train: 36.74%, Valid: 36.34%, Test: 37.26%
Epoch: 75, Loss: 1.4024, Train: 38.14%, Valid: 37.67%, Test: 38.15%
Epoch: 100, Loss: 1.3811, Train: 41.47%, Valid: 40.95%, Test: 41.41%
Epoch: 125, Loss: 1.4028, Train: 38.95%, Valid: 38.70%, Test: 39.13%
Epoch: 150, Loss: 1.3837, Train: 40.98%, Valid: 40.49%, Test: 40.82%
Epoch: 175, Loss: 1.3620, Train: 41.62%, Valid: 41.19%, Test: 41.58%
Epoch: 200, Loss: 1.3695, Train: 39.66%, Valid: 39.64%, Test: 40.02%
Epoch: 225, Loss: 1.3508, Train: 41.90%, Valid: 41.59%, Test: 42.00%
Epoch: 250, Loss: 1.4112, Train: 42.07%, Valid: 41.56%, Test: 41.97%
Epoch: 275, Loss: 1.3902, Train: 40.35%, Valid: 39.95%, Test: 40.27%
Epoch: 300, Loss: 1.3590, Train: 41.74%, Valid: 41.53%, Test: 41.85%
Epoch: 325, Loss: 1.3910, Train: 41.57%, Valid: 41.24%, Test: 41.57%
Epoch: 350, Loss: 1.3460, Train: 42.02%, Valid: 41.68%, Test: 42.02%
Epoch: 375, Loss: 1.7195, Train: 37.68%, Valid: 37.50%, Test: 37.66%
Epoch: 400, Loss: 1.3910, Train: 41.09%, Valid: 40.59%, Test: 40.95%
Epoch: 425, Loss: 1.3650, Train: 41.83%, Valid: 41.51%, Test: 41.86%
Epoch: 450, Loss: 1.3586, Train: 41.82%, Valid: 41.50%, Test: 41.81%
Epoch: 475, Loss: 1.3449, Train: 41.99%, Valid: 41.74%, Test: 42.11%
Run 01:
Highest Train: 42.48
Highest Valid: 42.13
  Final Train: 42.48
   Final Test: 42.57
All runs:
Highest Train: 42.48 ± nan
Highest Valid: 42.13 ± nan
  Final Train: 42.48 ± nan
   Final Test: 42.57 ± nan
Saving results to results/arxiv-year.csv
20211116-18:10 ---> 20211116-18:18 Totl:491 seconds
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.9441, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.7914, Train: 49.29%, Valid: 49.36%, Test: 49.41%
Epoch: 50, Loss: 0.6885, Train: 52.98%, Valid: 53.06%, Test: 53.02%
Epoch: 75, Loss: 0.6805, Train: 57.92%, Valid: 57.87%, Test: 57.86%
Epoch: 100, Loss: 0.6757, Train: 58.79%, Valid: 58.65%, Test: 58.75%
Epoch: 125, Loss: 0.6697, Train: 59.31%, Valid: 59.23%, Test: 59.29%
Epoch: 150, Loss: 0.6626, Train: 60.07%, Valid: 59.99%, Test: 60.06%
Epoch: 175, Loss: 0.6556, Train: 60.61%, Valid: 60.58%, Test: 60.58%
Epoch: 200, Loss: 0.6502, Train: 61.00%, Valid: 60.98%, Test: 60.97%
Epoch: 225, Loss: 0.6464, Train: 61.25%, Valid: 61.22%, Test: 61.23%
Epoch: 250, Loss: 0.6439, Train: 61.43%, Valid: 61.37%, Test: 61.33%
Epoch: 275, Loss: 0.6423, Train: 61.50%, Valid: 61.49%, Test: 61.45%
Epoch: 300, Loss: 0.6413, Train: 61.55%, Valid: 61.54%, Test: 61.50%
Epoch: 325, Loss: 0.6407, Train: 61.58%, Valid: 61.59%, Test: 61.55%
Epoch: 350, Loss: 0.6403, Train: 61.59%, Valid: 61.62%, Test: 61.57%
Epoch: 375, Loss: 0.6400, Train: 61.61%, Valid: 61.65%, Test: 61.56%
Epoch: 400, Loss: 0.6398, Train: 61.62%, Valid: 61.68%, Test: 61.57%
Epoch: 425, Loss: 0.6396, Train: 61.65%, Valid: 61.71%, Test: 61.61%
Epoch: 450, Loss: 0.6393, Train: 61.68%, Valid: 61.73%, Test: 61.63%
Epoch: 475, Loss: 0.6391, Train: 61.70%, Valid: 61.77%, Test: 61.63%
Run 01:
Highest Train: 61.73
Highest Valid: 61.78
  Final Train: 61.73
   Final Test: 61.65
All runs:
Highest Train: 61.73 ± nan
Highest Valid: 61.78 ± nan
  Final Train: 61.73 ± nan
   Final Test: 61.65 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.1084, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7699, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 50, Loss: 0.6833, Train: 54.63%, Valid: 54.67%, Test: 54.64%
Epoch: 75, Loss: 0.6798, Train: 56.59%, Valid: 56.51%, Test: 56.53%
Epoch: 100, Loss: 0.6738, Train: 58.87%, Valid: 58.77%, Test: 58.81%
Epoch: 125, Loss: 0.6667, Train: 59.62%, Valid: 59.53%, Test: 59.63%
Epoch: 150, Loss: 0.6588, Train: 60.27%, Valid: 60.23%, Test: 60.27%
Epoch: 175, Loss: 0.6521, Train: 60.76%, Valid: 60.70%, Test: 60.75%
Epoch: 200, Loss: 0.6473, Train: 61.15%, Valid: 61.10%, Test: 61.12%
Epoch: 225, Loss: 0.6442, Train: 61.38%, Valid: 61.30%, Test: 61.34%
Epoch: 250, Loss: 0.6423, Train: 61.48%, Valid: 61.47%, Test: 61.41%
Epoch: 275, Loss: 0.6412, Train: 61.57%, Valid: 61.54%, Test: 61.48%
Epoch: 300, Loss: 0.6406, Train: 61.58%, Valid: 61.58%, Test: 61.53%
Epoch: 325, Loss: 0.6402, Train: 61.59%, Valid: 61.61%, Test: 61.55%
Epoch: 350, Loss: 0.6400, Train: 61.62%, Valid: 61.64%, Test: 61.55%
Epoch: 375, Loss: 0.6398, Train: 61.64%, Valid: 61.67%, Test: 61.56%
Epoch: 400, Loss: 0.6396, Train: 61.65%, Valid: 61.67%, Test: 61.56%
Epoch: 425, Loss: 0.6395, Train: 61.66%, Valid: 61.67%, Test: 61.58%
Epoch: 450, Loss: 0.6394, Train: 61.68%, Valid: 61.70%, Test: 61.62%
Epoch: 475, Loss: 0.6392, Train: 61.69%, Valid: 61.73%, Test: 61.63%
Run 01:
Highest Train: 61.73
Highest Valid: 61.78
  Final Train: 61.73
   Final Test: 61.67
All runs:
Highest Train: 61.73 ± nan
Highest Valid: 61.78 ± nan
  Final Train: 61.73 ± nan
   Final Test: 61.67 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.8972, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7146, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 50, Loss: 0.6876, Train: 52.47%, Valid: 52.50%, Test: 52.34%
Epoch: 75, Loss: 0.6799, Train: 57.65%, Valid: 57.48%, Test: 57.46%
Epoch: 100, Loss: 0.6729, Train: 58.95%, Valid: 58.83%, Test: 58.91%
Epoch: 125, Loss: 0.6640, Train: 59.98%, Valid: 59.92%, Test: 59.95%
Epoch: 150, Loss: 0.6542, Train: 60.80%, Valid: 60.75%, Test: 60.74%
Epoch: 175, Loss: 0.6452, Train: 61.39%, Valid: 61.33%, Test: 61.32%
Epoch: 200, Loss: 0.6405, Train: 61.65%, Valid: 61.62%, Test: 61.57%
Epoch: 225, Loss: 0.6397, Train: 61.69%, Valid: 61.72%, Test: 61.63%
Epoch: 250, Loss: 0.6394, Train: 61.70%, Valid: 61.76%, Test: 61.65%
Epoch: 275, Loss: 0.6391, Train: 61.74%, Valid: 61.79%, Test: 61.68%
Epoch: 300, Loss: 0.6388, Train: 61.78%, Valid: 61.80%, Test: 61.72%
Epoch: 325, Loss: 0.6385, Train: 61.85%, Valid: 61.88%, Test: 61.80%
Epoch: 350, Loss: 0.6381, Train: 61.88%, Valid: 61.91%, Test: 61.84%
Epoch: 375, Loss: 0.6377, Train: 61.93%, Valid: 61.97%, Test: 61.87%
Epoch: 400, Loss: 0.6372, Train: 62.01%, Valid: 62.05%, Test: 61.93%
Epoch: 425, Loss: 0.6366, Train: 62.09%, Valid: 62.11%, Test: 62.01%
Epoch: 450, Loss: 0.6357, Train: 62.24%, Valid: 62.26%, Test: 62.17%
Epoch: 475, Loss: 0.6345, Train: 62.46%, Valid: 62.49%, Test: 62.40%
Run 01:
Highest Train: 62.86
Highest Valid: 62.87
  Final Train: 62.86
   Final Test: 62.85
All runs:
Highest Train: 62.86 ± nan
Highest Valid: 62.87 ± nan
  Final Train: 62.86 ± nan
   Final Test: 62.85 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.2973, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.6975, Train: 49.77%, Valid: 49.84%, Test: 49.88%
Epoch: 50, Loss: 0.6863, Train: 53.18%, Valid: 53.22%, Test: 53.22%
Epoch: 75, Loss: 0.6810, Train: 57.01%, Valid: 57.00%, Test: 56.93%
Epoch: 100, Loss: 0.6756, Train: 58.50%, Valid: 58.37%, Test: 58.46%
Epoch: 125, Loss: 0.6689, Train: 59.52%, Valid: 59.43%, Test: 59.47%
Epoch: 150, Loss: 0.6609, Train: 60.28%, Valid: 60.22%, Test: 60.24%
Epoch: 175, Loss: 0.6534, Train: 60.82%, Valid: 60.81%, Test: 60.79%
Epoch: 200, Loss: 0.6481, Train: 61.15%, Valid: 61.12%, Test: 61.13%
Epoch: 225, Loss: 0.6446, Train: 61.35%, Valid: 61.31%, Test: 61.29%
Epoch: 250, Loss: 0.6425, Train: 61.47%, Valid: 61.45%, Test: 61.40%
Epoch: 275, Loss: 0.6413, Train: 61.53%, Valid: 61.52%, Test: 61.46%
Epoch: 300, Loss: 0.6406, Train: 61.57%, Valid: 61.58%, Test: 61.51%
Epoch: 325, Loss: 0.6401, Train: 61.63%, Valid: 61.63%, Test: 61.52%
Epoch: 350, Loss: 0.6396, Train: 61.64%, Valid: 61.68%, Test: 61.62%
Epoch: 375, Loss: 0.6388, Train: 61.74%, Valid: 61.75%, Test: 61.66%
Epoch: 400, Loss: 0.6383, Train: 61.82%, Valid: 61.81%, Test: 61.73%
Epoch: 425, Loss: 0.6377, Train: 61.87%, Valid: 61.87%, Test: 61.75%
Epoch: 450, Loss: 0.6372, Train: 61.94%, Valid: 61.93%, Test: 61.81%
Epoch: 475, Loss: 0.6367, Train: 61.97%, Valid: 62.00%, Test: 61.85%
Run 01:
Highest Train: 62.03
Highest Valid: 62.07
  Final Train: 62.02
   Final Test: 61.89
All runs:
Highest Train: 62.03 ± nan
Highest Valid: 62.07 ± nan
  Final Train: 62.02 ± nan
   Final Test: 61.89 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7801, Train: 50.57%, Valid: 50.77%, Test: 50.55%
Epoch: 25, Loss: 0.6870, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 50, Loss: 0.6810, Train: 56.96%, Valid: 56.88%, Test: 56.96%
Epoch: 75, Loss: 0.6751, Train: 58.54%, Valid: 58.41%, Test: 58.50%
Epoch: 100, Loss: 0.6672, Train: 59.64%, Valid: 59.60%, Test: 59.63%
Epoch: 125, Loss: 0.6582, Train: 60.53%, Valid: 60.49%, Test: 60.54%
Epoch: 150, Loss: 0.6467, Train: 61.16%, Valid: 61.15%, Test: 61.12%
Epoch: 175, Loss: 0.6410, Train: 61.52%, Valid: 61.49%, Test: 61.47%
Epoch: 200, Loss: 0.6402, Train: 61.58%, Valid: 61.62%, Test: 61.56%
Epoch: 225, Loss: 0.6398, Train: 61.62%, Valid: 61.64%, Test: 61.58%
Epoch: 250, Loss: 0.6394, Train: 61.66%, Valid: 61.68%, Test: 61.58%
Epoch: 275, Loss: 0.6390, Train: 61.67%, Valid: 61.74%, Test: 61.61%
Epoch: 300, Loss: 0.6386, Train: 61.69%, Valid: 61.77%, Test: 61.63%
Epoch: 325, Loss: 0.6380, Train: 61.73%, Valid: 61.79%, Test: 61.68%
Epoch: 350, Loss: 0.6375, Train: 61.81%, Valid: 61.87%, Test: 61.71%
Epoch: 375, Loss: 0.6370, Train: 61.85%, Valid: 61.90%, Test: 61.77%
Epoch: 400, Loss: 0.6365, Train: 61.93%, Valid: 61.95%, Test: 61.83%
Epoch: 425, Loss: 0.6361, Train: 61.95%, Valid: 61.97%, Test: 61.87%
Epoch: 450, Loss: 0.6358, Train: 62.00%, Valid: 62.01%, Test: 61.93%
Epoch: 475, Loss: 0.6359, Train: 62.11%, Valid: 62.15%, Test: 61.97%
Run 01:
Highest Train: 62.19
Highest Valid: 62.22
  Final Train: 62.19
   Final Test: 62.02
All runs:
Highest Train: 62.19 ± nan
Highest Valid: 62.22 ± nan
  Final Train: 62.19 ± nan
   Final Test: 62.02 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.6633, Train: 50.59%, Valid: 50.50%, Test: 50.45%
Epoch: 25, Loss: 0.8430, Train: 49.46%, Valid: 49.46%, Test: 49.53%
Epoch: 50, Loss: 0.6919, Train: 51.30%, Valid: 51.36%, Test: 51.25%
Epoch: 75, Loss: 0.6959, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 100, Loss: 0.6922, Train: 51.68%, Valid: 51.78%, Test: 51.76%
Epoch: 125, Loss: 0.6896, Train: 53.38%, Valid: 53.43%, Test: 53.35%
Epoch: 150, Loss: 0.6855, Train: 57.10%, Valid: 57.19%, Test: 57.03%
Epoch: 175, Loss: 0.6758, Train: 58.92%, Valid: 58.81%, Test: 58.83%
Epoch: 200, Loss: 0.6509, Train: 61.10%, Valid: 61.07%, Test: 60.99%
Epoch: 225, Loss: 0.6412, Train: 61.51%, Valid: 61.45%, Test: 61.45%
Epoch: 250, Loss: 0.6402, Train: 61.61%, Valid: 61.59%, Test: 61.57%
Epoch: 275, Loss: 0.6398, Train: 61.67%, Valid: 61.66%, Test: 61.65%
Epoch: 300, Loss: 0.6394, Train: 61.69%, Valid: 61.66%, Test: 61.65%
Epoch: 325, Loss: 0.6391, Train: 61.72%, Valid: 61.68%, Test: 61.65%
Epoch: 350, Loss: 0.6387, Train: 61.72%, Valid: 61.70%, Test: 61.65%
Epoch: 375, Loss: 0.6383, Train: 61.75%, Valid: 61.72%, Test: 61.69%
Epoch: 400, Loss: 0.6383, Train: 61.79%, Valid: 61.76%, Test: 61.71%
Epoch: 425, Loss: 0.6374, Train: 61.86%, Valid: 61.81%, Test: 61.78%
Epoch: 450, Loss: 0.6366, Train: 61.96%, Valid: 61.94%, Test: 61.89%
Epoch: 475, Loss: 0.6376, Train: 62.07%, Valid: 62.09%, Test: 62.05%
Run 01:
Highest Train: 62.42
Highest Valid: 62.37
  Final Train: 62.42
   Final Test: 62.33
All runs:
Highest Train: 62.42 ± nan
Highest Valid: 62.37 ± nan
  Final Train: 62.42 ± nan
   Final Test: 62.33 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.9503, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.7256, Train: 49.35%, Valid: 49.43%, Test: 49.48%
Epoch: 50, Loss: 0.6875, Train: 52.95%, Valid: 53.02%, Test: 53.02%
Epoch: 75, Loss: 0.6794, Train: 58.50%, Valid: 58.40%, Test: 58.32%
Epoch: 100, Loss: 0.6729, Train: 58.99%, Valid: 58.92%, Test: 58.91%
Epoch: 125, Loss: 0.6553, Train: 60.76%, Valid: 60.78%, Test: 60.73%
Epoch: 150, Loss: 0.6429, Train: 61.35%, Valid: 61.27%, Test: 61.29%
Epoch: 175, Loss: 0.6413, Train: 61.46%, Valid: 61.40%, Test: 61.40%
Epoch: 200, Loss: 0.6410, Train: 61.54%, Valid: 61.52%, Test: 61.44%
Epoch: 225, Loss: 0.6411, Train: 61.53%, Valid: 61.54%, Test: 61.48%
Epoch: 250, Loss: 0.6407, Train: 61.58%, Valid: 61.59%, Test: 61.50%
Epoch: 275, Loss: 0.6405, Train: 61.61%, Valid: 61.62%, Test: 61.54%
Epoch: 300, Loss: 0.6403, Train: 61.62%, Valid: 61.63%, Test: 61.55%
Epoch: 325, Loss: 0.6402, Train: 61.62%, Valid: 61.66%, Test: 61.53%
Epoch: 350, Loss: 0.6397, Train: 61.65%, Valid: 61.69%, Test: 61.59%
Epoch: 375, Loss: 0.6394, Train: 61.67%, Valid: 61.72%, Test: 61.61%
Epoch: 400, Loss: 0.6393, Train: 61.68%, Valid: 61.73%, Test: 61.56%
Epoch: 425, Loss: 0.6389, Train: 61.70%, Valid: 61.75%, Test: 61.63%
Epoch: 450, Loss: 0.6389, Train: 61.68%, Valid: 61.72%, Test: 61.64%
Epoch: 475, Loss: 0.6385, Train: 61.79%, Valid: 61.80%, Test: 61.64%
Run 01:
Highest Train: 61.79
Highest Valid: 61.82
  Final Train: 61.79
   Final Test: 61.65
All runs:
Highest Train: 61.79 ± nan
Highest Valid: 61.82 ± nan
  Final Train: 61.79 ± nan
   Final Test: 61.65 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.5484, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7396, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 50, Loss: 0.6826, Train: 56.27%, Valid: 56.21%, Test: 56.25%
Epoch: 75, Loss: 0.6767, Train: 58.00%, Valid: 57.91%, Test: 57.91%
Epoch: 100, Loss: 0.6692, Train: 59.35%, Valid: 59.24%, Test: 59.33%
Epoch: 125, Loss: 0.6600, Train: 60.41%, Valid: 60.33%, Test: 60.37%
Epoch: 150, Loss: 0.6516, Train: 60.96%, Valid: 60.91%, Test: 60.92%
Epoch: 175, Loss: 0.6461, Train: 61.39%, Valid: 61.33%, Test: 61.36%
Epoch: 200, Loss: 0.6430, Train: 61.48%, Valid: 61.46%, Test: 61.40%
Epoch: 225, Loss: 0.6412, Train: 61.56%, Valid: 61.57%, Test: 61.51%
Epoch: 250, Loss: 0.6402, Train: 61.62%, Valid: 61.64%, Test: 61.57%
Epoch: 275, Loss: 0.6396, Train: 61.66%, Valid: 61.68%, Test: 61.60%
Epoch: 300, Loss: 0.6391, Train: 61.72%, Valid: 61.74%, Test: 61.63%
Epoch: 325, Loss: 0.6385, Train: 61.76%, Valid: 61.81%, Test: 61.68%
Epoch: 350, Loss: 0.6380, Train: 61.82%, Valid: 61.86%, Test: 61.74%
Epoch: 375, Loss: 0.6373, Train: 61.92%, Valid: 61.94%, Test: 61.81%
Epoch: 400, Loss: 0.6365, Train: 62.04%, Valid: 62.07%, Test: 61.95%
Epoch: 425, Loss: 0.6352, Train: 62.24%, Valid: 62.27%, Test: 62.15%
Epoch: 450, Loss: 0.6326, Train: 62.71%, Valid: 62.69%, Test: 62.57%
Epoch: 475, Loss: 0.6299, Train: 62.44%, Valid: 62.32%, Test: 62.31%
Run 01:
Highest Train: 64.55
Highest Valid: 64.48
  Final Train: 64.55
   Final Test: 64.43
All runs:
Highest Train: 64.55 ± nan
Highest Valid: 64.48 ± nan
  Final Train: 64.55 ± nan
   Final Test: 64.43 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.4249, Train: 50.51%, Valid: 50.46%, Test: 50.31%
Epoch: 25, Loss: 1.0610, Train: 49.50%, Valid: 49.62%, Test: 49.64%
Epoch: 50, Loss: 0.7073, Train: 52.63%, Valid: 52.55%, Test: 52.54%
Epoch: 75, Loss: 0.6805, Train: 58.13%, Valid: 58.07%, Test: 57.98%
Epoch: 100, Loss: 0.6690, Train: 60.05%, Valid: 59.89%, Test: 60.01%
Epoch: 125, Loss: 0.6585, Train: 61.09%, Valid: 60.96%, Test: 61.01%
Epoch: 150, Loss: 0.6497, Train: 61.63%, Valid: 61.53%, Test: 61.54%
Epoch: 175, Loss: 0.6436, Train: 62.10%, Valid: 61.98%, Test: 62.00%
Epoch: 200, Loss: 0.6397, Train: 62.47%, Valid: 62.42%, Test: 62.39%
Epoch: 225, Loss: 0.6368, Train: 62.84%, Valid: 62.80%, Test: 62.73%
Epoch: 250, Loss: 0.6284, Train: 64.62%, Valid: 64.62%, Test: 64.51%
Epoch: 275, Loss: 0.6478, Train: 61.41%, Valid: 61.44%, Test: 61.32%
Epoch: 300, Loss: 0.6929, Train: 62.42%, Valid: 62.63%, Test: 62.51%
Epoch: 325, Loss: 0.6348, Train: 62.93%, Valid: 62.88%, Test: 62.83%
Epoch: 350, Loss: 0.6279, Train: 64.03%, Valid: 64.02%, Test: 63.94%
Epoch: 375, Loss: 0.6468, Train: 62.32%, Valid: 62.33%, Test: 62.24%
Epoch: 400, Loss: 0.6126, Train: 66.02%, Valid: 66.03%, Test: 65.90%
Epoch: 425, Loss: 0.6167, Train: 65.69%, Valid: 65.70%, Test: 65.54%
Epoch: 450, Loss: 0.6260, Train: 64.07%, Valid: 64.05%, Test: 63.96%
Epoch: 475, Loss: 0.6483, Train: 63.86%, Valid: 64.00%, Test: 63.85%
Run 01:
Highest Train: 68.50
Highest Valid: 68.58
  Final Train: 68.50
   Final Test: 68.46
All runs:
Highest Train: 68.50 ± nan
Highest Valid: 68.58 ± nan
  Final Train: 68.50 ± nan
   Final Test: 68.46 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.7078, Train: 49.21%, Valid: 49.29%, Test: 49.34%
Epoch: 25, Loss: 0.7312, Train: 49.21%, Valid: 49.30%, Test: 49.34%
Epoch: 50, Loss: 0.6901, Train: 53.05%, Valid: 53.08%, Test: 52.96%
Epoch: 75, Loss: 0.6873, Train: 56.02%, Valid: 55.88%, Test: 55.90%
Epoch: 100, Loss: 0.6828, Train: 57.51%, Valid: 57.42%, Test: 57.38%
Epoch: 125, Loss: 0.6754, Train: 58.55%, Valid: 58.47%, Test: 58.53%
Epoch: 150, Loss: 0.6650, Train: 59.76%, Valid: 59.72%, Test: 59.73%
Epoch: 175, Loss: 0.6542, Train: 60.69%, Valid: 60.69%, Test: 60.68%
Epoch: 200, Loss: 0.6472, Train: 61.17%, Valid: 61.14%, Test: 61.13%
Epoch: 225, Loss: 0.6434, Train: 61.38%, Valid: 61.30%, Test: 61.32%
Epoch: 250, Loss: 0.6415, Train: 61.49%, Valid: 61.47%, Test: 61.43%
Epoch: 275, Loss: 0.6406, Train: 61.56%, Valid: 61.55%, Test: 61.50%
Epoch: 300, Loss: 0.6400, Train: 61.59%, Valid: 61.62%, Test: 61.52%
Epoch: 325, Loss: 0.6396, Train: 61.60%, Valid: 61.64%, Test: 61.55%
Epoch: 350, Loss: 0.6393, Train: 61.62%, Valid: 61.68%, Test: 61.54%
Epoch: 375, Loss: 0.6389, Train: 61.67%, Valid: 61.72%, Test: 61.60%
Epoch: 400, Loss: 0.6385, Train: 61.70%, Valid: 61.76%, Test: 61.62%
Epoch: 425, Loss: 0.6382, Train: 61.74%, Valid: 61.78%, Test: 61.66%
Epoch: 450, Loss: 0.6378, Train: 61.77%, Valid: 61.81%, Test: 61.71%
Epoch: 475, Loss: 0.6375, Train: 61.83%, Valid: 61.84%, Test: 61.78%
Run 01:
Highest Train: 61.88
Highest Valid: 61.88
  Final Train: 61.88
   Final Test: 61.84
All runs:
Highest Train: 61.88 ± nan
Highest Valid: 61.88 ± nan
  Final Train: 61.88 ± nan
   Final Test: 61.84 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.5258, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7670, Train: 52.16%, Valid: 52.32%, Test: 52.07%
Epoch: 50, Loss: 0.7135, Train: 57.39%, Valid: 57.44%, Test: 57.34%
Epoch: 75, Loss: 0.6998, Train: 55.66%, Valid: 55.81%, Test: 55.60%
Epoch: 100, Loss: 0.6899, Train: 57.65%, Valid: 57.81%, Test: 57.66%
Epoch: 125, Loss: 0.6717, Train: 59.77%, Valid: 59.75%, Test: 59.73%
Epoch: 150, Loss: 0.6613, Train: 60.33%, Valid: 60.25%, Test: 60.27%
Epoch: 175, Loss: 0.6516, Train: 60.93%, Valid: 60.93%, Test: 60.91%
Epoch: 200, Loss: 0.6452, Train: 61.34%, Valid: 61.31%, Test: 61.27%
Epoch: 225, Loss: 0.6422, Train: 61.49%, Valid: 61.48%, Test: 61.42%
Epoch: 250, Loss: 0.6409, Train: 61.55%, Valid: 61.58%, Test: 61.51%
Epoch: 275, Loss: 0.6403, Train: 61.57%, Valid: 61.61%, Test: 61.51%
Epoch: 300, Loss: 0.6398, Train: 61.61%, Valid: 61.65%, Test: 61.54%
Epoch: 325, Loss: 0.6394, Train: 61.67%, Valid: 61.71%, Test: 61.58%
Epoch: 350, Loss: 0.6390, Train: 61.73%, Valid: 61.77%, Test: 61.65%
Epoch: 375, Loss: 0.6384, Train: 61.79%, Valid: 61.84%, Test: 61.75%
Epoch: 400, Loss: 0.6375, Train: 61.93%, Valid: 61.91%, Test: 61.87%
Epoch: 425, Loss: 0.6356, Train: 62.20%, Valid: 62.19%, Test: 62.09%
Epoch: 450, Loss: 0.6292, Train: 63.33%, Valid: 63.29%, Test: 63.19%
Epoch: 475, Loss: 0.6692, Train: 61.97%, Valid: 61.97%, Test: 61.95%
Run 01:
Highest Train: 64.90
Highest Valid: 64.93
  Final Train: 64.90
   Final Test: 64.82
All runs:
Highest Train: 64.90 ± nan
Highest Valid: 64.93 ± nan
  Final Train: 64.90 ± nan
   Final Test: 64.82 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 8.7881, Train: 49.62%, Valid: 49.42%, Test: 49.65%
Epoch: 25, Loss: 2.3587, Train: 49.75%, Valid: 49.56%, Test: 49.60%
Epoch: 50, Loss: 0.9748, Train: 50.95%, Valid: 50.83%, Test: 51.09%
Epoch: 75, Loss: 0.7259, Train: 54.77%, Valid: 54.79%, Test: 54.82%
Epoch: 100, Loss: 0.6714, Train: 59.21%, Valid: 59.23%, Test: 59.30%
Epoch: 125, Loss: 0.7360, Train: 56.73%, Valid: 56.85%, Test: 56.71%
Epoch: 150, Loss: 0.6356, Train: 63.49%, Valid: 63.43%, Test: 63.50%
Epoch: 175, Loss: 1.2358, Train: 56.17%, Valid: 56.04%, Test: 56.16%
Epoch: 200, Loss: 0.7197, Train: 59.32%, Valid: 59.24%, Test: 59.27%
Epoch: 225, Loss: 0.6288, Train: 63.56%, Valid: 63.68%, Test: 63.54%
Epoch: 250, Loss: 0.6148, Train: 65.43%, Valid: 65.55%, Test: 65.40%
Epoch: 275, Loss: 0.6229, Train: 66.25%, Valid: 66.38%, Test: 66.25%
Epoch: 300, Loss: 0.5915, Train: 67.57%, Valid: 67.58%, Test: 67.48%
Epoch: 325, Loss: 0.6528, Train: 66.64%, Valid: 66.75%, Test: 66.65%
Epoch: 350, Loss: 0.6619, Train: 65.70%, Valid: 65.86%, Test: 65.70%
Epoch: 375, Loss: 0.5840, Train: 68.48%, Valid: 68.46%, Test: 68.41%
Epoch: 400, Loss: 0.5943, Train: 66.97%, Valid: 66.98%, Test: 66.96%
Epoch: 425, Loss: 0.6256, Train: 67.19%, Valid: 67.28%, Test: 67.21%
Epoch: 450, Loss: 0.6329, Train: 65.23%, Valid: 65.41%, Test: 65.23%
Epoch: 475, Loss: 0.5929, Train: 67.57%, Valid: 67.49%, Test: 67.43%
Run 01:
Highest Train: 69.93
Highest Valid: 69.90
  Final Train: 69.86
   Final Test: 69.81
All runs:
Highest Train: 69.93 ± nan
Highest Valid: 69.90 ± nan
  Final Train: 69.86 ± nan
   Final Test: 69.81 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.5471, Train: 50.79%, Valid: 50.71%, Test: 50.66%
Epoch: 25, Loss: 0.7238, Train: 50.54%, Valid: 50.45%, Test: 50.39%
Epoch: 50, Loss: 0.6871, Train: 52.39%, Valid: 52.38%, Test: 52.31%
Epoch: 75, Loss: 0.6795, Train: 58.31%, Valid: 58.26%, Test: 58.28%
Epoch: 100, Loss: 0.6678, Train: 60.92%, Valid: 60.98%, Test: 60.94%
Epoch: 125, Loss: 0.6388, Train: 65.97%, Valid: 65.91%, Test: 65.97%
Epoch: 150, Loss: 0.6266, Train: 59.83%, Valid: 59.75%, Test: 59.77%
Epoch: 175, Loss: 0.5921, Train: 69.87%, Valid: 69.89%, Test: 69.96%
Epoch: 200, Loss: 0.5740, Train: 72.10%, Valid: 72.09%, Test: 72.14%
Epoch: 225, Loss: 0.6701, Train: 71.93%, Valid: 71.90%, Test: 72.00%
Epoch: 250, Loss: 0.5787, Train: 70.68%, Valid: 70.74%, Test: 70.71%
Epoch: 275, Loss: 0.5498, Train: 73.79%, Valid: 73.78%, Test: 73.84%
Epoch: 300, Loss: 0.5434, Train: 74.14%, Valid: 74.15%, Test: 74.19%
Epoch: 325, Loss: 0.5433, Train: 74.51%, Valid: 74.49%, Test: 74.58%
Epoch: 350, Loss: 0.5377, Train: 73.46%, Valid: 73.51%, Test: 73.44%
Epoch: 375, Loss: 0.5264, Train: 74.69%, Valid: 74.68%, Test: 74.71%
Epoch: 400, Loss: 0.5338, Train: 74.01%, Valid: 74.03%, Test: 74.05%
Epoch: 425, Loss: 0.5224, Train: 74.98%, Valid: 74.95%, Test: 75.07%
Epoch: 450, Loss: 0.5188, Train: 75.01%, Valid: 75.00%, Test: 75.09%
Epoch: 475, Loss: 0.5439, Train: 73.53%, Valid: 73.54%, Test: 73.62%
Run 01:
Highest Train: 75.19
Highest Valid: 75.16
  Final Train: 75.19
   Final Test: 75.24
All runs:
Highest Train: 75.19 ± nan
Highest Valid: 75.16 ± nan
  Final Train: 75.19 ± nan
   Final Test: 75.24 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 1.4942, Train: 49.74%, Valid: 49.87%, Test: 49.88%
Epoch: 25, Loss: 1.0603, Train: 50.99%, Valid: 51.27%, Test: 51.02%
Epoch: 50, Loss: 0.7091, Train: 59.02%, Valid: 59.13%, Test: 59.08%
Epoch: 75, Loss: 0.6414, Train: 64.05%, Valid: 64.06%, Test: 64.11%
Epoch: 100, Loss: 0.6563, Train: 60.00%, Valid: 59.96%, Test: 59.95%
Epoch: 125, Loss: 0.6518, Train: 60.05%, Valid: 60.00%, Test: 60.00%
Epoch: 150, Loss: 0.6424, Train: 61.76%, Valid: 61.70%, Test: 61.66%
Epoch: 175, Loss: 0.6362, Train: 62.83%, Valid: 62.80%, Test: 62.72%
Epoch: 200, Loss: 0.6050, Train: 65.46%, Valid: 65.32%, Test: 65.32%
Epoch: 225, Loss: 0.6249, Train: 64.25%, Valid: 64.21%, Test: 64.13%
Epoch: 250, Loss: 0.6433, Train: 63.07%, Valid: 63.08%, Test: 62.95%
Epoch: 275, Loss: 0.6004, Train: 67.62%, Valid: 67.62%, Test: 67.59%
Epoch: 300, Loss: 0.6539, Train: 60.99%, Valid: 60.83%, Test: 60.86%
Epoch: 325, Loss: 0.6296, Train: 64.33%, Valid: 64.44%, Test: 64.26%
Epoch: 350, Loss: 0.6135, Train: 70.45%, Valid: 70.46%, Test: 70.33%
Epoch: 375, Loss: 0.5646, Train: 70.44%, Valid: 70.52%, Test: 70.36%
Epoch: 400, Loss: 0.6051, Train: 67.05%, Valid: 67.07%, Test: 67.03%
Epoch: 425, Loss: 0.6031, Train: 67.43%, Valid: 67.55%, Test: 67.45%
Epoch: 450, Loss: 0.6255, Train: 72.74%, Valid: 72.77%, Test: 72.69%
Epoch: 475, Loss: 0.5319, Train: 72.38%, Valid: 72.39%, Test: 72.35%
Run 01:
Highest Train: 73.45
Highest Valid: 73.45
  Final Train: 73.44
   Final Test: 73.43
All runs:
Highest Train: 73.45 ± nan
Highest Valid: 73.45 ± nan
  Final Train: 73.44 ± nan
   Final Test: 73.43 ± nan
Saving results to results/pokec.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='pokec', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 1632803 | num classes 2 | num node feats 65
MODEL: MLPNORM(
  (fc1): Linear(in_features=65, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 20.8026, Train: 49.63%, Valid: 49.74%, Test: 49.82%
Epoch: 25, Loss: 3.3856, Train: 50.51%, Valid: 50.63%, Test: 50.59%
Epoch: 50, Loss: 0.9961, Train: 51.22%, Valid: 51.12%, Test: 51.22%
Epoch: 75, Loss: 1.0048, Train: 51.52%, Valid: 51.48%, Test: 51.39%
Epoch: 100, Loss: 0.9071, Train: 52.06%, Valid: 52.00%, Test: 52.07%
Epoch: 125, Loss: 0.8039, Train: 54.25%, Valid: 54.17%, Test: 54.21%
Epoch: 150, Loss: 0.7361, Train: 59.39%, Valid: 59.25%, Test: 59.39%
Epoch: 175, Loss: 0.7206, Train: 60.97%, Valid: 60.81%, Test: 61.05%
Epoch: 200, Loss: 0.7094, Train: 60.90%, Valid: 60.70%, Test: 60.90%
Epoch: 225, Loss: 0.6972, Train: 59.04%, Valid: 58.88%, Test: 59.01%
Epoch: 250, Loss: 0.6744, Train: 59.33%, Valid: 59.22%, Test: 59.30%
Epoch: 275, Loss: 0.6701, Train: 60.35%, Valid: 60.28%, Test: 60.38%
Epoch: 300, Loss: 0.6579, Train: 62.27%, Valid: 62.22%, Test: 62.27%
Epoch: 325, Loss: 0.6601, Train: 62.73%, Valid: 62.69%, Test: 62.68%
Epoch: 350, Loss: 0.6518, Train: 63.80%, Valid: 63.81%, Test: 63.79%
Epoch: 375, Loss: 0.6450, Train: 63.71%, Valid: 63.68%, Test: 63.64%
Epoch: 400, Loss: 0.6508, Train: 64.44%, Valid: 64.45%, Test: 64.40%
Epoch: 425, Loss: 0.6408, Train: 64.98%, Valid: 64.98%, Test: 64.98%
Epoch: 450, Loss: 0.6363, Train: 64.61%, Valid: 64.59%, Test: 64.54%
Epoch: 475, Loss: 0.6466, Train: 65.41%, Valid: 65.42%, Test: 65.42%
Run 01:
Highest Train: 65.73
Highest Valid: 65.73
  Final Train: 65.73
   Final Test: 65.71
All runs:
Highest Train: 65.73 ± nan
Highest Valid: 65.73 ± nan
  Final Train: 65.73 ± nan
   Final Test: 65.71 ± nan
Saving results to results/pokec.csv
20211116-18:18 ---> 20211116-20:24 Totl:7586 seconds
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6095, Train: 27.59%, Valid: 27.50%, Test: 27.45%
Epoch: 25, Loss: 1.5114, Train: 31.07%, Valid: 30.91%, Test: 30.87%
Epoch: 50, Loss: 1.5033, Train: 31.63%, Valid: 31.31%, Test: 31.34%
Epoch: 75, Loss: 1.4994, Train: 31.87%, Valid: 31.44%, Test: 31.47%
Epoch: 100, Loss: 1.4972, Train: 32.01%, Valid: 31.45%, Test: 31.51%
Epoch: 125, Loss: 1.4960, Train: 32.13%, Valid: 31.48%, Test: 31.53%
Epoch: 150, Loss: 1.4950, Train: 32.19%, Valid: 31.46%, Test: 31.51%
Epoch: 175, Loss: 1.4940, Train: 32.22%, Valid: 31.39%, Test: 31.49%
Epoch: 200, Loss: 1.4931, Train: 32.30%, Valid: 31.49%, Test: 31.51%
Epoch: 225, Loss: 1.4928, Train: 32.34%, Valid: 31.46%, Test: 31.50%
Epoch: 250, Loss: 1.4924, Train: 32.35%, Valid: 31.51%, Test: 31.53%
Epoch: 275, Loss: 1.4919, Train: 32.38%, Valid: 31.46%, Test: 31.49%
Epoch: 300, Loss: 1.4927, Train: 32.27%, Valid: 31.47%, Test: 31.42%
Epoch: 325, Loss: 1.4908, Train: 32.45%, Valid: 31.53%, Test: 31.56%
Epoch: 350, Loss: 1.4917, Train: 32.32%, Valid: 31.31%, Test: 31.41%
Epoch: 375, Loss: 1.4903, Train: 32.45%, Valid: 31.51%, Test: 31.55%
Epoch: 400, Loss: 1.4901, Train: 32.47%, Valid: 31.52%, Test: 31.57%
Epoch: 425, Loss: 1.4896, Train: 32.51%, Valid: 31.47%, Test: 31.55%
Epoch: 450, Loss: 1.4896, Train: 32.50%, Valid: 31.50%, Test: 31.51%
Epoch: 475, Loss: 1.4901, Train: 32.50%, Valid: 31.48%, Test: 31.54%
Run 01:
Highest Train: 32.53
Highest Valid: 31.54
  Final Train: 32.44
   Final Test: 31.58
All runs:
Highest Train: 32.53 ± nan
Highest Valid: 31.54 ± nan
  Final Train: 32.44 ± nan
   Final Test: 31.58 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6098, Train: 27.49%, Valid: 27.41%, Test: 27.36%
Epoch: 25, Loss: 1.5117, Train: 31.11%, Valid: 30.96%, Test: 30.90%
Epoch: 50, Loss: 1.5031, Train: 31.60%, Valid: 31.30%, Test: 31.30%
Epoch: 75, Loss: 1.4997, Train: 31.88%, Valid: 31.43%, Test: 31.44%
Epoch: 100, Loss: 1.4969, Train: 32.03%, Valid: 31.45%, Test: 31.44%
Epoch: 125, Loss: 1.4965, Train: 32.09%, Valid: 31.44%, Test: 31.45%
Epoch: 150, Loss: 1.4951, Train: 32.13%, Valid: 31.45%, Test: 31.44%
Epoch: 175, Loss: 1.4935, Train: 32.26%, Valid: 31.52%, Test: 31.51%
Epoch: 200, Loss: 1.4924, Train: 32.30%, Valid: 31.45%, Test: 31.51%
Epoch: 225, Loss: 1.4931, Train: 32.32%, Valid: 31.45%, Test: 31.52%
Epoch: 250, Loss: 1.4918, Train: 32.39%, Valid: 31.53%, Test: 31.55%
Epoch: 275, Loss: 1.4911, Train: 32.41%, Valid: 31.48%, Test: 31.55%
Epoch: 300, Loss: 1.4904, Train: 32.33%, Valid: 31.45%, Test: 31.50%
Epoch: 325, Loss: 1.4904, Train: 32.43%, Valid: 31.47%, Test: 31.49%
Epoch: 350, Loss: 1.4906, Train: 32.43%, Valid: 31.42%, Test: 31.48%
Epoch: 375, Loss: 1.4897, Train: 32.50%, Valid: 31.49%, Test: 31.55%
Epoch: 400, Loss: 1.4896, Train: 32.46%, Valid: 31.43%, Test: 31.55%
Epoch: 425, Loss: 1.4893, Train: 32.54%, Valid: 31.53%, Test: 31.55%
Epoch: 450, Loss: 1.4893, Train: 32.51%, Valid: 31.48%, Test: 31.51%
Epoch: 475, Loss: 1.4908, Train: 32.22%, Valid: 31.23%, Test: 31.30%
Run 01:
Highest Train: 32.59
Highest Valid: 31.57
  Final Train: 32.43
   Final Test: 31.60
All runs:
Highest Train: 32.59 ± nan
Highest Valid: 31.57 ± nan
  Final Train: 32.43 ± nan
   Final Test: 31.60 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6104, Train: 26.62%, Valid: 26.59%, Test: 26.56%
Epoch: 25, Loss: 1.5117, Train: 31.15%, Valid: 30.96%, Test: 30.94%
Epoch: 50, Loss: 1.5031, Train: 31.61%, Valid: 31.27%, Test: 31.34%
Epoch: 75, Loss: 1.5004, Train: 31.84%, Valid: 31.40%, Test: 31.44%
Epoch: 100, Loss: 1.4971, Train: 32.00%, Valid: 31.44%, Test: 31.48%
Epoch: 125, Loss: 1.4966, Train: 32.11%, Valid: 31.45%, Test: 31.52%
Epoch: 150, Loss: 1.4945, Train: 32.18%, Valid: 31.48%, Test: 31.51%
Epoch: 175, Loss: 1.4946, Train: 32.24%, Valid: 31.53%, Test: 31.56%
Epoch: 200, Loss: 1.4930, Train: 32.30%, Valid: 31.53%, Test: 31.57%
Epoch: 225, Loss: 1.4954, Train: 32.08%, Valid: 31.37%, Test: 31.32%
Epoch: 250, Loss: 1.4921, Train: 32.35%, Valid: 31.52%, Test: 31.53%
Epoch: 275, Loss: 1.4915, Train: 32.39%, Valid: 31.52%, Test: 31.58%
Epoch: 300, Loss: 1.4931, Train: 32.32%, Valid: 31.54%, Test: 31.55%
Epoch: 325, Loss: 1.4909, Train: 32.41%, Valid: 31.48%, Test: 31.53%
Epoch: 350, Loss: 1.4904, Train: 32.45%, Valid: 31.50%, Test: 31.55%
Epoch: 375, Loss: 1.4903, Train: 32.40%, Valid: 31.41%, Test: 31.50%
Epoch: 400, Loss: 1.4917, Train: 32.35%, Valid: 31.39%, Test: 31.38%
Epoch: 425, Loss: 1.4893, Train: 32.49%, Valid: 31.50%, Test: 31.53%
Epoch: 450, Loss: 1.4928, Train: 31.97%, Valid: 31.07%, Test: 31.09%
Epoch: 475, Loss: 1.4885, Train: 32.61%, Valid: 31.61%, Test: 31.63%
Run 01:
Highest Train: 32.73
Highest Valid: 31.75
  Final Train: 32.73
   Final Test: 31.77
All runs:
Highest Train: 32.73 ± nan
Highest Valid: 31.75 ± nan
  Final Train: 32.73 ± nan
   Final Test: 31.77 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6116, Train: 26.95%, Valid: 26.85%, Test: 26.84%
Epoch: 25, Loss: 1.5116, Train: 31.12%, Valid: 30.97%, Test: 30.88%
Epoch: 50, Loss: 1.5030, Train: 31.59%, Valid: 31.29%, Test: 31.28%
Epoch: 75, Loss: 1.4993, Train: 31.89%, Valid: 31.46%, Test: 31.42%
Epoch: 100, Loss: 1.4968, Train: 32.04%, Valid: 31.53%, Test: 31.47%
Epoch: 125, Loss: 1.4950, Train: 32.16%, Valid: 31.49%, Test: 31.53%
Epoch: 150, Loss: 1.4943, Train: 32.19%, Valid: 31.51%, Test: 31.55%
Epoch: 175, Loss: 1.4943, Train: 32.29%, Valid: 31.56%, Test: 31.53%
Epoch: 200, Loss: 1.4924, Train: 32.33%, Valid: 31.46%, Test: 31.51%
Epoch: 225, Loss: 1.4919, Train: 32.30%, Valid: 31.37%, Test: 31.46%
Epoch: 250, Loss: 1.4914, Train: 32.37%, Valid: 31.47%, Test: 31.52%
Epoch: 275, Loss: 1.4912, Train: 32.41%, Valid: 31.46%, Test: 31.51%
Epoch: 300, Loss: 1.4906, Train: 32.40%, Valid: 31.46%, Test: 31.53%
Epoch: 325, Loss: 1.4905, Train: 32.44%, Valid: 31.45%, Test: 31.49%
Epoch: 350, Loss: 1.4899, Train: 32.49%, Valid: 31.52%, Test: 31.53%
Epoch: 375, Loss: 1.4899, Train: 32.47%, Valid: 31.49%, Test: 31.51%
Epoch: 400, Loss: 1.4941, Train: 32.38%, Valid: 31.32%, Test: 31.37%
Epoch: 425, Loss: 1.4896, Train: 32.49%, Valid: 31.44%, Test: 31.51%
Epoch: 450, Loss: 1.4891, Train: 32.53%, Valid: 31.49%, Test: 31.54%
Epoch: 475, Loss: 1.4931, Train: 32.35%, Valid: 31.41%, Test: 31.47%
Run 01:
Highest Train: 32.55
Highest Valid: 31.57
  Final Train: 32.09
   Final Test: 31.48
All runs:
Highest Train: 32.55 ± nan
Highest Valid: 31.57 ± nan
  Final Train: 32.09 ± nan
   Final Test: 31.48 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6110, Train: 28.23%, Valid: 28.19%, Test: 28.17%
Epoch: 25, Loss: 1.5107, Train: 31.17%, Valid: 31.00%, Test: 30.98%
Epoch: 50, Loss: 1.5026, Train: 31.67%, Valid: 31.34%, Test: 31.34%
Epoch: 75, Loss: 1.4980, Train: 31.93%, Valid: 31.49%, Test: 31.48%
Epoch: 100, Loss: 1.4968, Train: 32.07%, Valid: 31.53%, Test: 31.52%
Epoch: 125, Loss: 1.4959, Train: 32.16%, Valid: 31.42%, Test: 31.51%
Epoch: 150, Loss: 1.4943, Train: 32.23%, Valid: 31.48%, Test: 31.53%
Epoch: 175, Loss: 1.4958, Train: 32.23%, Valid: 31.51%, Test: 31.53%
Epoch: 200, Loss: 1.4927, Train: 32.33%, Valid: 31.53%, Test: 31.55%
Epoch: 225, Loss: 1.4935, Train: 32.33%, Valid: 31.50%, Test: 31.51%
Epoch: 250, Loss: 1.4916, Train: 32.38%, Valid: 31.51%, Test: 31.52%
Epoch: 275, Loss: 1.4911, Train: 32.41%, Valid: 31.51%, Test: 31.52%
Epoch: 300, Loss: 1.4912, Train: 32.33%, Valid: 31.35%, Test: 31.43%
Epoch: 325, Loss: 1.4903, Train: 32.52%, Valid: 31.56%, Test: 31.56%
Epoch: 350, Loss: 1.4906, Train: 32.41%, Valid: 31.50%, Test: 31.47%
Epoch: 375, Loss: 1.4893, Train: 32.48%, Valid: 31.46%, Test: 31.49%
Epoch: 400, Loss: 1.4884, Train: 32.56%, Valid: 31.54%, Test: 31.51%
Epoch: 425, Loss: 1.4917, Train: 32.01%, Valid: 31.15%, Test: 31.14%
Epoch: 450, Loss: 1.4858, Train: 32.89%, Valid: 31.95%, Test: 31.94%
Epoch: 475, Loss: 1.4891, Train: 32.47%, Valid: 31.63%, Test: 31.56%
Run 01:
Highest Train: 32.94
Highest Valid: 32.01
  Final Train: 32.94
   Final Test: 31.98
All runs:
Highest Train: 32.94 ± nan
Highest Valid: 32.01 ± nan
  Final Train: 32.94 ± nan
   Final Test: 31.98 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6134, Train: 27.48%, Valid: 27.42%, Test: 27.37%
Epoch: 25, Loss: 1.5115, Train: 31.07%, Valid: 30.91%, Test: 30.84%
Epoch: 50, Loss: 1.5024, Train: 31.62%, Valid: 31.31%, Test: 31.36%
Epoch: 75, Loss: 1.4976, Train: 32.03%, Valid: 31.61%, Test: 31.57%
Epoch: 100, Loss: 1.4956, Train: 31.96%, Valid: 31.42%, Test: 31.36%
Epoch: 125, Loss: 1.4897, Train: 31.75%, Valid: 31.22%, Test: 31.19%
Epoch: 150, Loss: 1.4898, Train: 32.49%, Valid: 31.98%, Test: 31.99%
Epoch: 175, Loss: 1.4913, Train: 32.35%, Valid: 31.97%, Test: 31.97%
Epoch: 200, Loss: 1.5126, Train: 31.33%, Valid: 31.06%, Test: 30.97%
Epoch: 225, Loss: 1.4686, Train: 33.80%, Valid: 33.46%, Test: 33.44%
Epoch: 250, Loss: 1.5399, Train: 25.87%, Valid: 25.66%, Test: 25.70%
Epoch: 275, Loss: 1.4820, Train: 32.89%, Valid: 32.66%, Test: 32.69%
Epoch: 300, Loss: 1.4555, Train: 33.27%, Valid: 33.06%, Test: 33.08%
Epoch: 325, Loss: 1.4721, Train: 33.10%, Valid: 32.87%, Test: 32.91%
Epoch: 350, Loss: 1.4464, Train: 35.03%, Valid: 34.86%, Test: 34.84%
Epoch: 375, Loss: 1.4388, Train: 36.26%, Valid: 36.06%, Test: 36.02%
Epoch: 400, Loss: 1.4139, Train: 37.45%, Valid: 37.29%, Test: 37.23%
Epoch: 425, Loss: 1.4102, Train: 37.11%, Valid: 36.89%, Test: 36.88%
Epoch: 450, Loss: 1.4006, Train: 38.21%, Valid: 38.00%, Test: 37.99%
Epoch: 475, Loss: 1.3979, Train: 38.83%, Valid: 38.60%, Test: 38.59%
Run 01:
Highest Train: 39.85
Highest Valid: 39.63
  Final Train: 39.85
   Final Test: 39.61
All runs:
Highest Train: 39.85 ± nan
Highest Valid: 39.63 ± nan
  Final Train: 39.85 ± nan
   Final Test: 39.61 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6116, Train: 27.05%, Valid: 27.02%, Test: 26.96%
Epoch: 25, Loss: 1.5114, Train: 31.06%, Valid: 30.90%, Test: 30.84%
Epoch: 50, Loss: 1.5026, Train: 31.64%, Valid: 31.31%, Test: 31.28%
Epoch: 75, Loss: 1.4992, Train: 31.90%, Valid: 31.45%, Test: 31.44%
Epoch: 100, Loss: 1.4970, Train: 32.04%, Valid: 31.47%, Test: 31.49%
Epoch: 125, Loss: 1.4955, Train: 32.10%, Valid: 31.42%, Test: 31.46%
Epoch: 150, Loss: 1.4941, Train: 32.21%, Valid: 31.52%, Test: 31.51%
Epoch: 175, Loss: 1.4939, Train: 32.10%, Valid: 31.49%, Test: 31.40%
Epoch: 200, Loss: 1.4928, Train: 32.34%, Valid: 31.58%, Test: 31.56%
Epoch: 225, Loss: 1.4917, Train: 32.39%, Valid: 31.57%, Test: 31.55%
Epoch: 250, Loss: 1.4928, Train: 32.45%, Valid: 31.58%, Test: 31.61%
Epoch: 275, Loss: 1.4901, Train: 32.41%, Valid: 31.50%, Test: 31.49%
Epoch: 300, Loss: 1.4967, Train: 32.44%, Valid: 31.61%, Test: 31.62%
Epoch: 325, Loss: 1.4894, Train: 32.34%, Valid: 31.42%, Test: 31.41%
Epoch: 350, Loss: 1.4876, Train: 32.65%, Valid: 31.72%, Test: 31.70%
Epoch: 375, Loss: 1.4851, Train: 32.78%, Valid: 31.93%, Test: 31.87%
Epoch: 400, Loss: 1.4877, Train: 32.65%, Valid: 32.10%, Test: 32.12%
Epoch: 425, Loss: 1.4599, Train: 35.27%, Valid: 34.63%, Test: 34.59%
Epoch: 450, Loss: 1.4757, Train: 33.62%, Valid: 33.20%, Test: 33.19%
Epoch: 475, Loss: 1.4670, Train: 34.50%, Valid: 34.08%, Test: 34.09%
Run 01:
Highest Train: 38.62
Highest Valid: 38.19
  Final Train: 38.57
   Final Test: 38.23
All runs:
Highest Train: 38.62 ± nan
Highest Valid: 38.19 ± nan
  Final Train: 38.57 ± nan
   Final Test: 38.23 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6095, Train: 27.46%, Valid: 27.38%, Test: 27.34%
Epoch: 25, Loss: 1.5110, Train: 31.12%, Valid: 30.94%, Test: 30.96%
Epoch: 50, Loss: 1.5030, Train: 31.65%, Valid: 31.37%, Test: 31.40%
Epoch: 75, Loss: 1.4990, Train: 31.83%, Valid: 31.51%, Test: 31.50%
Epoch: 100, Loss: 1.4920, Train: 32.11%, Valid: 31.72%, Test: 31.70%
Epoch: 125, Loss: 1.4796, Train: 33.89%, Valid: 33.48%, Test: 33.47%
Epoch: 150, Loss: 1.4418, Train: 35.71%, Valid: 35.37%, Test: 35.41%
Epoch: 175, Loss: 1.4316, Train: 35.93%, Valid: 35.66%, Test: 35.67%
Epoch: 200, Loss: 1.3548, Train: 38.57%, Valid: 38.29%, Test: 38.28%
Epoch: 225, Loss: 1.3065, Train: 42.58%, Valid: 42.22%, Test: 42.28%
Epoch: 250, Loss: 1.2830, Train: 43.87%, Valid: 43.41%, Test: 43.41%
Epoch: 275, Loss: 1.2491, Train: 46.00%, Valid: 45.60%, Test: 45.55%
Epoch: 300, Loss: 1.2046, Train: 47.41%, Valid: 47.01%, Test: 46.94%
Epoch: 325, Loss: 1.1702, Train: 48.65%, Valid: 48.14%, Test: 48.12%
Epoch: 350, Loss: 1.1615, Train: 49.68%, Valid: 49.06%, Test: 49.07%
Epoch: 375, Loss: 1.1651, Train: 48.67%, Valid: 48.15%, Test: 48.18%
Epoch: 400, Loss: 1.1480, Train: 49.67%, Valid: 49.18%, Test: 49.16%
Epoch: 425, Loss: 1.1154, Train: 52.20%, Valid: 51.60%, Test: 51.50%
Epoch: 450, Loss: 1.1085, Train: 51.15%, Valid: 50.61%, Test: 50.55%
Epoch: 475, Loss: 1.1059, Train: 52.36%, Valid: 51.77%, Test: 51.64%
Run 01:
Highest Train: 53.13
Highest Valid: 52.48
  Final Train: 53.13
   Final Test: 52.38
All runs:
Highest Train: 53.13 ± nan
Highest Valid: 52.48 ± nan
  Final Train: 53.13 ± nan
   Final Test: 52.38 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6120, Train: 26.84%, Valid: 26.77%, Test: 26.76%
Epoch: 25, Loss: 1.5096, Train: 31.28%, Valid: 31.14%, Test: 31.08%
Epoch: 50, Loss: 1.5028, Train: 31.36%, Valid: 31.18%, Test: 31.12%
Epoch: 75, Loss: 1.4931, Train: 32.29%, Valid: 31.96%, Test: 31.95%
Epoch: 100, Loss: 1.4741, Train: 31.78%, Valid: 31.50%, Test: 31.48%
Epoch: 125, Loss: 1.4878, Train: 33.98%, Valid: 33.71%, Test: 33.62%
Epoch: 150, Loss: 1.4609, Train: 33.68%, Valid: 33.38%, Test: 33.37%
Epoch: 175, Loss: 1.4341, Train: 36.30%, Valid: 36.08%, Test: 36.05%
Epoch: 200, Loss: 1.3752, Train: 37.93%, Valid: 37.60%, Test: 37.56%
Epoch: 225, Loss: 1.5109, Train: 34.34%, Valid: 34.20%, Test: 34.13%
Epoch: 250, Loss: 1.4316, Train: 35.78%, Valid: 35.54%, Test: 35.56%
Epoch: 275, Loss: 1.3595, Train: 39.07%, Valid: 38.81%, Test: 38.80%
Epoch: 300, Loss: 1.4964, Train: 34.87%, Valid: 34.63%, Test: 34.68%
Epoch: 325, Loss: 1.3477, Train: 39.78%, Valid: 39.54%, Test: 39.49%
Epoch: 350, Loss: 1.2963, Train: 42.87%, Valid: 42.63%, Test: 42.52%
Epoch: 375, Loss: 1.4680, Train: 35.13%, Valid: 34.92%, Test: 34.92%
Epoch: 400, Loss: 1.3072, Train: 43.35%, Valid: 43.07%, Test: 42.98%
Epoch: 425, Loss: 1.2441, Train: 45.86%, Valid: 45.67%, Test: 45.53%
Epoch: 450, Loss: 1.2300, Train: 47.16%, Valid: 46.89%, Test: 46.82%
Epoch: 475, Loss: 1.1831, Train: 49.54%, Valid: 49.23%, Test: 49.17%
Run 01:
Highest Train: 49.64
Highest Valid: 49.34
  Final Train: 49.64
   Final Test: 49.30
All runs:
Highest Train: 49.64 ± nan
Highest Valid: 49.34 ± nan
  Final Train: 49.64 ± nan
   Final Test: 49.30 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6112, Train: 27.42%, Valid: 27.33%, Test: 27.33%
Epoch: 25, Loss: 1.5104, Train: 31.09%, Valid: 30.92%, Test: 30.88%
Epoch: 50, Loss: 1.4993, Train: 31.82%, Valid: 31.50%, Test: 31.53%
Epoch: 75, Loss: 1.4984, Train: 31.96%, Valid: 31.58%, Test: 31.57%
Epoch: 100, Loss: 1.4851, Train: 32.19%, Valid: 31.81%, Test: 31.76%
Epoch: 125, Loss: 1.4650, Train: 34.38%, Valid: 33.96%, Test: 33.96%
Epoch: 150, Loss: 1.4347, Train: 37.39%, Valid: 36.84%, Test: 36.88%
Epoch: 175, Loss: 1.3785, Train: 38.43%, Valid: 37.91%, Test: 37.91%
Epoch: 200, Loss: 1.3349, Train: 42.01%, Valid: 41.27%, Test: 41.32%
Epoch: 225, Loss: 1.2671, Train: 45.31%, Valid: 44.48%, Test: 44.52%
Epoch: 250, Loss: 1.2358, Train: 46.18%, Valid: 45.47%, Test: 45.44%
Epoch: 275, Loss: 1.1890, Train: 47.44%, Valid: 46.64%, Test: 46.64%
Epoch: 300, Loss: 1.1676, Train: 47.96%, Valid: 47.13%, Test: 47.14%
Epoch: 325, Loss: 1.1531, Train: 48.35%, Valid: 47.45%, Test: 47.48%
Epoch: 350, Loss: 1.1489, Train: 48.24%, Valid: 47.33%, Test: 47.35%
Epoch: 375, Loss: 1.1399, Train: 48.50%, Valid: 47.62%, Test: 47.63%
Epoch: 400, Loss: 1.1328, Train: 48.62%, Valid: 47.80%, Test: 47.79%
Epoch: 425, Loss: 1.1327, Train: 48.81%, Valid: 47.93%, Test: 47.95%
Epoch: 450, Loss: 1.1241, Train: 49.01%, Valid: 48.07%, Test: 48.05%
Epoch: 475, Loss: 1.1242, Train: 49.01%, Valid: 48.08%, Test: 48.10%
Run 01:
Highest Train: 49.12
Highest Valid: 48.17
  Final Train: 49.10
   Final Test: 48.16
All runs:
Highest Train: 49.12 ± nan
Highest Valid: 48.17 ± nan
  Final Train: 49.10 ± nan
   Final Test: 48.16 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6094, Train: 23.89%, Valid: 23.78%, Test: 23.72%
Epoch: 25, Loss: 1.5076, Train: 31.28%, Valid: 31.13%, Test: 31.09%
Epoch: 50, Loss: 1.4913, Train: 32.10%, Valid: 31.88%, Test: 31.86%
Epoch: 75, Loss: 1.4847, Train: 32.94%, Valid: 32.72%, Test: 32.65%
Epoch: 100, Loss: 1.4290, Train: 36.41%, Valid: 36.12%, Test: 36.16%
Epoch: 125, Loss: 1.4158, Train: 37.24%, Valid: 36.84%, Test: 36.89%
Epoch: 150, Loss: 1.3330, Train: 40.66%, Valid: 40.27%, Test: 40.20%
Epoch: 175, Loss: 1.2982, Train: 42.21%, Valid: 41.85%, Test: 41.81%
Epoch: 200, Loss: 1.2426, Train: 45.65%, Valid: 45.22%, Test: 45.22%
Epoch: 225, Loss: 1.1787, Train: 48.74%, Valid: 48.23%, Test: 48.14%
Epoch: 250, Loss: 1.1354, Train: 50.45%, Valid: 49.91%, Test: 49.81%
Epoch: 275, Loss: 1.1178, Train: 51.61%, Valid: 51.12%, Test: 51.00%
Epoch: 300, Loss: 1.1019, Train: 52.47%, Valid: 51.96%, Test: 51.80%
Epoch: 325, Loss: 1.0917, Train: 52.29%, Valid: 51.74%, Test: 51.67%
Epoch: 350, Loss: 1.0894, Train: 52.16%, Valid: 51.62%, Test: 51.57%
Epoch: 375, Loss: 1.0758, Train: 53.53%, Valid: 52.89%, Test: 52.80%
Epoch: 400, Loss: 1.0771, Train: 53.51%, Valid: 52.89%, Test: 52.83%
Epoch: 425, Loss: 1.1177, Train: 51.47%, Valid: 51.02%, Test: 50.87%
Epoch: 450, Loss: 1.0711, Train: 53.32%, Valid: 52.72%, Test: 52.65%
Epoch: 475, Loss: 1.0733, Train: 53.11%, Valid: 52.50%, Test: 52.40%
Run 01:
Highest Train: 53.84
Highest Valid: 53.15
  Final Train: 53.84
   Final Test: 53.05
All runs:
Highest Train: 53.84 ± nan
Highest Valid: 53.15 ± nan
  Final Train: 53.84 ± nan
   Final Test: 53.05 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6122, Train: 20.83%, Valid: 20.83%, Test: 20.83%
Epoch: 25, Loss: 1.5047, Train: 31.54%, Valid: 31.49%, Test: 31.43%
Epoch: 50, Loss: 1.4701, Train: 33.70%, Valid: 33.56%, Test: 33.53%
Epoch: 75, Loss: 1.4217, Train: 36.57%, Valid: 36.39%, Test: 36.40%
Epoch: 100, Loss: 1.3907, Train: 38.16%, Valid: 37.91%, Test: 37.95%
Epoch: 125, Loss: 1.3844, Train: 40.08%, Valid: 39.77%, Test: 39.91%
Epoch: 150, Loss: 1.3247, Train: 40.45%, Valid: 40.27%, Test: 40.21%
Epoch: 175, Loss: 1.3029, Train: 41.69%, Valid: 41.42%, Test: 41.46%
Epoch: 200, Loss: 1.2515, Train: 42.37%, Valid: 42.13%, Test: 42.16%
Epoch: 225, Loss: 1.2411, Train: 44.51%, Valid: 44.26%, Test: 44.25%
Epoch: 250, Loss: 1.2081, Train: 46.85%, Valid: 46.59%, Test: 46.60%
Epoch: 275, Loss: 1.1766, Train: 47.77%, Valid: 47.46%, Test: 47.51%
Epoch: 300, Loss: 1.1804, Train: 49.67%, Valid: 49.33%, Test: 49.34%
Epoch: 325, Loss: 1.1692, Train: 49.07%, Valid: 48.80%, Test: 48.77%
Epoch: 350, Loss: 1.1669, Train: 49.83%, Valid: 49.52%, Test: 49.51%
Epoch: 375, Loss: 1.1481, Train: 51.48%, Valid: 51.15%, Test: 51.17%
Epoch: 400, Loss: 1.1395, Train: 51.71%, Valid: 51.37%, Test: 51.36%
Epoch: 425, Loss: 1.1123, Train: 51.81%, Valid: 51.53%, Test: 51.49%
Epoch: 450, Loss: 1.1482, Train: 51.31%, Valid: 51.00%, Test: 50.98%
Epoch: 475, Loss: 1.1069, Train: 53.00%, Valid: 52.61%, Test: 52.61%
Run 01:
Highest Train: 54.26
Highest Valid: 53.71
  Final Train: 54.26
   Final Test: 53.78
All runs:
Highest Train: 54.26 ± nan
Highest Valid: 53.71 ± nan
  Final Train: 54.26 ± nan
   Final Test: 53.78 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6118, Train: 25.78%, Valid: 25.75%, Test: 25.67%
Epoch: 25, Loss: 1.5081, Train: 31.29%, Valid: 31.12%, Test: 31.09%
Epoch: 50, Loss: 1.4917, Train: 32.15%, Valid: 31.86%, Test: 31.86%
Epoch: 75, Loss: 1.4727, Train: 33.50%, Valid: 33.09%, Test: 33.15%
Epoch: 100, Loss: 1.4442, Train: 35.68%, Valid: 35.21%, Test: 35.20%
Epoch: 125, Loss: 1.3936, Train: 39.18%, Valid: 38.66%, Test: 38.61%
Epoch: 150, Loss: 1.3267, Train: 42.09%, Valid: 41.67%, Test: 41.64%
Epoch: 175, Loss: 1.2633, Train: 45.25%, Valid: 44.73%, Test: 44.79%
Epoch: 200, Loss: 1.2133, Train: 46.55%, Valid: 46.07%, Test: 46.05%
Epoch: 225, Loss: 1.1982, Train: 47.45%, Valid: 46.84%, Test: 46.90%
Epoch: 250, Loss: 1.1619, Train: 48.38%, Valid: 47.73%, Test: 47.83%
Epoch: 275, Loss: 1.1490, Train: 48.49%, Valid: 47.78%, Test: 47.88%
Epoch: 300, Loss: 1.1378, Train: 48.96%, Valid: 48.18%, Test: 48.29%
Epoch: 325, Loss: 1.1331, Train: 48.84%, Valid: 48.09%, Test: 48.16%
Epoch: 350, Loss: 1.1299, Train: 48.83%, Valid: 48.13%, Test: 48.19%
Epoch: 375, Loss: 1.1323, Train: 48.97%, Valid: 48.26%, Test: 48.29%
Epoch: 400, Loss: 1.1232, Train: 49.23%, Valid: 48.44%, Test: 48.49%
Epoch: 425, Loss: 1.1230, Train: 49.31%, Valid: 48.47%, Test: 48.50%
Epoch: 450, Loss: 1.1247, Train: 49.28%, Valid: 48.48%, Test: 48.48%
Epoch: 475, Loss: 1.1163, Train: 49.50%, Valid: 48.64%, Test: 48.68%
Run 01:
Highest Train: 49.55
Highest Valid: 48.72
  Final Train: 49.55
   Final Test: 48.73
All runs:
Highest Train: 49.55 ± nan
Highest Valid: 48.72 ± nan
  Final Train: 49.55 ± nan
   Final Test: 48.73 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6155, Train: 21.36%, Valid: 21.34%, Test: 21.31%
Epoch: 25, Loss: 1.5036, Train: 31.48%, Valid: 31.34%, Test: 31.32%
Epoch: 50, Loss: 1.4711, Train: 32.96%, Valid: 32.82%, Test: 32.72%
Epoch: 75, Loss: 1.4174, Train: 35.98%, Valid: 35.71%, Test: 35.73%
Epoch: 100, Loss: 1.3396, Train: 40.09%, Valid: 39.84%, Test: 39.81%
Epoch: 125, Loss: 1.2658, Train: 43.16%, Valid: 42.93%, Test: 42.87%
Epoch: 150, Loss: 1.1976, Train: 47.39%, Valid: 47.12%, Test: 47.11%
Epoch: 175, Loss: 1.1636, Train: 49.13%, Valid: 48.86%, Test: 48.85%
Epoch: 200, Loss: 1.1328, Train: 49.08%, Valid: 48.79%, Test: 48.75%
Epoch: 225, Loss: 1.1218, Train: 50.90%, Valid: 50.58%, Test: 50.57%
Epoch: 250, Loss: 1.1115, Train: 51.11%, Valid: 50.74%, Test: 50.75%
Epoch: 275, Loss: 1.1070, Train: 52.76%, Valid: 52.34%, Test: 52.33%
Epoch: 300, Loss: 1.0936, Train: 52.51%, Valid: 52.12%, Test: 52.09%
Epoch: 325, Loss: 1.0851, Train: 53.09%, Valid: 52.68%, Test: 52.70%
Epoch: 350, Loss: 1.0928, Train: 52.06%, Valid: 51.68%, Test: 51.60%
Epoch: 375, Loss: 1.0743, Train: 52.99%, Valid: 52.57%, Test: 52.54%
Epoch: 400, Loss: 1.0843, Train: 50.93%, Valid: 50.55%, Test: 50.51%
Epoch: 425, Loss: 1.0746, Train: 52.47%, Valid: 52.03%, Test: 52.01%
Epoch: 450, Loss: 1.0769, Train: 52.62%, Valid: 52.20%, Test: 52.15%
Epoch: 475, Loss: 1.0796, Train: 53.65%, Valid: 53.20%, Test: 53.17%
Run 01:
Highest Train: 54.32
Highest Valid: 53.79
  Final Train: 54.32
   Final Test: 53.81
All runs:
Highest Train: 54.32 ± nan
Highest Valid: 53.79 ± nan
  Final Train: 54.32 ± nan
   Final Test: 53.81 ± nan
Saving results to results/snap-patents.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='snap-patents', directed=True, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 2923922 | num classes 5 | num node feats 269
MODEL: MLPNORM(
  (fc1): Linear(in_features=269, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=5, bias=True)
)
Epoch: 00, Loss: 1.6185, Train: 19.84%, Valid: 19.81%, Test: 19.78%
Epoch: 25, Loss: 1.4910, Train: 32.78%, Valid: 32.75%, Test: 32.69%
Epoch: 50, Loss: 1.4540, Train: 33.62%, Valid: 33.51%, Test: 33.51%
Epoch: 75, Loss: 1.4248, Train: 34.74%, Valid: 34.68%, Test: 34.61%
Epoch: 100, Loss: 1.3708, Train: 38.59%, Valid: 38.52%, Test: 38.46%
Epoch: 125, Loss: 1.3185, Train: 41.04%, Valid: 40.82%, Test: 40.96%
Epoch: 150, Loss: 1.2686, Train: 43.20%, Valid: 43.05%, Test: 43.12%
Epoch: 175, Loss: 1.2147, Train: 46.15%, Valid: 46.00%, Test: 46.01%
Epoch: 200, Loss: 1.2023, Train: 48.69%, Valid: 48.56%, Test: 48.57%
Epoch: 225, Loss: 1.1675, Train: 50.25%, Valid: 50.07%, Test: 50.06%
Epoch: 250, Loss: 1.1458, Train: 50.84%, Valid: 50.67%, Test: 50.65%
Epoch: 275, Loss: 1.1545, Train: 52.21%, Valid: 52.00%, Test: 51.98%
Epoch: 300, Loss: 1.1432, Train: 52.39%, Valid: 52.20%, Test: 52.19%
Epoch: 325, Loss: 1.1235, Train: 52.74%, Valid: 52.55%, Test: 52.51%
Epoch: 350, Loss: 1.1100, Train: 53.74%, Valid: 53.48%, Test: 53.45%
Epoch: 375, Loss: 1.1132, Train: 53.84%, Valid: 53.59%, Test: 53.50%
Epoch: 400, Loss: 1.1409, Train: 53.01%, Valid: 52.65%, Test: 52.66%
Epoch: 425, Loss: 1.0997, Train: 54.38%, Valid: 54.16%, Test: 54.05%
Epoch: 450, Loss: 1.1027, Train: 52.96%, Valid: 52.76%, Test: 52.63%
Epoch: 475, Loss: 1.0990, Train: 53.92%, Valid: 53.65%, Test: 53.51%
Run 01:
Highest Train: 54.80
Highest Valid: 54.51
  Final Train: 54.80
   Final Test: 54.42
All runs:
Highest Train: 54.80 ± nan
Highest Valid: 54.51 ± nan
  Final Train: 54.80 ± nan
   Final Test: 54.42 ± nan
Saving results to results/snap-patents.csv
20211116-20:24 ---> 20211116-22:10 Totl:6328 seconds
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 20.4964, Train: 86.60%, Valid: 86.45%, Test: 86.67%
Epoch: 25, Loss: 2.5395, Train: 85.28%, Valid: 85.29%, Test: 85.28%
Epoch: 50, Loss: 2.6448, Train: 85.31%, Valid: 85.32%, Test: 85.33%
Epoch: 75, Loss: 2.3262, Train: 85.42%, Valid: 85.46%, Test: 85.45%
Epoch: 100, Loss: 0.4410, Train: 84.87%, Valid: 84.90%, Test: 84.97%
Epoch: 125, Loss: 0.3757, Train: 85.15%, Valid: 85.16%, Test: 85.21%
Epoch: 150, Loss: 0.3540, Train: 85.57%, Valid: 85.57%, Test: 85.65%
Epoch: 175, Loss: 0.6875, Train: 87.00%, Valid: 86.82%, Test: 87.03%
Epoch: 200, Loss: 1.2923, Train: 87.45%, Valid: 87.33%, Test: 87.48%
Epoch: 225, Loss: 0.8949, Train: 87.25%, Valid: 87.28%, Test: 87.36%
Epoch: 250, Loss: 1.7151, Train: 86.39%, Valid: 86.42%, Test: 86.48%
Epoch: 275, Loss: 2033.5157, Train: 50.09%, Valid: 50.10%, Test: 50.09%
Epoch: 300, Loss: 69.7448, Train: 50.11%, Valid: 50.12%, Test: 50.10%
Epoch: 325, Loss: 1660.7754, Train: 15.94%, Valid: 15.94%, Test: 15.84%
Epoch: 350, Loss: 1570.0160, Train: 50.11%, Valid: 50.13%, Test: 50.11%
Epoch: 375, Loss: 4858.4419, Train: 16.01%, Valid: 16.00%, Test: 15.92%
Epoch: 400, Loss: 66544.8984, Train: 50.12%, Valid: 50.13%, Test: 50.12%
Epoch: 425, Loss: 1223.2512, Train: 84.20%, Valid: 84.20%, Test: 84.31%
Epoch: 450, Loss: 1333.5314, Train: 17.70%, Valid: 17.86%, Test: 17.64%
Epoch: 475, Loss: 4254.7998, Train: 84.16%, Valid: 84.18%, Test: 84.26%
Run 01:
Highest Train: 88.48
Highest Valid: 88.54
  Final Train: 88.48
   Final Test: 88.55
All runs:
Highest Train: 88.48 ± nan
Highest Valid: 88.54 ± nan
  Final Train: 88.48 ± nan
   Final Test: 88.55 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.6628, Train: 85.58%, Valid: 85.48%, Test: 85.71%
Epoch: 25, Loss: 4.6176, Train: 86.87%, Valid: 86.77%, Test: 86.86%
Epoch: 50, Loss: 467.0075, Train: 86.04%, Valid: 85.85%, Test: 85.98%
Epoch: 75, Loss: 66.3123, Train: 15.54%, Valid: 15.64%, Test: 15.41%
Epoch: 100, Loss: 4358942.0000, Train: 84.25%, Valid: 84.06%, Test: 84.36%
Epoch: 125, Loss: 624453.5625, Train: 86.45%, Valid: 86.53%, Test: 86.49%
Epoch: 150, Loss: 1965.6836, Train: 84.91%, Valid: 84.90%, Test: 85.12%
Epoch: 175, Loss: 8.9710, Train: 85.06%, Valid: 85.04%, Test: 85.27%
Epoch: 200, Loss: 756.1282, Train: 84.51%, Valid: 84.51%, Test: 84.72%
Epoch: 225, Loss: 18.6054, Train: 85.48%, Valid: 85.31%, Test: 85.47%
Epoch: 250, Loss: 9.9287, Train: 85.38%, Valid: 85.20%, Test: 85.39%
Epoch: 275, Loss: 8.6885, Train: 84.92%, Valid: 84.91%, Test: 85.14%
Epoch: 300, Loss: 184.0789, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 325, Loss: 30431.8086, Train: 85.68%, Valid: 85.50%, Test: 85.69%
Epoch: 350, Loss: 79.3434, Train: 85.50%, Valid: 85.32%, Test: 85.50%
Epoch: 375, Loss: 6.2320, Train: 85.54%, Valid: 85.36%, Test: 85.53%
Epoch: 400, Loss: 2136.9116, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 425, Loss: 7.7335, Train: 84.65%, Valid: 84.43%, Test: 84.78%
Epoch: 450, Loss: 6.8422, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 475, Loss: 27139.4668, Train: 84.66%, Valid: 84.66%, Test: 84.86%
Run 01:
Highest Train: 87.30
Highest Valid: 87.24
  Final Train: 87.30
   Final Test: 87.28
All runs:
Highest Train: 87.30 ± nan
Highest Valid: 87.24 ± nan
  Final Train: 87.30 ± nan
   Final Test: 87.28 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=0.1, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 28.7944, Train: 85.47%, Valid: 85.25%, Test: 85.47%
Epoch: 25, Loss: 2.3444, Train: 85.93%, Valid: 85.88%, Test: 86.04%
Epoch: 50, Loss: 10.9996, Train: 85.78%, Valid: 85.83%, Test: 85.89%
Epoch: 75, Loss: 22693880.0000, Train: 50.00%, Valid: 50.00%, Test: 50.00%
Epoch: 100, Loss: 2491.1313, Train: 86.02%, Valid: 86.17%, Test: 86.11%
Epoch: 125, Loss: 256.2574, Train: 15.20%, Valid: 15.42%, Test: 15.10%
Epoch: 150, Loss: 41745.2109, Train: 86.85%, Valid: 86.92%, Test: 86.96%
Epoch: 175, Loss: 128.5806, Train: 15.18%, Valid: 15.43%, Test: 15.09%
Epoch: 200, Loss: 225.1977, Train: 86.83%, Valid: 86.89%, Test: 86.93%
Epoch: 225, Loss: 314.5666, Train: 86.85%, Valid: 86.91%, Test: 86.96%
Epoch: 250, Loss: 226.1577, Train: 83.46%, Valid: 83.45%, Test: 83.60%
Epoch: 275, Loss: 3802.0059, Train: 83.42%, Valid: 83.46%, Test: 83.57%
Epoch: 300, Loss: 320.9763, Train: 84.32%, Valid: 84.53%, Test: 84.44%
Epoch: 325, Loss: 205.3218, Train: 86.85%, Valid: 86.92%, Test: 86.96%
Epoch: 350, Loss: 15387.1904, Train: 85.66%, Valid: 85.82%, Test: 85.74%
Epoch: 375, Loss: 359.1505, Train: 86.86%, Valid: 86.93%, Test: 86.97%
Epoch: 400, Loss: 201.7781, Train: 86.90%, Valid: 86.97%, Test: 87.00%
Epoch: 425, Loss: 229.4075, Train: 86.89%, Valid: 86.97%, Test: 86.99%
Epoch: 450, Loss: 674.7407, Train: 86.85%, Valid: 86.91%, Test: 86.95%
Epoch: 475, Loss: 45.5438, Train: 83.42%, Valid: 83.47%, Test: 83.57%
Run 01:
Highest Train: 87.13
Highest Valid: 87.19
  Final Train: 87.13
   Final Test: 87.19
All runs:
Highest Train: 87.13 ± nan
Highest Valid: 87.19 ± nan
  Final Train: 87.13 ± nan
   Final Test: 87.19 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.4190, Train: 15.48%, Valid: 15.56%, Test: 15.51%
Epoch: 25, Loss: 3.9970, Train: 85.59%, Valid: 85.62%, Test: 85.67%
Epoch: 50, Loss: 8.8436, Train: 84.06%, Valid: 83.86%, Test: 84.19%
Epoch: 75, Loss: 7.1969, Train: 84.28%, Valid: 84.08%, Test: 84.39%
Epoch: 100, Loss: 7.2778, Train: 84.27%, Valid: 84.06%, Test: 84.35%
Epoch: 125, Loss: 7.2246, Train: 84.32%, Valid: 84.14%, Test: 84.43%
Epoch: 150, Loss: 7.2782, Train: 84.25%, Valid: 84.05%, Test: 84.35%
Epoch: 175, Loss: 7.2825, Train: 84.23%, Valid: 84.02%, Test: 84.34%
Epoch: 200, Loss: 7.2825, Train: 84.29%, Valid: 84.08%, Test: 84.40%
Epoch: 225, Loss: 7.2447, Train: 84.28%, Valid: 84.06%, Test: 84.37%
Epoch: 250, Loss: 7.3372, Train: 84.23%, Valid: 84.04%, Test: 84.33%
Epoch: 275, Loss: 7.3153, Train: 84.33%, Valid: 84.11%, Test: 84.42%
Epoch: 300, Loss: 7.2243, Train: 84.27%, Valid: 84.06%, Test: 84.37%
Epoch: 325, Loss: 7.4911, Train: 84.37%, Valid: 84.17%, Test: 84.49%
Epoch: 350, Loss: 7.2352, Train: 84.30%, Valid: 84.10%, Test: 84.37%
Epoch: 375, Loss: 7.3125, Train: 84.36%, Valid: 84.14%, Test: 84.47%
Epoch: 400, Loss: 7.4285, Train: 84.27%, Valid: 84.06%, Test: 84.37%
Epoch: 425, Loss: 7.3203, Train: 84.37%, Valid: 84.18%, Test: 84.48%
Epoch: 450, Loss: 7.3769, Train: 84.29%, Valid: 84.07%, Test: 84.39%
Epoch: 475, Loss: 7.3842, Train: 84.31%, Valid: 84.09%, Test: 84.41%
Run 01:
Highest Train: 86.52
Highest Valid: 86.54
  Final Train: 86.52
   Final Test: 86.54
All runs:
Highest Train: 86.52 ± nan
Highest Valid: 86.54 ± nan
  Final Train: 86.52 ± nan
   Final Test: 86.54 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 42.5798, Train: 85.48%, Valid: 85.28%, Test: 85.52%
Epoch: 25, Loss: 2.9664, Train: 85.87%, Valid: 85.73%, Test: 85.95%
Epoch: 50, Loss: 3.7394, Train: 85.80%, Valid: 85.74%, Test: 85.89%
Epoch: 75, Loss: 3.8731, Train: 86.28%, Valid: 86.20%, Test: 86.35%
Epoch: 100, Loss: 3.8551, Train: 86.51%, Valid: 86.44%, Test: 86.61%
Epoch: 125, Loss: 3.7713, Train: 86.56%, Valid: 86.48%, Test: 86.65%
Epoch: 150, Loss: 3.7431, Train: 86.63%, Valid: 86.55%, Test: 86.71%
Epoch: 175, Loss: 3.7585, Train: 86.65%, Valid: 86.57%, Test: 86.72%
Epoch: 200, Loss: 3.7778, Train: 86.69%, Valid: 86.62%, Test: 86.78%
Epoch: 225, Loss: 3.7947, Train: 86.72%, Valid: 86.65%, Test: 86.81%
Epoch: 250, Loss: 3.7643, Train: 86.70%, Valid: 86.63%, Test: 86.78%
Epoch: 275, Loss: 3.7715, Train: 86.71%, Valid: 86.65%, Test: 86.80%
Epoch: 300, Loss: 3.7704, Train: 86.73%, Valid: 86.67%, Test: 86.82%
Epoch: 325, Loss: 3.7562, Train: 86.75%, Valid: 86.68%, Test: 86.84%
Epoch: 350, Loss: 3.8046, Train: 86.73%, Valid: 86.67%, Test: 86.82%
Epoch: 375, Loss: 3.7935, Train: 86.75%, Valid: 86.69%, Test: 86.83%
Epoch: 400, Loss: 3.7574, Train: 86.70%, Valid: 86.64%, Test: 86.78%
Epoch: 425, Loss: 3.7657, Train: 86.69%, Valid: 86.63%, Test: 86.77%
Epoch: 450, Loss: 3.7442, Train: 86.69%, Valid: 86.63%, Test: 86.77%
Epoch: 475, Loss: 3.7792, Train: 86.68%, Valid: 86.63%, Test: 86.76%
Run 01:
Highest Train: 86.87
Highest Valid: 86.81
  Final Train: 86.87
   Final Test: 86.91
All runs:
Highest Train: 86.87 ± nan
Highest Valid: 86.81 ± nan
  Final Train: 86.87 ± nan
   Final Test: 86.91 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 16.1858, Train: 86.71%, Valid: 86.73%, Test: 86.77%
Epoch: 25, Loss: 4.2845, Train: 85.52%, Valid: 85.28%, Test: 85.53%
Epoch: 50, Loss: 3.7594, Train: 86.31%, Valid: 86.31%, Test: 86.44%
Epoch: 75, Loss: 5.1983, Train: 86.37%, Valid: 86.23%, Test: 86.37%
Epoch: 100, Loss: 5.0713, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 125, Loss: 4.9755, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 150, Loss: 4.7221, Train: 86.38%, Valid: 86.25%, Test: 86.38%
Epoch: 175, Loss: 5.0289, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 200, Loss: 4.5854, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 225, Loss: 4.8256, Train: 86.38%, Valid: 86.25%, Test: 86.38%
Epoch: 250, Loss: 5.0367, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 275, Loss: 4.9112, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 300, Loss: 4.9178, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 325, Loss: 5.2608, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 350, Loss: 4.7699, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 375, Loss: 4.9512, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 400, Loss: 5.0016, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 425, Loss: 5.0210, Train: 86.38%, Valid: 86.25%, Test: 86.37%
Epoch: 450, Loss: 5.1406, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Epoch: 475, Loss: 4.8832, Train: 86.37%, Valid: 86.24%, Test: 86.37%
Run 01:
Highest Train: 87.13
Highest Valid: 87.11
  Final Train: 87.02
   Final Test: 87.12
All runs:
Highest Train: 87.13 ± nan
Highest Valid: 87.11 ± nan
  Final Train: 87.02 ± nan
   Final Test: 87.12 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 0.4208, Train: 14.04%, Valid: 14.01%, Test: 13.98%
Epoch: 25, Loss: 3.3907, Train: 85.51%, Valid: 85.36%, Test: 85.60%
Epoch: 50, Loss: 3.4295, Train: 86.19%, Valid: 86.08%, Test: 86.27%
Epoch: 75, Loss: 3.4402, Train: 86.13%, Valid: 86.20%, Test: 86.20%
Epoch: 100, Loss: 1.8774, Train: 85.22%, Valid: 85.28%, Test: 85.27%
Epoch: 125, Loss: 0.4919, Train: 84.36%, Valid: 84.40%, Test: 84.49%
Epoch: 150, Loss: 0.3818, Train: 85.07%, Valid: 85.03%, Test: 85.20%
Epoch: 175, Loss: 0.3594, Train: 85.85%, Valid: 85.84%, Test: 85.91%
Epoch: 200, Loss: 0.3441, Train: 86.77%, Valid: 86.85%, Test: 86.94%
Epoch: 225, Loss: 0.5380, Train: 86.90%, Valid: 86.94%, Test: 86.91%
Epoch: 250, Loss: 0.6043, Train: 86.83%, Valid: 86.85%, Test: 86.86%
Epoch: 275, Loss: 0.3581, Train: 86.63%, Valid: 86.62%, Test: 86.65%
Epoch: 300, Loss: 0.3466, Train: 85.45%, Valid: 85.46%, Test: 85.55%
Epoch: 325, Loss: 0.3356, Train: 85.69%, Valid: 85.68%, Test: 85.79%
Epoch: 350, Loss: 1.5599, Train: 85.69%, Valid: 85.71%, Test: 85.73%
Epoch: 375, Loss: 2.8356, Train: 85.73%, Valid: 85.75%, Test: 85.82%
Epoch: 400, Loss: 2.4916, Train: 85.79%, Valid: 85.79%, Test: 85.89%
Epoch: 425, Loss: 3.0307, Train: 86.11%, Valid: 86.07%, Test: 86.18%
Epoch: 450, Loss: 1.9536, Train: 87.12%, Valid: 87.09%, Test: 87.13%
Epoch: 475, Loss: 3.3915, Train: 87.02%, Valid: 87.05%, Test: 87.07%
Run 01:
Highest Train: 88.15
Highest Valid: 88.21
  Final Train: 88.15
   Final Test: 88.24
All runs:
Highest Train: 88.15 ± nan
Highest Valid: 88.21 ± nan
  Final Train: 88.15 ± nan
   Final Test: 88.24 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 11.8606, Train: 86.68%, Valid: 86.54%, Test: 86.58%
Epoch: 25, Loss: 188.2137, Train: 86.80%, Valid: 86.68%, Test: 86.86%
Epoch: 50, Loss: 209.5581, Train: 86.45%, Valid: 86.40%, Test: 86.51%
Epoch: 75, Loss: 210.8011, Train: 86.44%, Valid: 86.39%, Test: 86.49%
Epoch: 100, Loss: 209.3440, Train: 86.44%, Valid: 86.39%, Test: 86.50%
Epoch: 125, Loss: 211.7231, Train: 86.44%, Valid: 86.39%, Test: 86.50%
Epoch: 150, Loss: 209.9168, Train: 86.44%, Valid: 86.40%, Test: 86.50%
Epoch: 175, Loss: 211.5069, Train: 86.36%, Valid: 86.31%, Test: 86.42%
Epoch: 200, Loss: 210.4691, Train: 86.44%, Valid: 86.40%, Test: 86.49%
Epoch: 225, Loss: 210.3838, Train: 86.44%, Valid: 86.40%, Test: 86.49%
Epoch: 250, Loss: 210.2378, Train: 86.45%, Valid: 86.40%, Test: 86.50%
Epoch: 275, Loss: 210.4082, Train: 86.45%, Valid: 86.40%, Test: 86.50%
Epoch: 300, Loss: 210.7035, Train: 86.45%, Valid: 86.40%, Test: 86.50%
Epoch: 325, Loss: 209.5605, Train: 86.46%, Valid: 86.41%, Test: 86.50%
Epoch: 350, Loss: 210.7721, Train: 86.48%, Valid: 86.42%, Test: 86.52%
Epoch: 375, Loss: 210.7681, Train: 86.48%, Valid: 86.41%, Test: 86.51%
Epoch: 400, Loss: 210.3066, Train: 86.77%, Valid: 86.68%, Test: 86.81%
Epoch: 425, Loss: 209.4951, Train: 86.77%, Valid: 86.68%, Test: 86.81%
Epoch: 450, Loss: 210.0278, Train: 86.77%, Valid: 86.68%, Test: 86.81%
Epoch: 475, Loss: 210.9033, Train: 86.77%, Valid: 86.68%, Test: 86.81%
Run 01:
Highest Train: 87.29
Highest Valid: 87.31
  Final Train: 87.29
   Final Test: 87.29
All runs:
Highest Train: 87.29 ± nan
Highest Valid: 87.31 ± nan
  Final Train: 87.29 ± nan
   Final Test: 87.29 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=10.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 50.8038, Train: 85.32%, Valid: 85.11%, Test: 85.37%
Epoch: 25, Loss: 2.4453, Train: 86.92%, Valid: 86.95%, Test: 87.02%
Epoch: 50, Loss: 1.2521, Train: 87.04%, Valid: 87.08%, Test: 87.10%
Epoch: 75, Loss: 0.4436, Train: 85.82%, Valid: 85.75%, Test: 85.99%
Epoch: 100, Loss: 0.3613, Train: 85.65%, Valid: 85.46%, Test: 85.70%
Epoch: 125, Loss: 0.3426, Train: 85.49%, Valid: 85.31%, Test: 85.56%
Epoch: 150, Loss: 0.3456, Train: 85.77%, Valid: 85.57%, Test: 85.82%
Epoch: 175, Loss: 0.3389, Train: 85.45%, Valid: 85.23%, Test: 85.51%
Epoch: 200, Loss: 0.3577, Train: 86.36%, Valid: 86.24%, Test: 86.43%
Epoch: 225, Loss: 0.3433, Train: 85.80%, Valid: 85.63%, Test: 85.87%
Epoch: 250, Loss: 0.3347, Train: 85.73%, Valid: 85.54%, Test: 85.79%
Epoch: 275, Loss: 0.5872, Train: 86.23%, Valid: 86.20%, Test: 86.35%
Epoch: 300, Loss: 0.8092, Train: 86.37%, Valid: 86.19%, Test: 86.44%
Epoch: 325, Loss: 0.3943, Train: 86.17%, Valid: 86.00%, Test: 86.25%
Epoch: 350, Loss: 0.3488, Train: 85.97%, Valid: 85.78%, Test: 86.03%
Epoch: 375, Loss: 0.3424, Train: 85.89%, Valid: 85.69%, Test: 85.95%
Epoch: 400, Loss: 0.3359, Train: 85.91%, Valid: 85.68%, Test: 85.97%
Epoch: 425, Loss: 0.6664, Train: 85.61%, Valid: 85.42%, Test: 85.67%
Epoch: 450, Loss: 0.3561, Train: 86.04%, Valid: 85.85%, Test: 86.09%
Epoch: 475, Loss: 0.3416, Train: 85.99%, Valid: 85.79%, Test: 86.05%
Run 01:
Highest Train: 87.04
Highest Valid: 87.08
  Final Train: 87.04
   Final Test: 87.10
All runs:
Highest Train: 87.04 ± nan
Highest Valid: 87.08 ± nan
  Final Train: 87.04 ± nan
   Final Test: 87.10 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 19.6217, Train: 85.58%, Valid: 85.41%, Test: 85.61%
Epoch: 25, Loss: 2.9853, Train: 84.66%, Valid: 84.46%, Test: 84.75%
Epoch: 50, Loss: 3.2587, Train: 85.90%, Valid: 85.96%, Test: 85.94%
Epoch: 75, Loss: 1.0399, Train: 84.37%, Valid: 84.48%, Test: 84.43%
Epoch: 100, Loss: 0.4035, Train: 84.86%, Valid: 84.92%, Test: 85.02%
Epoch: 125, Loss: 0.3531, Train: 85.49%, Valid: 85.46%, Test: 85.61%
Epoch: 150, Loss: 0.7692, Train: 88.37%, Valid: 88.44%, Test: 88.42%
Epoch: 175, Loss: 3.4327, Train: 86.26%, Valid: 86.30%, Test: 86.29%
Epoch: 200, Loss: 3.0049, Train: 86.38%, Valid: 86.44%, Test: 86.44%
Epoch: 225, Loss: 0.6934, Train: 85.38%, Valid: 85.41%, Test: 85.48%
Epoch: 250, Loss: 0.5393, Train: 85.61%, Valid: 85.66%, Test: 85.71%
Epoch: 275, Loss: 0.3859, Train: 85.70%, Valid: 85.74%, Test: 85.82%
Epoch: 300, Loss: 0.4618, Train: 87.35%, Valid: 87.17%, Test: 87.34%
Epoch: 325, Loss: 1.3795, Train: 85.91%, Valid: 85.77%, Test: 85.92%
Epoch: 350, Loss: 0.4209, Train: 86.08%, Valid: 85.92%, Test: 86.07%
Epoch: 375, Loss: 0.3652, Train: 86.79%, Valid: 86.84%, Test: 86.91%
Epoch: 400, Loss: 0.3405, Train: 86.75%, Valid: 86.76%, Test: 86.84%
Epoch: 425, Loss: 0.3316, Train: 85.89%, Valid: 85.93%, Test: 85.95%
Epoch: 450, Loss: 2.2418, Train: 84.85%, Valid: 84.63%, Test: 84.87%
Epoch: 475, Loss: 1.7461, Train: 85.84%, Valid: 85.67%, Test: 85.85%
Run 01:
Highest Train: 88.46
Highest Valid: 88.51
  Final Train: 88.45
   Final Test: 88.52
All runs:
Highest Train: 88.46 ± nan
Highest Valid: 88.51 ± nan
  Final Train: 88.45 ± nan
   Final Test: 88.52 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 9.3343, Train: 84.79%, Valid: 84.69%, Test: 84.95%
Epoch: 25, Loss: 1.3607, Train: 85.76%, Valid: 85.67%, Test: 85.83%
Epoch: 50, Loss: 1.3060, Train: 85.87%, Valid: 85.79%, Test: 85.95%
Epoch: 75, Loss: 3.6129, Train: 85.83%, Valid: 85.81%, Test: 85.93%
Epoch: 100, Loss: 1.2034, Train: 85.16%, Valid: 85.17%, Test: 85.21%
Epoch: 125, Loss: 2.8050, Train: 86.17%, Valid: 86.17%, Test: 86.25%
Epoch: 150, Loss: 2.1161, Train: 86.43%, Valid: 86.40%, Test: 86.46%
Epoch: 175, Loss: 4.7591, Train: 86.07%, Valid: 86.03%, Test: 86.07%
Epoch: 200, Loss: 1.0238, Train: 83.61%, Valid: 83.55%, Test: 83.73%
Epoch: 225, Loss: 1.2420, Train: 84.73%, Valid: 84.78%, Test: 84.79%
Epoch: 250, Loss: 4.1605, Train: 85.81%, Valid: 85.78%, Test: 85.83%
Epoch: 275, Loss: 2.8574, Train: 85.58%, Valid: 85.62%, Test: 85.61%
Epoch: 300, Loss: 0.6418, Train: 85.10%, Valid: 84.90%, Test: 85.21%
Epoch: 325, Loss: 0.3870, Train: 85.46%, Valid: 85.46%, Test: 85.60%
Epoch: 350, Loss: 0.3654, Train: 85.31%, Valid: 85.20%, Test: 85.40%
Epoch: 375, Loss: 7.0535, Train: 86.71%, Valid: 86.72%, Test: 86.77%
Epoch: 400, Loss: 14.2051, Train: 84.19%, Valid: 84.19%, Test: 84.31%
Epoch: 425, Loss: 153.7652, Train: 84.74%, Valid: 84.56%, Test: 84.88%
Epoch: 450, Loss: 657828.5625, Train: 84.25%, Valid: 84.05%, Test: 84.39%
Epoch: 475, Loss: 11.0610, Train: 84.39%, Valid: 84.19%, Test: 84.53%
Run 01:
Highest Train: 87.08
Highest Valid: 87.05
  Final Train: 87.04
   Final Test: 87.03
All runs:
Highest Train: 87.08 ± nan
Highest Valid: 87.05 ± nan
  Final Train: 87.04 ± nan
   Final Test: 87.03 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=100.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 52.5548, Train: 86.51%, Valid: 86.49%, Test: 86.57%
Epoch: 25, Loss: 2.9909, Train: 85.61%, Valid: 85.46%, Test: 85.68%
Epoch: 50, Loss: 0.6867, Train: 84.77%, Valid: 84.70%, Test: 84.81%
Epoch: 75, Loss: 0.7685, Train: 84.90%, Valid: 84.77%, Test: 84.92%
Epoch: 100, Loss: 0.5889, Train: 85.56%, Valid: 85.46%, Test: 85.56%
Epoch: 125, Loss: 0.3777, Train: 85.50%, Valid: 85.32%, Test: 85.56%
Epoch: 150, Loss: 0.3566, Train: 85.60%, Valid: 85.45%, Test: 85.64%
Epoch: 175, Loss: 0.3442, Train: 85.49%, Valid: 85.32%, Test: 85.61%
Epoch: 200, Loss: 0.3401, Train: 86.95%, Valid: 86.94%, Test: 86.92%
Epoch: 225, Loss: 30.9556, Train: 86.70%, Valid: 86.77%, Test: 86.79%
Epoch: 250, Loss: 2.5426, Train: 86.62%, Valid: 86.55%, Test: 86.66%
Epoch: 275, Loss: 7.3953, Train: 86.22%, Valid: 86.13%, Test: 86.26%
Epoch: 300, Loss: 4.3745, Train: 85.77%, Valid: 85.61%, Test: 85.82%
Epoch: 325, Loss: 1.3636, Train: 85.57%, Valid: 85.42%, Test: 85.60%
Epoch: 350, Loss: 0.8965, Train: 86.15%, Valid: 86.06%, Test: 86.19%
Epoch: 375, Loss: 0.6233, Train: 86.82%, Valid: 86.72%, Test: 86.84%
Epoch: 400, Loss: 0.5184, Train: 86.97%, Valid: 86.91%, Test: 87.07%
Epoch: 425, Loss: 0.4368, Train: 87.05%, Valid: 86.93%, Test: 87.15%
Epoch: 450, Loss: 0.5096, Train: 85.56%, Valid: 85.44%, Test: 85.64%
Epoch: 475, Loss: 0.4280, Train: 86.90%, Valid: 86.78%, Test: 86.93%
Run 01:
Highest Train: 87.90
Highest Valid: 87.83
  Final Train: 87.90
   Final Test: 87.90
All runs:
Highest Train: 87.90 ± nan
Highest Valid: 87.83 ± nan
  Final Train: 87.90 ± nan
   Final Test: 87.90 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=1, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 21.4340, Train: 85.19%, Valid: 85.12%, Test: 85.28%
Epoch: 25, Loss: 3.2712, Train: 87.08%, Valid: 86.97%, Test: 87.06%
Epoch: 50, Loss: 4.2459, Train: 86.17%, Valid: 86.04%, Test: 86.22%
Epoch: 75, Loss: 4.2651, Train: 85.77%, Valid: 85.59%, Test: 85.78%
Epoch: 100, Loss: 3.9455, Train: 85.80%, Valid: 85.63%, Test: 85.83%
Epoch: 125, Loss: 1.4875, Train: 84.73%, Valid: 84.62%, Test: 84.71%
Epoch: 150, Loss: 0.4124, Train: 85.33%, Valid: 85.40%, Test: 85.46%
Epoch: 175, Loss: 0.3699, Train: 85.35%, Valid: 85.28%, Test: 85.48%
Epoch: 200, Loss: 0.5832, Train: 86.26%, Valid: 86.17%, Test: 86.38%
Epoch: 225, Loss: 0.3707, Train: 87.34%, Valid: 87.39%, Test: 87.47%
Epoch: 250, Loss: 0.3373, Train: 85.77%, Valid: 85.76%, Test: 85.87%
Epoch: 275, Loss: 0.5370, Train: 85.66%, Valid: 85.68%, Test: 85.75%
Epoch: 300, Loss: 1.6201, Train: 86.88%, Valid: 86.68%, Test: 86.90%
Epoch: 325, Loss: 0.4736, Train: 86.85%, Valid: 86.69%, Test: 86.86%
Epoch: 350, Loss: 0.3931, Train: 86.05%, Valid: 85.92%, Test: 86.16%
Epoch: 375, Loss: 0.3494, Train: 85.60%, Valid: 85.59%, Test: 85.69%
Epoch: 400, Loss: 0.3350, Train: 85.39%, Valid: 85.42%, Test: 85.53%
Epoch: 425, Loss: 0.6740, Train: 87.11%, Valid: 87.19%, Test: 87.15%
Epoch: 450, Loss: 0.6854, Train: 86.45%, Valid: 86.33%, Test: 86.52%
Epoch: 475, Loss: 0.3583, Train: 85.86%, Valid: 85.84%, Test: 86.00%
Run 01:
Highest Train: 88.31
Highest Valid: 88.36
  Final Train: 88.31
   Final Test: 88.39
All runs:
Highest Train: 88.31 ± nan
Highest Valid: 88.36 ± nan
  Final Train: 88.31 ± nan
   Final Test: 88.39 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=2, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 10.6288, Train: 85.75%, Valid: 85.66%, Test: 85.79%
Epoch: 25, Loss: 3.4107, Train: 87.41%, Valid: 87.37%, Test: 87.42%
Epoch: 50, Loss: 2.6190, Train: 86.79%, Valid: 86.81%, Test: 86.86%
Epoch: 75, Loss: 0.5096, Train: 85.13%, Valid: 85.01%, Test: 85.23%
Epoch: 100, Loss: 0.3761, Train: 85.61%, Valid: 85.42%, Test: 85.71%
Epoch: 125, Loss: 0.3607, Train: 86.17%, Valid: 86.03%, Test: 86.25%
Epoch: 150, Loss: 0.3439, Train: 85.85%, Valid: 85.67%, Test: 85.95%
Epoch: 175, Loss: 1.1161, Train: 85.94%, Valid: 85.81%, Test: 86.06%
Epoch: 200, Loss: 3.4535, Train: 87.09%, Valid: 87.08%, Test: 87.12%
Epoch: 225, Loss: 1.2442, Train: 85.99%, Valid: 85.98%, Test: 86.04%
Epoch: 250, Loss: 0.4562, Train: 86.32%, Valid: 86.20%, Test: 86.41%
Epoch: 275, Loss: 0.3764, Train: 86.80%, Valid: 86.70%, Test: 86.92%
Epoch: 300, Loss: 0.3521, Train: 87.05%, Valid: 86.92%, Test: 87.17%
Epoch: 325, Loss: 0.9675, Train: 86.51%, Valid: 86.41%, Test: 86.57%
Epoch: 350, Loss: 0.7017, Train: 86.24%, Valid: 86.16%, Test: 86.28%
Epoch: 375, Loss: 0.7540, Train: 86.35%, Valid: 86.31%, Test: 86.40%
Epoch: 400, Loss: 0.3810, Train: 85.84%, Valid: 85.71%, Test: 86.01%
Epoch: 425, Loss: 0.3467, Train: 87.69%, Valid: 87.60%, Test: 87.85%
Epoch: 450, Loss: 0.3369, Train: 87.07%, Valid: 86.97%, Test: 87.16%
Epoch: 475, Loss: 0.3317, Train: 86.40%, Valid: 86.27%, Test: 86.50%
Run 01:
Highest Train: 88.02
Highest Valid: 87.89
  Final Train: 88.02
   Final Test: 88.09
All runs:
Highest Train: 88.02 ± nan
Highest Valid: 87.89 ± nan
  Final Train: 88.02 ± nan
   Final Test: 88.09 ± nan
Saving results to results/genius.csv
Namespace(SGD=False, adam=False, alpha=1.0, beta=1000.0, cached=False, cpu=False, dataset='genius', directed=False, display_step=25, dropout=0.0, epochs=500, gamma=0.9, gat_heads=8, gcn2_alpha=0.1, gpr_alpha=0.1, hidden_channels=256, hops=1, inner_activation=False, inner_dropout=False, jk_type='max', link_init_layers_A=1, link_init_layers_X=1, lp_alpha=0.1, lr=0.01, method='mlpnorm', no_bn=False, norm_func_id=2, norm_layers=2, num_layers=2, num_mlp_layers=1, orders=3, orders_func_id=2, print_prop=False, rand_split=False, rocauc=False, runs=1, sampling=False, sub_dataset='', theta=0.5, train_prop=0.5, valid_prop=0.25, weight_decay=0.0)
num nodes 421961 | num classes 2 | num node feats 12
MODEL: MLPNORM(
  (fc1): Linear(in_features=12, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=2, bias=True)
)
Epoch: 00, Loss: 23.8120, Train: 85.03%, Valid: 84.91%, Test: 85.12%
Epoch: 25, Loss: 2.5077, Train: 86.02%, Valid: 85.88%, Test: 86.08%
Epoch: 50, Loss: 7.7215, Train: 85.87%, Valid: 85.76%, Test: 85.94%
Epoch: 75, Loss: 3.0196, Train: 86.23%, Valid: 86.22%, Test: 86.29%
Epoch: 100, Loss: 1.2231, Train: 86.49%, Valid: 86.50%, Test: 86.54%
Epoch: 125, Loss: 1.5954, Train: 85.38%, Valid: 85.33%, Test: 85.47%
Epoch: 150, Loss: 2.8742, Train: 86.22%, Valid: 86.22%, Test: 86.37%
Epoch: 175, Loss: 1.3131, Train: 86.27%, Valid: 86.33%, Test: 86.31%
Epoch: 200, Loss: 0.4086, Train: 85.12%, Valid: 85.16%, Test: 85.21%
Epoch: 225, Loss: 0.3886, Train: 85.65%, Valid: 85.52%, Test: 85.76%
Epoch: 250, Loss: 0.3624, Train: 85.16%, Valid: 85.14%, Test: 85.41%
Epoch: 275, Loss: 0.3570, Train: 86.90%, Valid: 86.83%, Test: 87.01%
Epoch: 300, Loss: 3.7143, Train: 86.02%, Valid: 85.99%, Test: 86.05%
Epoch: 325, Loss: 2.7445, Train: 86.31%, Valid: 86.37%, Test: 86.38%
Epoch: 350, Loss: 0.5404, Train: 86.43%, Valid: 86.39%, Test: 86.56%
Epoch: 375, Loss: 1.6749, Train: 86.35%, Valid: 86.36%, Test: 86.38%
Epoch: 400, Loss: 0.7896, Train: 86.03%, Valid: 86.02%, Test: 86.05%
Epoch: 425, Loss: 0.4003, Train: 86.61%, Valid: 86.44%, Test: 86.71%
Epoch: 450, Loss: 0.3528, Train: 85.78%, Valid: 85.61%, Test: 85.86%
Epoch: 475, Loss: 0.3401, Train: 85.87%, Valid: 85.77%, Test: 85.99%
Run 01:
Highest Train: 87.79
Highest Valid: 87.72
  Final Train: 87.79
   Final Test: 87.77
All runs:
Highest Train: 87.79 ± nan
Highest Valid: 87.72 ± nan
  Final Train: 87.79 ± nan
   Final Test: 87.77 ± nan
Saving results to results/genius.csv
20211116-22:10 ---> 20211116-22:32 Totl:1332 seconds