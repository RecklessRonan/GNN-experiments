{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'chameleon'\n",
    "\n",
    "graph_adjacency_list_file_path = os.path.join('new_data', dataset_name, 'out1_graph_edges.txt')\n",
    "graph_node_features_and_labels_file_path = os.path.join('new_data', dataset_name,\n",
    "                                                                f'out1_node_feature_label.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict object;\n",
    "\n",
    "graph_dict = defaultdict(list)\n",
    "with open(graph_adjacency_list_file_path) as graph_adjacency_list_file:\n",
    "    graph_adjacency_list_file.readline()\n",
    "    for line in graph_adjacency_list_file:\n",
    "        line = line.rstrip().split('\\t')\n",
    "        assert (len(line) == 2)\n",
    "        graph_dict[int(line[0])].append(int(line[1]))\n",
    "        graph_dict[int(line[1])].append(int(line[0]))\n",
    "\n",
    "# print(sorted(graph_dict))\n",
    "graph_dict_ordered = defaultdict(list)\n",
    "for key in sorted(graph_dict):\n",
    "    graph_dict_ordered[key] = graph_dict[key]\n",
    "    graph_dict_ordered[key].sort()\n",
    "\n",
    "adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph_dict_ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = sparse.csr_matrix(adj)\n",
    "type(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2277, 2277)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
    "# ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
    "# ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n",
    "#     (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
    "# ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
    "# ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
    "# ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
    "\n",
    "\n",
    "graph_node_features_dict = {}\n",
    "graph_labels_dict = {}\n",
    "\n",
    "if dataset_name == 'film':\n",
    "    with open(graph_node_features_and_labels_file_path) as graph_node_features_and_labels_file:\n",
    "        graph_node_features_and_labels_file.readline()\n",
    "        for line in graph_node_features_and_labels_file:\n",
    "            line = line.rstrip().split('\\t')\n",
    "            assert (len(line) == 3)\n",
    "            assert (int(line[0]) not in graph_node_features_dict and int(line[0]) not in graph_labels_dict)\n",
    "            feature_blank = np.zeros(932, dtype=np.uint8)\n",
    "            feature_blank[np.array(line[1].split(','), dtype=np.uint16)] = 1\n",
    "            graph_node_features_dict[int(line[0])] = feature_blank\n",
    "            graph_labels_dict[int(line[0])] = int(line[2])\n",
    "else:\n",
    "    with open(graph_node_features_and_labels_file_path) as graph_node_features_and_labels_file:\n",
    "        graph_node_features_and_labels_file.readline()\n",
    "        for line in graph_node_features_and_labels_file:\n",
    "            line = line.rstrip().split('\\t')\n",
    "            assert (len(line) == 3)\n",
    "            assert (int(line[0]) not in graph_node_features_dict and int(line[0]) not in graph_labels_dict)\n",
    "            graph_node_features_dict[int(line[0])] = np.array(line[1].split(','), dtype=np.uint8)\n",
    "            graph_labels_dict[int(line[0])] = int(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for key in sorted(graph_node_features_dict):\n",
    "    features_list.append(graph_node_features_dict[key])\n",
    "features = np.vstack(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2277, 2325)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_file_path = 'splits/chameleon_split_0.6_0.2_0.npz'\n",
    "\n",
    "with np.load(splits_file_path) as splits_file:\n",
    "    train_mask = splits_file['train_mask']\n",
    "    val_mask = splits_file['val_mask']\n",
    "    test_mask = splits_file['test_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False, False])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_mask, dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label classes 5\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for key in graph_labels_dict.keys():\n",
    "    labels.append(graph_labels_dict[key])\n",
    "\n",
    "label_classes = max(labels) + 1\n",
    "print('label classes', label_classes)\n",
    "zeros_array = np.zeros(label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_list, valid_features_list, test_features_list = [], [], []\n",
    "train_labels_list, valid_labels_list, test_labels_list = [], [], []\n",
    "\n",
    "for i in range(train_mask.shape[0]):\n",
    "    if train_mask[i] == 1:\n",
    "        train_features_list.append(graph_node_features_dict[i])\n",
    "        train_labels_list.append(graph_labels_dict[i])\n",
    "\n",
    "for i in range(val_mask.shape[0]):\n",
    "    if val_mask[i] == 1:\n",
    "        valid_features_list.append(graph_node_features_dict[i])\n",
    "        valid_labels_list.append(graph_labels_dict[i])\n",
    "\n",
    "for i in range(test_mask.shape[0]):\n",
    "    if test_mask[i] == 1:\n",
    "        test_features_list.append(graph_node_features_dict[i])\n",
    "        test_labels_list.append(graph_labels_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels shape (1092, 5) valid labels shape (729, 5) test labels shape (456, 5)\n"
     ]
    }
   ],
   "source": [
    "train_labels = np.eye(label_classes)[train_labels_list]\n",
    "valid_labels = np.eye(label_classes)[valid_labels_list]\n",
    "test_labels = np.eye(label_classes)[test_labels_list]\n",
    "\n",
    "print('train labels shape', train_labels.shape, 'valid labels shape', valid_labels.shape, 'test labels shape', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features shape (1092, 2325) valid features shape (729, 2325) test features shape (456, 2325)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.vstack(train_features_list)\n",
    "valid_features = np.vstack(valid_features_list)\n",
    "test_features = np.vstack(test_features_list)\n",
    "\n",
    "print('train features shape', train_features.shape, 'valid features shape', valid_features.shape, 'test features shape', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30645ce1cf6e309bc342305d9828a61e54ac4ec65cf577c5bc805d61208f222b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('gcn-py3.7': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
