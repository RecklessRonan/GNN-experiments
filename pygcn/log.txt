nohup: ignoring input
Epoch: 0001 loss_train: 1.6097 acc_train: 0.2060 loss_val: 1.5650 acc_val: 0.3196 time: 0.1071s
Epoch: 0002 loss_train: 1.4835 acc_train: 0.4103 loss_val: 1.4670 acc_val: 0.4033 time: 0.0902s
Epoch: 0003 loss_train: 1.1118 acc_train: 0.7921 loss_val: 1.4491 acc_val: 0.4870 time: 0.0432s
Epoch: 0004 loss_train: 0.7537 acc_train: 0.8773 loss_val: 1.5674 acc_val: 0.4856 time: 0.0476s
Epoch: 0005 loss_train: 0.5013 acc_train: 0.9002 loss_val: 1.8066 acc_val: 0.4897 time: 0.0499s
Epoch: 0006 loss_train: 0.3326 acc_train: 0.9203 loss_val: 2.0896 acc_val: 0.4979 time: 0.0497s
Epoch: 0007 loss_train: 0.2272 acc_train: 0.9386 loss_val: 2.4938 acc_val: 0.5089 time: 0.0579s
Epoch: 0008 loss_train: 0.1604 acc_train: 0.9533 loss_val: 2.9386 acc_val: 0.5117 time: 0.1309s
Epoch: 0009 loss_train: 0.1244 acc_train: 0.9643 loss_val: 3.3826 acc_val: 0.5075 time: 0.0871s
Epoch: 0010 loss_train: 0.1116 acc_train: 0.9615 loss_val: 3.7518 acc_val: 0.5144 time: 0.0414s
Epoch: 0011 loss_train: 0.1156 acc_train: 0.9634 loss_val: 4.1406 acc_val: 0.5117 time: 0.0424s
Epoch: 0012 loss_train: 0.0871 acc_train: 0.9744 loss_val: 4.5266 acc_val: 0.5117 time: 0.0453s
Epoch: 0013 loss_train: 0.0799 acc_train: 0.9744 loss_val: 4.9174 acc_val: 0.5144 time: 0.0552s
Epoch: 0014 loss_train: 0.0841 acc_train: 0.9725 loss_val: 5.2888 acc_val: 0.5130 time: 0.0469s
Epoch: 0015 loss_train: 0.0803 acc_train: 0.9762 loss_val: 5.5846 acc_val: 0.5158 time: 0.0437s
Epoch: 0016 loss_train: 0.0687 acc_train: 0.9789 loss_val: 5.8498 acc_val: 0.5281 time: 0.0445s
Epoch: 0017 loss_train: 0.0549 acc_train: 0.9808 loss_val: 6.0836 acc_val: 0.5322 time: 0.0497s
Epoch: 0018 loss_train: 0.0484 acc_train: 0.9835 loss_val: 6.2958 acc_val: 0.5364 time: 0.0460s
Epoch: 0019 loss_train: 0.0422 acc_train: 0.9853 loss_val: 6.4785 acc_val: 0.5391 time: 0.0631s
Epoch: 0020 loss_train: 0.0368 acc_train: 0.9890 loss_val: 6.6662 acc_val: 0.5446 time: 0.0540s
Epoch: 0021 loss_train: 0.0367 acc_train: 0.9890 loss_val: 6.8924 acc_val: 0.5528 time: 0.0505s
Epoch: 0022 loss_train: 0.0282 acc_train: 0.9918 loss_val: 7.1393 acc_val: 0.5528 time: 0.0549s
Epoch: 0023 loss_train: 0.0248 acc_train: 0.9918 loss_val: 7.3962 acc_val: 0.5432 time: 0.0644s
Epoch: 0024 loss_train: 0.0261 acc_train: 0.9927 loss_val: 7.6016 acc_val: 0.5405 time: 0.0506s
Epoch: 0025 loss_train: 0.0242 acc_train: 0.9918 loss_val: 7.7837 acc_val: 0.5336 time: 0.0558s
Epoch: 0026 loss_train: 0.0226 acc_train: 0.9927 loss_val: 7.9484 acc_val: 0.5309 time: 0.0501s
Epoch: 0027 loss_train: 0.0170 acc_train: 0.9936 loss_val: 8.1218 acc_val: 0.5281 time: 0.0535s
Epoch: 0028 loss_train: 0.0172 acc_train: 0.9945 loss_val: 8.2776 acc_val: 0.5254 time: 0.0487s
Epoch: 0029 loss_train: 0.0161 acc_train: 0.9945 loss_val: 8.4496 acc_val: 0.5240 time: 0.0520s
Epoch: 0030 loss_train: 0.0160 acc_train: 0.9945 loss_val: 8.6312 acc_val: 0.5281 time: 0.0709s
Epoch: 0031 loss_train: 0.0156 acc_train: 0.9945 loss_val: 8.8183 acc_val: 0.5240 time: 0.0461s
Epoch: 0032 loss_train: 0.0145 acc_train: 0.9963 loss_val: 8.9947 acc_val: 0.5226 time: 0.0644s
Epoch: 0033 loss_train: 0.0140 acc_train: 0.9945 loss_val: 9.1523 acc_val: 0.5171 time: 0.0508s
Epoch: 0034 loss_train: 0.0104 acc_train: 0.9963 loss_val: 9.2914 acc_val: 0.5171 time: 0.0451s
Epoch: 0035 loss_train: 0.0117 acc_train: 0.9954 loss_val: 9.4065 acc_val: 0.5185 time: 0.0585s
Epoch: 0036 loss_train: 0.0116 acc_train: 0.9954 loss_val: 9.4868 acc_val: 0.5199 time: 0.0518s
Epoch: 0037 loss_train: 0.0115 acc_train: 0.9963 loss_val: 9.5140 acc_val: 0.5199 time: 0.0751s
Epoch: 0038 loss_train: 0.0108 acc_train: 0.9963 loss_val: 9.5406 acc_val: 0.5226 time: 0.0690s
Epoch: 0039 loss_train: 0.0104 acc_train: 0.9973 loss_val: 9.5696 acc_val: 0.5185 time: 0.0476s
Epoch: 0040 loss_train: 0.0151 acc_train: 0.9945 loss_val: 9.6060 acc_val: 0.5185 time: 0.0491s
Epoch: 0041 loss_train: 0.0115 acc_train: 0.9954 loss_val: 9.6338 acc_val: 0.5158 time: 0.0551s
Epoch: 0042 loss_train: 0.0112 acc_train: 0.9963 loss_val: 9.6798 acc_val: 0.5144 time: 0.0442s
Early stopping...
Optimization Finished!
Total time elapsed: 2.4063s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split0_results.txt
Test set results: loss= 9.8629 accuracy= 0.4978
Epoch: 0001 loss_train: 1.6106 acc_train: 0.2015 loss_val: 1.5986 acc_val: 0.2716 time: 0.0837s
Epoch: 0002 loss_train: 1.4948 acc_train: 0.3810 loss_val: 1.4960 acc_val: 0.4211 time: 0.0496s
Epoch: 0003 loss_train: 1.1421 acc_train: 0.8370 loss_val: 1.5231 acc_val: 0.4307 time: 0.0676s
Epoch: 0004 loss_train: 0.7826 acc_train: 0.8773 loss_val: 1.7003 acc_val: 0.4376 time: 0.0506s
Epoch: 0005 loss_train: 0.5248 acc_train: 0.9038 loss_val: 1.9739 acc_val: 0.4458 time: 0.0498s
Epoch: 0006 loss_train: 0.3435 acc_train: 0.9249 loss_val: 2.3723 acc_val: 0.4376 time: 0.0613s
Epoch: 0007 loss_train: 0.2368 acc_train: 0.9414 loss_val: 2.8366 acc_val: 0.4486 time: 0.0472s
Epoch: 0008 loss_train: 0.1675 acc_train: 0.9451 loss_val: 3.3952 acc_val: 0.4636 time: 0.0487s
Epoch: 0009 loss_train: 0.1376 acc_train: 0.9542 loss_val: 4.0417 acc_val: 0.4787 time: 0.1432s
Epoch: 0010 loss_train: 0.1121 acc_train: 0.9597 loss_val: 4.8102 acc_val: 0.4787 time: 0.0753s
Epoch: 0011 loss_train: 0.0981 acc_train: 0.9670 loss_val: 5.5211 acc_val: 0.4787 time: 0.0526s
Epoch: 0012 loss_train: 0.0769 acc_train: 0.9744 loss_val: 6.1903 acc_val: 0.4664 time: 0.0513s
Epoch: 0013 loss_train: 0.0706 acc_train: 0.9734 loss_val: 6.6424 acc_val: 0.4623 time: 0.0622s
Epoch: 0014 loss_train: 0.0661 acc_train: 0.9771 loss_val: 6.8663 acc_val: 0.4664 time: 0.0580s
Epoch: 0015 loss_train: 0.0612 acc_train: 0.9789 loss_val: 7.1653 acc_val: 0.4623 time: 0.0532s
Epoch: 0016 loss_train: 0.0456 acc_train: 0.9835 loss_val: 7.4759 acc_val: 0.4527 time: 0.0505s
Epoch: 0017 loss_train: 0.1201 acc_train: 0.9698 loss_val: 7.5328 acc_val: 0.4636 time: 0.0489s
Epoch: 0018 loss_train: 0.0453 acc_train: 0.9817 loss_val: 7.7107 acc_val: 0.4540 time: 0.0463s
Epoch: 0019 loss_train: 0.0587 acc_train: 0.9844 loss_val: 7.8826 acc_val: 0.4719 time: 0.0411s
Epoch: 0020 loss_train: 0.0550 acc_train: 0.9835 loss_val: 8.1453 acc_val: 0.4664 time: 0.0524s
Epoch: 0021 loss_train: 0.0674 acc_train: 0.9817 loss_val: 8.4641 acc_val: 0.4664 time: 0.0569s
Epoch: 0022 loss_train: 0.0530 acc_train: 0.9817 loss_val: 8.8239 acc_val: 0.4540 time: 0.0463s
Epoch: 0023 loss_train: 0.0580 acc_train: 0.9826 loss_val: 8.9576 acc_val: 0.4568 time: 0.0438s
Epoch: 0024 loss_train: 0.0496 acc_train: 0.9826 loss_val: 9.0980 acc_val: 0.4636 time: 0.0422s
Epoch: 0025 loss_train: 0.0399 acc_train: 0.9853 loss_val: 9.2872 acc_val: 0.4595 time: 0.0427s
Epoch: 0026 loss_train: 0.0445 acc_train: 0.9844 loss_val: 9.5289 acc_val: 0.4582 time: 0.0440s
Epoch: 0027 loss_train: 0.0323 acc_train: 0.9872 loss_val: 9.7802 acc_val: 0.4568 time: 0.0407s
Epoch: 0028 loss_train: 0.0341 acc_train: 0.9844 loss_val: 10.0202 acc_val: 0.4513 time: 0.0568s
Epoch: 0029 loss_train: 0.0289 acc_train: 0.9918 loss_val: 10.2521 acc_val: 0.4595 time: 0.0435s
Epoch: 0030 loss_train: 0.0271 acc_train: 0.9927 loss_val: 10.4528 acc_val: 0.4650 time: 0.0389s
Epoch: 0031 loss_train: 0.0497 acc_train: 0.9908 loss_val: 10.5666 acc_val: 0.4568 time: 0.0438s
Epoch: 0032 loss_train: 0.0271 acc_train: 0.9927 loss_val: 10.6552 acc_val: 0.4568 time: 0.0624s
Epoch: 0033 loss_train: 0.0263 acc_train: 0.9936 loss_val: 10.7272 acc_val: 0.4595 time: 0.0448s
Epoch: 0034 loss_train: 0.0238 acc_train: 0.9936 loss_val: 10.7989 acc_val: 0.4636 time: 0.0451s
Epoch: 0035 loss_train: 0.0297 acc_train: 0.9908 loss_val: 10.8621 acc_val: 0.4636 time: 0.0423s
Epoch: 0036 loss_train: 0.0268 acc_train: 0.9927 loss_val: 10.9159 acc_val: 0.4636 time: 0.0415s
Epoch: 0037 loss_train: 0.0228 acc_train: 0.9945 loss_val: 10.9670 acc_val: 0.4636 time: 0.0439s
Epoch: 0038 loss_train: 0.0210 acc_train: 0.9945 loss_val: 11.0232 acc_val: 0.4746 time: 0.0517s
Epoch: 0039 loss_train: 0.0200 acc_train: 0.9927 loss_val: 11.0972 acc_val: 0.4733 time: 0.0428s
Epoch: 0040 loss_train: 0.0232 acc_train: 0.9936 loss_val: 11.1722 acc_val: 0.4746 time: 0.0471s
Epoch: 0041 loss_train: 0.0235 acc_train: 0.9945 loss_val: 11.2251 acc_val: 0.4760 time: 0.0512s
Epoch: 0042 loss_train: 0.0189 acc_train: 0.9954 loss_val: 11.2559 acc_val: 0.4760 time: 0.0420s
Early stopping...
Optimization Finished!
Total time elapsed: 2.2097s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split1_results.txt
Test set results: loss= 10.3205 accuracy= 0.5351
Epoch: 0001 loss_train: 1.6100 acc_train: 0.2033 loss_val: 1.5947 acc_val: 0.2716 time: 0.0670s
Epoch: 0002 loss_train: 1.4844 acc_train: 0.3654 loss_val: 1.5047 acc_val: 0.4170 time: 0.0483s
Epoch: 0003 loss_train: 1.1366 acc_train: 0.8223 loss_val: 1.5481 acc_val: 0.4060 time: 0.0554s
Epoch: 0004 loss_train: 0.7855 acc_train: 0.8425 loss_val: 1.7369 acc_val: 0.4582 time: 0.0479s
Epoch: 0005 loss_train: 0.5280 acc_train: 0.9002 loss_val: 2.0299 acc_val: 0.4733 time: 0.0580s
Epoch: 0006 loss_train: 0.3590 acc_train: 0.9231 loss_val: 2.4130 acc_val: 0.4664 time: 0.0497s
Epoch: 0007 loss_train: 0.2413 acc_train: 0.9359 loss_val: 2.8427 acc_val: 0.4650 time: 0.0514s
Epoch: 0008 loss_train: 0.1639 acc_train: 0.9579 loss_val: 3.3153 acc_val: 0.4691 time: 0.0607s
Epoch: 0009 loss_train: 0.1296 acc_train: 0.9634 loss_val: 3.8043 acc_val: 0.4733 time: 0.0486s
Epoch: 0010 loss_train: 0.1097 acc_train: 0.9625 loss_val: 4.2981 acc_val: 0.4774 time: 0.0524s
Epoch: 0011 loss_train: 0.1022 acc_train: 0.9652 loss_val: 4.7969 acc_val: 0.4801 time: 0.0886s
Epoch: 0012 loss_train: 0.0859 acc_train: 0.9725 loss_val: 5.3864 acc_val: 0.4815 time: 0.0504s
Epoch: 0013 loss_train: 0.0699 acc_train: 0.9716 loss_val: 6.0880 acc_val: 0.4815 time: 0.0557s
Epoch: 0014 loss_train: 0.0726 acc_train: 0.9725 loss_val: 6.6820 acc_val: 0.4870 time: 0.0475s
Epoch: 0015 loss_train: 0.0654 acc_train: 0.9753 loss_val: 7.0532 acc_val: 0.4883 time: 0.0583s
Epoch: 0016 loss_train: 0.0693 acc_train: 0.9716 loss_val: 7.3736 acc_val: 0.4842 time: 0.0421s
Epoch: 0017 loss_train: 0.0617 acc_train: 0.9753 loss_val: 7.7744 acc_val: 0.4870 time: 0.0550s
Epoch: 0018 loss_train: 0.0532 acc_train: 0.9799 loss_val: 8.1453 acc_val: 0.4842 time: 0.0485s
Epoch: 0019 loss_train: 0.0528 acc_train: 0.9789 loss_val: 8.4800 acc_val: 0.4883 time: 0.0454s
Epoch: 0020 loss_train: 0.0495 acc_train: 0.9789 loss_val: 8.7847 acc_val: 0.4842 time: 0.0463s
Epoch: 0021 loss_train: 0.0587 acc_train: 0.9771 loss_val: 9.1797 acc_val: 0.4787 time: 0.0630s
Epoch: 0022 loss_train: 0.0561 acc_train: 0.9771 loss_val: 9.4225 acc_val: 0.4815 time: 0.0467s
Epoch: 0023 loss_train: 0.0421 acc_train: 0.9817 loss_val: 9.6893 acc_val: 0.4801 time: 0.0577s
Epoch: 0024 loss_train: 0.0513 acc_train: 0.9799 loss_val: 9.9307 acc_val: 0.4842 time: 0.0429s
Epoch: 0025 loss_train: 0.0413 acc_train: 0.9826 loss_val: 10.1811 acc_val: 0.4842 time: 0.0413s
Epoch: 0026 loss_train: 0.0356 acc_train: 0.9835 loss_val: 10.4612 acc_val: 0.4801 time: 0.0415s
Epoch: 0027 loss_train: 0.0383 acc_train: 0.9844 loss_val: 10.7313 acc_val: 0.4774 time: 0.0387s
Epoch: 0028 loss_train: 0.0367 acc_train: 0.9844 loss_val: 10.8644 acc_val: 0.4705 time: 0.0416s
Epoch: 0029 loss_train: 0.0323 acc_train: 0.9844 loss_val: 10.9514 acc_val: 0.4691 time: 0.0441s
Epoch: 0030 loss_train: 0.0250 acc_train: 0.9881 loss_val: 11.0163 acc_val: 0.4719 time: 0.0473s
Epoch: 0031 loss_train: 0.0238 acc_train: 0.9918 loss_val: 11.1157 acc_val: 0.4733 time: 0.0521s
Epoch: 0032 loss_train: 0.0187 acc_train: 0.9936 loss_val: 11.2611 acc_val: 0.4760 time: 0.0449s
Epoch: 0033 loss_train: 0.0247 acc_train: 0.9918 loss_val: 11.3946 acc_val: 0.4801 time: 0.0458s
Epoch: 0034 loss_train: 0.0203 acc_train: 0.9908 loss_val: 11.4789 acc_val: 0.4801 time: 0.0671s
Epoch: 0035 loss_train: 0.0194 acc_train: 0.9908 loss_val: 11.6905 acc_val: 0.4801 time: 0.0504s
Epoch: 0036 loss_train: 0.0136 acc_train: 0.9927 loss_val: 11.9258 acc_val: 0.4760 time: 0.0446s
Epoch: 0037 loss_train: 0.0172 acc_train: 0.9927 loss_val: 12.1465 acc_val: 0.4760 time: 0.0878s
Epoch: 0038 loss_train: 0.0201 acc_train: 0.9908 loss_val: 12.3451 acc_val: 0.4733 time: 0.0493s
Epoch: 0039 loss_train: 0.0178 acc_train: 0.9899 loss_val: 12.4119 acc_val: 0.4705 time: 0.0499s
Epoch: 0040 loss_train: 0.0160 acc_train: 0.9945 loss_val: 12.4639 acc_val: 0.4719 time: 0.0878s
Epoch: 0041 loss_train: 0.0098 acc_train: 0.9945 loss_val: 12.4824 acc_val: 0.4746 time: 0.0409s
Epoch: 0042 loss_train: 0.0105 acc_train: 0.9954 loss_val: 12.3785 acc_val: 0.4801 time: 0.0436s
Early stopping...
Optimization Finished!
Total time elapsed: 2.2075s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split2_results.txt
Test set results: loss= 11.1416 accuracy= 0.5154
Epoch: 0001 loss_train: 1.6105 acc_train: 0.2005 loss_val: 1.5760 acc_val: 0.3086 time: 0.0801s
Epoch: 0002 loss_train: 1.4854 acc_train: 0.4185 loss_val: 1.4789 acc_val: 0.3333 time: 0.0522s
Epoch: 0003 loss_train: 1.1246 acc_train: 0.6694 loss_val: 1.4592 acc_val: 0.4294 time: 0.0485s
Epoch: 0004 loss_train: 0.7643 acc_train: 0.8636 loss_val: 1.5832 acc_val: 0.4554 time: 0.0522s
Epoch: 0005 loss_train: 0.5053 acc_train: 0.9029 loss_val: 1.8361 acc_val: 0.4595 time: 0.0574s
Epoch: 0006 loss_train: 0.3274 acc_train: 0.9148 loss_val: 2.1320 acc_val: 0.4870 time: 0.0492s
Epoch: 0007 loss_train: 0.2133 acc_train: 0.9524 loss_val: 2.5279 acc_val: 0.4829 time: 0.1389s
Epoch: 0008 loss_train: 0.1411 acc_train: 0.9661 loss_val: 3.0018 acc_val: 0.4829 time: 0.0627s
Epoch: 0009 loss_train: 0.1122 acc_train: 0.9652 loss_val: 3.5283 acc_val: 0.4746 time: 0.0546s
Epoch: 0010 loss_train: 0.1076 acc_train: 0.9652 loss_val: 3.9538 acc_val: 0.4856 time: 0.0472s
Epoch: 0011 loss_train: 0.0969 acc_train: 0.9707 loss_val: 4.4626 acc_val: 0.4787 time: 0.0455s
Epoch: 0012 loss_train: 0.0906 acc_train: 0.9734 loss_val: 4.9414 acc_val: 0.4815 time: 0.0528s
Epoch: 0013 loss_train: 0.0679 acc_train: 0.9771 loss_val: 5.4054 acc_val: 0.4815 time: 0.1141s
Epoch: 0014 loss_train: 0.0729 acc_train: 0.9725 loss_val: 5.7954 acc_val: 0.4815 time: 0.0448s
Epoch: 0015 loss_train: 0.0576 acc_train: 0.9817 loss_val: 6.1479 acc_val: 0.4801 time: 0.0472s
Epoch: 0016 loss_train: 0.0514 acc_train: 0.9844 loss_val: 6.4969 acc_val: 0.4787 time: 0.0533s
Epoch: 0017 loss_train: 0.0432 acc_train: 0.9844 loss_val: 6.8920 acc_val: 0.4787 time: 0.0515s
Epoch: 0018 loss_train: 0.0420 acc_train: 0.9844 loss_val: 7.2745 acc_val: 0.4842 time: 0.0453s
Epoch: 0019 loss_train: 0.0383 acc_train: 0.9872 loss_val: 7.5747 acc_val: 0.4842 time: 0.0463s
Epoch: 0020 loss_train: 0.0413 acc_train: 0.9863 loss_val: 7.7705 acc_val: 0.4842 time: 0.0479s
Epoch: 0021 loss_train: 0.0395 acc_train: 0.9890 loss_val: 7.9346 acc_val: 0.4870 time: 0.0490s
Epoch: 0022 loss_train: 0.0317 acc_train: 0.9899 loss_val: 8.1095 acc_val: 0.4911 time: 0.0429s
Epoch: 0023 loss_train: 0.0208 acc_train: 0.9927 loss_val: 8.2768 acc_val: 0.4925 time: 0.0497s
Epoch: 0024 loss_train: 0.0241 acc_train: 0.9936 loss_val: 8.4384 acc_val: 0.4870 time: 0.0434s
Epoch: 0025 loss_train: 0.0284 acc_train: 0.9899 loss_val: 8.6482 acc_val: 0.4842 time: 0.0439s
Epoch: 0026 loss_train: 0.0237 acc_train: 0.9936 loss_val: 8.8741 acc_val: 0.4842 time: 0.0503s
Epoch: 0027 loss_train: 0.0219 acc_train: 0.9927 loss_val: 9.1045 acc_val: 0.4815 time: 0.0466s
Epoch: 0028 loss_train: 0.0193 acc_train: 0.9945 loss_val: 9.3105 acc_val: 0.4746 time: 0.0495s
Epoch: 0029 loss_train: 0.0188 acc_train: 0.9945 loss_val: 9.5263 acc_val: 0.4774 time: 0.0766s
Epoch: 0030 loss_train: 0.0177 acc_train: 0.9954 loss_val: 9.7291 acc_val: 0.4733 time: 0.0494s
Epoch: 0031 loss_train: 0.0180 acc_train: 0.9954 loss_val: 9.9492 acc_val: 0.4719 time: 0.0547s
Epoch: 0032 loss_train: 0.0185 acc_train: 0.9927 loss_val: 10.2072 acc_val: 0.4705 time: 0.0433s
Epoch: 0033 loss_train: 0.0179 acc_train: 0.9945 loss_val: 10.3648 acc_val: 0.4691 time: 0.0411s
Epoch: 0034 loss_train: 0.0130 acc_train: 0.9945 loss_val: 10.5446 acc_val: 0.4636 time: 0.0401s
Epoch: 0035 loss_train: 0.0206 acc_train: 0.9963 loss_val: 10.6918 acc_val: 0.4636 time: 0.0446s
Epoch: 0036 loss_train: 0.0155 acc_train: 0.9954 loss_val: 10.7692 acc_val: 0.4582 time: 0.0476s
Epoch: 0037 loss_train: 0.0107 acc_train: 0.9963 loss_val: 10.8379 acc_val: 0.4568 time: 0.0461s
Epoch: 0038 loss_train: 0.0130 acc_train: 0.9963 loss_val: 10.8918 acc_val: 0.4595 time: 0.0428s
Epoch: 0039 loss_train: 0.0171 acc_train: 0.9945 loss_val: 10.9626 acc_val: 0.4595 time: 0.0868s
Epoch: 0040 loss_train: 0.0133 acc_train: 0.9945 loss_val: 11.0492 acc_val: 0.4582 time: 0.0410s
Epoch: 0041 loss_train: 0.0176 acc_train: 0.9927 loss_val: 11.1377 acc_val: 0.4595 time: 0.0505s
Epoch: 0042 loss_train: 0.0101 acc_train: 0.9954 loss_val: 11.2383 acc_val: 0.4582 time: 0.0693s
Early stopping...
Optimization Finished!
Total time elapsed: 2.3028s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split3_results.txt
Test set results: loss= 9.6587 accuracy= 0.5285
Epoch: 0001 loss_train: 1.6123 acc_train: 0.1914 loss_val: 1.5796 acc_val: 0.3073 time: 0.1314s
Epoch: 0002 loss_train: 1.4940 acc_train: 0.3626 loss_val: 1.5146 acc_val: 0.3278 time: 0.0488s
Epoch: 0003 loss_train: 1.1656 acc_train: 0.6859 loss_val: 1.4910 acc_val: 0.4472 time: 0.1562s
Epoch: 0004 loss_train: 0.8129 acc_train: 0.8361 loss_val: 1.6368 acc_val: 0.4623 time: 0.1455s
Epoch: 0005 loss_train: 0.5637 acc_train: 0.8599 loss_val: 1.8530 acc_val: 0.4897 time: 0.0626s
Epoch: 0006 loss_train: 0.3737 acc_train: 0.9194 loss_val: 2.1955 acc_val: 0.4856 time: 0.0545s
Epoch: 0007 loss_train: 0.2512 acc_train: 0.9332 loss_val: 2.6332 acc_val: 0.4938 time: 0.0468s
Epoch: 0008 loss_train: 0.1718 acc_train: 0.9570 loss_val: 3.1503 acc_val: 0.4979 time: 0.0436s
Epoch: 0009 loss_train: 0.1304 acc_train: 0.9588 loss_val: 3.8594 acc_val: 0.5089 time: 0.0475s
Epoch: 0010 loss_train: 0.1020 acc_train: 0.9689 loss_val: 4.7949 acc_val: 0.5144 time: 0.0464s
Epoch: 0011 loss_train: 0.0876 acc_train: 0.9753 loss_val: 5.6406 acc_val: 0.5117 time: 0.0430s
Epoch: 0012 loss_train: 0.0646 acc_train: 0.9762 loss_val: 6.5995 acc_val: 0.5048 time: 0.0450s
Epoch: 0013 loss_train: 0.0612 acc_train: 0.9762 loss_val: 6.7974 acc_val: 0.5048 time: 0.0689s
Epoch: 0014 loss_train: 0.0579 acc_train: 0.9799 loss_val: 6.8916 acc_val: 0.4979 time: 0.0480s
Epoch: 0015 loss_train: 0.0587 acc_train: 0.9826 loss_val: 6.7890 acc_val: 0.4938 time: 0.0489s
Epoch: 0016 loss_train: 0.0544 acc_train: 0.9835 loss_val: 6.8482 acc_val: 0.4966 time: 0.0667s
Epoch: 0017 loss_train: 0.0505 acc_train: 0.9808 loss_val: 7.0250 acc_val: 0.4993 time: 0.0492s
Epoch: 0018 loss_train: 0.0487 acc_train: 0.9817 loss_val: 7.1818 acc_val: 0.5034 time: 0.0746s
Epoch: 0019 loss_train: 0.0440 acc_train: 0.9881 loss_val: 7.2543 acc_val: 0.5034 time: 0.0448s
Epoch: 0020 loss_train: 0.0432 acc_train: 0.9890 loss_val: 7.4116 acc_val: 0.5075 time: 0.0475s
Epoch: 0021 loss_train: 0.0419 acc_train: 0.9881 loss_val: 7.6207 acc_val: 0.5048 time: 0.0610s
Epoch: 0022 loss_train: 0.0305 acc_train: 0.9908 loss_val: 7.8759 acc_val: 0.5034 time: 0.0515s
Epoch: 0023 loss_train: 0.0284 acc_train: 0.9927 loss_val: 8.1849 acc_val: 0.5034 time: 0.0513s
Epoch: 0024 loss_train: 0.0259 acc_train: 0.9918 loss_val: 8.4613 acc_val: 0.5062 time: 0.0470s
Epoch: 0025 loss_train: 0.0201 acc_train: 0.9945 loss_val: 8.7071 acc_val: 0.5034 time: 0.0495s
Epoch: 0026 loss_train: 0.0205 acc_train: 0.9963 loss_val: 8.9233 acc_val: 0.4993 time: 0.0464s
Epoch: 0027 loss_train: 0.0182 acc_train: 0.9936 loss_val: 9.0960 acc_val: 0.5007 time: 0.0504s
Epoch: 0028 loss_train: 0.0137 acc_train: 0.9954 loss_val: 9.2862 acc_val: 0.4952 time: 0.0504s
Epoch: 0029 loss_train: 0.0121 acc_train: 0.9973 loss_val: 9.5367 acc_val: 0.4979 time: 0.0486s
Epoch: 0030 loss_train: 0.0109 acc_train: 0.9963 loss_val: 9.7684 acc_val: 0.4979 time: 0.0688s
Epoch: 0031 loss_train: 0.0157 acc_train: 0.9936 loss_val: 9.5942 acc_val: 0.5034 time: 0.0521s
Epoch: 0032 loss_train: 0.0076 acc_train: 0.9982 loss_val: 9.5635 acc_val: 0.5089 time: 0.0555s
Epoch: 0033 loss_train: 0.0085 acc_train: 0.9973 loss_val: 9.6355 acc_val: 0.5062 time: 0.0477s
Epoch: 0034 loss_train: 0.0121 acc_train: 0.9945 loss_val: 9.8017 acc_val: 0.5117 time: 0.0469s
Epoch: 0035 loss_train: 0.0057 acc_train: 0.9982 loss_val: 9.9517 acc_val: 0.5089 time: 0.0459s
Epoch: 0036 loss_train: 0.0045 acc_train: 0.9982 loss_val: 10.0834 acc_val: 0.5117 time: 0.0602s
Epoch: 0037 loss_train: 0.0053 acc_train: 0.9973 loss_val: 10.1372 acc_val: 0.5117 time: 0.0471s
Epoch: 0038 loss_train: 0.0055 acc_train: 0.9982 loss_val: 10.2371 acc_val: 0.5048 time: 0.0467s
Epoch: 0039 loss_train: 0.0033 acc_train: 0.9991 loss_val: 10.3549 acc_val: 0.5007 time: 0.0474s
Epoch: 0040 loss_train: 0.0088 acc_train: 0.9973 loss_val: 10.4945 acc_val: 0.4993 time: 0.0921s
Epoch: 0041 loss_train: 0.0031 acc_train: 0.9991 loss_val: 10.6846 acc_val: 0.4979 time: 0.0454s
Epoch: 0042 loss_train: 0.0048 acc_train: 0.9991 loss_val: 10.8299 acc_val: 0.4952 time: 0.0958s
Early stopping...
Optimization Finished!
Total time elapsed: 2.5297s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split4_results.txt
Test set results: loss= 11.1476 accuracy= 0.4649
Epoch: 0001 loss_train: 1.6096 acc_train: 0.2070 loss_val: 1.5840 acc_val: 0.2977 time: 0.0901s
Epoch: 0002 loss_train: 1.4819 acc_train: 0.4304 loss_val: 1.4736 acc_val: 0.4664 time: 0.0516s
Epoch: 0003 loss_train: 1.1232 acc_train: 0.8672 loss_val: 1.4911 acc_val: 0.4060 time: 0.0471s
Epoch: 0004 loss_train: 0.7751 acc_train: 0.8315 loss_val: 1.6166 acc_val: 0.4568 time: 0.0448s
Epoch: 0005 loss_train: 0.5126 acc_train: 0.8883 loss_val: 1.8259 acc_val: 0.4760 time: 0.0498s
Epoch: 0006 loss_train: 0.3367 acc_train: 0.9258 loss_val: 2.1522 acc_val: 0.4925 time: 0.0529s
Epoch: 0007 loss_train: 0.2243 acc_train: 0.9496 loss_val: 2.5322 acc_val: 0.5021 time: 0.0747s
Epoch: 0008 loss_train: 0.1501 acc_train: 0.9606 loss_val: 3.0472 acc_val: 0.5021 time: 0.0432s
Epoch: 0009 loss_train: 0.1203 acc_train: 0.9652 loss_val: 3.5387 acc_val: 0.4925 time: 0.0440s
Epoch: 0010 loss_train: 0.1026 acc_train: 0.9679 loss_val: 4.0111 acc_val: 0.4952 time: 0.0472s
Epoch: 0011 loss_train: 0.0961 acc_train: 0.9707 loss_val: 4.5128 acc_val: 0.4952 time: 0.0451s
Epoch: 0012 loss_train: 0.0845 acc_train: 0.9744 loss_val: 4.9528 acc_val: 0.5089 time: 0.0534s
Epoch: 0013 loss_train: 0.0737 acc_train: 0.9762 loss_val: 5.3488 acc_val: 0.5089 time: 0.1019s
Epoch: 0014 loss_train: 0.0749 acc_train: 0.9789 loss_val: 5.7400 acc_val: 0.4993 time: 0.0554s
Epoch: 0015 loss_train: 0.0653 acc_train: 0.9835 loss_val: 6.0914 acc_val: 0.5021 time: 0.0618s
Epoch: 0016 loss_train: 0.0580 acc_train: 0.9835 loss_val: 6.4449 acc_val: 0.4979 time: 0.0422s
Epoch: 0017 loss_train: 0.0529 acc_train: 0.9844 loss_val: 6.8315 acc_val: 0.4979 time: 0.0439s
Epoch: 0018 loss_train: 0.0459 acc_train: 0.9863 loss_val: 7.2399 acc_val: 0.4883 time: 0.0522s
Epoch: 0019 loss_train: 0.0441 acc_train: 0.9872 loss_val: 7.5875 acc_val: 0.4897 time: 0.0478s
Epoch: 0020 loss_train: 0.0417 acc_train: 0.9890 loss_val: 7.8593 acc_val: 0.4952 time: 0.0480s
Epoch: 0021 loss_train: 0.0385 acc_train: 0.9908 loss_val: 8.0758 acc_val: 0.5007 time: 0.0556s
Epoch: 0022 loss_train: 0.0382 acc_train: 0.9881 loss_val: 8.2893 acc_val: 0.4952 time: 0.0749s
Epoch: 0023 loss_train: 0.0366 acc_train: 0.9899 loss_val: 8.6338 acc_val: 0.4829 time: 0.0414s
Epoch: 0024 loss_train: 0.0348 acc_train: 0.9927 loss_val: 8.9072 acc_val: 0.4870 time: 0.0416s
Epoch: 0025 loss_train: 0.0377 acc_train: 0.9853 loss_val: 9.0648 acc_val: 0.4897 time: 0.0501s
Epoch: 0026 loss_train: 0.0259 acc_train: 0.9927 loss_val: 9.2501 acc_val: 0.4897 time: 0.0436s
Epoch: 0027 loss_train: 0.0398 acc_train: 0.9872 loss_val: 9.2634 acc_val: 0.4897 time: 0.0497s
Epoch: 0028 loss_train: 0.0265 acc_train: 0.9927 loss_val: 9.2738 acc_val: 0.4870 time: 0.0552s
Epoch: 0029 loss_train: 0.0227 acc_train: 0.9927 loss_val: 9.3601 acc_val: 0.4774 time: 0.0481s
Epoch: 0030 loss_train: 0.0259 acc_train: 0.9908 loss_val: 9.5570 acc_val: 0.4774 time: 0.0455s
Epoch: 0031 loss_train: 0.0218 acc_train: 0.9927 loss_val: 9.6633 acc_val: 0.4787 time: 0.0435s
Epoch: 0032 loss_train: 0.0185 acc_train: 0.9918 loss_val: 9.7355 acc_val: 0.4829 time: 0.0537s
Epoch: 0033 loss_train: 0.0186 acc_train: 0.9936 loss_val: 9.7867 acc_val: 0.4842 time: 0.0573s
Epoch: 0034 loss_train: 0.0138 acc_train: 0.9963 loss_val: 9.8688 acc_val: 0.4842 time: 0.0547s
Epoch: 0035 loss_train: 0.0176 acc_train: 0.9945 loss_val: 9.9246 acc_val: 0.4842 time: 0.0489s
Epoch: 0036 loss_train: 0.0134 acc_train: 0.9963 loss_val: 9.9674 acc_val: 0.4842 time: 0.0463s
Epoch: 0037 loss_train: 0.0144 acc_train: 0.9954 loss_val: 10.0196 acc_val: 0.4801 time: 0.0469s
Epoch: 0038 loss_train: 0.0097 acc_train: 0.9973 loss_val: 10.0831 acc_val: 0.4815 time: 0.0544s
Epoch: 0039 loss_train: 0.0084 acc_train: 0.9973 loss_val: 10.1548 acc_val: 0.4815 time: 0.0582s
Epoch: 0040 loss_train: 0.0106 acc_train: 0.9954 loss_val: 10.2417 acc_val: 0.4774 time: 0.0581s
Epoch: 0041 loss_train: 0.0083 acc_train: 0.9973 loss_val: 10.3108 acc_val: 0.4787 time: 0.0413s
Epoch: 0042 loss_train: 0.0100 acc_train: 0.9973 loss_val: 10.3931 acc_val: 0.4760 time: 0.0435s
Early stopping...
Optimization Finished!
Total time elapsed: 2.2106s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split5_results.txt
Test set results: loss= 10.1282 accuracy= 0.5197
Epoch: 0001 loss_train: 1.6114 acc_train: 0.1941 loss_val: 1.5731 acc_val: 0.2908 time: 0.0964s
Epoch: 0002 loss_train: 1.4630 acc_train: 0.3901 loss_val: 1.4711 acc_val: 0.4060 time: 0.0494s
Epoch: 0003 loss_train: 1.0869 acc_train: 0.8223 loss_val: 1.4657 acc_val: 0.4390 time: 0.0608s
Epoch: 0004 loss_train: 0.7324 acc_train: 0.8544 loss_val: 1.5933 acc_val: 0.4774 time: 0.0909s
Epoch: 0005 loss_train: 0.4870 acc_train: 0.9057 loss_val: 1.8442 acc_val: 0.4870 time: 0.0632s
Epoch: 0006 loss_train: 0.3208 acc_train: 0.9322 loss_val: 2.1375 acc_val: 0.4911 time: 0.1294s
Epoch: 0007 loss_train: 0.2118 acc_train: 0.9451 loss_val: 2.5390 acc_val: 0.5144 time: 0.0602s
Epoch: 0008 loss_train: 0.1563 acc_train: 0.9560 loss_val: 2.9523 acc_val: 0.5185 time: 0.0466s
Epoch: 0009 loss_train: 0.1137 acc_train: 0.9643 loss_val: 3.3804 acc_val: 0.5185 time: 0.0472s
Epoch: 0010 loss_train: 0.1003 acc_train: 0.9744 loss_val: 3.8891 acc_val: 0.5171 time: 0.0486s
Epoch: 0011 loss_train: 0.0959 acc_train: 0.9707 loss_val: 4.4580 acc_val: 0.5226 time: 0.0518s
Epoch: 0012 loss_train: 0.0858 acc_train: 0.9789 loss_val: 5.0605 acc_val: 0.5281 time: 0.0436s
Epoch: 0013 loss_train: 0.0728 acc_train: 0.9817 loss_val: 5.5500 acc_val: 0.5267 time: 0.0460s
Epoch: 0014 loss_train: 0.0747 acc_train: 0.9817 loss_val: 5.7799 acc_val: 0.5295 time: 0.0487s
Epoch: 0015 loss_train: 0.0717 acc_train: 0.9844 loss_val: 6.1228 acc_val: 0.5322 time: 0.0502s
Epoch: 0016 loss_train: 0.0641 acc_train: 0.9863 loss_val: 6.4467 acc_val: 0.5391 time: 0.0521s
Epoch: 0017 loss_train: 0.0614 acc_train: 0.9835 loss_val: 6.6917 acc_val: 0.5336 time: 0.0584s
Epoch: 0018 loss_train: 0.0506 acc_train: 0.9881 loss_val: 6.9678 acc_val: 0.5309 time: 0.0430s
Epoch: 0019 loss_train: 0.0464 acc_train: 0.9890 loss_val: 7.1329 acc_val: 0.5267 time: 0.0489s
Epoch: 0020 loss_train: 0.0431 acc_train: 0.9899 loss_val: 7.3294 acc_val: 0.5309 time: 0.0427s
Epoch: 0021 loss_train: 0.0452 acc_train: 0.9881 loss_val: 7.5090 acc_val: 0.5377 time: 0.0455s
Epoch: 0022 loss_train: 0.0421 acc_train: 0.9899 loss_val: 7.6750 acc_val: 0.5405 time: 0.0424s
Epoch: 0023 loss_train: 0.0429 acc_train: 0.9881 loss_val: 7.7964 acc_val: 0.5418 time: 0.0490s
Epoch: 0024 loss_train: 0.0352 acc_train: 0.9908 loss_val: 7.9260 acc_val: 0.5446 time: 0.0586s
Epoch: 0025 loss_train: 0.0386 acc_train: 0.9899 loss_val: 8.1468 acc_val: 0.5405 time: 0.0658s
Epoch: 0026 loss_train: 0.0376 acc_train: 0.9881 loss_val: 8.2583 acc_val: 0.5391 time: 0.0569s
Epoch: 0027 loss_train: 0.0294 acc_train: 0.9899 loss_val: 8.3340 acc_val: 0.5377 time: 0.0642s
Epoch: 0028 loss_train: 0.0302 acc_train: 0.9908 loss_val: 8.3907 acc_val: 0.5405 time: 0.1213s
Epoch: 0029 loss_train: 0.0295 acc_train: 0.9927 loss_val: 8.4847 acc_val: 0.5528 time: 0.0447s
Epoch: 0030 loss_train: 0.0280 acc_train: 0.9899 loss_val: 8.5898 acc_val: 0.5514 time: 0.0711s
Epoch: 0031 loss_train: 0.0260 acc_train: 0.9927 loss_val: 8.6808 acc_val: 0.5514 time: 0.0422s
Epoch: 0032 loss_train: 0.0252 acc_train: 0.9945 loss_val: 8.7607 acc_val: 0.5556 time: 0.0444s
Epoch: 0033 loss_train: 0.0297 acc_train: 0.9908 loss_val: 8.8084 acc_val: 0.5528 time: 0.0473s
Epoch: 0034 loss_train: 0.0213 acc_train: 0.9973 loss_val: 8.8637 acc_val: 0.5418 time: 0.0469s
Epoch: 0035 loss_train: 0.0211 acc_train: 0.9927 loss_val: 8.9520 acc_val: 0.5460 time: 0.0477s
Epoch: 0036 loss_train: 0.0186 acc_train: 0.9927 loss_val: 9.0433 acc_val: 0.5418 time: 0.0491s
Epoch: 0037 loss_train: 0.0187 acc_train: 0.9945 loss_val: 9.1338 acc_val: 0.5391 time: 0.0772s
Epoch: 0038 loss_train: 0.0218 acc_train: 0.9927 loss_val: 9.2177 acc_val: 0.5377 time: 0.0474s
Epoch: 0039 loss_train: 0.0203 acc_train: 0.9945 loss_val: 9.2938 acc_val: 0.5364 time: 0.0469s
Epoch: 0040 loss_train: 0.0169 acc_train: 0.9945 loss_val: 9.3905 acc_val: 0.5295 time: 0.0644s
Epoch: 0041 loss_train: 0.0170 acc_train: 0.9936 loss_val: 9.4218 acc_val: 0.5213 time: 0.0651s
Epoch: 0042 loss_train: 0.0173 acc_train: 0.9945 loss_val: 9.3197 acc_val: 0.5240 time: 0.0475s
Early stopping...
Optimization Finished!
Total time elapsed: 2.4252s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split6_results.txt
Test set results: loss= 9.7662 accuracy= 0.4825
Epoch: 0001 loss_train: 1.6098 acc_train: 0.2051 loss_val: 1.5806 acc_val: 0.2812 time: 0.0684s
Epoch: 0002 loss_train: 1.4905 acc_train: 0.3626 loss_val: 1.4885 acc_val: 0.4129 time: 0.0515s
Epoch: 0003 loss_train: 1.1380 acc_train: 0.8416 loss_val: 1.5088 acc_val: 0.3882 time: 0.0829s
Epoch: 0004 loss_train: 0.7866 acc_train: 0.8159 loss_val: 1.6497 acc_val: 0.4472 time: 0.0484s
Epoch: 0005 loss_train: 0.5385 acc_train: 0.8919 loss_val: 1.8992 acc_val: 0.4623 time: 0.0649s
Epoch: 0006 loss_train: 0.3698 acc_train: 0.9075 loss_val: 2.2203 acc_val: 0.4719 time: 0.0591s
Epoch: 0007 loss_train: 0.2613 acc_train: 0.9203 loss_val: 2.6217 acc_val: 0.4705 time: 0.0688s
Epoch: 0008 loss_train: 0.1775 acc_train: 0.9478 loss_val: 3.1046 acc_val: 0.4719 time: 0.0825s
Epoch: 0009 loss_train: 0.1367 acc_train: 0.9551 loss_val: 3.6214 acc_val: 0.4787 time: 0.0590s
Epoch: 0010 loss_train: 0.1257 acc_train: 0.9588 loss_val: 4.1492 acc_val: 0.4856 time: 0.0916s
Epoch: 0011 loss_train: 0.1095 acc_train: 0.9689 loss_val: 4.6754 acc_val: 0.4842 time: 0.0554s
Epoch: 0012 loss_train: 0.0942 acc_train: 0.9707 loss_val: 5.1053 acc_val: 0.4870 time: 0.0480s
Epoch: 0013 loss_train: 0.0821 acc_train: 0.9725 loss_val: 5.5554 acc_val: 0.4842 time: 0.0519s
Epoch: 0014 loss_train: 0.0730 acc_train: 0.9744 loss_val: 5.9636 acc_val: 0.4815 time: 0.0467s
Epoch: 0015 loss_train: 0.0704 acc_train: 0.9725 loss_val: 6.3740 acc_val: 0.4829 time: 0.0420s
Epoch: 0016 loss_train: 0.0642 acc_train: 0.9771 loss_val: 6.6581 acc_val: 0.4842 time: 0.0437s
Epoch: 0017 loss_train: 0.0565 acc_train: 0.9808 loss_val: 6.9824 acc_val: 0.4911 time: 0.0483s
Epoch: 0018 loss_train: 0.0516 acc_train: 0.9817 loss_val: 7.3882 acc_val: 0.4883 time: 0.0483s
Epoch: 0019 loss_train: 0.0457 acc_train: 0.9881 loss_val: 7.6630 acc_val: 0.4897 time: 0.0501s
Epoch: 0020 loss_train: 0.0425 acc_train: 0.9872 loss_val: 7.8943 acc_val: 0.4966 time: 0.0517s
Epoch: 0021 loss_train: 0.0380 acc_train: 0.9863 loss_val: 8.0488 acc_val: 0.5021 time: 0.0519s
Epoch: 0022 loss_train: 0.0367 acc_train: 0.9899 loss_val: 8.2280 acc_val: 0.4897 time: 0.0684s
Epoch: 0023 loss_train: 0.0276 acc_train: 0.9908 loss_val: 8.4323 acc_val: 0.4870 time: 0.0439s
Epoch: 0024 loss_train: 0.0263 acc_train: 0.9908 loss_val: 8.6316 acc_val: 0.4870 time: 0.0469s
Epoch: 0025 loss_train: 0.0298 acc_train: 0.9908 loss_val: 8.7577 acc_val: 0.4911 time: 0.0476s
Epoch: 0026 loss_train: 0.0323 acc_train: 0.9908 loss_val: 8.9451 acc_val: 0.4938 time: 0.0449s
Epoch: 0027 loss_train: 0.0267 acc_train: 0.9881 loss_val: 9.1284 acc_val: 0.4925 time: 0.0471s
Epoch: 0028 loss_train: 0.0217 acc_train: 0.9936 loss_val: 9.2544 acc_val: 0.4925 time: 0.0463s
Epoch: 0029 loss_train: 0.0183 acc_train: 0.9954 loss_val: 9.3561 acc_val: 0.4925 time: 0.0633s
Epoch: 0030 loss_train: 0.0167 acc_train: 0.9945 loss_val: 9.4411 acc_val: 0.4883 time: 0.0426s
Epoch: 0031 loss_train: 0.0151 acc_train: 0.9945 loss_val: 9.5295 acc_val: 0.4856 time: 0.0462s
Epoch: 0032 loss_train: 0.0142 acc_train: 0.9954 loss_val: 9.6347 acc_val: 0.4938 time: 0.0433s
Epoch: 0033 loss_train: 0.0151 acc_train: 0.9945 loss_val: 9.6850 acc_val: 0.4952 time: 0.0464s
Epoch: 0034 loss_train: 0.0110 acc_train: 0.9945 loss_val: 9.7844 acc_val: 0.4897 time: 0.0511s
Epoch: 0035 loss_train: 0.0133 acc_train: 0.9945 loss_val: 9.8379 acc_val: 0.4883 time: 0.0469s
Epoch: 0036 loss_train: 0.0139 acc_train: 0.9954 loss_val: 9.9862 acc_val: 0.4842 time: 0.0502s
Epoch: 0037 loss_train: 0.0119 acc_train: 0.9936 loss_val: 10.1539 acc_val: 0.4787 time: 0.0535s
Epoch: 0038 loss_train: 0.0096 acc_train: 0.9973 loss_val: 10.2724 acc_val: 0.4705 time: 0.1437s
Epoch: 0039 loss_train: 0.0135 acc_train: 0.9973 loss_val: 10.3490 acc_val: 0.4733 time: 0.0484s
Epoch: 0040 loss_train: 0.0105 acc_train: 0.9954 loss_val: 10.4294 acc_val: 0.4705 time: 0.0506s
Epoch: 0041 loss_train: 0.0086 acc_train: 0.9982 loss_val: 10.4979 acc_val: 0.4678 time: 0.0484s
Epoch: 0042 loss_train: 0.0077 acc_train: 0.9982 loss_val: 10.5602 acc_val: 0.4664 time: 0.0469s
Early stopping...
Optimization Finished!
Total time elapsed: 2.3431s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split7_results.txt
Test set results: loss= 10.0136 accuracy= 0.4912
Epoch: 0001 loss_train: 1.6115 acc_train: 0.1941 loss_val: 1.5749 acc_val: 0.3045 time: 0.0720s
Epoch: 0002 loss_train: 1.4749 acc_train: 0.4313 loss_val: 1.4617 acc_val: 0.3567 time: 0.0672s
Epoch: 0003 loss_train: 1.0983 acc_train: 0.7811 loss_val: 1.4602 acc_val: 0.4280 time: 0.0550s
Epoch: 0004 loss_train: 0.7309 acc_train: 0.8562 loss_val: 1.6310 acc_val: 0.4540 time: 0.0542s
Epoch: 0005 loss_train: 0.4837 acc_train: 0.8947 loss_val: 1.8661 acc_val: 0.5048 time: 0.0687s
Epoch: 0006 loss_train: 0.3217 acc_train: 0.9322 loss_val: 2.1932 acc_val: 0.5007 time: 0.0534s
Epoch: 0007 loss_train: 0.2195 acc_train: 0.9551 loss_val: 2.7745 acc_val: 0.5089 time: 0.0488s
Epoch: 0008 loss_train: 0.1504 acc_train: 0.9625 loss_val: 3.2875 acc_val: 0.5158 time: 0.0451s
Epoch: 0009 loss_train: 0.1234 acc_train: 0.9652 loss_val: 3.6320 acc_val: 0.5350 time: 0.0587s
Epoch: 0010 loss_train: 0.0933 acc_train: 0.9753 loss_val: 3.9953 acc_val: 0.5391 time: 0.1178s
Epoch: 0011 loss_train: 0.0922 acc_train: 0.9734 loss_val: 4.3714 acc_val: 0.5391 time: 0.0600s
Epoch: 0012 loss_train: 0.0799 acc_train: 0.9762 loss_val: 4.7649 acc_val: 0.5377 time: 0.0487s
Epoch: 0013 loss_train: 0.0715 acc_train: 0.9753 loss_val: 5.0995 acc_val: 0.5364 time: 0.0490s
Epoch: 0014 loss_train: 0.0640 acc_train: 0.9789 loss_val: 5.4086 acc_val: 0.5364 time: 0.0492s
Epoch: 0015 loss_train: 0.0534 acc_train: 0.9835 loss_val: 5.7844 acc_val: 0.5281 time: 0.0448s
Epoch: 0016 loss_train: 0.0525 acc_train: 0.9826 loss_val: 6.1626 acc_val: 0.5336 time: 0.0487s
Epoch: 0017 loss_train: 0.0539 acc_train: 0.9817 loss_val: 6.3363 acc_val: 0.5336 time: 0.0547s
Epoch: 0018 loss_train: 0.0427 acc_train: 0.9872 loss_val: 6.5344 acc_val: 0.5240 time: 0.0491s
Epoch: 0019 loss_train: 0.0363 acc_train: 0.9899 loss_val: 6.7223 acc_val: 0.5240 time: 0.0507s
Epoch: 0020 loss_train: 0.0306 acc_train: 0.9927 loss_val: 6.9303 acc_val: 0.5213 time: 0.0513s
Epoch: 0021 loss_train: 0.0308 acc_train: 0.9927 loss_val: 7.1648 acc_val: 0.5267 time: 0.0477s
Epoch: 0022 loss_train: 0.0347 acc_train: 0.9918 loss_val: 7.4020 acc_val: 0.5240 time: 0.0441s
Epoch: 0023 loss_train: 0.0324 acc_train: 0.9918 loss_val: 7.6528 acc_val: 0.5226 time: 0.0457s
Epoch: 0024 loss_train: 0.0247 acc_train: 0.9936 loss_val: 7.9171 acc_val: 0.5254 time: 0.0473s
Epoch: 0025 loss_train: 0.0256 acc_train: 0.9908 loss_val: 8.1779 acc_val: 0.5336 time: 0.0526s
Epoch: 0026 loss_train: 0.0251 acc_train: 0.9927 loss_val: 8.5044 acc_val: 0.5267 time: 0.0485s
Epoch: 0027 loss_train: 0.0273 acc_train: 0.9899 loss_val: 8.8917 acc_val: 0.5281 time: 0.0498s
Epoch: 0028 loss_train: 0.0169 acc_train: 0.9954 loss_val: 9.2862 acc_val: 0.5281 time: 0.0470s
Epoch: 0029 loss_train: 0.0182 acc_train: 0.9945 loss_val: 9.6807 acc_val: 0.5267 time: 0.0467s
Epoch: 0030 loss_train: 0.0146 acc_train: 0.9963 loss_val: 10.1439 acc_val: 0.5213 time: 0.0478s
Epoch: 0031 loss_train: 0.0239 acc_train: 0.9936 loss_val: 10.1724 acc_val: 0.5199 time: 0.0505s
Epoch: 0032 loss_train: 0.0166 acc_train: 0.9963 loss_val: 10.1823 acc_val: 0.5185 time: 0.0457s
Epoch: 0033 loss_train: 0.0162 acc_train: 0.9927 loss_val: 10.2310 acc_val: 0.5213 time: 0.0932s
Epoch: 0034 loss_train: 0.0131 acc_train: 0.9945 loss_val: 10.2499 acc_val: 0.5185 time: 0.0549s
Epoch: 0035 loss_train: 0.0129 acc_train: 0.9954 loss_val: 10.2626 acc_val: 0.5199 time: 0.0561s
Epoch: 0036 loss_train: 0.0101 acc_train: 0.9963 loss_val: 10.3027 acc_val: 0.5226 time: 0.0495s
Epoch: 0037 loss_train: 0.0110 acc_train: 0.9945 loss_val: 10.3862 acc_val: 0.5226 time: 0.0504s
Epoch: 0038 loss_train: 0.0087 acc_train: 0.9973 loss_val: 10.5044 acc_val: 0.5226 time: 0.0466s
Epoch: 0039 loss_train: 0.0099 acc_train: 0.9973 loss_val: 10.6167 acc_val: 0.5213 time: 0.0432s
Epoch: 0040 loss_train: 0.0100 acc_train: 0.9963 loss_val: 10.6989 acc_val: 0.5267 time: 0.0455s
Epoch: 0041 loss_train: 0.0073 acc_train: 0.9973 loss_val: 10.8094 acc_val: 0.5322 time: 0.0493s
Epoch: 0042 loss_train: 0.0092 acc_train: 0.9973 loss_val: 10.9409 acc_val: 0.5309 time: 0.0494s
Early stopping...
Optimization Finished!
Total time elapsed: 2.2601s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split8_results.txt
Test set results: loss= 10.7133 accuracy= 0.4956
Epoch: 0001 loss_train: 1.6099 acc_train: 0.2051 loss_val: 1.5965 acc_val: 0.2977 time: 0.1015s
Epoch: 0002 loss_train: 1.4883 acc_train: 0.4625 loss_val: 1.4948 acc_val: 0.4102 time: 0.0490s
Epoch: 0003 loss_train: 1.1261 acc_train: 0.8168 loss_val: 1.5050 acc_val: 0.4458 time: 0.0495s
Epoch: 0004 loss_train: 0.7634 acc_train: 0.8626 loss_val: 1.6756 acc_val: 0.4554 time: 0.0449s
Epoch: 0005 loss_train: 0.5122 acc_train: 0.8993 loss_val: 1.9580 acc_val: 0.4595 time: 0.0566s
Epoch: 0006 loss_train: 0.3320 acc_train: 0.9130 loss_val: 2.3320 acc_val: 0.4733 time: 0.0483s
Epoch: 0007 loss_train: 0.2177 acc_train: 0.9451 loss_val: 2.7551 acc_val: 0.4760 time: 0.0418s
Epoch: 0008 loss_train: 0.1547 acc_train: 0.9533 loss_val: 3.3108 acc_val: 0.5007 time: 0.1461s
Epoch: 0009 loss_train: 0.1179 acc_train: 0.9606 loss_val: 3.9543 acc_val: 0.4938 time: 0.0853s
Epoch: 0010 loss_train: 0.1109 acc_train: 0.9652 loss_val: 4.4510 acc_val: 0.5075 time: 0.0756s
Epoch: 0011 loss_train: 0.0958 acc_train: 0.9725 loss_val: 4.9601 acc_val: 0.4993 time: 0.0737s
Epoch: 0012 loss_train: 0.0935 acc_train: 0.9716 loss_val: 5.5928 acc_val: 0.4966 time: 0.0513s
Epoch: 0013 loss_train: 0.1041 acc_train: 0.9716 loss_val: 5.9499 acc_val: 0.4966 time: 0.0507s
Epoch: 0014 loss_train: 0.0788 acc_train: 0.9679 loss_val: 6.3876 acc_val: 0.4966 time: 0.0676s
Epoch: 0015 loss_train: 0.0805 acc_train: 0.9716 loss_val: 6.8230 acc_val: 0.4883 time: 0.0455s
Epoch: 0016 loss_train: 0.0779 acc_train: 0.9707 loss_val: 7.2021 acc_val: 0.4938 time: 0.0515s
Epoch: 0017 loss_train: 0.0683 acc_train: 0.9762 loss_val: 7.5144 acc_val: 0.4952 time: 0.0592s
Epoch: 0018 loss_train: 0.0575 acc_train: 0.9799 loss_val: 7.8165 acc_val: 0.4938 time: 0.0444s
Epoch: 0019 loss_train: 0.0510 acc_train: 0.9835 loss_val: 8.1163 acc_val: 0.4925 time: 0.0471s
Epoch: 0020 loss_train: 0.0531 acc_train: 0.9826 loss_val: 8.4297 acc_val: 0.4966 time: 0.0585s
Epoch: 0021 loss_train: 0.0508 acc_train: 0.9853 loss_val: 8.7530 acc_val: 0.4952 time: 0.1403s
Epoch: 0022 loss_train: 0.0429 acc_train: 0.9881 loss_val: 9.0423 acc_val: 0.4897 time: 0.0446s
Epoch: 0023 loss_train: 0.0349 acc_train: 0.9899 loss_val: 9.2948 acc_val: 0.4883 time: 0.0472s
Epoch: 0024 loss_train: 0.0465 acc_train: 0.9881 loss_val: 9.5180 acc_val: 0.4856 time: 0.0549s
Epoch: 0025 loss_train: 0.0391 acc_train: 0.9881 loss_val: 9.7242 acc_val: 0.4842 time: 0.0484s
Epoch: 0026 loss_train: 0.0378 acc_train: 0.9908 loss_val: 9.9336 acc_val: 0.4801 time: 0.0462s
Epoch: 0027 loss_train: 0.0313 acc_train: 0.9918 loss_val: 10.1537 acc_val: 0.4801 time: 0.0512s
Epoch: 0028 loss_train: 0.0297 acc_train: 0.9927 loss_val: 10.2707 acc_val: 0.4842 time: 0.0505s
Epoch: 0029 loss_train: 0.0278 acc_train: 0.9927 loss_val: 10.4635 acc_val: 0.4801 time: 0.0484s
Epoch: 0030 loss_train: 0.0267 acc_train: 0.9927 loss_val: 10.6711 acc_val: 0.4787 time: 0.0460s
Epoch: 0031 loss_train: 0.0269 acc_train: 0.9936 loss_val: 10.8705 acc_val: 0.4787 time: 0.0482s
Epoch: 0032 loss_train: 0.0300 acc_train: 0.9908 loss_val: 11.0223 acc_val: 0.4760 time: 0.0488s
Epoch: 0033 loss_train: 0.0211 acc_train: 0.9945 loss_val: 11.1428 acc_val: 0.4746 time: 0.0496s
Epoch: 0034 loss_train: 0.0184 acc_train: 0.9954 loss_val: 11.2497 acc_val: 0.4719 time: 0.0530s
Epoch: 0035 loss_train: 0.0232 acc_train: 0.9936 loss_val: 11.3325 acc_val: 0.4636 time: 0.0423s
Epoch: 0036 loss_train: 0.0190 acc_train: 0.9954 loss_val: 11.4277 acc_val: 0.4664 time: 0.0558s
Epoch: 0037 loss_train: 0.0163 acc_train: 0.9954 loss_val: 11.5309 acc_val: 0.4650 time: 0.0469s
Epoch: 0038 loss_train: 0.0174 acc_train: 0.9945 loss_val: 11.6076 acc_val: 0.4705 time: 0.0462s
Epoch: 0039 loss_train: 0.0222 acc_train: 0.9954 loss_val: 11.6296 acc_val: 0.4691 time: 0.0470s
Epoch: 0040 loss_train: 0.0161 acc_train: 0.9963 loss_val: 11.6138 acc_val: 0.4678 time: 0.0515s
Epoch: 0041 loss_train: 0.0191 acc_train: 0.9945 loss_val: 11.5904 acc_val: 0.4650 time: 0.0467s
Epoch: 0042 loss_train: 0.0151 acc_train: 0.9954 loss_val: 11.5804 acc_val: 0.4664 time: 0.0498s
Early stopping...
Optimization Finished!
Total time elapsed: 2.4136s
chameleon_lr0.1_do0.1_es40_wd0.0_alpha1.0_beta10000.0_gamma0.9_nlid2_nl2_ordersid3_orders3_split9_results.txt
Test set results: loss= 11.1832 accuracy= 0.4890
Epoch: 0001 loss_train: 1.6104 acc_train: 0.1609 loss_val: 1.5681 acc_val: 0.5424 time: 0.0345s
Epoch: 0002 loss_train: 1.5595 acc_train: 0.5632 loss_val: 1.4291 acc_val: 0.5424 time: 0.0149s
Epoch: 0003 loss_train: 1.3958 acc_train: 0.5632 loss_val: 1.2732 acc_val: 0.5424 time: 0.0351s
Epoch: 0004 loss_train: 1.2003 acc_train: 0.5632 loss_val: 1.2513 acc_val: 0.5424 time: 0.1094s
Epoch: 0005 loss_train: 1.1295 acc_train: 0.5632 loss_val: 1.2262 acc_val: 0.5424 time: 0.0093s
Epoch: 0006 loss_train: 1.0492 acc_train: 0.5632 loss_val: 1.1102 acc_val: 0.5424 time: 0.0078s
Epoch: 0007 loss_train: 0.9031 acc_train: 0.5632 loss_val: 1.0353 acc_val: 0.6610 time: 0.0098s
Epoch: 0008 loss_train: 0.8024 acc_train: 0.7126 loss_val: 0.9845 acc_val: 0.7627 time: 0.0076s
Epoch: 0009 loss_train: 0.7034 acc_train: 0.8851 loss_val: 0.8742 acc_val: 0.7966 time: 0.0074s
Epoch: 0010 loss_train: 0.5457 acc_train: 0.9080 loss_val: 0.7487 acc_val: 0.7627 time: 0.0102s
Epoch: 0011 loss_train: 0.3963 acc_train: 0.9195 loss_val: 0.6693 acc_val: 0.7627 time: 0.0075s
Epoch: 0012 loss_train: 0.2760 acc_train: 0.9080 loss_val: 0.6341 acc_val: 0.7627 time: 0.0127s
Epoch: 0013 loss_train: 0.1949 acc_train: 0.9425 loss_val: 0.6351 acc_val: 0.7458 time: 0.0088s
Epoch: 0014 loss_train: 0.1240 acc_train: 0.9770 loss_val: 0.6970 acc_val: 0.7288 time: 0.0085s
Epoch: 0015 loss_train: 0.0838 acc_train: 0.9885 loss_val: 0.8062 acc_val: 0.7288 time: 0.0093s
Epoch: 0016 loss_train: 0.0562 acc_train: 0.9885 loss_val: 0.9640 acc_val: 0.7119 time: 0.0075s
Epoch: 0017 loss_train: 0.0430 acc_train: 0.9885 loss_val: 1.2080 acc_val: 0.7288 time: 0.0080s
Epoch: 0018 loss_train: 0.0522 acc_train: 0.9885 loss_val: 1.5355 acc_val: 0.7288 time: 0.0075s
Epoch: 0019 loss_train: 0.0495 acc_train: 0.9885 loss_val: 1.9218 acc_val: 0.7458 time: 0.0085s
Epoch: 0020 loss_train: 0.0451 acc_train: 0.9885 loss_val: 2.3718 acc_val: 0.7458 time: 0.0352s
Epoch: 0021 loss_train: 0.0365 acc_train: 0.9885 loss_val: 2.8893 acc_val: 0.7627 time: 0.0069s
Epoch: 0022 loss_train: 0.0240 acc_train: 0.9885 loss_val: 3.4504 acc_val: 0.7797 time: 0.0075s
Epoch: 0023 loss_train: 0.0195 acc_train: 0.9885 loss_val: 4.0198 acc_val: 0.7627 time: 0.0078s
Epoch: 0024 loss_train: 0.0132 acc_train: 1.0000 loss_val: 4.5744 acc_val: 0.7627 time: 0.0074s
Epoch: 0025 loss_train: 0.0168 acc_train: 1.0000 loss_val: 5.1008 acc_val: 0.7627 time: 0.0077s
Epoch: 0026 loss_train: 0.0163 acc_train: 1.0000 loss_val: 5.5950 acc_val: 0.7627 time: 0.0093s
Epoch: 0027 loss_train: 0.0125 acc_train: 1.0000 loss_val: 6.0655 acc_val: 0.7627 time: 0.0082s
Epoch: 0028 loss_train: 0.0094 acc_train: 1.0000 loss_val: 6.5136 acc_val: 0.7627 time: 0.0096s
Epoch: 0029 loss_train: 0.0054 acc_train: 1.0000 loss_val: 6.9408 acc_val: 0.7627 time: 0.0074s
Epoch: 0030 loss_train: 0.0028 acc_train: 1.0000 loss_val: 7.3519 acc_val: 0.7627 time: 0.0073s
Epoch: 0031 loss_train: 0.0028 acc_train: 1.0000 loss_val: 7.7511 acc_val: 0.7627 time: 0.0080s
Epoch: 0032 loss_train: 0.0022 acc_train: 1.0000 loss_val: 8.1479 acc_val: 0.7627 time: 0.0127s
Epoch: 0033 loss_train: 0.0009 acc_train: 1.0000 loss_val: 8.5453 acc_val: 0.7458 time: 0.0075s
Epoch: 0034 loss_train: 0.0009 acc_train: 1.0000 loss_val: 8.9464 acc_val: 0.7458 time: 0.0085s
Epoch: 0035 loss_train: 0.0963 acc_train: 0.9885 loss_val: 10.5328 acc_val: 0.7797 time: 0.0247s
Epoch: 0036 loss_train: 0.0009 acc_train: 1.0000 loss_val: 12.1974 acc_val: 0.7627 time: 0.0144s
Epoch: 0037 loss_train: 0.0005 acc_train: 1.0000 loss_val: 13.7804 acc_val: 0.7458 time: 0.0074s
Epoch: 0038 loss_train: 0.1353 acc_train: 0.9885 loss_val: 12.1900 acc_val: 0.7458 time: 0.0066s
Epoch: 0039 loss_train: 0.0006 acc_train: 1.0000 loss_val: 10.8914 acc_val: 0.7288 time: 0.0067s
Epoch: 0040 loss_train: 0.0009 acc_train: 1.0000 loss_val: 9.9630 acc_val: 0.7458 time: 0.0083s
Epoch: 0041 loss_train: 0.0003 acc_train: 1.0000 loss_val: 9.2543 acc_val: 0.7458 time: 0.0090s
Epoch: 0042 loss_train: 0.0023 acc_train: 1.0000 loss_val: 8.6435 acc_val: 0.7458 time: 0.0074s
Early stopping...
Optimization Finished!
Total time elapsed: 0.5609s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split0_results.txt
Test set results: loss= 18.4527 accuracy= 0.5676
Epoch: 0001 loss_train: 1.6095 acc_train: 0.1609 loss_val: 1.5739 acc_val: 0.5763 time: 0.0225s
Epoch: 0002 loss_train: 1.5647 acc_train: 0.5402 loss_val: 1.4442 acc_val: 0.5763 time: 0.0478s
Epoch: 0003 loss_train: 1.4182 acc_train: 0.5172 loss_val: 1.2874 acc_val: 0.5763 time: 0.0137s
Epoch: 0004 loss_train: 1.2291 acc_train: 0.5172 loss_val: 1.2338 acc_val: 0.5763 time: 0.0093s
Epoch: 0005 loss_train: 1.1367 acc_train: 0.5172 loss_val: 1.2467 acc_val: 0.5763 time: 0.0067s
Epoch: 0006 loss_train: 1.0697 acc_train: 0.5172 loss_val: 1.1821 acc_val: 0.5763 time: 0.0067s
Epoch: 0007 loss_train: 0.9269 acc_train: 0.5172 loss_val: 1.1579 acc_val: 0.5932 time: 0.0071s
Epoch: 0008 loss_train: 0.8474 acc_train: 0.8736 loss_val: 1.1171 acc_val: 0.7627 time: 0.0089s
Epoch: 0009 loss_train: 0.7566 acc_train: 0.9195 loss_val: 0.9990 acc_val: 0.7627 time: 0.0145s
Epoch: 0010 loss_train: 0.6071 acc_train: 0.9195 loss_val: 0.8852 acc_val: 0.7288 time: 0.0184s
Epoch: 0011 loss_train: 0.4452 acc_train: 0.9080 loss_val: 0.8801 acc_val: 0.7119 time: 0.0073s
Epoch: 0012 loss_train: 0.3195 acc_train: 0.9080 loss_val: 0.8317 acc_val: 0.7288 time: 0.0070s
Epoch: 0013 loss_train: 0.2003 acc_train: 0.9310 loss_val: 0.7216 acc_val: 0.7627 time: 0.0072s
Epoch: 0014 loss_train: 0.1180 acc_train: 0.9425 loss_val: 0.6762 acc_val: 0.7797 time: 0.0074s
Epoch: 0015 loss_train: 0.0927 acc_train: 0.9885 loss_val: 0.6865 acc_val: 0.7797 time: 0.0083s
Epoch: 0016 loss_train: 0.0611 acc_train: 0.9885 loss_val: 0.7356 acc_val: 0.7797 time: 0.0141s
Epoch: 0017 loss_train: 0.0245 acc_train: 1.0000 loss_val: 0.8397 acc_val: 0.7797 time: 0.0072s
Epoch: 0018 loss_train: 0.0161 acc_train: 1.0000 loss_val: 0.9973 acc_val: 0.7966 time: 0.0065s
Epoch: 0019 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.2190 acc_val: 0.7966 time: 0.0075s
Epoch: 0020 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.4923 acc_val: 0.7966 time: 0.0091s
Epoch: 0021 loss_train: 0.0153 acc_train: 0.9885 loss_val: 1.8238 acc_val: 0.8136 time: 0.0111s
Epoch: 0022 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2066 acc_val: 0.8136 time: 0.0076s
Epoch: 0023 loss_train: 0.0007 acc_train: 1.0000 loss_val: 2.6380 acc_val: 0.8475 time: 0.0084s
Epoch: 0024 loss_train: 0.0010 acc_train: 1.0000 loss_val: 3.1105 acc_val: 0.8475 time: 0.0080s
Epoch: 0025 loss_train: 0.0034 acc_train: 1.0000 loss_val: 3.5372 acc_val: 0.8475 time: 0.0082s
Epoch: 0026 loss_train: 0.0026 acc_train: 1.0000 loss_val: 3.9641 acc_val: 0.8305 time: 0.0071s
Epoch: 0027 loss_train: 0.0012 acc_train: 1.0000 loss_val: 4.4304 acc_val: 0.8305 time: 0.0092s
Epoch: 0028 loss_train: 0.0005 acc_train: 1.0000 loss_val: 4.9170 acc_val: 0.8305 time: 0.0089s
Epoch: 0029 loss_train: 0.0000 acc_train: 1.0000 loss_val: 5.4066 acc_val: 0.8305 time: 0.0067s
Epoch: 0030 loss_train: 0.0000 acc_train: 1.0000 loss_val: 5.8999 acc_val: 0.8475 time: 0.0120s
Epoch: 0031 loss_train: 0.0001 acc_train: 1.0000 loss_val: 6.3881 acc_val: 0.8475 time: 0.0094s
Epoch: 0032 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.8691 acc_val: 0.8475 time: 0.0089s
Epoch: 0033 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.3420 acc_val: 0.8644 time: 0.0159s
Epoch: 0034 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.8041 acc_val: 0.8644 time: 0.0074s
Epoch: 0035 loss_train: 0.0001 acc_train: 1.0000 loss_val: 8.2442 acc_val: 0.8475 time: 0.0074s
Epoch: 0036 loss_train: 0.0000 acc_train: 1.0000 loss_val: 8.6652 acc_val: 0.8475 time: 0.0342s
Epoch: 0037 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.0658 acc_val: 0.8475 time: 0.0076s
Epoch: 0038 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.4439 acc_val: 0.8475 time: 0.0085s
Epoch: 0039 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.7990 acc_val: 0.8475 time: 0.0082s
Epoch: 0040 loss_train: 0.0000 acc_train: 1.0000 loss_val: 10.1312 acc_val: 0.8475 time: 0.0076s
Epoch: 0041 loss_train: 0.0000 acc_train: 1.0000 loss_val: 10.4176 acc_val: 0.8475 time: 0.0074s
Epoch: 0042 loss_train: 0.0001 acc_train: 1.0000 loss_val: 10.6648 acc_val: 0.8475 time: 0.0116s
Early stopping...
Optimization Finished!
Total time elapsed: 0.4595s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split1_results.txt
Test set results: loss= 21.6173 accuracy= 0.7568
Epoch: 0001 loss_train: 1.6101 acc_train: 0.2299 loss_val: 1.5669 acc_val: 0.5593 time: 0.0684s
Epoch: 0002 loss_train: 1.5621 acc_train: 0.5402 loss_val: 1.4272 acc_val: 0.5593 time: 0.0122s
Epoch: 0003 loss_train: 1.4102 acc_train: 0.5402 loss_val: 1.2789 acc_val: 0.5593 time: 0.0245s
Epoch: 0004 loss_train: 1.2307 acc_train: 0.5402 loss_val: 1.2778 acc_val: 0.5593 time: 0.0101s
Epoch: 0005 loss_train: 1.2071 acc_train: 0.5402 loss_val: 1.1732 acc_val: 0.5593 time: 0.0101s
Epoch: 0006 loss_train: 1.0771 acc_train: 0.5402 loss_val: 1.0698 acc_val: 0.5593 time: 0.0107s
Epoch: 0007 loss_train: 0.9384 acc_train: 0.5402 loss_val: 1.0176 acc_val: 0.5593 time: 0.0290s
Epoch: 0008 loss_train: 0.8649 acc_train: 0.6897 loss_val: 0.9609 acc_val: 0.6949 time: 0.0077s
Epoch: 0009 loss_train: 0.7564 acc_train: 0.8391 loss_val: 0.8505 acc_val: 0.7458 time: 0.0132s
Epoch: 0010 loss_train: 0.6031 acc_train: 0.8736 loss_val: 0.7186 acc_val: 0.7458 time: 0.0508s
Epoch: 0011 loss_train: 0.4216 acc_train: 0.8851 loss_val: 0.6424 acc_val: 0.7458 time: 0.0100s
Epoch: 0012 loss_train: 0.2578 acc_train: 0.9425 loss_val: 0.5875 acc_val: 0.7627 time: 0.0073s
Epoch: 0013 loss_train: 0.1703 acc_train: 0.9770 loss_val: 0.5089 acc_val: 0.8305 time: 0.0081s
Epoch: 0014 loss_train: 0.0813 acc_train: 0.9770 loss_val: 0.4531 acc_val: 0.8475 time: 0.0569s
Epoch: 0015 loss_train: 0.0452 acc_train: 0.9885 loss_val: 0.5143 acc_val: 0.8305 time: 0.0177s
Epoch: 0016 loss_train: 0.0344 acc_train: 0.9885 loss_val: 0.6814 acc_val: 0.8136 time: 0.0301s
Epoch: 0017 loss_train: 0.0223 acc_train: 1.0000 loss_val: 0.8883 acc_val: 0.8305 time: 0.0075s
Epoch: 0018 loss_train: 0.0019 acc_train: 1.0000 loss_val: 1.3718 acc_val: 0.8305 time: 0.0226s
Epoch: 0019 loss_train: 0.0005 acc_train: 1.0000 loss_val: 2.0232 acc_val: 0.7966 time: 0.0081s
Epoch: 0020 loss_train: 0.0004 acc_train: 1.0000 loss_val: 2.7475 acc_val: 0.7966 time: 0.0162s
Epoch: 0021 loss_train: 0.0580 acc_train: 0.9885 loss_val: 2.6365 acc_val: 0.8305 time: 0.0123s
Epoch: 0022 loss_train: 0.0000 acc_train: 1.0000 loss_val: 2.7225 acc_val: 0.8305 time: 0.0161s
Epoch: 0023 loss_train: 0.0000 acc_train: 1.0000 loss_val: 3.0695 acc_val: 0.8475 time: 0.0113s
Epoch: 0024 loss_train: 0.0566 acc_train: 0.9885 loss_val: 3.6823 acc_val: 0.8136 time: 0.0197s
Epoch: 0025 loss_train: 0.0000 acc_train: 1.0000 loss_val: 4.5680 acc_val: 0.8136 time: 0.0078s
Epoch: 0026 loss_train: 0.0000 acc_train: 1.0000 loss_val: 5.5504 acc_val: 0.7966 time: 0.0098s
Epoch: 0027 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.6128 acc_val: 0.7797 time: 0.0117s
Epoch: 0028 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.8200 acc_val: 0.7458 time: 0.0110s
Epoch: 0029 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.0699 acc_val: 0.7288 time: 0.0371s
Epoch: 0030 loss_train: 0.0001 acc_train: 1.0000 loss_val: 10.2445 acc_val: 0.7288 time: 0.0151s
Epoch: 0031 loss_train: 0.0002 acc_train: 1.0000 loss_val: 11.3365 acc_val: 0.7288 time: 0.0083s
Epoch: 0032 loss_train: 0.0001 acc_train: 1.0000 loss_val: 12.3675 acc_val: 0.7288 time: 0.0087s
Epoch: 0033 loss_train: 0.1398 acc_train: 0.9885 loss_val: 10.6871 acc_val: 0.7288 time: 0.0091s
Epoch: 0034 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.2144 acc_val: 0.7797 time: 0.0085s
Epoch: 0035 loss_train: 0.0000 acc_train: 1.0000 loss_val: 8.2606 acc_val: 0.7966 time: 0.0103s
Epoch: 0036 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.5895 acc_val: 0.8136 time: 0.0091s
Epoch: 0037 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.0536 acc_val: 0.8305 time: 0.0093s
Epoch: 0038 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.6503 acc_val: 0.8305 time: 0.0476s
Epoch: 0039 loss_train: 0.0017 acc_train: 1.0000 loss_val: 6.5186 acc_val: 0.8644 time: 0.0093s
Epoch: 0040 loss_train: 0.0007 acc_train: 1.0000 loss_val: 6.4278 acc_val: 0.8644 time: 0.0108s
Epoch: 0041 loss_train: 0.0032 acc_train: 1.0000 loss_val: 6.3662 acc_val: 0.8644 time: 0.0087s
Epoch: 0042 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.3262 acc_val: 0.8475 time: 0.0322s
Early stopping...
Optimization Finished!
Total time elapsed: 0.7457s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split2_results.txt
Test set results: loss= 9.0289 accuracy= 0.8108
Epoch: 0001 loss_train: 1.6098 acc_train: 0.2184 loss_val: 1.5620 acc_val: 0.5932 time: 0.0351s
Epoch: 0002 loss_train: 1.5640 acc_train: 0.5172 loss_val: 1.4000 acc_val: 0.5932 time: 0.0141s
Epoch: 0003 loss_train: 1.4160 acc_train: 0.5172 loss_val: 1.2087 acc_val: 0.5932 time: 0.0175s
Epoch: 0004 loss_train: 1.2541 acc_train: 0.5172 loss_val: 1.1345 acc_val: 0.5932 time: 0.0140s
Epoch: 0005 loss_train: 1.2407 acc_train: 0.5172 loss_val: 1.0411 acc_val: 0.5932 time: 0.0109s
Epoch: 0006 loss_train: 1.0616 acc_train: 0.5172 loss_val: 0.9605 acc_val: 0.5932 time: 0.0171s
Epoch: 0007 loss_train: 0.9063 acc_train: 0.6437 loss_val: 0.9246 acc_val: 0.7458 time: 0.0116s
Epoch: 0008 loss_train: 0.8111 acc_train: 0.6897 loss_val: 0.8405 acc_val: 0.7458 time: 0.0081s
Epoch: 0009 loss_train: 0.6581 acc_train: 0.8161 loss_val: 0.7262 acc_val: 0.7966 time: 0.0117s
Epoch: 0010 loss_train: 0.4948 acc_train: 0.8621 loss_val: 0.7174 acc_val: 0.7966 time: 0.0125s
Epoch: 0011 loss_train: 0.4115 acc_train: 0.8736 loss_val: 0.7422 acc_val: 0.7797 time: 0.0114s
Epoch: 0012 loss_train: 0.3134 acc_train: 0.9195 loss_val: 0.6853 acc_val: 0.7797 time: 0.0099s
Epoch: 0013 loss_train: 0.2105 acc_train: 0.9655 loss_val: 0.5731 acc_val: 0.8305 time: 0.0101s
Epoch: 0014 loss_train: 0.1131 acc_train: 0.9770 loss_val: 0.6396 acc_val: 0.7627 time: 0.0098s
Epoch: 0015 loss_train: 0.0830 acc_train: 0.9885 loss_val: 0.6856 acc_val: 0.7627 time: 0.0113s
Epoch: 0016 loss_train: 0.0570 acc_train: 0.9885 loss_val: 0.8171 acc_val: 0.7797 time: 0.0081s
Epoch: 0017 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.3189 acc_val: 0.7627 time: 0.0082s
Epoch: 0018 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1141 acc_val: 0.7627 time: 0.0146s
Epoch: 0019 loss_train: 0.0521 acc_train: 0.9885 loss_val: 2.1582 acc_val: 0.7797 time: 0.0095s
Epoch: 0020 loss_train: 0.0115 acc_train: 0.9885 loss_val: 1.7930 acc_val: 0.7797 time: 0.0074s
Epoch: 0021 loss_train: 0.0003 acc_train: 1.0000 loss_val: 1.5549 acc_val: 0.8136 time: 0.0101s
Epoch: 0022 loss_train: 0.0000 acc_train: 1.0000 loss_val: 1.4759 acc_val: 0.8305 time: 0.0105s
Epoch: 0023 loss_train: 0.0000 acc_train: 1.0000 loss_val: 1.5169 acc_val: 0.8475 time: 0.0076s
Epoch: 0024 loss_train: 0.0000 acc_train: 1.0000 loss_val: 1.7284 acc_val: 0.8475 time: 0.0083s
Epoch: 0025 loss_train: 0.0000 acc_train: 1.0000 loss_val: 2.0088 acc_val: 0.8305 time: 0.0077s
Epoch: 0026 loss_train: 0.0000 acc_train: 1.0000 loss_val: 2.3578 acc_val: 0.8305 time: 0.0103s
Epoch: 0027 loss_train: 0.0006 acc_train: 1.0000 loss_val: 2.7033 acc_val: 0.8305 time: 0.0076s
Epoch: 0028 loss_train: 0.0004 acc_train: 1.0000 loss_val: 3.0568 acc_val: 0.8136 time: 0.0127s
Epoch: 0029 loss_train: 0.0463 acc_train: 0.9885 loss_val: 3.4470 acc_val: 0.8305 time: 0.0085s
Epoch: 0030 loss_train: 0.0000 acc_train: 1.0000 loss_val: 4.8973 acc_val: 0.8136 time: 0.0076s
Epoch: 0031 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.9142 acc_val: 0.7797 time: 0.0109s
Epoch: 0032 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.2266 acc_val: 0.7458 time: 0.0086s
Epoch: 0033 loss_train: 0.0596 acc_train: 0.9885 loss_val: 8.4153 acc_val: 0.7627 time: 0.0088s
Epoch: 0034 loss_train: 0.0039 acc_train: 1.0000 loss_val: 7.3115 acc_val: 0.7288 time: 0.0078s
Epoch: 0035 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.9398 acc_val: 0.7458 time: 0.0086s
Epoch: 0036 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.9581 acc_val: 0.6949 time: 0.0079s
Epoch: 0037 loss_train: 0.0001 acc_train: 1.0000 loss_val: 8.0636 acc_val: 0.6949 time: 0.0079s
Epoch: 0038 loss_train: 0.0000 acc_train: 1.0000 loss_val: 10.2126 acc_val: 0.6441 time: 0.0075s
Epoch: 0039 loss_train: 0.0658 acc_train: 0.9885 loss_val: 6.7109 acc_val: 0.7119 time: 0.0080s
Epoch: 0040 loss_train: 0.0000 acc_train: 1.0000 loss_val: 4.5715 acc_val: 0.7797 time: 0.0077s
Epoch: 0041 loss_train: 0.0000 acc_train: 1.0000 loss_val: 3.5974 acc_val: 0.8644 time: 0.0076s
Epoch: 0042 loss_train: 0.0000 acc_train: 1.0000 loss_val: 3.3350 acc_val: 0.7966 time: 0.0077s
Early stopping...
Optimization Finished!
Total time elapsed: 0.4433s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split3_results.txt
Test set results: loss= 10.7821 accuracy= 0.8108
Epoch: 0001 loss_train: 1.6101 acc_train: 0.1494 loss_val: 1.5702 acc_val: 0.5254 time: 0.0752s
Epoch: 0002 loss_train: 1.5596 acc_train: 0.5402 loss_val: 1.4507 acc_val: 0.5254 time: 0.0148s
Epoch: 0003 loss_train: 1.3983 acc_train: 0.5402 loss_val: 1.3364 acc_val: 0.5254 time: 0.0157s
Epoch: 0004 loss_train: 1.2077 acc_train: 0.5402 loss_val: 1.4286 acc_val: 0.5254 time: 0.0075s
Epoch: 0005 loss_train: 1.1949 acc_train: 0.5402 loss_val: 1.3216 acc_val: 0.5254 time: 0.0081s
Epoch: 0006 loss_train: 1.0575 acc_train: 0.5402 loss_val: 1.1837 acc_val: 0.5254 time: 0.0093s
Epoch: 0007 loss_train: 0.9063 acc_train: 0.6552 loss_val: 1.1091 acc_val: 0.6271 time: 0.0082s
Epoch: 0008 loss_train: 0.8144 acc_train: 0.7356 loss_val: 1.0268 acc_val: 0.6271 time: 0.0117s
Epoch: 0009 loss_train: 0.6667 acc_train: 0.7701 loss_val: 0.9150 acc_val: 0.6271 time: 0.0107s
Epoch: 0010 loss_train: 0.5049 acc_train: 0.8276 loss_val: 0.8856 acc_val: 0.6441 time: 0.0588s
Epoch: 0011 loss_train: 0.3887 acc_train: 0.8851 loss_val: 0.9380 acc_val: 0.6441 time: 0.0535s
Epoch: 0012 loss_train: 0.3091 acc_train: 0.8736 loss_val: 0.9502 acc_val: 0.6441 time: 0.0071s
Epoch: 0013 loss_train: 0.2528 acc_train: 0.9195 loss_val: 0.8924 acc_val: 0.6441 time: 0.0069s
Epoch: 0014 loss_train: 0.2210 acc_train: 0.9195 loss_val: 0.9168 acc_val: 0.6441 time: 0.0066s
Epoch: 0015 loss_train: 0.1477 acc_train: 0.9770 loss_val: 0.9899 acc_val: 0.6441 time: 0.0069s
Epoch: 0016 loss_train: 0.1236 acc_train: 0.9885 loss_val: 1.1121 acc_val: 0.6441 time: 0.0073s
Epoch: 0017 loss_train: 0.0611 acc_train: 1.0000 loss_val: 1.2895 acc_val: 0.7288 time: 0.0077s
Epoch: 0018 loss_train: 0.0310 acc_train: 1.0000 loss_val: 1.5500 acc_val: 0.7458 time: 0.0159s
Epoch: 0019 loss_train: 0.0138 acc_train: 1.0000 loss_val: 1.9175 acc_val: 0.7458 time: 0.0126s
Epoch: 0020 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.3705 acc_val: 0.7627 time: 0.0091s
Epoch: 0021 loss_train: 0.0015 acc_train: 1.0000 loss_val: 2.9235 acc_val: 0.7119 time: 0.0100s
Epoch: 0022 loss_train: 0.0011 acc_train: 1.0000 loss_val: 3.6556 acc_val: 0.7119 time: 0.0104s
Epoch: 0023 loss_train: 0.0004 acc_train: 1.0000 loss_val: 4.4913 acc_val: 0.7119 time: 0.0077s
Epoch: 0024 loss_train: 0.0006 acc_train: 1.0000 loss_val: 5.3905 acc_val: 0.7627 time: 0.0100s
Epoch: 0025 loss_train: 0.0002 acc_train: 1.0000 loss_val: 6.3667 acc_val: 0.7458 time: 0.0083s
Epoch: 0026 loss_train: 0.0006 acc_train: 1.0000 loss_val: 7.3625 acc_val: 0.7458 time: 0.0070s
Epoch: 0027 loss_train: 0.0001 acc_train: 1.0000 loss_val: 8.3665 acc_val: 0.7458 time: 0.0074s
Epoch: 0028 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.3711 acc_val: 0.7288 time: 0.0071s
Epoch: 0029 loss_train: 0.0000 acc_train: 1.0000 loss_val: 10.3691 acc_val: 0.7119 time: 0.0108s
Epoch: 0030 loss_train: 0.0001 acc_train: 1.0000 loss_val: 11.3313 acc_val: 0.7119 time: 0.0068s
Epoch: 0031 loss_train: 0.0000 acc_train: 1.0000 loss_val: 12.2651 acc_val: 0.7119 time: 0.0099s
Epoch: 0032 loss_train: 0.0000 acc_train: 1.0000 loss_val: 13.1690 acc_val: 0.7119 time: 0.0321s
Epoch: 0033 loss_train: 0.0000 acc_train: 1.0000 loss_val: 14.0383 acc_val: 0.7119 time: 0.0078s
Epoch: 0034 loss_train: 0.0000 acc_train: 1.0000 loss_val: 14.8704 acc_val: 0.7119 time: 0.0102s
Epoch: 0035 loss_train: 0.0000 acc_train: 1.0000 loss_val: 15.6628 acc_val: 0.7119 time: 0.0132s
Epoch: 0036 loss_train: 0.0000 acc_train: 1.0000 loss_val: 16.4142 acc_val: 0.7119 time: 0.0551s
Epoch: 0037 loss_train: 0.0001 acc_train: 1.0000 loss_val: 17.1019 acc_val: 0.7288 time: 0.0076s
Epoch: 0038 loss_train: 0.0253 acc_train: 0.9885 loss_val: 13.4445 acc_val: 0.6949 time: 0.0069s
Epoch: 0039 loss_train: 0.0000 acc_train: 1.0000 loss_val: 11.0706 acc_val: 0.6441 time: 0.0085s
Epoch: 0040 loss_train: 0.0004 acc_train: 1.0000 loss_val: 10.1383 acc_val: 0.6271 time: 0.0068s
Epoch: 0041 loss_train: 0.0115 acc_train: 0.9885 loss_val: 8.6755 acc_val: 0.7288 time: 0.0115s
Epoch: 0042 loss_train: 0.0002 acc_train: 1.0000 loss_val: 11.0172 acc_val: 0.7797 time: 0.0214s
Early stopping...
Optimization Finished!
Total time elapsed: 0.6312s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split4_results.txt
Test set results: loss= 11.4565 accuracy= 0.7568
Epoch: 0001 loss_train: 1.6089 acc_train: 0.2299 loss_val: 1.5595 acc_val: 0.6271 time: 0.0921s
Epoch: 0002 loss_train: 1.5647 acc_train: 0.4713 loss_val: 1.3986 acc_val: 0.6271 time: 0.0094s
Epoch: 0003 loss_train: 1.4319 acc_train: 0.4713 loss_val: 1.1864 acc_val: 0.6271 time: 0.0081s
Epoch: 0004 loss_train: 1.2715 acc_train: 0.4713 loss_val: 1.0270 acc_val: 0.6271 time: 0.0384s
Epoch: 0005 loss_train: 1.2146 acc_train: 0.4713 loss_val: 0.9769 acc_val: 0.6271 time: 0.0071s
Epoch: 0006 loss_train: 1.0588 acc_train: 0.4713 loss_val: 1.0158 acc_val: 0.7288 time: 0.0092s
Epoch: 0007 loss_train: 0.9188 acc_train: 0.8506 loss_val: 0.9868 acc_val: 0.8475 time: 0.0068s
Epoch: 0008 loss_train: 0.7529 acc_train: 0.8851 loss_val: 0.8392 acc_val: 0.8475 time: 0.0070s
Epoch: 0009 loss_train: 0.5286 acc_train: 0.8736 loss_val: 0.7109 acc_val: 0.8136 time: 0.0077s
Epoch: 0010 loss_train: 0.3325 acc_train: 0.8851 loss_val: 0.6641 acc_val: 0.8305 time: 0.0074s
Epoch: 0011 loss_train: 0.2239 acc_train: 0.8851 loss_val: 0.6873 acc_val: 0.8136 time: 0.0068s
Epoch: 0012 loss_train: 0.1530 acc_train: 0.9195 loss_val: 0.7178 acc_val: 0.8305 time: 0.0071s
Epoch: 0013 loss_train: 0.1090 acc_train: 0.9655 loss_val: 0.7644 acc_val: 0.8644 time: 0.0069s
Epoch: 0014 loss_train: 0.0756 acc_train: 0.9770 loss_val: 0.9189 acc_val: 0.8983 time: 0.0082s
Epoch: 0015 loss_train: 0.0781 acc_train: 0.9885 loss_val: 1.1979 acc_val: 0.8814 time: 0.0185s
Epoch: 0016 loss_train: 0.0420 acc_train: 1.0000 loss_val: 1.5865 acc_val: 0.8814 time: 0.0194s
Epoch: 0017 loss_train: 0.0228 acc_train: 1.0000 loss_val: 2.0672 acc_val: 0.8475 time: 0.0096s
Epoch: 0018 loss_train: 0.0132 acc_train: 1.0000 loss_val: 2.6407 acc_val: 0.8475 time: 0.0105s
Epoch: 0019 loss_train: 0.0052 acc_train: 1.0000 loss_val: 3.3221 acc_val: 0.8305 time: 0.0079s
Epoch: 0020 loss_train: 0.0051 acc_train: 1.0000 loss_val: 4.0719 acc_val: 0.8136 time: 0.0146s
Epoch: 0021 loss_train: 0.0292 acc_train: 0.9885 loss_val: 4.4568 acc_val: 0.8475 time: 0.0089s
Epoch: 0022 loss_train: 0.0005 acc_train: 1.0000 loss_val: 5.2025 acc_val: 0.8305 time: 0.0117s
Epoch: 0023 loss_train: 0.0005 acc_train: 1.0000 loss_val: 6.0258 acc_val: 0.7966 time: 0.0173s
Epoch: 0024 loss_train: 0.5607 acc_train: 0.9540 loss_val: 5.1101 acc_val: 0.8475 time: 0.0076s
Epoch: 0025 loss_train: 0.0003 acc_train: 1.0000 loss_val: 5.0957 acc_val: 0.8644 time: 0.0080s
Epoch: 0026 loss_train: 0.0001 acc_train: 1.0000 loss_val: 5.6404 acc_val: 0.8475 time: 0.0078s
Epoch: 0027 loss_train: 0.0003 acc_train: 1.0000 loss_val: 6.6584 acc_val: 0.7458 time: 0.0072s
Epoch: 0028 loss_train: 0.0116 acc_train: 0.9885 loss_val: 7.4269 acc_val: 0.7288 time: 0.0069s
Epoch: 0029 loss_train: 0.2186 acc_train: 0.9770 loss_val: 6.7122 acc_val: 0.7627 time: 0.0074s
Epoch: 0030 loss_train: 0.2031 acc_train: 0.9770 loss_val: 5.4849 acc_val: 0.7627 time: 0.0075s
Epoch: 0031 loss_train: 0.0023 acc_train: 1.0000 loss_val: 4.8873 acc_val: 0.7797 time: 0.0092s
Epoch: 0032 loss_train: 0.1808 acc_train: 0.9885 loss_val: 4.1953 acc_val: 0.8305 time: 0.0088s
Epoch: 0033 loss_train: 0.0000 acc_train: 1.0000 loss_val: 4.5583 acc_val: 0.8475 time: 0.0169s
Epoch: 0034 loss_train: 0.0000 acc_train: 1.0000 loss_val: 5.2025 acc_val: 0.8475 time: 0.0276s
Epoch: 0035 loss_train: 0.0020 acc_train: 1.0000 loss_val: 5.7761 acc_val: 0.8475 time: 0.0075s
Epoch: 0036 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.3225 acc_val: 0.8475 time: 0.0101s
Epoch: 0037 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.0313 acc_val: 0.8136 time: 0.0120s
Epoch: 0038 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.7897 acc_val: 0.7797 time: 0.0074s
Epoch: 0039 loss_train: 0.0000 acc_train: 1.0000 loss_val: 8.5746 acc_val: 0.7627 time: 0.0081s
Epoch: 0040 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.3076 acc_val: 0.7627 time: 0.0109s
Epoch: 0041 loss_train: 0.2169 acc_train: 0.9770 loss_val: 5.9838 acc_val: 0.8136 time: 0.0071s
Epoch: 0042 loss_train: 0.0000 acc_train: 1.0000 loss_val: 4.1904 acc_val: 0.8136 time: 0.0072s
Early stopping...
Optimization Finished!
Total time elapsed: 0.5265s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split5_results.txt
Test set results: loss= 3.6895 accuracy= 0.7027
Epoch: 0001 loss_train: 1.6098 acc_train: 0.1609 loss_val: 1.5738 acc_val: 0.5254 time: 0.0707s
Epoch: 0002 loss_train: 1.5603 acc_train: 0.5287 loss_val: 1.4689 acc_val: 0.5254 time: 0.0081s
Epoch: 0003 loss_train: 1.4032 acc_train: 0.5287 loss_val: 1.3734 acc_val: 0.5254 time: 0.0080s
Epoch: 0004 loss_train: 1.2209 acc_train: 0.5287 loss_val: 1.4391 acc_val: 0.5254 time: 0.0101s
Epoch: 0005 loss_train: 1.1691 acc_train: 0.5287 loss_val: 1.3703 acc_val: 0.5254 time: 0.0074s
Epoch: 0006 loss_train: 1.0557 acc_train: 0.5287 loss_val: 1.2603 acc_val: 0.5254 time: 0.0152s
Epoch: 0007 loss_train: 0.9150 acc_train: 0.6092 loss_val: 1.2061 acc_val: 0.5932 time: 0.0472s
Epoch: 0008 loss_train: 0.8220 acc_train: 0.7241 loss_val: 1.1829 acc_val: 0.6271 time: 0.0098s
Epoch: 0009 loss_train: 0.7218 acc_train: 0.8046 loss_val: 1.1484 acc_val: 0.6441 time: 0.0074s
Epoch: 0010 loss_train: 0.5867 acc_train: 0.8391 loss_val: 1.1412 acc_val: 0.6441 time: 0.0139s
Epoch: 0011 loss_train: 0.4555 acc_train: 0.8391 loss_val: 1.2173 acc_val: 0.6441 time: 0.0071s
Epoch: 0012 loss_train: 0.3375 acc_train: 0.8851 loss_val: 1.3145 acc_val: 0.6441 time: 0.0115s
Epoch: 0013 loss_train: 0.2530 acc_train: 0.8966 loss_val: 1.3625 acc_val: 0.6102 time: 0.0074s
Epoch: 0014 loss_train: 0.1581 acc_train: 0.9655 loss_val: 1.4733 acc_val: 0.6949 time: 0.0099s
Epoch: 0015 loss_train: 0.0950 acc_train: 0.9885 loss_val: 1.6087 acc_val: 0.7458 time: 0.0069s
Epoch: 0016 loss_train: 0.0486 acc_train: 0.9885 loss_val: 1.8140 acc_val: 0.8136 time: 0.0075s
Epoch: 0017 loss_train: 0.0141 acc_train: 1.0000 loss_val: 2.1103 acc_val: 0.8136 time: 0.0076s
Epoch: 0018 loss_train: 0.0075 acc_train: 1.0000 loss_val: 2.4912 acc_val: 0.7966 time: 0.0074s
Epoch: 0019 loss_train: 0.0311 acc_train: 0.9885 loss_val: 2.8177 acc_val: 0.7797 time: 0.0097s
Epoch: 0020 loss_train: 0.0004 acc_train: 1.0000 loss_val: 3.4782 acc_val: 0.7288 time: 0.0085s
Epoch: 0021 loss_train: 0.0003 acc_train: 1.0000 loss_val: 4.4267 acc_val: 0.7119 time: 0.0472s
Epoch: 0022 loss_train: 0.0287 acc_train: 0.9885 loss_val: 5.1420 acc_val: 0.7627 time: 0.0119s
Epoch: 0023 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.3592 acc_val: 0.7797 time: 0.0099s
Epoch: 0024 loss_train: 0.0981 acc_train: 0.9885 loss_val: 6.4801 acc_val: 0.7797 time: 0.0097s
Epoch: 0025 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.9842 acc_val: 0.7288 time: 0.0108s
Epoch: 0026 loss_train: 0.0000 acc_train: 1.0000 loss_val: 8.0924 acc_val: 0.7288 time: 0.0100s
Epoch: 0027 loss_train: 0.0002 acc_train: 1.0000 loss_val: 9.7449 acc_val: 0.6780 time: 0.0088s
Epoch: 0028 loss_train: 0.0462 acc_train: 0.9885 loss_val: 9.5116 acc_val: 0.7627 time: 0.0097s
Epoch: 0029 loss_train: 0.0223 acc_train: 0.9885 loss_val: 8.3374 acc_val: 0.7797 time: 0.0500s
Epoch: 0030 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.6607 acc_val: 0.7627 time: 0.0682s
Epoch: 0031 loss_train: 0.0003 acc_train: 1.0000 loss_val: 7.4599 acc_val: 0.7627 time: 0.0089s
Epoch: 0032 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.5592 acc_val: 0.7458 time: 0.0084s
Epoch: 0033 loss_train: 0.0019 acc_train: 1.0000 loss_val: 7.4141 acc_val: 0.7288 time: 0.0102s
Epoch: 0034 loss_train: 0.0028 acc_train: 1.0000 loss_val: 7.2846 acc_val: 0.7458 time: 0.0084s
Epoch: 0035 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.7796 acc_val: 0.6949 time: 0.0098s
Epoch: 0036 loss_train: 0.0000 acc_train: 1.0000 loss_val: 8.7749 acc_val: 0.6780 time: 0.0086s
Epoch: 0037 loss_train: 0.0000 acc_train: 1.0000 loss_val: 10.1863 acc_val: 0.6610 time: 0.0082s
Epoch: 0038 loss_train: 0.0000 acc_train: 1.0000 loss_val: 11.8309 acc_val: 0.6102 time: 0.0091s
Epoch: 0039 loss_train: 0.0000 acc_train: 1.0000 loss_val: 13.7204 acc_val: 0.5424 time: 0.0089s
Epoch: 0040 loss_train: 0.0201 acc_train: 0.9885 loss_val: 10.2485 acc_val: 0.6949 time: 0.0088s
Epoch: 0041 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.6905 acc_val: 0.7627 time: 0.0089s
Epoch: 0042 loss_train: 0.0000 acc_train: 1.0000 loss_val: 9.9273 acc_val: 0.7966 time: 0.0083s
Early stopping...
Optimization Finished!
Total time elapsed: 0.6246s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split6_results.txt
Test set results: loss= 4.3680 accuracy= 0.8649
Epoch: 0001 loss_train: 1.6105 acc_train: 0.1839 loss_val: 1.5659 acc_val: 0.5254 time: 0.0774s
Epoch: 0002 loss_train: 1.5566 acc_train: 0.5632 loss_val: 1.4328 acc_val: 0.5254 time: 0.0202s
Epoch: 0003 loss_train: 1.3834 acc_train: 0.5632 loss_val: 1.3024 acc_val: 0.5254 time: 0.0539s
Epoch: 0004 loss_train: 1.1890 acc_train: 0.5632 loss_val: 1.3835 acc_val: 0.5254 time: 0.0102s
Epoch: 0005 loss_train: 1.2037 acc_train: 0.5632 loss_val: 1.2621 acc_val: 0.5254 time: 0.0092s
Epoch: 0006 loss_train: 1.0492 acc_train: 0.5632 loss_val: 1.1280 acc_val: 0.5254 time: 0.0121s
Epoch: 0007 loss_train: 0.9235 acc_train: 0.6207 loss_val: 1.0491 acc_val: 0.6441 time: 0.0210s
Epoch: 0008 loss_train: 0.8479 acc_train: 0.7241 loss_val: 0.9685 acc_val: 0.6949 time: 0.0079s
Epoch: 0009 loss_train: 0.7343 acc_train: 0.7931 loss_val: 0.8451 acc_val: 0.6949 time: 0.0086s
Epoch: 0010 loss_train: 0.5939 acc_train: 0.7931 loss_val: 0.7474 acc_val: 0.6780 time: 0.0142s
Epoch: 0011 loss_train: 0.4956 acc_train: 0.8276 loss_val: 0.6851 acc_val: 0.6780 time: 0.0250s
Epoch: 0012 loss_train: 0.3971 acc_train: 0.8276 loss_val: 0.6501 acc_val: 0.6780 time: 0.0081s
Epoch: 0013 loss_train: 0.3408 acc_train: 0.8736 loss_val: 0.6439 acc_val: 0.6949 time: 0.0088s
Epoch: 0014 loss_train: 0.2816 acc_train: 0.9195 loss_val: 0.6488 acc_val: 0.7288 time: 0.0097s
Epoch: 0015 loss_train: 0.2351 acc_train: 0.9655 loss_val: 0.6440 acc_val: 0.7288 time: 0.0104s
Epoch: 0016 loss_train: 0.1730 acc_train: 0.9885 loss_val: 0.5694 acc_val: 0.7288 time: 0.0092s
Epoch: 0017 loss_train: 0.1119 acc_train: 0.9885 loss_val: 0.5567 acc_val: 0.8475 time: 0.0083s
Epoch: 0018 loss_train: 0.0710 acc_train: 0.9885 loss_val: 0.7032 acc_val: 0.7797 time: 0.0075s
Epoch: 0019 loss_train: 0.0458 acc_train: 0.9885 loss_val: 1.0143 acc_val: 0.7627 time: 0.0100s
Epoch: 0020 loss_train: 0.0466 acc_train: 0.9770 loss_val: 1.3562 acc_val: 0.7627 time: 0.0105s
Epoch: 0021 loss_train: 0.0921 acc_train: 0.9770 loss_val: 0.7711 acc_val: 0.7797 time: 0.0073s
Epoch: 0022 loss_train: 0.0254 acc_train: 0.9885 loss_val: 1.2097 acc_val: 0.8305 time: 0.0095s
Epoch: 0023 loss_train: 0.0189 acc_train: 0.9885 loss_val: 2.0743 acc_val: 0.8136 time: 0.0078s
Epoch: 0024 loss_train: 0.0016 acc_train: 1.0000 loss_val: 3.0769 acc_val: 0.7966 time: 0.0092s
Epoch: 0025 loss_train: 0.0015 acc_train: 1.0000 loss_val: 4.4270 acc_val: 0.7627 time: 0.0090s
Epoch: 0026 loss_train: 0.0401 acc_train: 0.9770 loss_val: 3.0927 acc_val: 0.7797 time: 0.0099s
Epoch: 0027 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.2522 acc_val: 0.7797 time: 0.0073s
Epoch: 0028 loss_train: 0.0018 acc_train: 1.0000 loss_val: 1.9682 acc_val: 0.7627 time: 0.0142s
Epoch: 0029 loss_train: 0.0001 acc_train: 1.0000 loss_val: 2.6377 acc_val: 0.6949 time: 0.0071s
Epoch: 0030 loss_train: 0.0003 acc_train: 1.0000 loss_val: 3.9699 acc_val: 0.7119 time: 0.0134s
Epoch: 0031 loss_train: 0.0000 acc_train: 1.0000 loss_val: 5.3944 acc_val: 0.6780 time: 0.0141s
Epoch: 0032 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.8163 acc_val: 0.6610 time: 0.0320s
Epoch: 0033 loss_train: 0.0000 acc_train: 1.0000 loss_val: 8.6508 acc_val: 0.6271 time: 0.0122s
Epoch: 0034 loss_train: 0.0019 acc_train: 1.0000 loss_val: 10.0089 acc_val: 0.6271 time: 0.0088s
Epoch: 0035 loss_train: 0.0028 acc_train: 1.0000 loss_val: 10.4714 acc_val: 0.6271 time: 0.0073s
Epoch: 0036 loss_train: 0.0081 acc_train: 1.0000 loss_val: 9.2029 acc_val: 0.6610 time: 0.0086s
Epoch: 0037 loss_train: 0.0000 acc_train: 1.0000 loss_val: 8.1855 acc_val: 0.6610 time: 0.0075s
Epoch: 0038 loss_train: 0.0000 acc_train: 1.0000 loss_val: 7.4242 acc_val: 0.6949 time: 0.0212s
Epoch: 0039 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.8063 acc_val: 0.7119 time: 0.0081s
Epoch: 0040 loss_train: 0.0000 acc_train: 1.0000 loss_val: 6.3074 acc_val: 0.7627 time: 0.0181s
Epoch: 0041 loss_train: 0.0000 acc_train: 1.0000 loss_val: 5.8557 acc_val: 0.7627 time: 0.0099s
Epoch: 0042 loss_train: 0.0000 acc_train: 1.0000 loss_val: 5.4749 acc_val: 0.7627 time: 0.0116s
Early stopping...
Optimization Finished!
Total time elapsed: 0.5973s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split7_results.txt
Test set results: loss= 10.8391 accuracy= 0.5946
Epoch: 0001 loss_train: 1.6089 acc_train: 0.2414 loss_val: 1.5710 acc_val: 0.6610 time: 0.0217s
Epoch: 0002 loss_train: 1.5711 acc_train: 0.6092 loss_val: 1.4281 acc_val: 0.6610 time: 0.0082s
Epoch: 0003 loss_train: 1.4453 acc_train: 0.4598 loss_val: 1.2181 acc_val: 0.6610 time: 0.0081s
Epoch: 0004 loss_train: 1.2705 acc_train: 0.4598 loss_val: 0.9986 acc_val: 0.6610 time: 0.0078s
Epoch: 0005 loss_train: 1.1583 acc_train: 0.4598 loss_val: 0.9381 acc_val: 0.6610 time: 0.0066s
Epoch: 0006 loss_train: 1.0016 acc_train: 0.5172 loss_val: 0.9919 acc_val: 0.8644 time: 0.0092s
Epoch: 0007 loss_train: 0.8191 acc_train: 0.8851 loss_val: 0.8788 acc_val: 0.7966 time: 0.0160s
Epoch: 0008 loss_train: 0.6162 acc_train: 0.8966 loss_val: 0.5856 acc_val: 0.8305 time: 0.0097s
Epoch: 0009 loss_train: 0.3813 acc_train: 0.8966 loss_val: 0.4912 acc_val: 0.8136 time: 0.0087s
Epoch: 0010 loss_train: 0.2869 acc_train: 0.8851 loss_val: 0.4795 acc_val: 0.8475 time: 0.0083s
Epoch: 0011 loss_train: 0.1877 acc_train: 0.9080 loss_val: 0.5731 acc_val: 0.8475 time: 0.0085s
Epoch: 0012 loss_train: 0.1412 acc_train: 0.9770 loss_val: 0.7879 acc_val: 0.8305 time: 0.0111s
Epoch: 0013 loss_train: 0.1273 acc_train: 0.9885 loss_val: 1.0638 acc_val: 0.8475 time: 0.0223s
Epoch: 0014 loss_train: 0.1072 acc_train: 0.9885 loss_val: 1.3531 acc_val: 0.8305 time: 0.0105s
Epoch: 0015 loss_train: 0.0871 acc_train: 0.9885 loss_val: 1.6556 acc_val: 0.8305 time: 0.0085s
Epoch: 0016 loss_train: 0.0598 acc_train: 0.9885 loss_val: 1.9867 acc_val: 0.8305 time: 0.0077s
Epoch: 0017 loss_train: 0.0455 acc_train: 0.9885 loss_val: 2.3596 acc_val: 0.8475 time: 0.0070s
Epoch: 0018 loss_train: 0.0367 acc_train: 0.9885 loss_val: 2.7712 acc_val: 0.8475 time: 0.0100s
Epoch: 0019 loss_train: 0.0287 acc_train: 0.9885 loss_val: 3.2159 acc_val: 0.8475 time: 0.0069s
Epoch: 0020 loss_train: 0.0283 acc_train: 0.9885 loss_val: 3.6944 acc_val: 0.8305 time: 0.0103s
Epoch: 0021 loss_train: 0.0270 acc_train: 0.9885 loss_val: 4.2041 acc_val: 0.8136 time: 0.0177s
Epoch: 0022 loss_train: 0.0222 acc_train: 0.9885 loss_val: 4.7387 acc_val: 0.8136 time: 0.0516s
Epoch: 0023 loss_train: 0.0174 acc_train: 0.9885 loss_val: 5.2762 acc_val: 0.8136 time: 0.0451s
Epoch: 0024 loss_train: 0.0135 acc_train: 0.9885 loss_val: 5.8122 acc_val: 0.7966 time: 0.0083s
Epoch: 0025 loss_train: 0.0115 acc_train: 0.9885 loss_val: 6.3537 acc_val: 0.7966 time: 0.0199s
Epoch: 0026 loss_train: 0.0320 acc_train: 0.9885 loss_val: 6.5787 acc_val: 0.7627 time: 0.0111s
Epoch: 0027 loss_train: 0.0049 acc_train: 1.0000 loss_val: 7.0474 acc_val: 0.7627 time: 0.0209s
Epoch: 0028 loss_train: 0.0023 acc_train: 1.0000 loss_val: 8.4576 acc_val: 0.7627 time: 0.0085s
Epoch: 0029 loss_train: 0.0014 acc_train: 1.0000 loss_val: 11.8550 acc_val: 0.7458 time: 0.0217s
Epoch: 0030 loss_train: 0.0007 acc_train: 1.0000 loss_val: 15.6452 acc_val: 0.7119 time: 0.0253s
Epoch: 0031 loss_train: 0.0014 acc_train: 1.0000 loss_val: 20.0604 acc_val: 0.6949 time: 0.0114s
Epoch: 0032 loss_train: 0.2184 acc_train: 0.9770 loss_val: 14.6432 acc_val: 0.7458 time: 0.0092s
Epoch: 0033 loss_train: 0.0010 acc_train: 1.0000 loss_val: 10.9746 acc_val: 0.7288 time: 0.0116s
Epoch: 0034 loss_train: 0.0004 acc_train: 1.0000 loss_val: 11.2848 acc_val: 0.7966 time: 0.0080s
Epoch: 0035 loss_train: 0.1208 acc_train: 0.9885 loss_val: 12.3076 acc_val: 0.7627 time: 0.0079s
Epoch: 0036 loss_train: 0.0001 acc_train: 1.0000 loss_val: 14.4478 acc_val: 0.7797 time: 0.0131s
Epoch: 0037 loss_train: 0.0004 acc_train: 1.0000 loss_val: 18.1930 acc_val: 0.7627 time: 0.0081s
Epoch: 0038 loss_train: 0.0001 acc_train: 1.0000 loss_val: 23.2421 acc_val: 0.7797 time: 0.0072s
Epoch: 0039 loss_train: 0.3013 acc_train: 0.9655 loss_val: 18.4074 acc_val: 0.7966 time: 0.0069s
Epoch: 0040 loss_train: 0.0002 acc_train: 1.0000 loss_val: 15.6745 acc_val: 0.8136 time: 0.0074s
Epoch: 0041 loss_train: 0.0003 acc_train: 1.0000 loss_val: 13.8899 acc_val: 0.7627 time: 0.0074s
Epoch: 0042 loss_train: 0.0001 acc_train: 1.0000 loss_val: 13.1329 acc_val: 0.8305 time: 0.0071s
Early stopping...
Optimization Finished!
Total time elapsed: 0.5434s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split8_results.txt
Test set results: loss= 7.5678 accuracy= 0.7838
Epoch: 0001 loss_train: 1.6101 acc_train: 0.1839 loss_val: 1.5742 acc_val: 0.5254 time: 0.0310s
Epoch: 0002 loss_train: 1.5555 acc_train: 0.5632 loss_val: 1.4619 acc_val: 0.5254 time: 0.0088s
Epoch: 0003 loss_train: 1.3818 acc_train: 0.5632 loss_val: 1.3543 acc_val: 0.5254 time: 0.0077s
Epoch: 0004 loss_train: 1.1727 acc_train: 0.5632 loss_val: 1.4388 acc_val: 0.5254 time: 0.0492s
Epoch: 0005 loss_train: 1.1011 acc_train: 0.5632 loss_val: 1.4435 acc_val: 0.5254 time: 0.0098s
Epoch: 0006 loss_train: 1.0082 acc_train: 0.5632 loss_val: 1.3346 acc_val: 0.5254 time: 0.0082s
Epoch: 0007 loss_train: 0.8627 acc_train: 0.6322 loss_val: 1.2908 acc_val: 0.6610 time: 0.0092s
Epoch: 0008 loss_train: 0.7664 acc_train: 0.7586 loss_val: 1.2410 acc_val: 0.6610 time: 0.0115s
Epoch: 0009 loss_train: 0.6330 acc_train: 0.8506 loss_val: 1.1420 acc_val: 0.6610 time: 0.0108s
Epoch: 0010 loss_train: 0.4727 acc_train: 0.8506 loss_val: 1.1354 acc_val: 0.6610 time: 0.0104s
Epoch: 0011 loss_train: 0.3676 acc_train: 0.8736 loss_val: 1.2221 acc_val: 0.6441 time: 0.0178s
Epoch: 0012 loss_train: 0.2997 acc_train: 0.8621 loss_val: 1.2554 acc_val: 0.6610 time: 0.0073s
Epoch: 0013 loss_train: 0.2413 acc_train: 0.8736 loss_val: 1.2214 acc_val: 0.6949 time: 0.0075s
Epoch: 0014 loss_train: 0.2412 acc_train: 0.9080 loss_val: 1.3694 acc_val: 0.6949 time: 0.0210s
Epoch: 0015 loss_train: 0.1306 acc_train: 0.9425 loss_val: 1.6257 acc_val: 0.6949 time: 0.0076s
Epoch: 0016 loss_train: 0.2128 acc_train: 0.9310 loss_val: 1.5236 acc_val: 0.7119 time: 0.0075s
Epoch: 0017 loss_train: 0.1103 acc_train: 0.9310 loss_val: 1.5040 acc_val: 0.7119 time: 0.0085s
Epoch: 0018 loss_train: 0.0706 acc_train: 0.9540 loss_val: 1.5916 acc_val: 0.6949 time: 0.0093s
Epoch: 0019 loss_train: 0.0876 acc_train: 0.9885 loss_val: 1.5227 acc_val: 0.6949 time: 0.0109s
Epoch: 0020 loss_train: 0.0794 acc_train: 0.9885 loss_val: 1.3184 acc_val: 0.7458 time: 0.0096s
Epoch: 0021 loss_train: 0.0230 acc_train: 0.9885 loss_val: 1.1470 acc_val: 0.7458 time: 0.0108s
Epoch: 0022 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.3031 acc_val: 0.7627 time: 0.0125s
Epoch: 0023 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.7386 acc_val: 0.6949 time: 0.0082s
Epoch: 0024 loss_train: 0.0334 acc_train: 0.9885 loss_val: 1.7358 acc_val: 0.6949 time: 0.0222s
Epoch: 0025 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.6973 acc_val: 0.7119 time: 0.0085s
Epoch: 0026 loss_train: 0.0527 acc_train: 0.9885 loss_val: 1.2976 acc_val: 0.7288 time: 0.0076s
Epoch: 0027 loss_train: 0.0002 acc_train: 1.0000 loss_val: 1.1851 acc_val: 0.8136 time: 0.0070s
Epoch: 0028 loss_train: 0.0001 acc_train: 1.0000 loss_val: 1.2479 acc_val: 0.7966 time: 0.0067s
Epoch: 0029 loss_train: 0.0000 acc_train: 1.0000 loss_val: 1.3501 acc_val: 0.7966 time: 0.0071s
Epoch: 0030 loss_train: 0.0000 acc_train: 1.0000 loss_val: 1.4905 acc_val: 0.7797 time: 0.0077s
Epoch: 0031 loss_train: 0.0000 acc_train: 1.0000 loss_val: 1.6633 acc_val: 0.7797 time: 0.0110s
Epoch: 0032 loss_train: 0.0000 acc_train: 1.0000 loss_val: 1.8438 acc_val: 0.8136 time: 0.0072s
Epoch: 0033 loss_train: 0.0005 acc_train: 1.0000 loss_val: 2.0194 acc_val: 0.8305 time: 0.0070s
Epoch: 0034 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1240 acc_val: 0.8136 time: 0.0075s
Epoch: 0035 loss_train: 0.0007 acc_train: 1.0000 loss_val: 2.2133 acc_val: 0.8136 time: 0.0089s
Epoch: 0036 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2584 acc_val: 0.7966 time: 0.0071s
Epoch: 0037 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.2560 acc_val: 0.7966 time: 0.0129s
Epoch: 0038 loss_train: 0.0065 acc_train: 1.0000 loss_val: 2.2759 acc_val: 0.7458 time: 0.0318s
Epoch: 0039 loss_train: 0.0000 acc_train: 1.0000 loss_val: 2.3805 acc_val: 0.7119 time: 0.0253s
Epoch: 0040 loss_train: 0.0000 acc_train: 1.0000 loss_val: 2.5392 acc_val: 0.6949 time: 0.0090s
Epoch: 0041 loss_train: 0.0000 acc_train: 1.0000 loss_val: 2.7235 acc_val: 0.7119 time: 0.0177s
Epoch: 0042 loss_train: 0.0000 acc_train: 1.0000 loss_val: 2.9158 acc_val: 0.6949 time: 0.0089s
Early stopping...
Optimization Finished!
Total time elapsed: 0.5169s
cornell_lr0.1_do0.1_es40_wd0.0_alpha0.5_beta0.1_gamma0.1_nlid2_nl2_ordersid3_orders3_split9_results.txt
Test set results: loss= 2.6537 accuracy= 0.7297
